{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crawl (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tr_J983cibq"
      },
      "source": [
        "توضیحات بخش ۲ و ۳\n",
        "\n",
        "سینا کاظمی ۹۶۱۰۶۰۱۱\n",
        "\n",
        "نیما جمالی ۹۶۱۰۵۶۶۱\n",
        "\n",
        "سپهر فعلی ۹۶۱۰۵۹۵۹"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UKCEqbLpzXj",
        "outputId": "bcd45299-d928-4dfd-84a2-bada6685011c"
      },
      "source": [
        "!apt install chromium-chromedriver\n",
        "!pip install selenium\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import time\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_argument('--user-agent=\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) ' + 'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36\"')\n",
        "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
        "\n",
        "\n",
        "urls = [\n",
        "    'https://academic.microsoft.com/paper/2981549002',\n",
        "    'https://academic.microsoft.com/paper/3105081694',\n",
        "    'https://academic.microsoft.com/paper/2950893734'\n",
        "]\n",
        "papers = []\n",
        "papers_id = []\n",
        "do_I_array = []\n",
        "\n",
        "class Paper:\n",
        "    def __init__(self,identifier):\n",
        "        self.identifier = identifier\n",
        "        self.title = None\n",
        "        self.abstract = None\n",
        "        self.date = None\n",
        "        self.authors = []\n",
        "        self.references = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 81.0 MB of archives.\n",
            "After this operation, 273 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 87.0.4280.66-0ubuntu0.18.04.1 [1,122 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 87.0.4280.66-0ubuntu0.18.04.1 [71.7 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 87.0.4280.66-0ubuntu0.18.04.1 [3,716 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 87.0.4280.66-0ubuntu0.18.04.1 [4,488 kB]\n",
            "Fetched 81.0 MB in 3s (23.9 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 146442 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_87.0.4280.66-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_87.0.4280.66-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_87.0.4280.66-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_87.0.4280.66-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (87.0.4280.66-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: use options instead of chrome_options\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGljRfdDdHsS"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "عملیات crawling در این فاز با استفاده از کتابخانه selenium انجام شده است.\n",
        "آپشن headless گذاشته شده تا بار پردازشی بر روی cpu , gpu کاهش یابد.\n",
        "\n",
        "در ضمن با تعریف user_agent برای web_driver کروم از بلاک شدن درخواست توسط سایت academia جلوگیری کردیم.\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBTIOhNmp3e2"
      },
      "source": [
        "import random\n",
        "def crawl(num_of_doc):\n",
        "    i = 0\n",
        "    while i < num_of_doc: \n",
        "        print(len(papers))\n",
        "        url = urls.pop(random.randrange(len(urls)))\n",
        "        paper_id = (url.split(\"/\"))[4]\n",
        "        if paper_id in papers_id:\n",
        "            continue\n",
        "        else:\n",
        "            driver.get(url)\n",
        "            time.sleep(2)\n",
        "            try:\n",
        "                do_i = driver.find_element_by_xpath('//*[@id=\"mainArea\"]/router-view/div/div/div/div/a[2]')\n",
        "                if do_i.text in do_I_array:\n",
        "                    continue\n",
        "                else:\n",
        "                    do_I_array.append(do_i.text)\n",
        "            except:\n",
        "                pass\n",
        "            i += 1\n",
        "            try:\n",
        "                papers_id.append(paper_id)\n",
        "                paper = Paper(paper_id)\n",
        "                title = driver.find_element_by_xpath('//*[@id=\"mainArea\"]/router-view/div/div/div/div/h1')\n",
        "                paper.title = title.text\n",
        "                abstract = driver.find_element_by_xpath('//*[@id=\"mainArea\"]/router-view/div/div/div/div/p')\n",
        "                paper.abstract = abstract.text\n",
        "                date = driver.find_element_by_xpath('//*[@id=\"mainArea\"]/router-view/div/div/div/div/a/span[1]')\n",
        "                paper.date = date.text\n",
        "                authors = driver.find_element_by_xpath('//*[@id=\"mainArea\"]/router-view/div/div/div/div/ma-author-string-collection/div/div')\n",
        "                paper.authors = authors.text.split(\",\")\n",
        "            except:\n",
        "                i -= 1\n",
        "                continue\n",
        "            for x in range(1,11):\n",
        "                try:\n",
        "                    ref = driver.find_element_by_xpath(f'//*[@id=\"mainArea\"]/router-view/router-view/ma-edp-serp/div/div[2]/div/compose/div/div[2]/ma-card[{x}]/div/compose/div/div[1]/a[1]')\n",
        "                    ref_url = ref.get_attribute(\"href\")\n",
        "                    urls.append(ref_url)\n",
        "                    ref_id = (ref_url.split(\"/\"))[4]\n",
        "                    paper.references.append(ref_id)\n",
        "                except:\n",
        "                    break\n",
        "            papers.append(paper.__dict__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUC7y46yflJi"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "سپس \n",
        "</div>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHf-zrlrfsNi"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "سپس یک کلاس paper ایجاد کرده تا هر مقاله ی بررسی شده را به عنوان یک آبجکت ایجاد کنیم و بعد از آن آرایه ای از آبجکت هارو با پسوند json. ذخیره سازی کنیم.\n",
        "\n",
        "ابتدا با url هایی که در فایل start.txt وجود داشتند شروع کردیم و سپس برای کراول کردن هر دفعه یکی از url هایی که درون آرایه url ها وجود داشت را به طور رندوم برداشتیم و در صورت تکراری نبودن مقاله شروع به استخراج اطلاعات نمودیم.\n",
        "\n",
        "تکراری نبودن مقاله را هم با استفاده از paper_id مقالات که در url آنها آمده است بررسی کردیم و هم با استفاده از do_i که در برخی مقالات وجود داشت و در بعضی از مقالات این فیلد نبود که امکان تکراری اومدن آنها وجود دارد.\n",
        "\n",
        "ورودی تابع crawl تعداد مقالاتی است که میخواهیم بررسی نماییم.\n",
        "\n",
        "مشخصاتی که از هر مقاله میخواستیم دریافت نماییم را با استفاده از آدرس xpath فایل html استخراج کردیم.\n",
        "\n",
        "برای اینکه قواعد اخلاقی در crawling را رعایت کرده باشیم بعد از هر بررسی مقاله ۲ ثانیه صبر می کنیم و سپس به سراغ مقاله بعدی می رویم.\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K5HkgjBreBH",
        "outputId": "b31ca516-e986-477a-a3f2-0f328417f45e"
      },
      "source": [
        "crawl(5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "48\n",
            "49\n",
            "50\n",
            "50\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "55\n",
            "55\n",
            "55\n",
            "55\n",
            "55\n",
            "56\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "75\n",
            "75\n",
            "75\n",
            "75\n",
            "76\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "81\n",
            "82\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "94\n",
            "95\n",
            "95\n",
            "95\n",
            "95\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "109\n",
            "110\n",
            "110\n",
            "111\n",
            "111\n",
            "112\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "115\n",
            "115\n",
            "115\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "132\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "135\n",
            "135\n",
            "135\n",
            "135\n",
            "135\n",
            "135\n",
            "136\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "145\n",
            "146\n",
            "146\n",
            "147\n",
            "148\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "155\n",
            "155\n",
            "155\n",
            "155\n",
            "155\n",
            "155\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "171\n",
            "171\n",
            "171\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "174\n",
            "175\n",
            "175\n",
            "175\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "178\n",
            "178\n",
            "178\n",
            "178\n",
            "178\n",
            "179\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "188\n",
            "189\n",
            "190\n",
            "190\n",
            "190\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "195\n",
            "195\n",
            "195\n",
            "195\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "206\n",
            "206\n",
            "206\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "213\n",
            "214\n",
            "215\n",
            "215\n",
            "215\n",
            "215\n",
            "215\n",
            "215\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "235\n",
            "235\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "255\n",
            "255\n",
            "255\n",
            "255\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "264\n",
            "265\n",
            "266\n",
            "266\n",
            "267\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "275\n",
            "275\n",
            "275\n",
            "275\n",
            "275\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "282\n",
            "283\n",
            "284\n",
            "284\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "295\n",
            "295\n",
            "295\n",
            "295\n",
            "295\n",
            "296\n",
            "297\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltisoJE9tUT2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "06a06c0e-f724-4f55-b316-eaf2f6740647"
      },
      "source": [
        "import json\n",
        "jsonString = json.dumps(papers)\n",
        "jsonFile = open(\"data.json\", \"w\")\n",
        "jsonFile.write(jsonString)\n",
        "jsonFile.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dfaa43f4f680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjsonString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpapers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjsonFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjsonFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonString\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mjsonFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'papers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-__CVsYiWZf"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "برای سیو کردن آرایه از آبجکت ها تحت فرمت json از کتابخانه json استفاده کردیم.\n",
        "\n",
        "یک فایل json ساخته می شود که حاوی اطلاعات مقالات کراول شده است.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jbSfmnvf3nO",
        "outputId": "f64ae23b-cb09-41b1-929e-810c2dbf1a41"
      },
      "source": [
        "import json \n",
        "\n",
        "f = open('/content/data.json', \"r\") \n",
        "papers = json.load(f) \n",
        "papers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'abstract': 'In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks. Traditional convolutional GANs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps. In SAGAN, details can be generated using cues from all feature locations. Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other. Furthermore, recent work has shown that generator conditioning affects GAN performance. Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics. The proposed SAGAN achieves the state-of-the-art results, boosting the best published Inception score from 36.8 to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset. Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape.',\n",
              "  'authors': ['Han Zhang 1',\n",
              "   ' Ian Goodfellow 1',\n",
              "   ' Dimitris Metaxas 2',\n",
              "   ' Augustus Odena 1'],\n",
              "  'date': '2018',\n",
              "  'identifier': '2950893734',\n",
              "  'references': ['2964121744',\n",
              "   '2963403868',\n",
              "   '2117539524',\n",
              "   '2099471712',\n",
              "   '2964308564',\n",
              "   '2963073614',\n",
              "   '2962793481',\n",
              "   '2963684088',\n",
              "   '2963373786',\n",
              "   '2963470893'],\n",
              "  'title': 'Self-Attention Generative Adversarial Networks'},\n",
              " {'abstract': 'The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.',\n",
              "  'authors': ['Olga Russakovsky 1',\n",
              "   ' Jia Deng 2',\n",
              "   ' Hao Su 1',\n",
              "   ' Jonathan Krause 1',\n",
              "   ' Sanjeev Satheesh 1',\n",
              "   ' Sean Ma 1',\n",
              "   ' Zhiheng Huang 1',\n",
              "   ' Andrej Karpathy 1',\n",
              "   ' Aditya Khosla 3',\n",
              "   ' Michael Bernstein 1',\n",
              "   ' Alexander C. Berg 4',\n",
              "   ' Li Fei-Fei 1'],\n",
              "  'date': '2015',\n",
              "  'identifier': '2117539524',\n",
              "  'references': ['2618530766',\n",
              "   '2962835968',\n",
              "   '2151103935',\n",
              "   '2097117768',\n",
              "   '2102605133',\n",
              "   '1614298861',\n",
              "   '2108598243',\n",
              "   '2155893237',\n",
              "   '2168356304',\n",
              "   '1849277567'],\n",
              "  'title': 'ImageNet Large Scale Visual Recognition Challenge'},\n",
              " {'abstract': 'We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.',\n",
              "  'authors': ['Alex Krizhevsky 1',\n",
              "   ' Ilya Sutskever 1',\n",
              "   ' Geoffrey E. Hinton 2'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2618530766',\n",
              "  'references': ['2194775991',\n",
              "   '2097117768',\n",
              "   '2108598243',\n",
              "   '2911964244',\n",
              "   '3118608800',\n",
              "   '1904365287',\n",
              "   '1665214252',\n",
              "   '2546302380',\n",
              "   '2110764733',\n",
              "   '2130325614'],\n",
              "  'title': 'ImageNet classification with deep convolutional neural networks'},\n",
              " {'abstract': 'We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.',\n",
              "  'authors': ['Christian Szegedy 1',\n",
              "   ' Wei Liu 2',\n",
              "   ' Yangqing Jia 1',\n",
              "   ' Pierre Sermanet 1',\n",
              "   ' Scott Reed 3',\n",
              "   ' Dragomir Anguelov 1',\n",
              "   ' Dumitru Erhan 1',\n",
              "   ' Vincent Vanhoucke 1',\n",
              "   ' Andrew Rabinovich 4'],\n",
              "  'date': '2015',\n",
              "  'identifier': '2097117768',\n",
              "  'references': ['2618530766',\n",
              "   '2102605133',\n",
              "   '1849277567',\n",
              "   '2963542991',\n",
              "   '2310919327',\n",
              "   '1904365287',\n",
              "   '2963911037',\n",
              "   '2168231600',\n",
              "   '2068730032',\n",
              "   '104184427'],\n",
              "  'title': 'Going deeper with convolutions'},\n",
              " {'abstract': 'Recent work in unsupervised feature learning and deep learning has shown that being able to train large models can dramatically improve performance. In this paper, we consider the problem of training a deep network with billions of parameters using tens of thousands of CPU cores. We have developed a software framework called DistBelief that can utilize computing clusters with thousands of machines to train large models. Within this framework, we have developed two algorithms for large-scale distributed training: (i) Downpour SGD, an asynchronous stochastic gradient descent procedure supporting a large number of model replicas, and (ii) Sandblaster, a framework that supports a variety of distributed batch optimization procedures, including a distributed implementation of L-BFGS. Downpour SGD and Sandblaster L-BFGS both increase the scale and speed of deep network training. We have successfully used our system to train a deep network 30x larger than previously reported in the literature, and achieves state-of-the-art performance on ImageNet, a visual object recognition task with 16 million images and 21k categories. We show that these same techniques dramatically accelerate the training of a more modestly- sized deep network for a commercial speech recognition service. Although we focus on and report performance of these methods as applied to training large neural networks, the underlying algorithms are applicable to any gradient-based machine learning algorithm.',\n",
              "  'authors': ['Jeffrey Dean ',\n",
              "   ' Greg Corrado ',\n",
              "   ' Rajat Monga ',\n",
              "   ' Kai Chen ',\n",
              "   ' Matthieu Devin ',\n",
              "   ' Mark Mao ',\n",
              "   \" Marc'aurelio Ranzato \",\n",
              "   ' Andrew Senior ',\n",
              "   ' Paul Tucker ',\n",
              "   ' Ke Yang ',\n",
              "   ' Quoc V. Le ',\n",
              "   ' Andrew Y. Ng'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2168231600',\n",
              "  'references': ['2173213060',\n",
              "   '2108598243',\n",
              "   '2146502635',\n",
              "   '3118608800',\n",
              "   '2117130368',\n",
              "   '2147768505',\n",
              "   '2132339004',\n",
              "   '2141125852',\n",
              "   '2184045248',\n",
              "   '2118858186'],\n",
              "  'title': 'Large Scale Distributed Deep Networks'},\n",
              " {'abstract': 'Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.',\n",
              "  'authors': ['Kaiming He ', ' Xiangyu Zhang ', ' Shaoqing Ren ', ' Jian Sun'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2194775991',\n",
              "  'references': ['2618530766',\n",
              "   '2962835968',\n",
              "   '2097117768',\n",
              "   '639708223',\n",
              "   '1836465849',\n",
              "   '2102605133',\n",
              "   '2117539524',\n",
              "   '1903029394',\n",
              "   '2155893237',\n",
              "   '1536680647'],\n",
              "  'title': 'Deep Residual Learning for Image Recognition'},\n",
              " {'abstract': 'We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.',\n",
              "  'authors': ['Tomas Mikolov 1',\n",
              "   ' Kai Chen 2',\n",
              "   ' Greg S. Corrado 2',\n",
              "   ' Jeffrey Dean 2'],\n",
              "  'date': '2013',\n",
              "  'identifier': '1614298861',\n",
              "  'references': ['2153579005',\n",
              "   '2250539671',\n",
              "   '2271840356',\n",
              "   '1895577753',\n",
              "   '3104097132',\n",
              "   '1888005072',\n",
              "   '1486649854',\n",
              "   '2964321699',\n",
              "   '2100664567',\n",
              "   '2123024445'],\n",
              "  'title': 'Efficient Estimation of Word Representations in Vector Space'},\n",
              " {'abstract': 'Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.',\n",
              "  'authors': ['Ross Girshick ',\n",
              "   ' Jeff Donahue ',\n",
              "   ' Trevor Darrell ',\n",
              "   ' Jitendra Malik'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2102605133',\n",
              "  'references': ['2618530766',\n",
              "   '2151103935',\n",
              "   '2161969291',\n",
              "   '2108598243',\n",
              "   '2168356304',\n",
              "   '3118608800',\n",
              "   '2310919327',\n",
              "   '2031489346',\n",
              "   '2088049833',\n",
              "   '2155541015'],\n",
              "  'title': 'Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation'},\n",
              " {'abstract': \"The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population. A critical step in the fight against COVID-19 is effective screening of infected patients, with one of the key screening approaches being radiology examination using chest radiography. It was found in early studies that patients present abnormalities in chest radiography images that are characteristic of those infected with COVID-19. Motivated by this and inspired by the open source efforts of the research community, in this study we introduce COVID-Net, a deep convolutional neural network design tailored for the detection of COVID-19 cases from chest X-ray (CXR) images that is open source and available to the general public. To the best of the authors' knowledge, COVID-Net is one of the first open source network designs for COVID-19 detection from CXR images at the time of initial release. We also introduce COVIDx, an open access benchmark dataset that we generated comprising of 13,975 CXR images across 13,870 patient patient cases, with the largest number of publicly available COVID-19 positive cases to the best of the authors' knowledge. Furthermore, we investigate how COVID-Net makes predictions using an explainability method in an attempt to not only gain deeper insights into critical factors associated with COVID cases, which can aid clinicians in improved screening, but also audit COVID-Net in a responsible and transparent manner to validate that it is making decisions based on relevant information from the CXR images. By no means a production-ready solution, the hope is that the open access COVID-Net, along with the description on constructing the open source COVIDx dataset, will be leveraged and build upon by both researchers and citizen data scientists alike to accelerate the development of highly accurate yet practical deep learning solutions for detecting COVID-19 cases and accelerate treatment of those who need it the most.\",\n",
              "  'authors': ['Linda Wang ', ' Zhong Qiu Lin ', ' Alexander Wong'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3105081694',\n",
              "  'references': ['2194775991',\n",
              "   '3001118548',\n",
              "   '2962835968',\n",
              "   '3008827533',\n",
              "   '2919115771',\n",
              "   '2108598243',\n",
              "   '2963446712',\n",
              "   '3007497549',\n",
              "   '3010604545',\n",
              "   '3008985036'],\n",
              "  'title': 'COVID-Net: a tailored deep convolutional neural network design for detection of COVID-19 cases from chest X-ray images.'},\n",
              " {'abstract': 'There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.',\n",
              "  'authors': ['Honglak Lee ',\n",
              "   ' Roger Grosse ',\n",
              "   ' Rajesh Ranganath ',\n",
              "   ' Andrew Y. Ng'],\n",
              "  'date': '2009',\n",
              "  'identifier': '2130325614',\n",
              "  'references': ['2136922672',\n",
              "   '2100495367',\n",
              "   '2162915993',\n",
              "   '2116064496',\n",
              "   '2110798204',\n",
              "   '2166049352',\n",
              "   '2145889472',\n",
              "   '2122922389',\n",
              "   '2147800946',\n",
              "   '2168002178'],\n",
              "  'title': 'Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations'},\n",
              " {'abstract': 'Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.',\n",
              "  'authors': ['Geoffrey Hinton ',\n",
              "   ' Li Deng ',\n",
              "   ' Dong Yu ',\n",
              "   ' George Dahl ',\n",
              "   ' Abdel-rahman Mohamed ',\n",
              "   ' Navdeep Jaitly ',\n",
              "   ' Andrew Senior ',\n",
              "   ' Vincent Vanhoucke ',\n",
              "   ' Patrick Nguyen ',\n",
              "   ' Tara Sainath ',\n",
              "   ' Brian Kingsbury'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2184045248',\n",
              "  'references': ['2136922672',\n",
              "   '2100495367',\n",
              "   '1533861849',\n",
              "   '2116064496',\n",
              "   '2147768505',\n",
              "   '2145094598',\n",
              "   '1993882792',\n",
              "   '2159080219',\n",
              "   '44815768',\n",
              "   '1498436455'],\n",
              "  'title': 'Deep Neural Networks for Acoustic Modeling in Speech Recognition'},\n",
              " {'abstract': 'State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features—using the recently popular terminology of neural networks with ’attention’ mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3] , our detection system has a frame rate of 5 fps ( including all steps ) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.',\n",
              "  'authors': ['Shaoqing Ren 1',\n",
              "   ' Kaiming He 2',\n",
              "   ' Ross Girshick 3',\n",
              "   ' Jian Sun 2'],\n",
              "  'date': '2017',\n",
              "  'identifier': '639708223',\n",
              "  'references': ['2194775991',\n",
              "   '2618530766',\n",
              "   '2962835968',\n",
              "   '2097117768',\n",
              "   '2102605133',\n",
              "   '2117539524',\n",
              "   '1903029394',\n",
              "   '2155893237',\n",
              "   '1536680647',\n",
              "   '2168356304'],\n",
              "  'title': 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Yann Lecun 1',\n",
              "   ' Leon Bottou 2',\n",
              "   ' 3',\n",
              "   ' Yoshua Bengio 3',\n",
              "   ' 4',\n",
              "   ' 5',\n",
              "   ' Patrick Haffner 3',\n",
              "   ' 6'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2310919327',\n",
              "  'references': ['2147880316',\n",
              "   '2156163116',\n",
              "   '2963399829',\n",
              "   '2964311892',\n",
              "   '2157364932',\n",
              "   '1510526001',\n",
              "   '1944615693',\n",
              "   '2158778629'],\n",
              "  'title': 'Gradient-based learning applied to document recognition'},\n",
              " {'abstract': 'Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art.',\n",
              "  'authors': ['Oriol Vinyals ',\n",
              "   ' Alexander Toshev ',\n",
              "   ' Samy Bengio ',\n",
              "   ' Dumitru Erhan'],\n",
              "  'date': '2015',\n",
              "  'identifier': '1895577753',\n",
              "  'references': ['2097117768',\n",
              "   '1836465849',\n",
              "   '2117539524',\n",
              "   '2964308564',\n",
              "   '1614298861',\n",
              "   '2130942839',\n",
              "   '2157331557',\n",
              "   '2963542991',\n",
              "   '2155541015',\n",
              "   '2064675550'],\n",
              "  'title': 'Show and tell: A neural image caption generator'},\n",
              " {'abstract': 'It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual \"expert\" models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called \"contrastive divergence\" whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data.',\n",
              "  'authors': ['Geoffrey E. Hinton'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2116064496',\n",
              "  'references': ['1652505363',\n",
              "   '1997063559',\n",
              "   '2096175520',\n",
              "   '1746680969',\n",
              "   '1993845689',\n",
              "   '2165225968',\n",
              "   '2083380015',\n",
              "   '1547224907',\n",
              "   '2114153178',\n",
              "   '2101706260'],\n",
              "  'title': 'Training products of experts by minimizing contrastive divergence'},\n",
              " {'abstract': 'Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.',\n",
              "  'authors': ['Jeffrey Pennington 1',\n",
              "   ' Richard Socher 2',\n",
              "   ' Christopher Manning 1'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2250539671',\n",
              "  'references': ['2153579005',\n",
              "   '1614298861',\n",
              "   '2146502635',\n",
              "   '2158899491',\n",
              "   '2072128103',\n",
              "   '2141599568',\n",
              "   '2117130368',\n",
              "   '2132339004',\n",
              "   '2118020653',\n",
              "   '2158139315'],\n",
              "  'title': 'Glove: Global Vectors for Word Representation'},\n",
              " {'abstract': 'Abstract: We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat.',\n",
              "  'authors': ['Pierre Sermanet ',\n",
              "   ' David Eigen ',\n",
              "   ' Xiang Zhang ',\n",
              "   ' Michael Mathieu ',\n",
              "   ' Rob Fergus ',\n",
              "   ' Yann LeCun'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2963542991',\n",
              "  'references': ['2194775991',\n",
              "   '2962835968',\n",
              "   '2097117768',\n",
              "   '639708223',\n",
              "   '1903029394',\n",
              "   '2155893237'],\n",
              "  'title': 'OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks'},\n",
              " {'abstract': 'The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.',\n",
              "  'authors': ['Tomas Mikolov ',\n",
              "   ' Ilya Sutskever ',\n",
              "   ' Kai Chen ',\n",
              "   ' Greg S Corrado ',\n",
              "   ' Jeff Dean'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2153579005',\n",
              "  'references': ['1614298861',\n",
              "   '2141599568',\n",
              "   '2117130368',\n",
              "   '2132339004',\n",
              "   '2158139315',\n",
              "   '1423339008',\n",
              "   '1498436455',\n",
              "   '1662133657',\n",
              "   '1889268436',\n",
              "   '2131462252'],\n",
              "  'title': 'Distributed Representations of Words and Phrases and their Compositionality'},\n",
              " {'abstract': 'Abstract: In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.',\n",
              "  'authors': ['Karen Simonyan ', ' Andrew Zisserman'],\n",
              "  'date': '2015',\n",
              "  'identifier': '2962835968',\n",
              "  'references': ['2194775991',\n",
              "   '639708223',\n",
              "   '1901129140',\n",
              "   '1903029394',\n",
              "   '1536680647',\n",
              "   '3106250896'],\n",
              "  'title': 'Very Deep Convolutional Networks for Large-Scale Image Recognition'},\n",
              " {'abstract': 'High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such \"autoencoder\" networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.',\n",
              "  'authors': ['G. E. Hinton ', ' R. R. Salakhutdinov'],\n",
              "  'date': '2006',\n",
              "  'identifier': '2100495367',\n",
              "  'references': ['2136922672',\n",
              "   '2053186076',\n",
              "   '2001141328',\n",
              "   '2293063825',\n",
              "   '2121122425',\n",
              "   '2032647857',\n",
              "   '2021774695'],\n",
              "  'title': 'Reducing the Dimensionality of Data with Neural Networks'},\n",
              " {'abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.',\n",
              "  'authors': ['Ashish Vaswani 1',\n",
              "   ' Noam Shazeer 1',\n",
              "   ' Niki Parmar 2',\n",
              "   ' Jakob Uszkoreit 1',\n",
              "   ' Llion Jones 1',\n",
              "   ' Aidan N. Gomez 1',\n",
              "   ' Lukasz Kaiser 1',\n",
              "   ' Illia Polosukhin 1'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2963403868',\n",
              "  'references': ['2963341956',\n",
              "   '2965373594',\n",
              "   '2970597249',\n",
              "   '2963091558',\n",
              "   '2923014074',\n",
              "   '2996428491',\n",
              "   '2911489562',\n",
              "   '2964110616'],\n",
              "  'title': 'Attention is All You Need'},\n",
              " {'abstract': 'Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.',\n",
              "  'authors': ['Zihang Dai 1',\n",
              "   ' Zhilin Yang 1',\n",
              "   ' Yiming Yang 1',\n",
              "   ' Jaime G. Carbonell 1',\n",
              "   ' Quoc Viet Le 1',\n",
              "   ' Ruslan Salakhutdinov 2'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2964110616',\n",
              "  'references': ['2963403868',\n",
              "   '2963341956',\n",
              "   '2964308564',\n",
              "   '2962739339',\n",
              "   '2064675550',\n",
              "   '179875071',\n",
              "   '2132339004',\n",
              "   '1810943226',\n",
              "   '2963374479',\n",
              "   '2584341106'],\n",
              "  'title': 'Transformer-XL: Attentive Language Models beyond a Fixed-Length Context.'},\n",
              " {'abstract': 'This chapter contains sections titled: Relaxation Searches, Easy and Hard Learning, The Boltzmann Machine Learning Algorithm, An Example of Hard Learning, Achieving Reliable Computation with Unreliable Hardware, An Example of the Effects of Damage, Conclusion, Acknowledgments, Appendix: Derivation of the Learning Algorithm, References',\n",
              "  'authors': ['G. E. Hinton ', ' T. J. Sejnowski'],\n",
              "  'date': '1986',\n",
              "  'identifier': '1547224907',\n",
              "  'references': ['2310919327',\n",
              "   '2076063813',\n",
              "   '2072128103',\n",
              "   '2116064496',\n",
              "   '2137813581',\n",
              "   '2133671888',\n",
              "   '1562911371',\n",
              "   '1516111018',\n",
              "   '2321533354'],\n",
              "  'title': 'Learning and relearning in Boltzmann machines'},\n",
              " {'abstract': 'We show how to use \"complementary priors\" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.',\n",
              "  'authors': ['Geoffrey E. Hinton 1', ' Simon Osindero 1', ' Yee-Whye Teh 2'],\n",
              "  'date': '2006',\n",
              "  'identifier': '2136922672',\n",
              "  'references': ['2310919327',\n",
              "   '2116064496',\n",
              "   '2057175746',\n",
              "   '2159080219',\n",
              "   '2156163116',\n",
              "   '2131686571',\n",
              "   '2567948266',\n",
              "   '2158778629',\n",
              "   '2159737176',\n",
              "   '2124914669'],\n",
              "  'title': 'A fast learning algorithm for deep belief nets'},\n",
              " {'abstract': 'We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI--SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function.',\n",
              "  'authors': ['P F Felzenszwalb 1',\n",
              "   ' R B Girshick 1',\n",
              "   ' D McAllester 2',\n",
              "   ' D Ramanan 3'],\n",
              "  'date': '2010',\n",
              "  'identifier': '2168356304',\n",
              "  'references': ['2151103935',\n",
              "   '2161969291',\n",
              "   '3097096317',\n",
              "   '2154422044',\n",
              "   '2120419212',\n",
              "   '2152826865',\n",
              "   '2145072179',\n",
              "   '1576520375',\n",
              "   '2030536784',\n",
              "   '2115763357'],\n",
              "  'title': 'Object Detection with Discriminatively Trained Part-Based Models'},\n",
              " {'abstract': 'From the Publisher: This book is a comprehensive introduction to the neural network models currently under intensive study for computational applications. It is a detailed, logically-developed treatment that covers the theory and uses of collective computational networks, including associative memory, feed forward networks, and unsupervised learning. It also provides coverage of neural network applications in a variety of problems of both theoretical and practical interest.',\n",
              "  'authors': ['John Hertz 1', ' Anders Krogh 2', ' Richard G. Palmer 3'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2133671888',\n",
              "  'references': ['2286699414',\n",
              "   '2128499899',\n",
              "   '137941959',\n",
              "   '1547224907',\n",
              "   '308480622'],\n",
              "  'title': 'Introduction To The Theory Of Neural Computation'},\n",
              " {'abstract': '',\n",
              "  'authors': ['James McClelland'],\n",
              "  'date': '1988',\n",
              "  'identifier': '137941959',\n",
              "  'references': ['2121863487',\n",
              "   '1535810436',\n",
              "   '1490454746',\n",
              "   '2322002063',\n",
              "   '158491281',\n",
              "   '2049093093',\n",
              "   '1968243487'],\n",
              "  'title': 'Explorations in parallel distributed processing'},\n",
              " {'abstract': 'We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).',\n",
              "  'authors': ['Jacob Devlin ',\n",
              "   ' Ming-Wei Chang ',\n",
              "   ' Kenton Lee ',\n",
              "   ' Kristina N. Toutanova'],\n",
              "  'date': '2018',\n",
              "  'identifier': '2963341956',\n",
              "  'references': ['2963403868',\n",
              "   '2153579005',\n",
              "   '2250539671',\n",
              "   '2108598243',\n",
              "   '2962739339',\n",
              "   '2131744502',\n",
              "   '2251939518',\n",
              "   '2963748441',\n",
              "   '2117130368',\n",
              "   '2025768430'],\n",
              "  'title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'},\n",
              " {'abstract': 'Replicator neural networks self-organize by using their inputs as desired outputs; they internally form a compressed representation for the input data. A theorem shows that a class of replicator networks can, through the minimization of mean squared reconstruction error (for instance, by training on raw data examples), carry out optimal data compression for arbitrary data vector sources. Data manifolds, a new general model of data sources, are then introduced and a second theorem shows that, in a practically important limiting case, optimal-compression replicator networks operate by creating an essentially unique natural coordinate system for the manifold.',\n",
              "  'authors': ['Robert Hecht-Nielsen'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2032647857',\n",
              "  'references': ['2137983211',\n",
              "   '2166116275',\n",
              "   '1993845689',\n",
              "   '2122538988',\n",
              "   '5731987',\n",
              "   '2142228262',\n",
              "   '2063971957',\n",
              "   '2089419199',\n",
              "   '2079782346',\n",
              "   '2162604518'],\n",
              "  'title': 'Replicator neural networks for universal optimal source coding.'},\n",
              " {'abstract': 'Abstract Connectionist learning procedures are presented for “sigmoid” and “noisy-OR” varieties of probabilistic belief networks. These networks have previously been seen primarily as a means of representing knowledge derived from experts. Here it is shown that the “Gibbs sampling” simulation procedure for such networks can support maximum-likelihood learning from empirical data through local gradient ascent. This learning procedure resembles that used for “Boltzmann machines”, and like it, allows the use of “hidden” variables to model correlations between visible variables. Due to the directed nature of the connections in a belief network, however, the “negative phase” of Boltzmann machine learning is unnecessary. Experimental results show that, as a result, learning in a sigmoid belief network can be faster than in a Boltzmann machine. These networks have other advantages over Boltzmann machines in pattern classification and decision making applications, are naturally applicable to unsupervised learning problems, and provide a link between work on connectionist learning and work on the representation of expert knowledge.',\n",
              "  'authors': ['Radford M. Neal'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2083380015',\n",
              "  'references': ['1652505363',\n",
              "   '2159080219',\n",
              "   '1498436455',\n",
              "   '2049633694',\n",
              "   '2083875149',\n",
              "   '1593793857',\n",
              "   '1507849272',\n",
              "   '2166698530',\n",
              "   '1992880122',\n",
              "   '1547224907'],\n",
              "  'title': 'Connectionist learning of belief networks'},\n",
              " {'abstract': 'Learning structure in temporally-extended sequences is a difficult computational problem because only a fraction of the relevant information is available at any instant. Although variants of back propagation can in principle be used to find structure in sequences, in practice they are not sufficiently powerful to discover arbitrary contingencies, especially those spanning long temporal intervals or involving high order statistics. For example, in designing a connectionist network for music composition, we have encountered the problem that the net is able to learn musical structure that occurs locally in time--e.g., relations among notes within a musical phrase--but not structure that occurs over longer time periods--e.g., relations among phrases. To address this problem, we require a means of constructing a reduced description of the sequence that makes global aspects more explicit or more readily detectable. I propose to achieve this using hidden units that operate with different time constants. Simulation experiments indicate that slower time-scale hidden units are able to pick up global structure, structure that simply can not be learned by standard back propagation.',\n",
              "  'authors': ['Michael C Mozer'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2128499899',\n",
              "  'references': ['2154642048',\n",
              "   '2016589492',\n",
              "   '2007431958',\n",
              "   '2143503258',\n",
              "   '1959983357',\n",
              "   '2028629011',\n",
              "   '2053127376',\n",
              "   '2167607759'],\n",
              "  'title': 'Induction of Multiscale Temporal Structure'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Hongyi Zhang 1',\n",
              "   ' Moustapha Cisse 2',\n",
              "   ' Yann N. Dauphin 2',\n",
              "   ' David Lopez-Paz 2'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2963399829',\n",
              "  'references': ['2964274690',\n",
              "   '2966415767',\n",
              "   '2963855133',\n",
              "   '2970902013',\n",
              "   '2987875759',\n",
              "   '2971149989',\n",
              "   '3098350627',\n",
              "   '3034351824',\n",
              "   '2988396473',\n",
              "   '3035743198'],\n",
              "  'title': 'mixup: Beyond Empirical Risk Minimization'},\n",
              " {'abstract': 'Abstract: In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.',\n",
              "  'authors': ['Alec Radford 1', ' Luke Metz 1', ' Soumith Chintala 2'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2963684088',\n",
              "  'references': ['2962793481',\n",
              "   '2331128040',\n",
              "   '2963470893',\n",
              "   '2963420272',\n",
              "   '2405756170',\n",
              "   '2963800363',\n",
              "   '2963836885',\n",
              "   '2738588019',\n",
              "   '2962947361'],\n",
              "  'title': 'Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks'},\n",
              " {'abstract': 'A recent cluster of pneumonia cases in Wuhan, China, was caused by a novel betacoronavirus, the 2019 novel coronavirus (2019-nCoV). We report the epidemiological, clinical, laboratory, and radiological characteristics and treatment and clinical outcomes of these patients. All patients with suspected 2019-nCoV were admitted to a designated hospital in Wuhan. We prospectively collected and analysed data on patients with laboratory-confirmed 2019-nCoV infection by real-time RT-PCR and next-generation sequencing. Data were obtained with standardised data collection forms shared by the International Severe Acute Respiratory and Emerging Infection Consortium from electronic medical records. Researchers also directly communicated with patients or their families to ascertain epidemiological and symptom data. Outcomes were also compared between patients who had been admitted to the intensive care unit (ICU) and those who had not.',\n",
              "  'authors': ['Chaolin Huang 1',\n",
              "   ' Yeming Wang 2',\n",
              "   ' Xingwang Li 3',\n",
              "   ' Lili Ren 4',\n",
              "   ' Jianping Zhao 5',\n",
              "   ' Yi Hu 5',\n",
              "   ' Li Zhang 1',\n",
              "   ' Guohui Fan 2',\n",
              "   ' Jiuyang Xu 6',\n",
              "   ' Xiaoying Gu 2',\n",
              "   ' Zhenshun Cheng 7',\n",
              "   ' Ting Yu 1',\n",
              "   ' Jiaan Xia 1',\n",
              "   ' Yuan Wei 1',\n",
              "   ' Wenjuan Wu 1',\n",
              "   ' Xuelei Xie 1',\n",
              "   ' Wen Yin 5',\n",
              "   ' Hui Li 2',\n",
              "   ' Min Liu 2',\n",
              "   ' Yan Xiao 4',\n",
              "   ' Hong Gao 4',\n",
              "   ' Li Guo 4',\n",
              "   ' Jungang Xie 5',\n",
              "   ' Guangfa Wang 8',\n",
              "   ' Rongmeng Jiang 3',\n",
              "   ' Zhancheng Gao 8',\n",
              "   ' Qi Jin 4',\n",
              "   ' Jianwei Wang 4',\n",
              "   ' Bin Cao 2'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3001118548',\n",
              "  'references': ['2903899730',\n",
              "   '2166867592',\n",
              "   '3000413850',\n",
              "   '2026274122',\n",
              "   '2132260239',\n",
              "   '2104548316',\n",
              "   '2131262274',\n",
              "   '2006434809',\n",
              "   '2725497285',\n",
              "   '1993577573'],\n",
              "  'title': 'Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China'},\n",
              " {'abstract': 'Given a set of stimuli presenting views of some environment, how can one characterize the natural modules or \"objects\" that compose the environment? Should a given set of items be encoded as a collection of instances or as a set of rules? Restricted formulations of these questions are addressed by analysis within a new mathematical framework that describes stochastic parallel computation. An algorithm is given for simulating this computation once schemas encoding the modules of the environment have been selected. The concept of computational temperature is introduced. As this temperature is lowered, the system appears to display a dramatic tendency to interpret input, even if the evidence for any particular interpretation is very weak.',\n",
              "  'authors': ['Paul Smolensky'],\n",
              "  'date': '1983',\n",
              "  'identifier': '158491281',\n",
              "  'references': ['2581275558',\n",
              "   '2293063825',\n",
              "   '1990309597',\n",
              "   '2073257493',\n",
              "   '2157629899',\n",
              "   '2068868410'],\n",
              "  'title': 'Schema selection and stochastic inference in modular environments'},\n",
              " {'abstract': 'Abstract Background Since December 2019, when coronavirus disease 2019 (Covid-19) emerged in Wuhan city and rapidly spread throughout China, data have been needed on the clinical characteristics of...',\n",
              "  'authors': ['Wei-Jie Guan ',\n",
              "   ' Zheng-Yi Ni ',\n",
              "   ' Yu Hu ',\n",
              "   ' Wen-Hua Liang ',\n",
              "   ' Chun-Quan Ou ',\n",
              "   ' Jian-Xing He ',\n",
              "   ' Lei Liu ',\n",
              "   ' Hong Shan ',\n",
              "   ' Chun-Liang Lei ',\n",
              "   ' David S C Hui ',\n",
              "   ' Bin Du ',\n",
              "   ' Lan-Juan Li ',\n",
              "   ' Guang Zeng ',\n",
              "   ' Kwok-Yung Yuen ',\n",
              "   ' Ru-Chong Chen ',\n",
              "   ' Chun-Li Tang ',\n",
              "   ' Tao Wang ',\n",
              "   ' Ping-Yan Chen ',\n",
              "   ' Jie Xiang ',\n",
              "   ' Shi-Yue Li ',\n",
              "   ' Jin-Lin Wang ',\n",
              "   ' Zi-Jing Liang ',\n",
              "   ' Yi-Xiang Peng ',\n",
              "   ' Li Wei ',\n",
              "   ' Yong Liu ',\n",
              "   ' Ya-Hua Hu ',\n",
              "   ' Peng Peng ',\n",
              "   ' Jian-Ming Wang ',\n",
              "   ' Ji-Yang Liu ',\n",
              "   ' Zhong Chen ',\n",
              "   ' Gang Li ',\n",
              "   ' Zhi-Jian Zheng ',\n",
              "   ' Shao-Qin Qiu ',\n",
              "   ' Jie Luo ',\n",
              "   ' Chang-Jiang Ye ',\n",
              "   ' Shao-Yong Zhu ',\n",
              "   ' Nan-Shan Zhong'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3008827533',\n",
              "  'references': ['3001118548',\n",
              "   '3001897055',\n",
              "   '3005079553',\n",
              "   '3003668884',\n",
              "   '3002108456',\n",
              "   '3002539152',\n",
              "   '3004318991',\n",
              "   '3003465021',\n",
              "   '3004239190',\n",
              "   '3003573988'],\n",
              "  'title': 'Clinical Characteristics of Coronavirus Disease 2019 in China'},\n",
              " {'abstract': 'Neural networks are a powerful technology forclassification of visual inputs arising from documents.However, there is a confusing plethora of different neuralnetwork methods that are used in the literature and inindustry. This paper describes a set of concrete bestpractices that document analysis researchers can use toget good results with neural networks. The mostimportant practice is getting a training set as large aspossible: we expand the training set by adding a newform of distorted data. The next most important practiceis that convolutional neural networks are better suited forvisual document tasks than fully connected networks. Wepropose that a simple \"do-it-yourself\" implementation ofconvolution with a flexible architecture is suitable formany visual document problems. This simpleconvolutional neural network does not require complexmethods, such as momentum, weight decay, structure-dependentlearning rates, averaging layers, tangent prop,or even finely-tuning the architecture. The end result is avery simple yet general architecture which can yieldstate-of-the-art performance for document analysis. Weillustrate our claims on the MNIST set of English digitimages.',\n",
              "  'authors': ['P.Y. Simard ', ' D. Steinkraus ', ' J.C. Platt'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2156163116',\n",
              "  'references': ['2310919327',\n",
              "   '1554663460',\n",
              "   '2159737176',\n",
              "   '2027197837',\n",
              "   '2068017609',\n",
              "   '2147345686',\n",
              "   '51975515',\n",
              "   '2166469100'],\n",
              "  'title': 'Best practices for convolutional neural networks applied to visual document analysis'},\n",
              " {'abstract': 'Continuous space language models have recently demonstrated outstanding results across a variety of tasks. In this paper, we examine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset. This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, “King Man + Woman” results in a vector very close to “Queen.” We demonstrate that the word vectors capture syntactic regularities by means of syntactic analogy questions (provided with this paper), and are able to correctly answer almost 40% of the questions. We demonstrate that the word vectors capture semantic regularities by using the vector offset method to answer SemEval-2012 Task 2 questions. Remarkably, this method outperforms the best previous systems.',\n",
              "  'authors': ['Tomas Mikolov 1', ' Wen-tau Yih 2', ' Geoffrey Zweig 2'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2141599568',\n",
              "  'references': ['1614298861',\n",
              "   '2100495367',\n",
              "   '2117130368',\n",
              "   '179875071',\n",
              "   '2132339004',\n",
              "   '2158139315',\n",
              "   '2147152072',\n",
              "   '1632114991',\n",
              "   '2131462252',\n",
              "   '1970689298'],\n",
              "  'title': 'Linguistic Regularities in Continuous Space Word Representations'},\n",
              " {'abstract': 'Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible, wide and deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks.',\n",
              "  'authors': ['Dan Cireşan ', ' Ueli Meier ', ' Juergen Schmidhuber'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2141125852',\n",
              "  'references': ['3118608800',\n",
              "   '2310919327',\n",
              "   '2110798204',\n",
              "   '2154642048',\n",
              "   '2134557905',\n",
              "   '2156163116',\n",
              "   '2138857742',\n",
              "   '2148461049',\n",
              "   '2144982973',\n",
              "   '1991848143'],\n",
              "  'title': 'Multi-column deep neural networks for image classification'},\n",
              " {'abstract': 'Visual features are of vital importance for human action understanding in videos. This paper presents a new video representation, called trajectory-pooled deep-convolutional descriptor (TDD), which shares the merits of both hand-crafted features [31] and deep-learned features [24]. Specifically, we utilize deep architectures to learn discriminative convolutional feature maps, and conduct trajectory-constrained pooling to aggregate these convolutional features into effective descriptors. To enhance the robustness of TDDs, we design two normalization methods to transform convolutional feature maps, namely spatiotemporal normalization and channel normalization. The advantages of our features come from (i) TDDs are automatically learned and contain high discriminative capacity compared with those hand-crafted features; (ii) TDDs take account of the intrinsic characteristics of temporal dimension and introduce the strategies of trajectory-constrained sampling and pooling for aggregating deep-learned features. We conduct experiments on two challenging datasets: HMD-B51 and UCF101. Experimental results show that TDDs outperform previous hand-crafted features [31] and deep-learned features [24]. Our method also achieves superior performance to the state of the art on these datasets.',\n",
              "  'authors': ['Limin Wang 1', ' Yu Qiao 2', ' Xiaoou Tang 1'],\n",
              "  'date': '2015',\n",
              "  'identifier': '1944615693',\n",
              "  'references': ['2618530766',\n",
              "   '2962835968',\n",
              "   '2151103935',\n",
              "   '2097117768',\n",
              "   '2161969291',\n",
              "   '2108598243',\n",
              "   '2155893237',\n",
              "   '1849277567',\n",
              "   '2310919327',\n",
              "   '1677409904'],\n",
              "  'title': 'Action recognition with trajectory-pooled deep-convolutional descriptors'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Haozhi Qi ',\n",
              "   ' Chong You ',\n",
              "   ' Xiaolong Wang ',\n",
              "   ' Yi Ma ',\n",
              "   ' Jitendra Malik'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3034351824',\n",
              "  'references': ['3109745609', '3089324491'],\n",
              "  'title': 'Deep Isometric Learning for Visual Recognition'},\n",
              " {'abstract': 'Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, aaa, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.',\n",
              "  'authors': ['Leo Breiman'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2911964244',\n",
              "  'references': ['2912934387',\n",
              "   '2112076978',\n",
              "   '1975846642',\n",
              "   '2152761983',\n",
              "   '2113242816',\n",
              "   '1605688901',\n",
              "   '2120240539',\n",
              "   '2099968818',\n",
              "   '2067885219',\n",
              "   '1580948147'],\n",
              "  'title': 'Random Forests'},\n",
              " {'abstract': 'In natural images, information is conveyed at different frequencies where higher frequencies are usually encoded with fine details and lower frequencies are usually encoded with global structures. Similarly, the output feature maps of a convolution layer can also be seen as a mixture of information at different frequencies. In this work, we propose to factorize the mixed feature maps by their frequencies, and design a novel Octave Convolution (OctConv) operation to store and process feature maps that vary spatially “slower” at a lower spatial resolution reducing both memory and computation cost. Unlike existing multi-scale methods, OctConv is formulated as a single, generic, plug-and-play convolutional unit that can be used as a direct replacement of (vanilla) convolutions without any adjustments in the network architecture. It is also orthogonal and complementary to methods that suggest better topologies or reduce channel-wise redundancy like group or depth-wise convolutions. We experimentally show that by simply replacing convolutions with OctConv, we can consistently boost accuracy for both image and video recognition tasks, while reducing memory and computational cost. An OctConv-equipped ResNet-152 can achieve 82.9% top-1 classification accuracy on ImageNet with merely 22.2 GFLOPs.',\n",
              "  'authors': ['Yunpeng Chen 1',\n",
              "   ' Haoqi Fan 2',\n",
              "   ' Bing Xu 2',\n",
              "   ' Zhicheng Yan 2',\n",
              "   ' Yannis Kalantidis 2',\n",
              "   ' Marcus Rohrbach 2',\n",
              "   ' Yan Shuicheng 1',\n",
              "   ' Jiashi Feng 1'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2988396473',\n",
              "  'references': ['2194775991',\n",
              "   '2618530766',\n",
              "   '2962835968',\n",
              "   '2097117768',\n",
              "   '2108598243',\n",
              "   '2963446712',\n",
              "   '2302255633',\n",
              "   '2612445135',\n",
              "   '2963163009',\n",
              "   '2964350391'],\n",
              "  'title': 'Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks With Octave Convolution'},\n",
              " {'abstract': 'We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.',\n",
              "  'authors': ['David E. Rumelhart 1',\n",
              "   ' Geoffrey E. Hinton 2',\n",
              "   ' Ronald J. Williams 1'],\n",
              "  'date': '1988',\n",
              "  'identifier': '1498436455',\n",
              "  'references': ['1652505363', '2322002063'],\n",
              "  'title': 'Learning representations by back-propagating errors'},\n",
              " {'abstract': \"This paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ``LINE,'' which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online\\\\footnote{\\\\url{https://github.com/tangjianpku/LINE}}.\",\n",
              "  'authors': ['Jian Tang 1',\n",
              "   ' Meng Qu 2',\n",
              "   ' Mingzhe Wang 2',\n",
              "   ' Ming Zhang 2',\n",
              "   ' Jun Yan 1',\n",
              "   ' Qiaozhu Mei 3'],\n",
              "  'date': '2015',\n",
              "  'identifier': '1888005072',\n",
              "  'references': ['2153579005',\n",
              "   '1614298861',\n",
              "   '2187089797',\n",
              "   '1532325895',\n",
              "   '2131744502',\n",
              "   '2053186076',\n",
              "   '2001141328',\n",
              "   '3104097132',\n",
              "   '1854214752',\n",
              "   '2156718197'],\n",
              "  'title': 'LINE: Large-scale Information Network Embedding'},\n",
              " {'abstract': '',\n",
              "  'authors': ['James L. McClelland'],\n",
              "  'date': '1979',\n",
              "  'identifier': '2053127376',\n",
              "  'references': [],\n",
              "  'title': 'On the time relations of mental processes: An examination of systems of processes in cascade.'},\n",
              " {'abstract': 'Neural probabilistic language models (NPLMs) have been shown to be competitive with and occasionally superior to the widely-used n-gram language models. The main drawback of NPLMs is their extremely long training and testing times. Morin and Bengio have proposed a hierarchical language model built around a binary tree of words, which was two orders of magnitude faster than the non-hierarchical model it was based on. However, it performed considerably worse than its non-hierarchical counterpart in spite of using a word tree created using expert knowledge. We introduce a fast hierarchical language model along with a simple feature-based algorithm for automatic construction of word trees from the data. We then show that the resulting models can outperform non-hierarchical neural models as well as the best n-gram models.',\n",
              "  'authors': ['Andriy Mnih ', ' Geoffrey E. Hinton'],\n",
              "  'date': '2008',\n",
              "  'identifier': '2131462252',\n",
              "  'references': ['2038721957',\n",
              "   '2132339004',\n",
              "   '36903255',\n",
              "   '2158195707',\n",
              "   '2121227244',\n",
              "   '2091812280',\n",
              "   '2127314673',\n",
              "   '2111305191',\n",
              "   '2056590938',\n",
              "   '1558797106'],\n",
              "  'title': 'A Scalable Hierarchical Distributed Language Model'},\n",
              " {'abstract': 'This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.',\n",
              "  'authors': ['David G. Lowe'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2151103935',\n",
              "  'references': ['2033819227',\n",
              "   '2124386111',\n",
              "   '2154422044',\n",
              "   '2012778485',\n",
              "   '2124404372',\n",
              "   '1676552347',\n",
              "   '2124087378',\n",
              "   '2111308925',\n",
              "   '2165497495',\n",
              "   '1949116567'],\n",
              "  'title': 'Distinctive Image Features from Scale-Invariant Keypoints'},\n",
              " {'abstract': 'We present a novel approach for image completion that results in images that are both locally and globally consistent. With a fully-convolutional neural network, we can complete images of arbitrary resolutions by filling-in missing regions of any shape. To train this image completion network to be consistent, we use global and local context discriminators that are trained to distinguish real images from completed ones. The global discriminator looks at the entire image to assess if it is coherent as a whole, while the local discriminator looks only at a small area centered at the completed region to ensure the local consistency of the generated patches. The image completion network is then trained to fool the both context discriminator networks, which requires it to generate images that are indistinguishable from real ones with regard to overall consistency as well as in details. We show that our approach can be used to complete a wide variety of scenes. Furthermore, in contrast with the patch-based approaches such as PatchMatch, our approach can generate fragments that do not appear elsewhere in the image, which allows us to naturally complete the images of objects with familiar and highly specific structures, such as faces.',\n",
              "  'authors': ['Satoshi Iizuka ', ' Edgar Simo-Serra ', ' Hiroshi Ishikawa'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2738588019',\n",
              "  'references': ['1836465849',\n",
              "   '1903029394',\n",
              "   '2099471712',\n",
              "   '2108598243',\n",
              "   '2963073614',\n",
              "   '2963684088',\n",
              "   '1665214252',\n",
              "   '2963373786',\n",
              "   '2963840672',\n",
              "   '6908809'],\n",
              "  'title': 'Globally and locally consistent image completion'},\n",
              " {'abstract': 'In this paper, we explore new approaches to combining information encoded within the learned representations of auto-encoders. We explore models that are capable of combining the attributes of multiple inputs such that a resynthesised output is trained to fool an adversarial discriminator for real versus synthesised data. Furthermore, we explore the use of such an architecture in the context of semi-supervised learning, where we learn a mixing function whose objective is to produce interpolations of hidden states, or masked combinations of latent representations that are consistent with a conditioned class label. We show quantitative and qualitative evidence that such a formulation is an interesting avenue of research.',\n",
              "  'authors': ['Christopher Beckham 1',\n",
              "   ' Sina Honari 2',\n",
              "   ' Vikas Verma 3',\n",
              "   ' Alex M. Lamb 2',\n",
              "   ' Farnoosh Ghadiri 4',\n",
              "   ' R Devon Hjelm 5',\n",
              "   ' Yoshua Bengio 2',\n",
              "   ' Chris Pal 2'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2970902013',\n",
              "  'references': ['3107669106',\n",
              "   '3125645205',\n",
              "   '3092206109',\n",
              "   '3118146262',\n",
              "   '3099306795',\n",
              "   '3108796939',\n",
              "   '3096851030',\n",
              "   '3093382707',\n",
              "   '3033844565',\n",
              "   '3034543211'],\n",
              "  'title': 'On Adversarial Mixup Resynthesis'},\n",
              " {'abstract': 'Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.',\n",
              "  'authors': ['Richard Socher 1',\n",
              "   ' Alex Perelygin ',\n",
              "   ' Jean Wu 1',\n",
              "   ' Jason Chuang 2',\n",
              "   ' Christopher D. Manning 1',\n",
              "   ' Andrew Ng 1',\n",
              "   ' Christopher Potts 1'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2251939518',\n",
              "  'references': ['2146502635',\n",
              "   '2097726431',\n",
              "   '2117130368',\n",
              "   '2132339004',\n",
              "   '1423339008',\n",
              "   '71795751',\n",
              "   '1662133657',\n",
              "   '1889268436',\n",
              "   '2164019165',\n",
              "   '2097606805'],\n",
              "  'title': 'Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank'},\n",
              " {'abstract': 'Summary Background Middle East respiratory syndrome (MERS) is a new human disease caused by a novel coronavirus (CoV). Clinical data on MERS-CoV infections are scarce. We report epidemiological, demographic, clinical, and laboratory characteristics of 47 cases of MERS-CoV infections, identify knowledge gaps, and define research priorities. Methods We abstracted and analysed epidemiological, demographic, clinical, and laboratory data from confirmed cases of sporadic, household, community, and health-care-associated MERS-CoV infections reported from Saudi Arabia between Sept 1, 2012, and June 15, 2013. Cases were confirmed as having MERS-CoV by real-time RT-PCR. Findings 47 individuals (46 adults, one child) with laboratory-confirmed MERS-CoV disease were identified; 36 (77%) were male (male:female ratio 3·3:1). 28 patients died, a 60% case-fatality rate. The case-fatality rate rose with increasing age. Only two of the 47 cases were previously healthy; most patients (45 [96%]) had underlying comorbid medical disorders, including diabetes (32 [68%]), hypertension (16 [34%]), chronic cardiac disease (13 [28%]), and chronic renal disease (23 [49%]). Common symptoms at presentation were fever (46 [98%]), fever with chills or rigors (41 [87%]), cough (39 [83%]), shortness of breath (34 [72%]), and myalgia (15 [32%]). Gastrointestinal symptoms were also frequent, including diarrhoea (12 [26%]), vomiting (ten [21%]), and abdominal pain (eight [17%]). All patients had abnormal findings on chest radiography, ranging from subtle to extensive unilateral and bilateral abnormalities. Laboratory analyses showed raised concentrations of lactate dehydrogenase (23 [49%]) and aspartate aminotransferase (seven [15%]) and thrombocytopenia (17 [36%]) and lymphopenia (16 [34%]). Interpretation Disease caused by MERS-CoV presents with a wide range of clinical manifestations and is associated with substantial mortality in admitted patients who have medical comorbidities. Major gaps in our knowledge of the epidemiology, community prevalence, and clinical spectrum of infection and disease need urgent definition. Funding None.',\n",
              "  'authors': ['Abdullah Assiri 1',\n",
              "   ' Jaffar A Al-Tawfiq 2',\n",
              "   ' Abdullah A Al-Rabeeah 1',\n",
              "   ' Fahad A Al-Rabiah 3',\n",
              "   ' Sami Al-Hajjar 3',\n",
              "   ' Ali Al-Barrak 4',\n",
              "   ' Hesham Flemban 5',\n",
              "   ' Wafa N Al-Nassir 6',\n",
              "   ' Hanan H Balkhy 7',\n",
              "   ' Rafat F Al-Hakeem 1',\n",
              "   ' Hatem Q Makhdoom 8',\n",
              "   ' Alimuddin I Zumla 9',\n",
              "   ' 10',\n",
              "   ' Ziad A Memish 1'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2006434809',\n",
              "  'references': ['2166867592',\n",
              "   '2107053896',\n",
              "   '2131262274',\n",
              "   '1703839189',\n",
              "   '2112147913',\n",
              "   '2045002682',\n",
              "   '1852588318',\n",
              "   '2163627712',\n",
              "   '2140143765',\n",
              "   '2119775949'],\n",
              "  'title': 'Epidemiological, demographic, and clinical characteristics of 47 cases of Middle East respiratory syndrome coronavirus disease from Saudi Arabia: a descriptive study'},\n",
              " {'abstract': 'A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.',\n",
              "  'authors': ['Yoshua Bengio ',\n",
              "   ' Réjean Ducharme ',\n",
              "   ' Pascal Vincent ',\n",
              "   ' Christian Janvin'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2132339004',\n",
              "  'references': ['2038721957',\n",
              "   '2116064496',\n",
              "   '2147152072',\n",
              "   '1631260214',\n",
              "   '2096175520',\n",
              "   '2110485445',\n",
              "   '1575350781',\n",
              "   '2158195707',\n",
              "   '2121227244',\n",
              "   '2914484425'],\n",
              "  'title': 'A neural probabilistic language model'},\n",
              " {'abstract': 'We present a new method for synthesizing high-resolution photo-realistic images from semantic label maps using conditional generative adversarial networks (conditional GANs). Conditional GANs have enabled a variety of applications, but the results are often limited to low-resolution and still far from realistic. In this work, we generate 2048 A— 1024 visually appealing results with a novel adversarial loss, as well as new multi-scale generator and discriminator architectures. Furthermore, we extend our framework to interactive visual manipulation with two additional features. First, we incorporate object instance segmentation information, which enables object manipulations such as removing/adding objects and changing the object category. Second, we propose a method to generate diverse results given the same input, allowing users to edit the object appearance interactively. Human opinion studies demonstrate that our method significantly outperforms existing methods, advancing both the quality and the resolution of deep image synthesis and editing.',\n",
              "  'authors': ['Ting-Chun Wang 1',\n",
              "   ' Ming-Yu Liu 1',\n",
              "   ' Jun-Yan Zhu 2',\n",
              "   ' Andrew Tao 1',\n",
              "   ' Jan Kautz 1',\n",
              "   ' Bryan Catanzaro 1'],\n",
              "  'date': '2018',\n",
              "  'identifier': '2963800363',\n",
              "  'references': ['2194775991',\n",
              "   '2962835968',\n",
              "   '1901129140',\n",
              "   '1903029394',\n",
              "   '1959608418',\n",
              "   '2962793481',\n",
              "   '2963684088',\n",
              "   '2340897893',\n",
              "   '2963373786',\n",
              "   '2331128040'],\n",
              "  'title': 'High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs'},\n",
              " {'abstract': 'Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these \"Stepped Sigmoid Units\" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.',\n",
              "  'authors': ['Vinod Nair ', ' Geoffrey E. Hinton'],\n",
              "  'date': '2010',\n",
              "  'identifier': '1665214252',\n",
              "  'references': ['2136922672',\n",
              "   '2100495367',\n",
              "   '2116064496',\n",
              "   '2546302380',\n",
              "   '1782590233',\n",
              "   '2134557905',\n",
              "   '2099866409',\n",
              "   '1994197834',\n",
              "   '2536626143',\n",
              "   '2157364932'],\n",
              "  'title': 'Rectified Linear Units Improve Restricted Boltzmann Machines'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Yangsibo Huang 1',\n",
              "   ' Zhao Song 2',\n",
              "   ' Kai Li 2',\n",
              "   ' Sanjeev Arora 2'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3118146262',\n",
              "  'references': ['3102554603',\n",
              "   '3100345364',\n",
              "   '3094371524',\n",
              "   '3106770805',\n",
              "   '3109512660',\n",
              "   '3097629404',\n",
              "   '3094150121'],\n",
              "  'title': 'InstaHide: Instance-hiding Schemes for Private Distributed Learning'},\n",
              " {'abstract': 'Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs-30,000 auditory nerve fibers or 10(6) optic nerve fibers-a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.',\n",
              "  'authors': ['J. B. Tenenbaum 1', ' V. de Silva 1', ' J. C. Langford 2'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2001141328',\n",
              "  'references': ['2138451337',\n",
              "   '2099741732',\n",
              "   '2108384452',\n",
              "   '2587818897',\n",
              "   '2123977795',\n",
              "   '2107636931',\n",
              "   '2122538988',\n",
              "   '2047870719',\n",
              "   '2070320140',\n",
              "   '2032647857'],\n",
              "  'title': 'A Global Geometric Framework for Nonlinear Dimensionality Reduction'},\n",
              " {'abstract': \"Extensions of the limiting qnanfizafion error formula of Bennet are proved. These are of the form D_{s,k}(N,F)=N^{-\\\\beta}B , where N is the number of output levels, D_{s,k}(N,F) is the s th moment of the metric distance between quantizer input and output, \\\\beta,B>0,k=s/\\\\beta is the signal space dimension, and F is the signal distribution. If a suitably well-behaved k -dimensional signal density f(x) exists, B=b_{s,k}[\\\\int f^{\\\\rho}(x)dx]^{1/ \\\\rho},\\\\rho=k/(s+k) , and b_{s,k} does not depend on f . For k=1,s=2 this reduces to Bennett's formula. If F is the Cantor distribution on [0,1],0 and this k equals the fractal dimension of the Cantor set [12,13] . Random quantization, optimal quantization in the presence of an output information constraint, and quantization noise in high dimensional spaces are also investigated.\",\n",
              "  'authors': ['P. Zador'],\n",
              "  'date': '1982',\n",
              "  'identifier': '2089419199',\n",
              "  'references': ['2142228262', '1973387369', '1976356564', '2001968606'],\n",
              "  'title': 'Asymptotic quantization error of continuous signals and the quantization dimension'},\n",
              " {'abstract': 'This chapter contains sections titled: The Problem, The Generalized Delta Rule, Simulation Results, Some Further Generalizations, Conclusion',\n",
              "  'authors': ['D. E. Rumelhart ', ' G. E. Hinton ', ' R. J. Williams'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2154642048',\n",
              "  'references': ['2154642048',\n",
              "   '1652505363',\n",
              "   '1535810436',\n",
              "   '1507849272',\n",
              "   '2101926813',\n",
              "   '2073257493',\n",
              "   '2021878536',\n",
              "   '1490454746',\n",
              "   '2115647291',\n",
              "   '1505136099'],\n",
              "  'title': 'Learning internal representations by error propagation'},\n",
              " {'abstract': 'Can machine learning deliver AI? Theoretical results, inspiration from the brain and cognition, as well as machine learning experiments suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one would need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers, graphical models with many levels of latent variables, or in complicated propositional formulae re-using many sub-formulae. Each level of the architecture represents features at a different level of abstraction, defined as a composition of lower-level features. Searching the parameter space of deep architectures is a difficult task, but new algorithms have been discovered and a new sub-area has emerged in the machine learning community since 2006, following these discoveries. Learning algorithms such as those for Deep Belief Networks and other related unsupervised learning algorithms have recently been proposed to train deep architectures, yielding exciting results and beating the state-of-the-art in certain areas. Learning Deep Architectures for AI discusses the motivations for and principles of learning algorithms for deep architectures. By analyzing and comparing recent results with different learning algorithms for deep architectures, explanations for their success are proposed and discussed, highlighting challenges and suggesting avenues for future explorations in this area.',\n",
              "  'authors': ['Yoshua Bengio'],\n",
              "  'date': '2009',\n",
              "  'identifier': '2072128103',\n",
              "  'references': ['2156909104',\n",
              "   '2911964244',\n",
              "   '2296616510',\n",
              "   '2136922672',\n",
              "   '2100495367',\n",
              "   '2310919327',\n",
              "   '2187089797',\n",
              "   '2129131372',\n",
              "   '2119821739',\n",
              "   '2053186076'],\n",
              "  'title': 'Learning Deep Architectures for AI'},\n",
              " {'abstract': 'Deep Neural Networks have shown great promise on a variety of downstream applications; but their ability to adapt and generalize to new data and tasks remains a challenge. However, the ability to perform few or zero-shot adaptation to novel tasks is important for the scalability and deployment of machine learning models. It is therefore crucial to understand what makes for good, transfer-able features in deep networks that best allow for such adaptation. In this paper, we shed light on this by showing that features that are most transferable have high uniformity in the embedding space and propose a uniformity regularization scheme that encourages better transfer and feature reuse. We evaluate the regularization on its ability to facilitate adaptation to unseen tasks and data, for which we conduct a thorough experimental study covering four relevant, and distinct domains: few-shot Meta-Learning, Deep Metric Learning, Zero-Shot Domain Adaptation, as well as Out-of-Distribution classification. Across all experiments, we show that uniformity regularization consistently offers benefits over baseline methods and is able to achieve state-of-the-art performance in Deep Metric Learning and Meta-Learning.',\n",
              "  'authors': ['Samarth Sinha ',\n",
              "   ' Karsten Roth ',\n",
              "   ' Anirudh Goyal ',\n",
              "   ' Marzyeh Ghassemi ',\n",
              "   ' Hugo Larochelle ',\n",
              "   ' Animesh Garg'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3093382707',\n",
              "  'references': ['2194775991',\n",
              "   '2964121744',\n",
              "   '2963403868',\n",
              "   '1836465849',\n",
              "   '2963341956',\n",
              "   '2117539524',\n",
              "   '1901129140',\n",
              "   '1903029394',\n",
              "   '2099471712',\n",
              "   '1536680647'],\n",
              "  'title': 'Uniform Priors for Data-Efficient Transfer.'},\n",
              " {'abstract': 'A previously unknown coronavirus was isolated from the sputum of a 60-year-old man who presented with acute pneumonia and subsequent renal failure with a fatal outcome in Saudi Arabia. The virus (called HCoV-EMC) replicated readily in cell culture, producing cytopathic effects of rounding, detachment, and syncytium formation. The virus represents a novel betacoronavirus species. The closest known relatives are bat coronaviruses HKU4 and HKU5. Here, the clinical data, virus isolation, and molecular identification are presented. The clinical picture was remarkably similar to that of the severe acute respiratory syndrome (SARS) outbreak in 2003 and reminds us that animal coronaviruses can cause severe disease in humans.',\n",
              "  'authors': ['Ali Moh Zaki 1',\n",
              "   ' Sander Van Boheemen 2',\n",
              "   ' Theo M. Bestebroer 2',\n",
              "   ' Albert D.M.E. Osterhaus ',\n",
              "   ' Ron A.M. Fouchier'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2166867592',\n",
              "  'references': ['2132260239',\n",
              "   '2025170735',\n",
              "   '2129542667',\n",
              "   '1703839189',\n",
              "   '2116586125',\n",
              "   '1987783718',\n",
              "   '1963953102',\n",
              "   '2111412754',\n",
              "   '2170933940',\n",
              "   '2126707939'],\n",
              "  'title': 'Isolation of a Novel Coronavirus from a Man with Pneumonia in Saudi Arabia'},\n",
              " {'abstract': 'This paper describes AutoClass II, a program for automatically discovering (inducing) classes from a database, based on a Bayesian statistical technique which automatically determines the most probable number of classes, their probabilistic descriptions, and the probability that each object is a member of each class. AutoClass has been tested on several large, real databases and has discovered previously unsuspected classes. There is no doubt that these classes represent new phenomena.',\n",
              "  'authors': ['Peter C. Cheeseman ',\n",
              "   ' James Kelly ',\n",
              "   ' Matthew Self ',\n",
              "   ' John C. Stutz ',\n",
              "   ' Will Taylor ',\n",
              "   ' Don Freeman'],\n",
              "  'date': '1993',\n",
              "  'identifier': '1992880122',\n",
              "  'references': ['2049633694',\n",
              "   '2029520384',\n",
              "   '2096059947',\n",
              "   '2037591014',\n",
              "   '3049188988',\n",
              "   '2072533619',\n",
              "   '2989873570',\n",
              "   '2000613518',\n",
              "   '2118570622',\n",
              "   '30272054'],\n",
              "  'title': 'AutoClass: a Bayesian classification system'},\n",
              " {'abstract': 'If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize.com/projects/wordreprs/',\n",
              "  'authors': ['Joseph Turian 1', ' Lev-Arie Ratinov 2', ' Yoshua Bengio 1'],\n",
              "  'date': '2010',\n",
              "  'identifier': '2158139315',\n",
              "  'references': ['1880262756',\n",
              "   '2117130368',\n",
              "   '2132339004',\n",
              "   '1662133657',\n",
              "   '2131462252',\n",
              "   '2296073425',\n",
              "   '168564468',\n",
              "   '2158997610',\n",
              "   '2156515921',\n",
              "   '2004763266'],\n",
              "  'title': 'Word Representations: A Simple and General Method for Semi-Supervised Learning'},\n",
              " {'abstract': 'An unsupervised learning algorithm for a multilayer network of stochastic neurons is described. Bottom-up \"recognition\" connections convert the input into representations in successive hidden layers, and top-down \"generative\" connections reconstruct the representation in one layer from the representation in the layer above. In the \"wake\" phase, neurons are driven by recognition connections, and generative connections are adapted to increase the probability that they would reconstruct the correct activity vector in the layer below. In the \"sleep\" phase, neurons are driven by generative connections, and recognition connections are adapted to increase the probability that they would produce the correct activity vector in the layer above.',\n",
              "  'authors': ['Geoffrey E. Hinton ',\n",
              "   ' Peter Dayan ',\n",
              "   ' Brendan J. Frey ',\n",
              "   ' Radford M. Neal'],\n",
              "  'date': '1995',\n",
              "  'identifier': '1993845689',\n",
              "  'references': ['2740373864',\n",
              "   '2177040213',\n",
              "   '1533169541',\n",
              "   '2044875682',\n",
              "   '94647076'],\n",
              "  'title': 'The \"Wake-Sleep\" Algorithm for Unsupervised Neural Networks'},\n",
              " {'abstract': 'When a vision system creates an interpretation of some input datn, it assigns truth values or probabilities to intcrnal hypothcses about the world. We present a non-dctcrministic method for assigning truth values that avoids many of the problcms encountered by existing relaxation methods. Instead of rcprcscnting probabilitics with realnumbers, we usc a more dircct encoding in which thc probability \\\\ associated with a hypotlmis is rcprcscntcd by the probability hat it is in one of two states, true or false. Wc give a particular nondeterministic operator, based on statistical mechanics, for updating the truth values of hypothcses. The operator ensures that the probability of discovering a particular combination of hypothcscs is a simplc function of how good that combination is. Wc show that thcrc is a simple relationship bctween this operator and Bayesian inference, and we describe a learning rule which allows a parallel system to converge on a set ofweights that optimizes its perccptt~al inferences.',\n",
              "  'authors': ['Geoffrey E. Hinton ', ' J. Sejnowski'],\n",
              "  'date': '1983',\n",
              "  'identifier': '2157629899',\n",
              "  'references': ['2581275558',\n",
              "   '2293063825',\n",
              "   '2048330959',\n",
              "   '2046425638',\n",
              "   '2080250034',\n",
              "   '1965044325',\n",
              "   '179212727',\n",
              "   '1581975000',\n",
              "   '2002010034',\n",
              "   '1548470819'],\n",
              "  'title': 'OPTIMAL PERCEPTUAL INFERENCE'},\n",
              " {'abstract': \"The problem of automatically learning object models for recognition and pose estimation is addressed. In contrast to the traditional approach, the recognition problem is formulated as one of matching appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties and constant for a rigid object, pose and illumination vary from scene to scene. A compact representation of object appearance is proposed that is parametrized by pose and illumination. For each object of interest, a large set of images is obtained by automatically varying pose and illumination. This image set is compressed to obtain a low-dimensional subspace, called the eigenspace, in which the object is represented as a manifold. Given an unknown input image, the recognition system projects the image to eigenspace. The object is recognized based on the manifold it lies on. The exact position of the projection on the manifold determines the object's pose in the image. A variety of experiments are conducted using objects with complex appearance characteristics. The performance of the recognition and pose estimation algorithms is studied using over a thousand input images of sample objects. Sensitivity of recognition to the number of eigenspace dimensions and the number of learning samples is analyzed. For the objects used, appearance representation in eigenspaces with less than 20 dimensions produces accurate recognition results with an average pose estimation error of about 1.0 degree. A near real-time recognition system with 20 complex objects in the database has been developed. The paper is concluded with a discussion on various issues related to the proposed learning and recognition methodology.\",\n",
              "  'authors': ['Hiroshi Murase 1', ' Shree K. Nayar 2'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2123977795',\n",
              "  'references': ['2170120409',\n",
              "   '2098693229',\n",
              "   '2143956139',\n",
              "   '2130259898',\n",
              "   '2135346934',\n",
              "   '2053197265',\n",
              "   '1996773532',\n",
              "   '2086479969',\n",
              "   '2026311529',\n",
              "   '2033554200'],\n",
              "  'title': 'Visual learning and recognition of 3-D objects from appearance'},\n",
              " {'abstract': 'The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks. These algorithms have (1) the advantage that they do not require a precisely defined training interval, operating while the network runs; and (2) the disadvantage that they require nonlocal communication in the network being trained and are computationally expensive. These algorithms allow networks having recurrent connections to learn complex tasks that require the retention of information over time periods having either fixed or indefinite length.',\n",
              "  'authors': ['Ronald J. Williams 1', ' David Zipser 2'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2016589492',\n",
              "  'references': ['2154642048',\n",
              "   '2293063825',\n",
              "   '2110485445',\n",
              "   '2143503258',\n",
              "   '1959983357',\n",
              "   '1881179843',\n",
              "   '1984205520',\n",
              "   '1984375561',\n",
              "   '2119796132',\n",
              "   '1527772862'],\n",
              "  'title': 'A learning algorithm for continually running fully recurrent neural networks'},\n",
              " {'abstract': \"Most of the existing approaches to collaborative filtering cannot handle very large data sets. In this paper we show how a class of two-layer undirected graphical models, called Restricted Boltzmann Machines (RBM's), can be used to model tabular data, such as user's ratings of movies. We present efficient learning and inference procedures for this class of models and demonstrate that RBM's can be successfully applied to the Netflix data set, containing over 100 million user/movie ratings. We also show that RBM's slightly outperform carefully-tuned SVD models. When the predictions of multiple RBM models and multiple SVD models are linearly combined, we achieve an error rate that is well over 6% better than the score of Netflix's own system.\",\n",
              "  'authors': ['Ruslan Salakhutdinov ', ' Andriy Mnih ', ' Geoffrey Hinton'],\n",
              "  'date': '2007',\n",
              "  'identifier': '2099866409',\n",
              "  'references': ['2136922672',\n",
              "   '2100495367',\n",
              "   '2116064496',\n",
              "   '2147152072',\n",
              "   '1612003148',\n",
              "   '2122090912',\n",
              "   '2158164339',\n",
              "   '2124914669',\n",
              "   '205159212',\n",
              "   '2165395308'],\n",
              "  'title': 'Restricted Boltzmann machines for collaborative filtering'},\n",
              " {'abstract': 'This paper describes an offline cursive handwritten word recognition system that combines hidden Markov models (HMM) and neural networks (NN). Using a fast left-right slicing method, we generate a segmentation graph that describes all possible ways to segment a word into letters. The NN computes the observation probabilities for each letter hypothesis in the segmentation graph. Then, the HMM compute the likelihood for each word in the lexicon by summing the probabilities over all possible paths through the graph. We present the preprocessing and the recognition process as well as the training procedure for the NN-HMM hybrid system. Another recognition system based on discrete HMM is also presented for performance comparison. The latter is also used for bootstrapping the NN-HMM hybrid system. Recognition performances of the two recognition systems using two image databases of French isolated words are presented. This paper is one of the first publications using the IRONOFF database, and thus can be used as a reference for future work on this database.',\n",
              "  'authors': ['Yong Haur Tay ',\n",
              "   ' P.M. Lallican ',\n",
              "   ' M. Khalid ',\n",
              "   ' C. Viard-Gaudin ',\n",
              "   ' S. Kneer'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2147345686',\n",
              "  'references': ['2310919327',\n",
              "   '2125838338',\n",
              "   '2142069714',\n",
              "   '183625566',\n",
              "   '2149597185',\n",
              "   '2077863651',\n",
              "   '2148295954',\n",
              "   '101240229',\n",
              "   '2064838583',\n",
              "   '1599953749'],\n",
              "  'title': 'An offline cursive handwritten word recognition system'},\n",
              " {'abstract': 'Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question: Are there any benefits to combining Inception architectures with residual connections? Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4 networks, we achieve 3.08% top-5 error on the test set of the ImageNet classification (CLS) challenge.',\n",
              "  'authors': ['Christian Szegedy ',\n",
              "   ' Sergey Ioffe ',\n",
              "   ' Vincent Vanhoucke ',\n",
              "   ' Alexander A Alemi'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2964350391',\n",
              "  'references': ['2604319603',\n",
              "   '2955425717',\n",
              "   '2996428491',\n",
              "   '2965658867',\n",
              "   '2886335102',\n",
              "   '2942841021',\n",
              "   '2963918968',\n",
              "   '2774644650',\n",
              "   '2963402313'],\n",
              "  'title': 'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning'},\n",
              " {'abstract': 'Selected Aspects of Multivariate Analysis. Principal Components Analysis. Factor Analysis. Multidimensional Scaling. Cluster Analysis. Multiple Regression. Some Practical Considerations: Data Analysis Problems. Cross-Classified Frequency Data. Canonical Correlation Analysis. Discriminant Analysis: The Two-Group Problem. Multiple Discriminant Analysis and Related Topics. Linear Structural Relations (LISREL). Latent Structure Analysis. Appendixes. References. Index.',\n",
              "  'authors': ['William R. Dillon ', ' Matthew Goldstein'],\n",
              "  'date': '1984',\n",
              "  'identifier': '2029520384',\n",
              "  'references': ['2110078189',\n",
              "   '2121866145',\n",
              "   '1992880122',\n",
              "   '2124611117',\n",
              "   '2058839291',\n",
              "   '2056554492',\n",
              "   '2096123611',\n",
              "   '1990168101',\n",
              "   '2113894235',\n",
              "   '1479838483'],\n",
              "  'title': 'Multivariate Analysis: Methods and Applications'},\n",
              " {'abstract': 'Deep neural networks (DNNs) trained on large-scale datasets have exhibited significant performance in image classification. Many large-scale datasets are collected from websites, however they tend to contain inaccurate labels that are termed as noisy labels. Training on such noisy labeled datasets causes performance degradation because DNNs easily overfit to noisy labels. To overcome this problem, we propose a joint optimization framework of learning DNN parameters and estimating true labels. Our framework can correct labels during training by alternating update of network parameters and labels. We conduct experiments on the noisy CIFAR-10 datasets and the Clothing1M dataset. The results indicate that our approach significantly outperforms other state-of-the-art methods.',\n",
              "  'authors': ['Daiki Tanaka ',\n",
              "   ' Daiki Ikami ',\n",
              "   ' Toshihiko Yamasaki ',\n",
              "   ' Kiyoharu Aizawa'],\n",
              "  'date': '2018',\n",
              "  'identifier': '2964274690',\n",
              "  'references': ['2194775991',\n",
              "   '3118608800',\n",
              "   '2963207607',\n",
              "   '2302255633',\n",
              "   '2073459066',\n",
              "   '2566079294',\n",
              "   '2136504847',\n",
              "   '2963399829',\n",
              "   '2963096987',\n",
              "   '2964292098'],\n",
              "  'title': 'Joint Optimization Framework for Learning with Noisy Labels'},\n",
              " {'abstract': 'We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13% for SVM and 7% for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7% error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second.',\n",
              "  'authors': ['Y. LeCun 1', ' Fu Jie Huang 1', ' L. Bottou 2'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2134557905',\n",
              "  'references': ['2164598857',\n",
              "   '2310919327',\n",
              "   '2217896605',\n",
              "   '2124087378',\n",
              "   '2124351082',\n",
              "   '2123977795',\n",
              "   '2155511848',\n",
              "   '2160225842',\n",
              "   '2295106276',\n",
              "   '2141376824'],\n",
              "  'title': 'Learning methods for generic object recognition with invariance to pose and lighting'},\n",
              " {'abstract': 'Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term-document, word-context, and pair-pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a specific open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the field.',\n",
              "  'authors': ['Peter D. Turney 1', ' Patrick Pantel 2'],\n",
              "  'date': '2010',\n",
              "  'identifier': '1662133657',\n",
              "  'references': ['2173213060',\n",
              "   '1880262756',\n",
              "   '1532325895',\n",
              "   '3013264884',\n",
              "   '2038721957',\n",
              "   '2024165284',\n",
              "   '1660390307',\n",
              "   '2117130368',\n",
              "   '2166706824',\n",
              "   '1992419399'],\n",
              "  'title': 'From frequency to meaning: vector space models of semantics'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Michael I. Jordan ', ' David E. Rumelhart'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2286699414',\n",
              "  'references': ['2100154879',\n",
              "   '2040122478',\n",
              "   '1550178333',\n",
              "   '2083338339',\n",
              "   '1592915594',\n",
              "   '2165243928',\n",
              "   '2153046743'],\n",
              "  'title': 'Forward models: supervised learning with a distal teacher'},\n",
              " {'abstract': 'We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.',\n",
              "  'authors': ['Andrew G. Howard ',\n",
              "   ' Menglong Zhu ',\n",
              "   ' Bo Chen ',\n",
              "   ' Dmitry Kalenichenko ',\n",
              "   ' Weijun Wang ',\n",
              "   ' Tobias Weyand ',\n",
              "   ' Marco Andreetto ',\n",
              "   ' Hartwig Adam'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2612445135',\n",
              "  'references': ['2194775991',\n",
              "   '2962835968',\n",
              "   '2097117768',\n",
              "   '639708223',\n",
              "   '1836465849',\n",
              "   '2117539524',\n",
              "   '2155893237',\n",
              "   '3106250896',\n",
              "   '2183341477',\n",
              "   '2096733369'],\n",
              "  'title': 'MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications'},\n",
              " {'abstract': 'Both convolutional and recurrent operations are building blocks that process one local neighborhood at a time. In this paper, we present non-local operations as a generic family of building blocks for capturing long-range dependencies. Inspired by the classical non-local means method [4] in computer vision, our non-local operation computes the response at a position as a weighted sum of the features at all positions. This building block can be plugged into many computer vision architectures. On the task of video classification, even without any bells and whistles, our nonlocal models can compete or outperform current competition winners on both Kinetics and Charades datasets. In static image recognition, our non-local models improve object detection/segmentation and pose estimation on the COCO suite of tasks. Code will be made available.',\n",
              "  'authors': ['Xiaolong Wang 1',\n",
              "   ' Ross Girshick 1',\n",
              "   ' Abhinav Gupta 2',\n",
              "   ' Kaiming He 1'],\n",
              "  'date': '2018',\n",
              "  'identifier': '2963091558',\n",
              "  'references': ['2194775991',\n",
              "   '2962835968',\n",
              "   '639708223',\n",
              "   '2963403868',\n",
              "   '1836465849',\n",
              "   '2117539524',\n",
              "   '1677182931',\n",
              "   '2806070179',\n",
              "   '1861492603',\n",
              "   '1904365287'],\n",
              "  'title': 'Non-local Neural Networks'},\n",
              " {'abstract': 'We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, non-linear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low-energy states (‘annealing’), or what is the same thing, the most probable states under the Gib...',\n",
              "  'authors': ['Stuart Geman 1', ' Donald Geman 2'],\n",
              "  'date': '1993',\n",
              "  'identifier': '1997063559',\n",
              "  'references': ['2581275558',\n",
              "   '2150060382',\n",
              "   '1622620102',\n",
              "   '2154061444',\n",
              "   '2114220616',\n",
              "   '2065301447',\n",
              "   '1979622972',\n",
              "   '2107792892',\n",
              "   '2014208555',\n",
              "   '1567885833'],\n",
              "  'title': 'Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images*'},\n",
              " {'abstract': 'This paper reporis the results of our studies with an unsupervised learning paradigm which we have called “Competitive Learning.” We have examined competitive learning using both computer simulation and formal analysis and hove found that when it is applied to parallel networks of neuron-like elements, many potentially useful learning tasks can be accomplished. We were attracted to competitive learning because it seems to provide o way to discover the salient, general features which can be used to classify o set of patterns. We show how o very simply competitive mechanism con discover a set of feature detectors which capture important aspects of the set of stimulus input patterns. We 0150 show how these feature detectors con form the basis of o multilayer system that con serve to learn categorizations of stimulus sets which ore not linearly separable. We show how the use of correlated stimuli con serve IX o kind of “teaching” input to the system to allow the development of feature detectors which would not develop otherwise. Although we find the competitive learning mechanism o very interesting and powerful learning principle, we do not, of course, imagine thot it is the only learning principle. Competitive learning is cm essentially nonassociative stotisticol learning scheme. We certainly imagine that other kinds of learning mechanisms will be involved in the building of associations among patterns of activation in o more complete neural network. We offer this analysis of these competitive learning mechanisms to further our understanding of how simple adaptive networks can discover features importont in the description of the stimulus environment in which the system finds itself.',\n",
              "  'authors': ['David E. Rumelhart ', ' David Zipser'],\n",
              "  'date': '1988',\n",
              "  'identifier': '1490454746',\n",
              "  'references': ['2073257493',\n",
              "   '1514711945',\n",
              "   '2113653296',\n",
              "   '2010315761',\n",
              "   '2103170504'],\n",
              "  'title': 'Feature discovery by competitive learning'},\n",
              " {'abstract': 'Bagging and boosting reduce error by changing both the inputs and outputs to form perturbed training sets, growing predictors on these perturbed training sets and combining them. An interesting question is whether it is possible to get comparable performance by perturbing the outputs alone. Two methods of randomizing outputs are experimented with. One is called output smearing and the other output flipping. Both are shown to consistently do better than bagging.',\n",
              "  'authors': ['Leo Breiman'],\n",
              "  'date': '2000',\n",
              "  'identifier': '1580948147',\n",
              "  'references': ['1988790447',\n",
              "   '2912934387',\n",
              "   '3085162807',\n",
              "   '2112076978',\n",
              "   '1594031697',\n",
              "   '2102201073',\n",
              "   '1605688901',\n",
              "   '2067885219',\n",
              "   '2076118331',\n",
              "   '2172195373'],\n",
              "  'title': 'Randomizing Outputs to Increase Prediction Accuracy'},\n",
              " {'abstract': '',\n",
              "  'authors': ['James L. McClelland ', ' David E. Rumelhart'],\n",
              "  'date': '1981',\n",
              "  'identifier': '2073257493',\n",
              "  'references': ['1509703770',\n",
              "   '2007780422',\n",
              "   '2045597501',\n",
              "   '2068868410',\n",
              "   '2053127376',\n",
              "   '2147311265',\n",
              "   '2098683904',\n",
              "   '2040187703',\n",
              "   '2006769754',\n",
              "   '2154634575'],\n",
              "  'title': 'An interactive activation model of context effects in letter perception: I. An account of basic findings.'},\n",
              " {'abstract': 'An unsolved challenge in distributed or federated learning is to effectively mitigate privacy risks without slowing down training or reducing accuracy. In this paper, we propose TextHide aiming at addressing this challenge for natural language understanding tasks. It requires all participants to add a simple encryption step to prevent an eavesdropping attacker from recovering private text data. Such an encryption step is efficient and only affects the task performance slightly. In addition, TextHide fits well with the popular framework of fine-tuning pre-trained language models (e.g., BERT) for any sentence or sentence-pair task. We evaluate TextHide on the GLUE benchmark, and our experiments show that TextHide can effectively defend attacks on shared gradients or representations and the averaged accuracy reduction is only 1.9%. We also present an analysis of the security of TextHide using a conjecture about the computational intractability of a mathematical problem.',\n",
              "  'authors': ['Yangsibo Huang ',\n",
              "   ' Zhao Song ',\n",
              "   ' Danqi Chen ',\n",
              "   ' Kai Li ',\n",
              "   ' Sanjeev Arora'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3102554603',\n",
              "  'references': ['2964121744',\n",
              "   '2963341956',\n",
              "   '3118608800',\n",
              "   '2310919327',\n",
              "   '2251939518',\n",
              "   '2963748441',\n",
              "   '2031533839',\n",
              "   '2965373594',\n",
              "   '2970971581',\n",
              "   '2027595342'],\n",
              "  'title': 'TextHide: Tackling Data Privacy in Language Understanding Tasks'},\n",
              " {'abstract': 'We seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.',\n",
              "  'authors': ['Bryan C. Russell 1',\n",
              "   ' Antonio Torralba 1',\n",
              "   ' Kevin P. Murphy 2',\n",
              "   ' William T. Freeman 1'],\n",
              "  'date': '2008',\n",
              "  'identifier': '2110764733',\n",
              "  'references': ['2156909104',\n",
              "   '2164598857',\n",
              "   '2038721957',\n",
              "   '2138451337',\n",
              "   '2154422044',\n",
              "   '2107034620',\n",
              "   '1566135517',\n",
              "   '2166049352',\n",
              "   '2156598602',\n",
              "   '2134557905'],\n",
              "  'title': 'LabelMe: A Database and Web-Based Tool for Image Annotation'},\n",
              " {'abstract': 'We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.',\n",
              "  'authors': ['John Duchi 1', ' Elad Hazan 2', ' Yoram Singer 3'],\n",
              "  'date': '2011',\n",
              "  'identifier': '2146502635',\n",
              "  'references': ['2296319761',\n",
              "   '2108598243',\n",
              "   '3120740533',\n",
              "   '2798766386',\n",
              "   '2610857016',\n",
              "   '2150102617',\n",
              "   '2124541940',\n",
              "   '2167732364',\n",
              "   '1992208280',\n",
              "   '2160218441'],\n",
              "  'title': 'Adaptive Subgradient Methods for Online Learning and Stochastic Optimization'},\n",
              " {'abstract': 'We present a family of margin based online learning algorithms for various prediction tasks. In particular we derive and analyze algorithms for binary and multiclass categorization, regression, uniclass prediction and sequence prediction. The update steps of our different algorithms are all based on analytical solutions to simple constrained optimization problems. This unified view allows us to prove worst-case loss bounds for the different algorithms and for the various decision problems based on a single lemma. Our bounds on the cumulative loss of the algorithms are relative to the smallest loss that can be attained by any fixed hypothesis, and as such are applicable to both realizable and unrealizable settings. We demonstrate some of the merits of the proposed algorithms in a series of experiments with synthetic and real data sets.',\n",
              "  'authors': ['Koby Crammer 1',\n",
              "   ' 2',\n",
              "   ' Ofer Dekel 2',\n",
              "   ' Joseph Keshet 2',\n",
              "   ' Shai Shalev-Shwartz 2',\n",
              "   ' Yoram Singer 2'],\n",
              "  'date': '2006',\n",
              "  'identifier': '2160218441',\n",
              "  'references': ['2296319761',\n",
              "   '2148603752',\n",
              "   '1563088657',\n",
              "   '1560724230',\n",
              "   '1601740268',\n",
              "   '2053463056',\n",
              "   '1978394996',\n",
              "   '2032210760',\n",
              "   '2101276256',\n",
              "   '3003716168'],\n",
              "  'title': 'Online Passive-Aggressive Algorithms'},\n",
              " {'abstract': 'A large class of problems can be formulated in terms of the assignment of labels to objects. Frequently, processes are needed which reduce ambiguity and noise, and select the best label among several possible choices. Relaxation labeling processes are just such a class of algorithms. They are based on the parallel use of local constraints between labels. This paper develops a theory to characterize the goal of relaxation labeling. The theory is founded on a definition of con-sistency in labelings, extending the notion of constraint satisfaction. In certain restricted circumstances, an explicit functional exists that can be maximized to guide the search for consistent labelings. This functional is used to derive a new relaxation labeling operator. When the restrictions are not satisfied, the theory relies on variational cal-culus. It is shown that the problem of finding consistent labelings is equivalent to solving a variational inequality. A procedure nearly identical to the relaxation operator derived under restricted circum-stances serves in the more general setting. Further, a local convergence result is established for this operator. The standard relaxation labeling formulas are shown to approximate our new operator, which leads us to conjecture that successful applications of the standard methods are explainable by the theory developed here. Observations about con-vergence and generalizations to higher order compatibility relations are described.',\n",
              "  'authors': ['Robert A. Hummel 1', ' Steven W. Zucker 2'],\n",
              "  'date': '1983',\n",
              "  'identifier': '2107792892',\n",
              "  'references': ['1979622972',\n",
              "   '1597474747',\n",
              "   '1736170383',\n",
              "   '2105038716',\n",
              "   '2080250034',\n",
              "   '1965044325',\n",
              "   '1990852520',\n",
              "   '2066780173',\n",
              "   '2040073555',\n",
              "   '154154965'],\n",
              "  'title': 'On the Foundations of Relaxation Labeling Processes'},\n",
              " {'abstract': \"We present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk's latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk's representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk's representations are able to outperform all baseline methods while using 60% less training data. DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.\",\n",
              "  'authors': ['Bryan Perozzi ', ' Rami Al-Rfou ', ' Steven Skiena'],\n",
              "  'date': '2014',\n",
              "  'identifier': '3104097132',\n",
              "  'references': ['2618530766',\n",
              "   '2153579005',\n",
              "   '1614298861',\n",
              "   '2163922914',\n",
              "   '2168231600',\n",
              "   '2122646361',\n",
              "   '2141599568',\n",
              "   '2118585731',\n",
              "   '2117130368',\n",
              "   '2147768505'],\n",
              "  'title': 'DeepWalk: online learning of social representations'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Naomi Weisstein ', ' Gregory Ozog ', ' Ronald Szoc'],\n",
              "  'date': '1975',\n",
              "  'identifier': '1968243487',\n",
              "  'references': ['2164847484',\n",
              "   '1999908130',\n",
              "   '2154634575',\n",
              "   '2018809434',\n",
              "   '2041181954',\n",
              "   '2163875444',\n",
              "   '2042236083',\n",
              "   '2062793957',\n",
              "   '1975080851',\n",
              "   '2074165728'],\n",
              "  'title': 'A comparison and elaboration of two models of metacontrast.'},\n",
              " {'abstract': 'A Neuro-Fuzzy Network (NFN) is proposed, combining the merits of Artificial Neural Networks and Fuzzy Logic Systems. Most specifically, prior knowledge can be embedded in the synaptic weights of the NFN, speeding up the convergence.This NFN can be used for rule extraction or for identification and control of nonlinear dynamical systems.',\n",
              "  'authors': ['Pierre Yves Glorennec 1',\n",
              "   ' Claude Barret 2',\n",
              "   ' Michèle Brunet 2'],\n",
              "  'date': '1992',\n",
              "  'identifier': '1592915594',\n",
              "  'references': ['2138484437',\n",
              "   '2103496339',\n",
              "   '2286699414',\n",
              "   '2156060469',\n",
              "   '2083023271',\n",
              "   '103128726',\n",
              "   '1893980568',\n",
              "   '2328615224'],\n",
              "  'title': 'Application of Neuro-Fuzzy Networks to the Identification and Control of Nonlinear Dynamical Systems'},\n",
              " {'abstract': 'We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without bells and whistles, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: https://github.com/facebookresearch/Detectron .',\n",
              "  'authors': ['Kaiming He ',\n",
              "   ' Georgia Gkioxari ',\n",
              "   ' Piotr Dollar ',\n",
              "   ' Ross Girshick'],\n",
              "  'date': '2020',\n",
              "  'identifier': '2806070179',\n",
              "  'references': ['2194775991',\n",
              "   '2618530766',\n",
              "   '639708223',\n",
              "   '2102605133',\n",
              "   '1903029394',\n",
              "   '1536680647',\n",
              "   '2806070179',\n",
              "   '1861492603',\n",
              "   '2109255472',\n",
              "   '2088049833'],\n",
              "  'title': 'Mask R-CNN'},\n",
              " {'abstract': 'The fundamental principles, basic mechanisms, and formal analyses involved in the development of parallel distributed processing (PDP) systems are presented in individual chapters contributed by leading experts. Topics examined include distributed representations, PDP models and general issues in cognitive science, feature discovery by competitive learning, the foundations of harmony theory, learning and relearning in Boltzmann machines, and learning internal representations by error propagation. Consideration is given to linear algebra in PDP, the logic of additive functions, resource requirements of standard and programmable nets, and the P3 parallel-network simulating system.',\n",
              "  'authors': ['David E. Rumelhart 1', ' James L. McClelland 2'],\n",
              "  'date': '1986',\n",
              "  'identifier': '1652505363',\n",
              "  'references': ['1614298861',\n",
              "   '2145339207',\n",
              "   '2076063813',\n",
              "   '2072128103',\n",
              "   '2116064496',\n",
              "   '2145094598',\n",
              "   '2025768430',\n",
              "   '2107941094',\n",
              "   '2154642048',\n",
              "   '2137983211'],\n",
              "  'title': 'Parallel distributed processing: explorations in the microstructure of cognition, vol. 1: foundations'},\n",
              " {'abstract': 'Adversarial robustness has become a central goal in deep learning, both in theory and in practice. However, successful methods to improve the adversarial robustness (such as adversarial training) greatly hurt generalization performance on the unperturbed data. This could have a major impact on how achieving adversarial robustness affects real world systems (i.e. many may opt to forego robustness if it can improve accuracy on the unperturbed data). We propose Interpolated Adversarial Training, which employs recently proposed interpolation based training methods in the framework of adversarial training. On CIFAR-10, adversarial training increases the standard test error (when there is no adversary) from 4.43% to 12.32%, whereas with our Interpolated adversarial training we retain adversarial robustness while achieving a standard test error of only 6.45%. With our technique, the relative increase in the standard error for the robust model is reduced from 178.1% to just 45.5%.',\n",
              "  'authors': ['Alex Lamb 1',\n",
              "   ' Vikas Verma 2',\n",
              "   ' Juho Kannala 2',\n",
              "   ' Yoshua Bengio 3'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2987875759',\n",
              "  'references': ['2194775991',\n",
              "   '2919115771',\n",
              "   '2964153729',\n",
              "   '2964253222',\n",
              "   '2964137095',\n",
              "   '2963374479',\n",
              "   '2963542245',\n",
              "   '2963399829',\n",
              "   '2962729158',\n",
              "   '2978426779'],\n",
              "  'title': 'Interpolated Adversarial Training: Achieving Robust Neural Networks Without Sacrificing Too Much Accuracy'},\n",
              " {'abstract': 'Despite extensive laboratory investigations in patients with respiratory tract infections, no microbiological cause can be identified in a significant proportion of patients. In the past 3 years, several novel respiratory viruses, including human metapneumovirus, severe acute respiratory syndrome (SARS) coronavirus (SARSCoV), and human coronavirus NL63, were discovered. Here we report the discovery of another novel coronavirus, coronavirus HKU1 (CoV-HKU1), from a 71-year-old man with pneumonia who had just returned from Shenzhen, China. Quantitative reverse transcription-PCR showed that the amount of CoV-HKU1 RNA was 8.5 to 9.6 10 6 copies per ml in his nasopharyngeal aspirates (NPAs) during the first week of the illness and dropped progressively to undetectable levels in subsequent weeks. He developed increasing serum levels of specific antibodies against the recombinant nucleocapsid protein of CoV-HKU1, with immunoglobulin M (IgM) titers of 1:20, 1:40, and 1:80 and IgG titers of <1:1,000, 1:2,000, and 1:8,000 in the first, second and fourth weeks of the illness, respectively. Isolation of the virus by using various cell lines, mixed neuron-glia culture, and intracerebral inoculation of suckling mice was unsuccessful. The complete genome sequence of CoV-HKU1 is a 29,926-nucleotide, polyadenylated RNA, with GC content of 32%, the lowest among all known coronaviruses with available genome sequence. Phylogenetic analysis reveals that CoV-HKU1 is a new group 2 coronavirus. Screening of 400 NPAs, negative for SARS-CoV, from patients with respiratory illness during the SARS period identified the presence of CoV-HKU1 RNA in an additional specimen, with a viral load of 1.13 10 6 copies per ml, from a 35-year-old woman with pneumonia. Our data support the existence of a novel group 2 coronavirus associated with pneumonia in humans.',\n",
              "  'authors': ['Patrick C. Y. Woo 1',\n",
              "   ' Susanna K. P. Lau 1',\n",
              "   ' Chung-ming Chu 2',\n",
              "   ' Kwok-hung Chan 3',\n",
              "   ' Hoi-wah Tsoi 3',\n",
              "   ' Yi Huang 3',\n",
              "   ' Beatrice H. L. Wong 3',\n",
              "   ' Rosana W. S. Poon 3',\n",
              "   ' James J. Cai 3',\n",
              "   ' Wei-kwang Luk 4',\n",
              "   ' Leo L. M. Poon 1',\n",
              "   ' Samson S. Y. Wong 1',\n",
              "   ' Yi Guan 1',\n",
              "   ' J. S. Malik Peiris 1',\n",
              "   ' Kwok-yung Yuen 1'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2170933940',\n",
              "  'references': ['2141885858',\n",
              "   '2025170735',\n",
              "   '2129542667',\n",
              "   '2116586125',\n",
              "   '2169198329',\n",
              "   '2171091522',\n",
              "   '2170881661',\n",
              "   '2134061616',\n",
              "   '2111412754',\n",
              "   '2141877163'],\n",
              "  'title': 'Characterization and Complete Genome Sequence of a Novel Coronavirus, Coronavirus HKU1, from Patients with Pneumonia'},\n",
              " {'abstract': 'The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed.',\n",
              "  'authors': ['Christopher G. Harris ', ' Mike Stephens'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2111308925',\n",
              "  'references': ['1639227073',\n",
              "   '1756736144',\n",
              "   '2063599328',\n",
              "   '2048192053',\n",
              "   '2039106392',\n",
              "   '2997169974'],\n",
              "  'title': 'A COMBINED CORNER AND EDGE DETECTOR'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Nutan Chen 1',\n",
              "   ' Alexej Klushyn 2',\n",
              "   ' Francesco Ferroni 3',\n",
              "   ' Justin Bayer 1',\n",
              "   ' Patrick van der Smagt 1'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3034543211',\n",
              "  'references': ['3034697580', '3113086944'],\n",
              "  'title': 'Learning Flat Latent Manifolds with VAEs'},\n",
              " {'abstract': 'Abstract Conceptual clustering has proved an effective means of summarizing data in an understandable manner. However, the recency of the conceptual clustering paradigm has allowed little exploration of conceptual clustering as a means of improving performance. This paper describes results obtained by COBWEB, a conceptual clustering system that organizes data so as to maximize inference abilities. The performance task for COBWEB (and implied for all conceptual clustering systems) generalizes the performance requirements typically associated with the better known task of learning from examples. Furthermore, criteria aimed at improving inference seem compatible with traditional conceptual clustering virtues of conceptual simplicity and comprehensibility.',\n",
              "  'authors': ['Douglas H. Fisher'],\n",
              "  'date': '1987',\n",
              "  'identifier': '30272054',\n",
              "  'references': ['2159047538',\n",
              "   '2070429602',\n",
              "   '167515793',\n",
              "   '2031977678',\n",
              "   '13520770',\n",
              "   '2037591014',\n",
              "   '2277957941',\n",
              "   '1601905586',\n",
              "   '2030647854',\n",
              "   '1564805656'],\n",
              "  'title': 'Conceptual Clustering, Learning from Examples, and Inference'},\n",
              " {'abstract': 'We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts. Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering. Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership. In many cases, the clusters can be thought of as encoding coarse sense distinctions. Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data. Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data.',\n",
              "  'authors': ['Fernando Pereira 1', ' Naftali Tishby 2', ' Lillian Lee 3'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2127314673',\n",
              "  'references': ['2099111195',\n",
              "   '2049633694',\n",
              "   '3017143921',\n",
              "   '2121227244',\n",
              "   '2099247782',\n",
              "   '2123084125',\n",
              "   '2025887562',\n",
              "   '2059800182',\n",
              "   '2016001305',\n",
              "   '1982944197'],\n",
              "  'title': 'DISTRIBUTIONAL CLUSTERING OF ENGLISH WORDS'},\n",
              " {'abstract': 'Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build “fully convolutional” networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by fine-tuning [3] to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.',\n",
              "  'authors': ['Jonathan Long ', ' Evan Shelhamer ', ' Trevor Darrell'],\n",
              "  'date': '2015',\n",
              "  'identifier': '1903029394',\n",
              "  'references': ['2618530766',\n",
              "   '2962835968',\n",
              "   '2097117768',\n",
              "   '2102605133',\n",
              "   '2155893237',\n",
              "   '1663973292',\n",
              "   '1849277567',\n",
              "   '2963542991',\n",
              "   '2109255472',\n",
              "   '2155541015'],\n",
              "  'title': 'Fully convolutional networks for semantic segmentation'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Urs-Viktor Marti ', ' Horst Bunke'],\n",
              "  'date': '1999',\n",
              "  'identifier': '101240229',\n",
              "  'references': ['2152928267',\n",
              "   '2147345686',\n",
              "   '2007714563',\n",
              "   '2171498274',\n",
              "   '2162395775',\n",
              "   '2107645346',\n",
              "   '2161369007',\n",
              "   '2111920731',\n",
              "   '2158078830',\n",
              "   '2202508626'],\n",
              "  'title': 'Towards General Cursive Script Recognition'},\n",
              " {'abstract': 'We describe a trainable system for analyzing videos of developing C. elegans embryos. The system automatically detects, segments, and locates cells and nuclei in microscopic images. The system was designed as the central component of a fully automated phenotyping system. The system contains three modules 1) a convolutional network trained to classify each pixel into five categories: cell wall, cytoplasm, nucleus membrane, nucleus, outside medium; 2) an energy-based model, which cleans up the output of the convolutional network by learning local consistency constraints that must be satisfied by label images; 3) a set of elastic models of the embryo at various stages of development that are matched to the label images.',\n",
              "  'authors': ['Feng Ning 1',\n",
              "   ' D. Delhomme 2',\n",
              "   ' Y. LeCun 3',\n",
              "   ' F. Piano 1',\n",
              "   ' L. Bottou 4',\n",
              "   ' P.E. Barbano 3'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2158778629',\n",
              "  'references': ['2164598857',\n",
              "   '2310919327',\n",
              "   '2147880316',\n",
              "   '2104095591',\n",
              "   '1647075334',\n",
              "   '2134557905',\n",
              "   '2121927366',\n",
              "   '2119823327',\n",
              "   '1991848143',\n",
              "   '2157364932'],\n",
              "  'title': 'Toward automatic phenotyping of developing embryos from videos'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Mingxing Tan ', ' Quoc V. Le'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2955425717',\n",
              "  'references': ['2955425717',\n",
              "   '3018757597',\n",
              "   '3034971973',\n",
              "   '3035160371',\n",
              "   '2994749257',\n",
              "   '2971315489',\n",
              "   '3036882155',\n",
              "   '3035743198'],\n",
              "  'title': 'EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks'},\n",
              " {'abstract': 'This paper considers a natural error correcting problem with real valued input/output. We wish to recover an input vector f/spl isin/R/sup n/ from corrupted measurements y=Af+e. Here, A is an m by n (coding) matrix and e is an arbitrary and unknown vector of errors. Is it possible to recover f exactly from the data y? We prove that under suitable conditions on the coding matrix A, the input f is the unique solution to the /spl lscr//sub 1/-minimization problem (/spl par/x/spl par//sub /spl lscr/1/:=/spl Sigma//sub i/|x/sub i/|) min(g/spl isin/R/sup n/) /spl par/y - Ag/spl par//sub /spl lscr/1/ provided that the support of the vector of errors is not too large, /spl par/e/spl par//sub /spl lscr/0/:=|{i:e/sub i/ /spl ne/ 0}|/spl les//spl rho//spl middot/m for some /spl rho/>0. In short, f can be recovered exactly by solving a simple convex optimization problem (which one can recast as a linear program). In addition, numerical experiments suggest that this recovery procedure works unreasonably well; f is recovered exactly even in situations where a significant fraction of the output is corrupted. This work is related to the problem of finding sparse solutions to vastly underdetermined systems of linear equations. There are also significant connections with the problem of recovering signals from highly incomplete measurements. In fact, the results introduced in this paper improve on our earlier work. Finally, underlying the success of /spl lscr//sub 1/ is a crucial property we call the uniform uncertainty principle that we shall describe in detail.',\n",
              "  'authors': ['E.J. Candes 1', ' T. Tao 2'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2129131372',\n",
              "  'references': ['2296319761',\n",
              "   '2296616510',\n",
              "   '2145096794',\n",
              "   '2129638195',\n",
              "   '2078204800',\n",
              "   '2116148865',\n",
              "   '2099641086',\n",
              "   '2050834445',\n",
              "   '2154332973',\n",
              "   '1573820523'],\n",
              "  'title': 'Decoding by linear programming'},\n",
              " {'abstract': \"The problem of the approximation of nonlinear mapping, (especially continuous mappings) is considered. Regularization theory and a theoretical framework for approximation (based on regularization techniques) that leads to a class of three-layer networks called regularization networks are discussed. Regularization networks are mathematically related to the radial basis functions, mainly used for strict interpolation tasks. Learning as approximation and learning as hypersurface reconstruction are discussed. Two extensions of the regularization approach are presented, along with the approach's corrections to splines, regularization, Bayes formulation, and clustering. The theory of regularization networks is generalized to a formulation that includes task-dependent clustering and dimensionality reduction. Applications of regularization networks are discussed. >\",\n",
              "  'authors': ['T. Poggio ', ' F. Girosi'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2143956139',\n",
              "  'references': ['2581275558',\n",
              "   '2154642048',\n",
              "   '2103496339',\n",
              "   '3017143921',\n",
              "   '2171277043',\n",
              "   '1971735090',\n",
              "   '65738273',\n",
              "   '2165758113',\n",
              "   '2019363670',\n",
              "   '94523489'],\n",
              "  'title': 'Networks for approximation and learning'},\n",
              " {'abstract': 'There has been significant progress on pose estimation and increasing interests on pose tracking in recent years. At the same time, the overall algorithm and system complexity increases as well, making the algorithm analysis and comparison more difficult. This work provides simple and effective baseline methods. They are helpful for inspiring and evaluating new ideas for the field. State-of-the-art results are achieved on challenging benchmarks. The code will be available at https://github.com/leoxiaobin/pose.pytorch.',\n",
              "  'authors': ['Bin Xiao 1', ' Haiping Wu 2', ' Yichen Wei 1'],\n",
              "  'date': '2018',\n",
              "  'identifier': '2963402313',\n",
              "  'references': ['2194775991',\n",
              "   '2618530766',\n",
              "   '2964121744',\n",
              "   '639708223',\n",
              "   '1836465849',\n",
              "   '2117539524',\n",
              "   '2806070179',\n",
              "   '1861492603',\n",
              "   '2964350391',\n",
              "   '2559085405'],\n",
              "  'title': 'Simple Baselines for Human Pose Estimation and Tracking'},\n",
              " {'abstract': 'Most face databases have been created under controlled conditions to facilitate the study of specific parameters on the face recognition problem. These parameters include such variables as position, pose, lighting, background, camera quality, and gender. While there are many applications for face recognition technology in which one can control the parameters of image acquisition, there are also many applications in which the practitioner has little or no control over such parameters. This database, Labeled Faces in the Wild, is provided as an aid in studying the latter, unconstrained, recognition problem. The database contains labeled face photographs spanning the range of conditions typically encountered in everyday life. The database exhibits “natural” variability in factors such as pose, lighting, race, accessories, occlusions, and background. In addition to describing the details of the database, we provide specific experimental paradigms for which the database is suitable. This is done in an effort to make research performed with the database as consistent and comparable as possible. We provide baseline results, including results of a state of the art face recognition system combined with a face alignment system. To facilitate experimentation on the database, we provide several parallel databases, including an aligned version.',\n",
              "  'authors': ['Gary B. Huang 1',\n",
              "   ' Marwan Mattar 1',\n",
              "   ' Tamara Berg 2',\n",
              "   ' Eric Learned-Miller 1'],\n",
              "  'date': '2008',\n",
              "  'identifier': '1782590233',\n",
              "  'references': ['3097096317',\n",
              "   '2121647436',\n",
              "   '1999478155',\n",
              "   '2033419168',\n",
              "   '2123921160',\n",
              "   '2137659841',\n",
              "   '2098693229',\n",
              "   '2125310925',\n",
              "   '2994340921',\n",
              "   '2006793117'],\n",
              "  'title': 'Labeled Faces in the Wild: A Database forStudying Face Recognition in Unconstrained Environments'},\n",
              " {'abstract': 'An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.',\n",
              "  'authors': ['D.G. Lowe'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2124386111',\n",
              "  'references': ['2914885528',\n",
              "   '2124087378',\n",
              "   '2123977795',\n",
              "   '2011891945',\n",
              "   '22745672',\n",
              "   '2096077837',\n",
              "   '2096600681',\n",
              "   '2131806657',\n",
              "   '2042243448',\n",
              "   '1553558465'],\n",
              "  'title': 'Object recognition from local scale-invariant features'},\n",
              " {'abstract': 'The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.',\n",
              "  'authors': ['Y. Bengio ', ' A. Courville ', ' P. Vincent'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2163922914',\n",
              "  'references': ['2618530766',\n",
              "   '2136922672',\n",
              "   '3118608800',\n",
              "   '2100495367',\n",
              "   '2310919327',\n",
              "   '2158899491',\n",
              "   '2162915993',\n",
              "   '2187089797',\n",
              "   '1665214252',\n",
              "   '2160815625'],\n",
              "  'title': 'Representation Learning: A Review and New Perspectives'},\n",
              " {'abstract': 'In December 2019, a cluster of patients with pneumonia of unknown cause was linked to a seafood wholesale market in Wuhan, China. A previously unknown betacoronavirus was discovered through the use of unbiased sequencing in samples from patients with pneumonia. Human airway epithelial cells were used to isolate a novel coronavirus, named 2019-nCoV, which formed a clade within the subgenus sarbecovirus, Orthocoronavirinae subfamily. Different from both MERS-CoV and SARS-CoV, 2019-nCoV is the seventh member of the family of coronaviruses that infect humans. Enhanced surveillance and further investigation are ongoing. (Funded by the National Key Research and Development Program of China and the National Major Project for Control and Prevention of Infectious Disease in China.).',\n",
              "  'authors': ['Na Zhu 1',\n",
              "   ' Dingyu Zhang 2',\n",
              "   ' Wenling Wang 1',\n",
              "   ' Xingwang Li 3',\n",
              "   ' Bo Yang 1',\n",
              "   ' Jingdong Song 1',\n",
              "   ' Xiang Zhao 1',\n",
              "   ' Baoying Huang 1',\n",
              "   ' Weifeng Shi 4',\n",
              "   ' Roujian Lu 1',\n",
              "   ' Peihua Niu 1',\n",
              "   ' Faxian Zhan 1',\n",
              "   ' Xuejun Ma 1',\n",
              "   ' Dayan Wang 1',\n",
              "   ' Wenbo Xu 1',\n",
              "   ' 5',\n",
              "   ' Guizhen Wu 1',\n",
              "   ' George F. Gao 6',\n",
              "   ' Wenjie Tan 1'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3001897055',\n",
              "  'references': ['2903899730',\n",
              "   '2166867592',\n",
              "   '2132260239',\n",
              "   '2104548316',\n",
              "   '2306794997',\n",
              "   '1909499787',\n",
              "   '3027518954',\n",
              "   '2792024998',\n",
              "   '2955025503',\n",
              "   '2257005270'],\n",
              "  'title': 'A Novel Coronavirus from Patients with Pneumonia in China, 2019.'},\n",
              " {'abstract': 'Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.',\n",
              "  'authors': ['Matthew D. Zeiler ', ' Rob Fergus'],\n",
              "  'date': '2014',\n",
              "  'identifier': '1849277567',\n",
              "  'references': ['2618530766',\n",
              "   '2102605133',\n",
              "   '2108598243',\n",
              "   '2136922672',\n",
              "   '1904365287',\n",
              "   '2155541015',\n",
              "   '2546302380',\n",
              "   '2025768430',\n",
              "   '2110798204',\n",
              "   '2097018403'],\n",
              "  'title': 'Visualizing and Understanding Convolutional Networks'},\n",
              " {'abstract': 'TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.',\n",
              "  'authors': ['Martín Abadi ',\n",
              "   ' Ashish Agarwal ',\n",
              "   ' Paul Barham ',\n",
              "   ' Eugene Brevdo ',\n",
              "   ' Zhifeng Chen ',\n",
              "   ' Craig Citro ',\n",
              "   ' Gregory S. Corrado ',\n",
              "   ' Andy Davis ',\n",
              "   ' Jeffrey Dean ',\n",
              "   ' Matthieu Devin ',\n",
              "   ' Sanjay Ghemawat ',\n",
              "   ' Ian J. Goodfellow ',\n",
              "   ' Andrew Harp ',\n",
              "   ' Geoffrey Irving ',\n",
              "   ' Michael Isard ',\n",
              "   ' Yangqing Jia ',\n",
              "   ' Rafal Józefowicz ',\n",
              "   ' Lukasz Kaiser ',\n",
              "   ' Manjunath Kudlur ',\n",
              "   ' Josh Levenberg ',\n",
              "   ' Dan Mané ',\n",
              "   ' Rajat Monga ',\n",
              "   ' Sherry Moore ',\n",
              "   ' Derek Gordon Murray ',\n",
              "   ' Chris Olah ',\n",
              "   ' Mike Schuster ',\n",
              "   ' Jonathon Shlens ',\n",
              "   ' Benoit Steiner ',\n",
              "   ' Ilya Sutskever ',\n",
              "   ' Kunal Talwar ',\n",
              "   ' Paul A. Tucker ',\n",
              "   ' Vincent Vanhoucke ',\n",
              "   ' Vijay Vasudevan ',\n",
              "   ' Fernanda B. Viégas ',\n",
              "   ' Oriol Vinyals ',\n",
              "   ' Pete Warden ',\n",
              "   ' Martin Wattenberg ',\n",
              "   ' Martin Wicke ',\n",
              "   ' Yuan Yu ',\n",
              "   ' Xiaoqiang Zheng'],\n",
              "  'date': '2015',\n",
              "  'identifier': '2271840356',\n",
              "  'references': ['2097117768',\n",
              "   '1836465849',\n",
              "   '1614298861',\n",
              "   '2130942839',\n",
              "   '2155893237',\n",
              "   '2064675550',\n",
              "   '2160815625',\n",
              "   '2168231600',\n",
              "   '2016053056',\n",
              "   '2131975293'],\n",
              "  'title': 'TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems'},\n",
              " {'abstract': 'From the Publisher: This is the first comprehensive treatment of feed-forward neural networks from the perspective of statistical pattern recognition. After introducing the basic concepts, the book examines techniques for modelling probability density functions and the properties and merits of the multi-layer perceptron and radial basis function network models. Also covered are various forms of error functions, principal algorithms for error function minimalization, learning and generalization in neural networks, and Bayesian techniques and their applications. Designed as a text, with over 100 exercises, this fully up-to-date work will benefit anyone involved in the fields of neural computation and pattern recognition.',\n",
              "  'authors': ['Christopher M. Bishop'],\n",
              "  'date': '1995',\n",
              "  'identifier': '1554663460',\n",
              "  'references': ['2194775991',\n",
              "   '2140190241',\n",
              "   '1746819321',\n",
              "   '1570448133',\n",
              "   '2139212933',\n",
              "   '1964357740',\n",
              "   '2117812871',\n",
              "   '1810943226',\n",
              "   '2097998348'],\n",
              "  'title': 'Neural networks for pattern recognition'},\n",
              " {'abstract': 'Suppose x is an unknown vector in Ropfm (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m1/4log5/2(m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscrp ball for 0<ples1. The N most important coefficients in that expansion allow reconstruction with lscr2 error O(N1/2-1p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of \"random\" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel\\'fand n-widths of lscrp balls in high-dimensional Euclidean space in the case 0<ples1, and give a criterion identifying near- optimal subspaces for Gel\\'fand n-widths. We show that \"most\" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces',\n",
              "  'authors': ['D.L. Donoho'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2296616510',\n",
              "  'references': ['2296319761',\n",
              "   '2145096794',\n",
              "   '2115755118',\n",
              "   '2129638195',\n",
              "   '2129131372',\n",
              "   '2135046866',\n",
              "   '2062024414',\n",
              "   '2078204800',\n",
              "   '2798909945',\n",
              "   '2138019504'],\n",
              "  'title': 'Compressed sensing'},\n",
              " {'abstract': 'In this paper we present a computationally efficient framework for part-based modeling and recognition of objects. Our work is motivated by the pictorial structure models introduced by Fischler and Elschlager. The basic idea is to represent an object by a collection of parts arranged in a deformable configuration. The appearance of each part is modeled separately, and the deformable configuration is represented by spring-like connections between pairs of parts. These models allow for qualitative descriptions of visual appearance, and are suitable for generic recognition problems. We address the problem of using pictorial structure models to find instances of an object in an image as well as the problem of learning an object model from training examples, presenting efficient algorithms in both cases. We demonstrate the techniques by learning models that represent faces and human bodies and using the resulting models to locate the corresponding objects in novel images.',\n",
              "  'authors': ['Pedro F. Felzenszwalb 1', ' Daniel P. Huttenlocher 2'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2030536784',\n",
              "  'references': ['2752885492',\n",
              "   '2138451337',\n",
              "   '2143516773',\n",
              "   '2159080219',\n",
              "   '1560013842',\n",
              "   '1997063559',\n",
              "   '301824129',\n",
              "   '2123977795',\n",
              "   '2085261163',\n",
              "   '1988520084'],\n",
              "  'title': 'Pictorial Structures for Object Recognition'},\n",
              " {'abstract': 'An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed. It is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views. For objects with sharp edges, the linear combination representation is exact. For objects with smooth boundaries, it is an approximation that often holds over a wide range of viewing angles. Rigid transformations (with or without scaling) can be distinguished from more general linear transformations of the object by testing certain constraints placed on the coefficients of the linear combinations. Three alternative methods of determining the transformation that matches a model to a given image are proposed. >',\n",
              "  'authors': ['S. Ullman ', ' R. Basri'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2053197265',\n",
              "  'references': ['2085261163',\n",
              "   '2125848778',\n",
              "   '1598123022',\n",
              "   '2164934677',\n",
              "   '1532977286',\n",
              "   '1981154266',\n",
              "   '1513966746',\n",
              "   '2125756925',\n",
              "   '1977827719',\n",
              "   '2088744610'],\n",
              "  'title': 'Recognition by linear combinations of models'},\n",
              " {'abstract': \"We have combined an artificial neural network (ANN) character classifier with context-driven search over character segmentation, word segmentation, and word recognition hypotheses to provide robust recognition of hand-printed English text in new models of Apple Computer's Newton Message Pad. We present some innovations in the training and use of ANNs as character classifiers for word recognition, including normalized output error, frequency balancing, error emphasis, negative training, and stroke warping. A recurring theme of reducing a priori biases emerges and is discussed.\",\n",
              "  'authors': ['Larry S. Yaeger 1', ' Richard F. Lyon 1', ' Brandyn J. Webb 2'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2166469100',\n",
              "  'references': ['2150884987',\n",
              "   '2137291015',\n",
              "   '2055075080',\n",
              "   '1980501707',\n",
              "   '2099070536',\n",
              "   '2111494971',\n",
              "   '2140539590',\n",
              "   '2124229187',\n",
              "   '2170541567',\n",
              "   '2607313294'],\n",
              "  'title': 'Effective Training of a Neural Network Character Classifier for Word Recognition'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Michael I. Jordan'],\n",
              "  'date': '1990',\n",
              "  'identifier': '1959983357',\n",
              "  'references': ['1546771929',\n",
              "   '2144499799',\n",
              "   '2136848157',\n",
              "   '1934184906',\n",
              "   '2016589492',\n",
              "   '1553004968',\n",
              "   '2128499899',\n",
              "   '1597190145',\n",
              "   '2986382673',\n",
              "   '2964138630'],\n",
              "  'title': 'Attractor dynamics and parallelism in a connectionist sequential machine'},\n",
              " {'abstract': 'Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224 $\\\\times$ 224) input image. This requirement is “artificial” and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, “spatial pyramid pooling”, to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102 $\\\\times$ faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank #2 in object detection and #3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.',\n",
              "  'authors': ['Kaiming He 1',\n",
              "   ' Xiangyu Zhang 2',\n",
              "   ' Shaoqing Ren 3',\n",
              "   ' Jian Sun 1'],\n",
              "  'date': '2015',\n",
              "  'identifier': '2109255472',\n",
              "  'references': ['2618530766',\n",
              "   '2962835968',\n",
              "   '2151103935',\n",
              "   '2097117768',\n",
              "   '2153635508',\n",
              "   '2102605133',\n",
              "   '2117539524',\n",
              "   '2161969291',\n",
              "   '2108598243',\n",
              "   '2168356304'],\n",
              "  'title': 'Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition'},\n",
              " {'abstract': 'THE standard form of back-propagation learning1 is implausible as a model of perceptual learning because it requires an external teacher to specify the desired output of the network. We show how the external teacher can be replaced by internally derived teaching signals. These signals are generated by using the assumption that different parts of the perceptual input have common causes in the external world. Small modules that look at separate but related parts of the perceptual input discover these common causes by striving to produce outputs that agree with each other (Fig. la). The modules may look at different modalities (such as vision and touch), or the same modality at different times (for example, the consecutive two-dimensional views of a rotating three-dimensional object), or even spatially adjacent parts of the same image. Our simulations show that when our learning procedure is applied to adjacent patches of two-dimensional images, it allows a neural network that has no prior knowledge of the third dimension to discover depth in random dot stereograms of curved surfaces.',\n",
              "  'authors': ['Suzanna Becker ', ' Geoffrey E. Hinton'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2063971957',\n",
              "  'references': ['1498436455', '2797583072', '1944592753'],\n",
              "  'title': 'Self-organizing neural network that discovers surfaces in random-dot stereograms'},\n",
              " {'abstract': \"In this work, we examine the security of InstaHide, a scheme recently proposed by [Huang, Song, Li and Arora, ICML'20] for preserving the security of private datasets in the context of distributed learning. To generate a synthetic training example to be shared among the distributed learners, InstaHide takes a convex combination of private feature vectors and randomly flips the sign of each entry of the resulting vector with probability 1/2. A salient question is whether this scheme is secure in any provable sense, perhaps under a plausible hardness assumption and assuming the distributions generating the public and private data satisfy certain properties. We show that the answer to this appears to be quite subtle and closely related to the average-case complexity of a new multi-task, missing-data version of the classic problem of phase retrieval. Motivated by this connection, we design a provable algorithm that can recover private vectors using only the public vectors and synthetic vectors generated by InstaHide, under the assumption that the private and public vectors are isotropic Gaussian.\",\n",
              "  'authors': ['Sitan Chen 1', ' Zhao Song ', ' Danyang Zhuo 2'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3106770805',\n",
              "  'references': ['2108598243',\n",
              "   '2963399829',\n",
              "   '2078397124',\n",
              "   '2142949395',\n",
              "   '2963443408',\n",
              "   '2963519230',\n",
              "   '2962767131',\n",
              "   '2026302946',\n",
              "   '3101774939',\n",
              "   '2962999772'],\n",
              "  'title': 'On InstaHide, Phase Retrieval, and Sparse Matrix Factorization.'},\n",
              " {'abstract': 'Three human coronaviruses are known to exist: human coronavirus 229E (HCoV-229E), HCoV-OC43 and severe acute respiratory syndrome (SARS)-associated coronavirus (SARS-CoV). Here we report the identification of a fourth human coronavirus, HCoV-NL63, using a new method of virus discovery. The virus was isolated from a 7-month-old child suffering from bronchiolitis and conjunctivitis. The complete genome sequence indicates that this virus is not a recombinant, but rather a new group 1 coronavirus. The in vitro host cell range of HCoV-NL63 is notable because it replicates on tertiary monkey kidney cells and the monkey kidney LLC-MK2 cell line. The viral genome contains distinctive features, including a unique N-terminal fragment within the spike protein. Screening of clinical specimens from individuals suffering from respiratory illness identified seven additional HCoV-NL63-infected individuals, indicating that the virus was widely spread within the human population.',\n",
              "  'authors': ['Lia van der Hoek 1',\n",
              "   ' Krzysztof Pyrc 1',\n",
              "   ' Maarten F Jebbink 1',\n",
              "   ' Wilma Vermeulen-Oost 2',\n",
              "   ' Ron J M Berkhout 2',\n",
              "   ' Katja C Wolthers 1',\n",
              "   ' Pauline M E Wertheim-van Dillen 1',\n",
              "   ' Jos Kaandorp 3',\n",
              "   ' Joke Spaargaren 2',\n",
              "   ' Ben Berkhout 1'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2111412754',\n",
              "  'references': ['2132260239',\n",
              "   '2104548316',\n",
              "   '2129542667',\n",
              "   '2116586125',\n",
              "   '2169198329',\n",
              "   '2134061616',\n",
              "   '2166229810',\n",
              "   '2163400707',\n",
              "   '2159857626',\n",
              "   '2029293367'],\n",
              "  'title': 'Identification of a new human coronavirus'},\n",
              " {'abstract': 'We survey the most widely-used algorithms for smoothing models for language n -gram modeling. We then present an extensive empirical comparison of several of these smoothing techniques, including those described by Jelinek and Mercer (1980); Katz (1987); Bell, Cleary and Witten (1990); Ney, Essen and Kneser (1994), and Kneser and Ney (1995). We investigate how factors such as training data size, training corpus (e.g. Brown vs. Wall Street Journal), count cutoffs, and n -gram order (bigram vs. trigram) affect the relative performance of these methods, which is measured through the cross-entropy of test data. We find that these factors can significantly affect the relative performance of models, with the most significant factor being training data size. Since no previous comparisons have examined these factors systematically, this is the first thorough characterization of the relative performance of various algorithms. In addition, we introduce methodologies for analyzing smoothing algorithm efficacy in detail, and using these techniques we motivate a novel variation of Kneser?Ney smoothing that consistently outperforms all other algorithms evaluated. Finally, results showing that improved language model smoothing leads to improved speech recognition performance are presented.',\n",
              "  'authors': ['Stanley F. Chen 1', ' Joshua Goodman 2'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2158195707',\n",
              "  'references': ['2170120409',\n",
              "   '2158195707',\n",
              "   '2121227244',\n",
              "   '2099247782',\n",
              "   '2097333193',\n",
              "   '1966812932',\n",
              "   '2611071497',\n",
              "   '2166637769',\n",
              "   '2134237567',\n",
              "   '2075201173'],\n",
              "  'title': 'An empirical study of smoothing techniques for language modeling'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Timothy C. Bell ', ' John G. Cleary ', ' Ian H. Witten'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2611071497',\n",
              "  'references': ['2053691921',\n",
              "   '2244729984',\n",
              "   '2158195707',\n",
              "   '1993803315',\n",
              "   '2138662031',\n",
              "   '2161439181',\n",
              "   '2088386938'],\n",
              "  'title': 'Text Compression'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Chiyuan Zhang 1',\n",
              "   ' Samy Bengio 2',\n",
              "   ' Moritz Hardt 2',\n",
              "   ' Benjamin Recht 3',\n",
              "   ' Oriol Vinyals 2'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2566079294',\n",
              "  'references': ['2963399829',\n",
              "   '2964013315',\n",
              "   '2966617434',\n",
              "   '2891612330',\n",
              "   '2892035503',\n",
              "   '2620998106',\n",
              "   '2963693742',\n",
              "   '2963239103',\n",
              "   '2963518130'],\n",
              "  'title': 'Understanding deep learning requires rethinking generalization'},\n",
              " {'abstract': \"Large corpora are ubiquitous in today's world and memory quickly becomes the limiting factor in practical applications of the Vector Space Model (VSM). We identify gap in existing VSM implementations, which is their scalability and ease of use. We describe a Natural Language Processing software framework which is based on the idea of document streaming, i.e. processing corpora document after document, in a memory independent fashion. In this framework, we implement several popular algorithms for topical inference, including Latent Semantic Analysis and Latent Dirichlet Allocation, in a way that makes them completely independent of the training corpus size. Particular emphasis is placed on straightforward and intuitive framework design, so that modifications and extensions of the methods and/or their application by interested practitioners are effortless. We demonstrate the usefulness of our approach on a real-world scenario of computing document similarities within an existing digital library DML-CZ.\",\n",
              "  'authors': ['Radim Řehůřek ', ' Petr Sojka'],\n",
              "  'date': '2010',\n",
              "  'identifier': '168564468',\n",
              "  'references': ['1880262756',\n",
              "   '2170120409',\n",
              "   '2001082470',\n",
              "   '2147152072',\n",
              "   '2158266063',\n",
              "   '2047804403',\n",
              "   '2143017621',\n",
              "   '2159426623',\n",
              "   '2334889010',\n",
              "   '2063392856'],\n",
              "  'title': 'Software Framework for Topic Modelling with Large Corpora'},\n",
              " {'abstract': 'We describe several improvements to Freund and Schapire‘s AdaBoost boosting algorithm, particularly in a setting in which hypotheses may assign confidences to each of their predictions. We give a simplified analysis of AdaBoost in this setting, and we show how this analysis can be used to find improved parameter settings as well as a refined criterion for training weak hypotheses. We give a specific method for assigning confidences to the predictions of decision trees, a method closely related to one used by Quinlan. This method also suggests a technique for growing decision trees which turns out to be identical to one proposed by Kearns and Mansour. We focus next on how to apply the new boosting algorithms to multiclass classification problems, particularly to the multi-label case in which each example may belong to more than one class. We give two boosting methods for this problem, plus a third method based on output coding. One of these leads to a new method for handling the single-label case which is simpler but as effective as techniques suggested by Freund and Schapire. Finally, we give some experimental results comparing a few of the algorithms discussed in this paper.',\n",
              "  'authors': ['Robert E. Schapire ', ' Yoram Singer'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2032210760',\n",
              "  'references': [],\n",
              "  'title': 'Improved boosting algorithms using confidence-rated predictions'},\n",
              " {'abstract': 'Full-text indexes provide fast substring search over large text collections. A serious problem of these indexes has traditionally been their space consumption. A recent trend is to develop indexes that exploit the compressibility of the text, so that their size is a function of the compressed text length. This concept has evolved into self-indexes, which in addition contain enough information to reproduce any text portion, so they replace the text. The exciting possibility of an index that takes space close to that of the compressed text, replaces it, and in addition provides fast search over it, has triggered a wealth of activity and produced surprising results in a very short time, which radically changed the status of this area in less than 5 years. The most successful indexes nowadays are able to obtain almost optimal space and search time simultaneously. In this article we present the main concepts underlying (compressed) self-indexes. We explain the relationship between text entropy and regularities that show up in index structures and permit compressing them. Then we cover the most relevant self-indexes, focusing on how they exploit text compressibility to achieve compact structures that can efficiently solve various search problems. Our aim is to give the background to understand and follow the developments in this area.',\n",
              "  'authors': ['Gonzalo Navarro 1', ' Veli Mäkinen 2'],\n",
              "  'date': '2007',\n",
              "  'identifier': '2088386938',\n",
              "  'references': ['2099111195',\n",
              "   '1660390307',\n",
              "   '2149906774',\n",
              "   '1990061958',\n",
              "   '2942925707',\n",
              "   '2158322625',\n",
              "   '1997841190',\n",
              "   '2161488606',\n",
              "   '3022618749',\n",
              "   '938539187'],\n",
              "  'title': 'Compressed full-text indexes'},\n",
              " {'abstract': 'Convex optimization problems arise frequently in many different fields. A comprehensive introduction to the subject, this book shows in detail how such problems can be solved numerically with great efficiency. The focus is on recognizing convex optimization problems and then finding the most appropriate technique for solving them. The text contains many worked examples and homework exercises and will appeal to students, researchers and practitioners in fields such as engineering, computer science, mathematics, statistics, finance, and economics.',\n",
              "  'authors': ['Stephen Boyd 1', ' Lieven Vandenberghe 2'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2296319761',\n",
              "  'references': ['2030723843',\n",
              "   '2000296233',\n",
              "   '2020830442',\n",
              "   '2006980285',\n",
              "   '82689443',\n",
              "   '2611147814'],\n",
              "  'title': 'Convex Optimization'},\n",
              " {'abstract': 'We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.',\n",
              "  'authors': ['Ronan Collobert ', ' Jason Weston'],\n",
              "  'date': '2008',\n",
              "  'identifier': '2117130368',\n",
              "  'references': ['2310919327',\n",
              "   '2132339004',\n",
              "   '2158847908',\n",
              "   '2130903752',\n",
              "   '2107008379',\n",
              "   '2914746235',\n",
              "   '2173629880',\n",
              "   '2885050925',\n",
              "   '2158823144',\n",
              "   '2163568299'],\n",
              "  'title': 'A unified architecture for natural language processing: deep neural networks with multitask learning'},\n",
              " {'abstract': 'We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.',\n",
              "  'authors': ['Matthew E. Peters 1',\n",
              "   ' Mark Neumann 1',\n",
              "   ' Mohit Iyyer 2',\n",
              "   ' Matt Gardner 3',\n",
              "   ' Christopher Clark 1',\n",
              "   ' Kenton Lee 4',\n",
              "   ' Luke Zettlemoyer 5'],\n",
              "  'date': '2018',\n",
              "  'identifier': '2962739339',\n",
              "  'references': ['2964121744',\n",
              "   '2153579005',\n",
              "   '2095705004',\n",
              "   '2250539671',\n",
              "   '2158899491',\n",
              "   '2064675550',\n",
              "   '2147880316',\n",
              "   '2251939518',\n",
              "   '2493916176',\n",
              "   '2963748441'],\n",
              "  'title': 'Deep contextualized word representations'},\n",
              " {'abstract': 'We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.',\n",
              "  'authors': ['N. Dalal ', ' B. Triggs'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2161969291',\n",
              "  'references': ['2151103935',\n",
              "   '2177274842',\n",
              "   '2145072179',\n",
              "   '2172188317',\n",
              "   '1576520375',\n",
              "   '2152473410',\n",
              "   '1608462934',\n",
              "   '1992825118',\n",
              "   '2295106276',\n",
              "   '2121899951'],\n",
              "  'title': 'Histograms of oriented gradients for human detection'},\n",
              " {'abstract': 'From the Publisher: Probabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\\x97and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\\x97in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. Probabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability.',\n",
              "  'authors': ['Judea Pearl'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2159080219',\n",
              "  'references': ['2581275558',\n",
              "   '1997063559',\n",
              "   '1593793857',\n",
              "   '2797148637',\n",
              "   '2155322595',\n",
              "   '158727920',\n",
              "   '2138162238',\n",
              "   '2108309071',\n",
              "   '1986808060',\n",
              "   '2142901448'],\n",
              "  'title': 'Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference'},\n",
              " {'abstract': 'Methods for voting classification algorithms, such as Bagging and AdaBoost, have been shown to be very successful in improving the accuracy of certain classifiers for artificial and real-world datasets. We review these algorithms and describe a large empirical study comparing several variants in conjunction with a decision tree inducer (three variants) and a Naive-Bayes inducer. The purpose of the study is to improve our understanding of why and when these algorithms, which use perturbation, reweighting, and combination techniques, affect classification error. We provide a bias and variance decomposition of the error to show how different methods and variants influence these two terms. This allowed us to determine that Bagging reduced variance of unstable methods, while boosting methods (AdaBoost and Arc-x4) reduced both the bias and variance of unstable methods but increased the variance for Naive-Bayes, which was very stable. We observed that Arc-x4 behaves differently than AdaBoost if reweighting is used instead of resampling, indicating a fundamental difference. Voting variants, some of which are introduced in this paper, include: pruning versus no pruning, use of probabilistic estimates, weight perturbations (Wagging), and backfitting of data. We found that Bagging improves when probabilistic estimates in conjunction with no-pruning are used, as well as when the data was backfit. We measure tree sizes and show an interesting positive correlation between the increase in the average tree size in AdaBoost trials and its success in reducing the error. We compare the mean-squared error of voting methods to non-voting methods and show that the voting methods lead to large and significant reductions in the mean-squared errors. Practical problems that arise in implementing boosting algorithms are explored, including numerical instabilities and underflows. We use scatterplots that graphically show how AdaBoost reweights instances, emphasizing not only “hard” areas but also outliers and noise.',\n",
              "  'authors': ['Eric Bauer 1', ' Ron Kohavi 2'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2152761983',\n",
              "  'references': ['2102865756',\n",
              "   '1988790447',\n",
              "   '2912934387',\n",
              "   '2084812512',\n",
              "   '2125055259',\n",
              "   '2112076978',\n",
              "   '1975846642',\n",
              "   '1680392829',\n",
              "   '2140785063',\n",
              "   '3017143921'],\n",
              "  'title': 'An Empirical Comparison of Voting Classification Algorithms: Bagging, Boosting, and Variants'},\n",
              " {'abstract': 'This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations.',\n",
              "  'authors': ['C. Schmid 1', ' R. Mohr 2'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2124087378',\n",
              "  'references': ['2914885528',\n",
              "   '2111308925',\n",
              "   '2098693229',\n",
              "   '2123977795',\n",
              "   '2095757522',\n",
              "   '2011891945',\n",
              "   '2109863423',\n",
              "   '2112328181',\n",
              "   '2022735534',\n",
              "   '2160835070'],\n",
              "  'title': 'Local grayvalue invariants for image retrieval'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Thorsten Joachims'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2107008379',\n",
              "  'references': [],\n",
              "  'title': 'Transductive Inference for Text Classification using Support Vector Machines'},\n",
              " {'abstract': 'We describe several improvements to Freund and Schapires AdaBoost boosting algorithm, particularly in a setting in which hypotheses may assign confidences to each of their predictions. We give a si...',\n",
              "  'authors': ['E SchapireRobert ', ' SingerYoram'],\n",
              "  'date': '1999',\n",
              "  'identifier': '3003716168',\n",
              "  'references': ['2605445762',\n",
              "   '2142827986',\n",
              "   '2119823327',\n",
              "   '2145310492',\n",
              "   '2436001372',\n",
              "   '2160218441',\n",
              "   '2155511848',\n",
              "   '1968405646',\n",
              "   '1999954155'],\n",
              "  'title': 'Improved Boosting Algorithms Using Confidence-rated Predictions'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Arthur P. Dempster ', ' Nan M. Laird ', ' Donald B. Rubin'],\n",
              "  'date': '1977',\n",
              "  'identifier': '2049633694',\n",
              "  'references': ['2798643531',\n",
              "   '2100358124',\n",
              "   '2074673068',\n",
              "   '2403035479',\n",
              "   '2327022120',\n",
              "   '1982585616',\n",
              "   '1575431606',\n",
              "   '2086699924',\n",
              "   '2000084758',\n",
              "   '2144578442'],\n",
              "  'title': 'Maximum likelihood from incomplete data via the EM algorithm'},\n",
              " {'abstract': 'The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data. High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.',\n",
              "  'authors': ['Corinna Cortes ', ' Vladimir Vapnik'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2119821739',\n",
              "  'references': ['2154642048',\n",
              "   '1498436455',\n",
              "   '2087347434',\n",
              "   '1530699444',\n",
              "   '2154579312',\n",
              "   '2168228682',\n",
              "   '2504871398',\n",
              "   '1568787085',\n",
              "   '5594912',\n",
              "   '2322002063'],\n",
              "  'title': 'Support-Vector Networks'},\n",
              " {'abstract': 'BACKGROUND: The severe acute respiratory syndrome (SARS) has recently been identified as a new clinical entity. SARS is thought to be caused by an unknown infectious agent. METHODS: Clinical specimens from patients with SARS were searched for unknown viruses with the use of cell cultures and molecular techniques. RESULTS: A novel coronavirus was identified in patients with SARS. The virus was isolated in cell culture, and a sequence 300 nucleotides in length was obtained by a polymerase-chain-reaction (PCR)-based random-amplification procedure. Genetic characterization indicated that the virus is only distantly related to known coronaviruses (identical in 50 to 60 percent of the nucleotide sequence). On the basis of the obtained sequence, conventional and real-time PCR assays for specific and sensitive detection of the novel virus were established. Virus was detected in a variety of clinical specimens from patients with SARS but not in controls. High concentrations of viral RNA of up to 100 million molecules per milliliter were found in sputum. Viral RNA was also detected at extremely low concentrations in plasma during the acute phase and in feces during the late convalescent phase. Infected patients showed seroconversion on the Vero cells in which the virus was isolated. CONCLUSIONS: The novel coronavirus might have a role in causing SARS.',\n",
              "  'authors': ['Christian Drosten 1',\n",
              "   ' Stephan Günther 1',\n",
              "   ' Wolfgang Preiser 2',\n",
              "   ' Sylvie van der Werf 3',\n",
              "   ' Hans-Reinhard Brodt 4',\n",
              "   ' Stephan Becker 5',\n",
              "   ' Holger Rabenau 2',\n",
              "   ' Marcus Panning 1',\n",
              "   ' Larissa Kolesnikova 5',\n",
              "   ' Ron A.M. Fouchier 6',\n",
              "   ' Annemarie Berger 2',\n",
              "   ' Ana-Maria Burguière 3',\n",
              "   ' Jindrich Cinatl 2',\n",
              "   ' Markus Eickmann 5',\n",
              "   ' Nicolas Escriou 3',\n",
              "   ' Klaus Grywna 1',\n",
              "   ' Stefanie Kramme 1',\n",
              "   ' Jean-Claude Manuguerra 3',\n",
              "   ' Stefanie Müller 1',\n",
              "   ' Volker Rickerts 4',\n",
              "   ' Martin Stürmer 2',\n",
              "   ' Simon Vieth 1',\n",
              "   ' Hans-Dieter Klenk 5',\n",
              "   ' Albert D.M.E. Osterhaus 6',\n",
              "   ' Herbert Schmitz 1',\n",
              "   ' Hans Wilhelm Doerr 2'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2132260239',\n",
              "  'references': ['2100820722',\n",
              "   '2125251240',\n",
              "   '2107922358',\n",
              "   '2127062009',\n",
              "   '2084994773',\n",
              "   '2149579937',\n",
              "   '2090060897',\n",
              "   '2004869546',\n",
              "   '2030133843'],\n",
              "  'title': 'Identification of a novel coronavirus in patients with severe acute respiratory syndrome.'},\n",
              " {'abstract': 'Abstract When integrating visual features into 3D for a structure from motion algorithm, the connectivity and relationships of features are an important adjunct to any quantitative 3D geometry. This paper describes a general purpose vision system which aims to perceive and refine this topology in conjunction with geometry, using edges, vertices and isolated corners extracted from a sequence of monocular images of an unconstrained scene. Rules which tackle the practical difficulties of imperfect image processing and obscuration features are defined. Results are shown for a rotating view of a polyhedral object and for an outdoor scene viewed from a moving vehicle.',\n",
              "  'authors': ['Mike Stephens ', ' Chris Harris'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2039106392',\n",
              "  'references': ['2111308925',\n",
              "   '2063599328',\n",
              "   '2048192053',\n",
              "   '2331801068',\n",
              "   '2020554914',\n",
              "   '2116453783',\n",
              "   '2065537272'],\n",
              "  'title': '3D wire-frame integration from image sequences'},\n",
              " {'abstract': \"Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.\",\n",
              "  'authors': ['Sergey Ioffe ', ' Christian Szegedy'],\n",
              "  'date': '2015',\n",
              "  'identifier': '1836465849',\n",
              "  'references': ['2097117768',\n",
              "   '2117539524',\n",
              "   '2095705004',\n",
              "   '1677182931',\n",
              "   '2146502635',\n",
              "   '2310919327',\n",
              "   '1665214252',\n",
              "   '2168231600',\n",
              "   '1533861849',\n",
              "   '104184427'],\n",
              "  'title': 'Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift'},\n",
              " {'abstract': 'We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders – a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.',\n",
              "  'authors': ['Deepak Pathak ',\n",
              "   ' Philipp Krahenbuhl ',\n",
              "   ' Jeff Donahue ',\n",
              "   ' Trevor Darrell ',\n",
              "   ' Alexei A. Efros'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2963420272',\n",
              "  'references': ['2618530766',\n",
              "   '2964121744',\n",
              "   '2102605133',\n",
              "   '2117539524',\n",
              "   '1903029394',\n",
              "   '2153579005',\n",
              "   '2099471712',\n",
              "   '2155893237',\n",
              "   '1536680647',\n",
              "   '1849277567'],\n",
              "  'title': 'Context Encoders: Feature Learning by Inpainting'},\n",
              " {'abstract': 'In March 2003, a novel coronavirus (SARS-CoV) was discovered in association with cases of severe acute respiratory syndrome (SARS). The sequence of the complete genome of SARS-CoV was determined, and the initial characterization of the viral genome is presented in this report. The genome of SARS-CoV is 29,727 nucleotides in length and has 11 open reading frames, and its genome organization is similar to that of other coronaviruses. Phylogenetic analyses and sequence comparisons showed that SARS-CoV is not closely related to any of the previously characterized coronaviruses.',\n",
              "  'authors': ['Paul A. Rota 1',\n",
              "   ' M. Steven Oberste 1',\n",
              "   ' Stephan S. Monroe 1',\n",
              "   ' W. Allan Nix 1',\n",
              "   ' Ray Campagnoli 1',\n",
              "   ' Joseph P. Icenogle 1',\n",
              "   ' Silvia Peñaranda 1',\n",
              "   ' Bettina Bankamp 1',\n",
              "   ' Kaija Maher 1',\n",
              "   ' Min hsin Chen 1',\n",
              "   ' Suxiong Tong 1',\n",
              "   ' Azaibi Tamin 1',\n",
              "   ' Luis Lowe 1',\n",
              "   ' Michael Frace 1',\n",
              "   ' Joseph L. DeRisi 2',\n",
              "   ' Qi Chen 1',\n",
              "   ' David Wang 2',\n",
              "   ' Dean D. Erdman 1',\n",
              "   ' Teresa C.T. Peret 1',\n",
              "   ' Cara Burns 1',\n",
              "   ' Thomas G. Ksiazek 1',\n",
              "   ' Pierre E. Rollin 1',\n",
              "   ' Anthony Sanchez 1',\n",
              "   ' Stephanie Liffick 1',\n",
              "   ' Brian Holloway 1',\n",
              "   ' Josef Limor 1',\n",
              "   ' Karen McCaustland 1',\n",
              "   ' Mellissa Olsen-Rasmussen 1',\n",
              "   ' Ron Fouchier 3',\n",
              "   ' Stephan Günther 4',\n",
              "   ' Albert D.H.E. Osterhaus 3',\n",
              "   ' Christian Drosten 4',\n",
              "   ' Mark A. Pallansch 1',\n",
              "   ' Larry J. Anderson 1',\n",
              "   ' William J. Bellini 1'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2116586125',\n",
              "  'references': ['2025170735',\n",
              "   '2169198329',\n",
              "   '2163400707',\n",
              "   '2103854602',\n",
              "   '2048093932',\n",
              "   '2152215476',\n",
              "   '72835126',\n",
              "   '2027659163',\n",
              "   '2126980050',\n",
              "   '2097622821'],\n",
              "  'title': 'Characterization of a novel coronavirus associated with severe acute respiratory syndrome'},\n",
              " {'abstract': '',\n",
              "  'authors': ['John Morton'],\n",
              "  'date': '1969',\n",
              "  'identifier': '2040187703',\n",
              "  'references': ['1784695092',\n",
              "   '1878893887',\n",
              "   '1994063459',\n",
              "   '2049059074',\n",
              "   '2073588290',\n",
              "   '2319178748',\n",
              "   '2008615354',\n",
              "   '2004522115',\n",
              "   '2048978768',\n",
              "   '1965555283'],\n",
              "  'title': 'Interaction of information in word recognition.'},\n",
              " {'abstract': 'A previously proposed model for memory based on neurophysiolo gical considerations is reviewed. We assume that (a) nervous system activity is usefully represented as the set of simultaneous individual neuron activities in a group of neurons; (b) different memory traces make use of the same synapses; and (c) synapses associate two patterns of neural activity by incrementing synaptic connectivity proportionally to the product of pre- and postsynaptic activity, forming a matrix of synaptic connectivities. We extend this model by (a) introducing positive feedback of a set of neurons onto itself and (b) allowing the individual neurons to saturate. A hybrid model, partly analog and partly binary, arises. The system has certain characteristics reminiscent of analysis by distinctive features. Next, we apply the model to \"categorical perception.\" Finally, we discuss probability learning. The model can predict overshooting, recency data, and probabilities occurring in systems with more than two events with reasonably good accuracy.',\n",
              "  'authors': ['James A. Anderson ',\n",
              "   ' Jack W. Silverstein ',\n",
              "   ' Stephen A. Ritz ',\n",
              "   ' Randall S. Jones'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2147311265',\n",
              "  'references': ['22297218',\n",
              "   '2116360511',\n",
              "   '2117731089',\n",
              "   '2082622165',\n",
              "   '2147502381',\n",
              "   '181468950',\n",
              "   '2023182894',\n",
              "   '2013239224',\n",
              "   '2414458198',\n",
              "   '2011238950'],\n",
              "  'title': 'Distinctive features, categorical perception, and probability learning: some applications of a neural model'},\n",
              " {'abstract': 'Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.',\n",
              "  'authors': ['Yangqing Jia 1',\n",
              "   ' Evan Shelhamer 2',\n",
              "   ' Jeff Donahue 2',\n",
              "   ' Sergey Karayev 2',\n",
              "   ' Jonathan Long 2',\n",
              "   ' Ross Girshick 2',\n",
              "   ' Sergio Guadarrama 2',\n",
              "   ' Trevor Darrell 2'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2155893237',\n",
              "  'references': ['2618530766',\n",
              "   '2102605133',\n",
              "   '2963542991',\n",
              "   '2088049833',\n",
              "   '2155541015',\n",
              "   '753012316',\n",
              "   '1825604117',\n",
              "   '2147414309',\n",
              "   '1872489089',\n",
              "   '2962883796'],\n",
              "  'title': 'Caffe: Convolutional Architecture for Fast Feature Embedding'},\n",
              " {'abstract': 'We present a rigorously validated and highly sensitive confirmatory real-time RT-PCR assay (1A assay) that can be used in combination with the previously reported upE assay. Two additional RT-PCR assays for sequencing are described, targeting the RdRp gene (RdRpSeq assay) and N gene (NSeq assay), where an insertion/deletion polymorphism might exist among different hCoV-EMC strains. Finally, a simplified and biologically safe protocol for detection of antibody response by immunofluorescence microscopy was developed using convalescent patient serum.',\n",
              "  'authors': ['Victor Corman 1',\n",
              "   ' Marcel Müller 1',\n",
              "   ' U. Costabel 2',\n",
              "   ' J. Timm 2',\n",
              "   ' Tabea Binger 1',\n",
              "   ' Bernhard Meyer 1',\n",
              "   ' P. Kreher 3',\n",
              "   ' Erik Lattwein 4',\n",
              "   ' Monika Eschbach-Bludau 1',\n",
              "   ' A. Nitsche 3',\n",
              "   ' T. Bleicker 1',\n",
              "   ' O. Landt 5',\n",
              "   ' Brunhilde Schweiger 3',\n",
              "   ' Jan-Felix Drexler 1',\n",
              "   ' Albert Osterhaus 6',\n",
              "   ' Bart Haagmans 6',\n",
              "   ' U. Dittmer 2',\n",
              "   ' F. Bonin 2',\n",
              "   ' Thorsten Wolff 3',\n",
              "   ' Christian Drosten 1'],\n",
              "  'date': '2012',\n",
              "  'identifier': '1852588318',\n",
              "  'references': ['2166867592',\n",
              "   '2129542667',\n",
              "   '1703839189',\n",
              "   '1690366459',\n",
              "   '2167080692',\n",
              "   '2082755732',\n",
              "   '1593955729',\n",
              "   '2145810580',\n",
              "   '2122612816',\n",
              "   '2136039989'],\n",
              "  'title': 'Assays for laboratory confirmation of novel human coronavirus (hCoV-EMC) infections.'},\n",
              " {'abstract': 'Nonlinear principal component analysis is a novel technique for multivariate data analysis, similar to the well-known method of principal component analysis. NLPCA, like PCA, is used to identify and remove correlations among problem variables as an aid to dimensionality reduction, visualization, and exploratory data analysis. While PCA identifies only linear correlations between variables, NLPCA uncovers both linear and nonlinear correlations, without restriction on the character of the nonlinearities present in the data. NLPCA operates by training a feedforward neural network to perform the identity mapping, where the network inputs are reproduced at the output layer. The network contains an internal “bottleneck” layer (containing fewer nodes than input or output layers), which forces the network to develop a compact representation of the input data, and two additional hidden layers. The NLPCA method is demonstrated using time-dependent, simulated batch reaction data. Results show that NLPCA successfully reduces dimensionality and produces a feature space map resembling the actual distribution of the underlying system parameters.',\n",
              "  'authors': ['Mark A. Kramer'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2122538988',\n",
              "  'references': ['2154642048',\n",
              "   '1965324089',\n",
              "   '2103496339',\n",
              "   '3017143921',\n",
              "   '2158863190',\n",
              "   '1507849272',\n",
              "   '2131329059',\n",
              "   '3121126077',\n",
              "   '2078626246',\n",
              "   '145476170'],\n",
              "  'title': 'Nonlinear principal component analysis using autoassociative neural networks'},\n",
              " {'abstract': 'We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be repurposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.',\n",
              "  'authors': ['Jeff Donahue ',\n",
              "   ' Yangqing Jia ',\n",
              "   ' Oriol Vinyals ',\n",
              "   ' Judy Hoffman ',\n",
              "   ' Ning Zhang ',\n",
              "   ' Eric Tzeng ',\n",
              "   ' Trevor Darrell'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2155541015',\n",
              "  'references': ['2618530766',\n",
              "   '2161969291',\n",
              "   '2108598243',\n",
              "   '2168356304',\n",
              "   '2100495367',\n",
              "   '2310919327',\n",
              "   '1677409904',\n",
              "   '1904365287',\n",
              "   '2187089797',\n",
              "   '2546302380'],\n",
              "  'title': 'DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition'},\n",
              " {'abstract': 'Abstract This paper proposes a robust approach to image matching by exploiting the only available geometric constraint, namely, the epipolar constraint. The images are uncalibrated, namely the motion between them and the camera parameters are not known. Thus, the images can be taken by different cameras or a single camera at different time instants. If we make an exhaustive search for the epipolar geometry, the complexity is prohibitively high. The idea underlying our approach is to use classical techniques (correlation and relaxation methods in our particular implementation) to find an initial set of matches, and then use a robust technique—the Least Median of Squares (LMedS)—to discard false matches in this set. The epipolar geometry can then be accurately estimated using a meaningful image criterion. More matches are eventually found, as in stereo matching, by using the recovered epipolar geometry. A large number of experiments have been carried out, and very good results have been obtained. Regarding the relaxation technique, we define a new measure of matching support, which allows a higher tolerance to deformation with respect to rigid transformations in the image plane and a smaller contribution for distant matches than for nearby ones. A new strategy for updating matches is developed, which only selects those matches having both high matching support and low matching ambiguity. The update strategy is different from the classical “winner-take-all”, which is easily stuck at a local minimum, and also from “loser-take-nothing”, which is usually very slow. The proposed algorithm has been widely tested and works remarkably well in a scene with many repetitive patterns.',\n",
              "  'authors': ['Zhengyou Zhang ',\n",
              "   ' Rachid Deriche ',\n",
              "   ' Olivier Faugeras ',\n",
              "   ' Quang-Tuan Luong'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2011891945',\n",
              "  'references': ['2111308925',\n",
              "   '2129249398',\n",
              "   '2740373864',\n",
              "   '1598123022',\n",
              "   '2065592949',\n",
              "   '2164934677',\n",
              "   '2090949637',\n",
              "   '1602748186',\n",
              "   '2009086487',\n",
              "   '2025934818'],\n",
              "  'title': 'A robust technique for matching two uncalibrated images through the recovery of the unknown epipolar geometry'},\n",
              " {'abstract': 'Abstract This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.',\n",
              "  'authors': ['K. Hornik 1', ' M. Stinchcombe 2', ' H. White 2'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2137983211',\n",
              "  'references': ['1652505363',\n",
              "   '2103496339',\n",
              "   '2056099894',\n",
              "   '2416739038',\n",
              "   '2090270852',\n",
              "   '1654142532',\n",
              "   '1581292930',\n",
              "   '135768573',\n",
              "   '2097415784'],\n",
              "  'title': 'Multilayer feedforward networks are universal approximators'},\n",
              " {'abstract': 'We present GraphMix, a regularization method for Graph Neural Network based semi-supervised object classification, whereby we propose to train a fully-connected network jointly with the graph neural network via parameter sharing and interpolation-based regularization. Further, we provide a theoretical analysis of how GraphMix improves the generalization bounds of the underlying graph neural network, without making any assumptions about the \"aggregation\" layer or the depth of the graph neural networks. We experimentally validate this analysis by applying GraphMix to various architectures such as Graph Convolutional Networks, Graph Attention Networks and Graph-U-Net. Despite its simplicity, we demonstrate that GraphMix can consistently improve or closely match state-of-the-art performance using even simpler architectures such as Graph Convolutional Networks, across three established graph benchmarks: Cora, Citeseer and Pubmed citation network datasets, as well as three newly proposed datasets: Cora-Full, Co-author-CS and Co-author-Physics.',\n",
              "  'authors': ['Vikas Verma ',\n",
              "   ' Meng Qu ',\n",
              "   ' Kenji Kawaguchi ',\n",
              "   ' Alex Lamb ',\n",
              "   ' Yoshua Bengio ',\n",
              "   ' Juho Kannala ',\n",
              "   ' Jian Tang'],\n",
              "  'date': '2019',\n",
              "  'identifier': '3092206109',\n",
              "  'references': ['2187089797',\n",
              "   '2964015378',\n",
              "   '3104097132',\n",
              "   '2963858333',\n",
              "   '2964321699',\n",
              "   '2962767366',\n",
              "   '2624431344',\n",
              "   '2104290444',\n",
              "   '2606780347',\n",
              "   '2048679005'],\n",
              "  'title': 'GraphMix: Improved Training of GNNs for Semi-Supervised Learning'},\n",
              " {'abstract': 'Probabilistic Latent Semantic Analysis is a novel statistical technique for the analysis of two-mode and co-occurrence data, which has applications in information retrieval and filtering, natural language processing, machine learning from text, and in related areas. Compared to standard Latent Semantic Analysis which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed method is based on a mixture decomposition derived from a latent class model. This results in a more principled approach which has a solid foundation in statistics. In order to avoid overfitting, we propose a widely applicable generalization of maximum likelihood model fitting by tempered EM. Our approach yields substantial and consistent improvements over Latent Semantic Analysis in a number of experiments.',\n",
              "  'authors': ['Thomas Hofmann'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1612003148',\n",
              "  'references': ['2147152072',\n",
              "   '2049633694',\n",
              "   '2107743791',\n",
              "   '1956559956',\n",
              "   '1983578042',\n",
              "   '2134731454',\n",
              "   '2127314673',\n",
              "   '2056029990',\n",
              "   '2140842551',\n",
              "   '2143144851'],\n",
              "  'title': 'Probabilistic latent semantic analysis'},\n",
              " {'abstract': 'Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, \"powerful,\" \"strong\" and \"Paris\" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperforms bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.',\n",
              "  'authors': ['Quoc Le ', ' Tomas Mikolov'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2131744502',\n",
              "  'references': ['2153579005',\n",
              "   '1614298861',\n",
              "   '2158899491',\n",
              "   '2131744502',\n",
              "   '2251939518',\n",
              "   '2141599568',\n",
              "   '2117130368',\n",
              "   '2132339004',\n",
              "   '2158139315',\n",
              "   '2113459411'],\n",
              "  'title': 'Distributed Representations of Sentences and Documents'},\n",
              " {'abstract': 'The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.',\n",
              "  'authors': ['Y. LeCun ',\n",
              "   ' B. Boser ',\n",
              "   ' J. S. Denker ',\n",
              "   ' D. Henderson ',\n",
              "   ' R. E. Howard ',\n",
              "   ' W. Hubbard ',\n",
              "   ' L. D. Jackel'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2147800946',\n",
              "  'references': ['2154642048',\n",
              "   '2165758113',\n",
              "   '169539560',\n",
              "   '19621276',\n",
              "   '2101926813',\n",
              "   '2157475639',\n",
              "   '1965770722',\n",
              "   '56903235',\n",
              "   '2606594511',\n",
              "   '2116360511'],\n",
              "  'title': 'Backpropagation applied to handwritten zip code recognition'},\n",
              " {'abstract': 'We propose a method for inferring human attributes (such as gender, hair style, clothes style, expression, action) from images of people under large variation of viewpoint, pose, appearance, articulation and occlusion. Convolutional Neural Nets (CNN) have been shown to perform very well on large scale object recognition problems. In the context of attribute classification, however, the signal is often subtle and it may cover only a small part of the image, while the image is dominated by the effects of pose and viewpoint. Discounting for pose variation would require training on very large labeled datasets which are not presently available. Part-based models, such as poselets [4] and DPM [12] have been shown to perform well for this problem but they are limited by shallow low-level features. We propose a new method which combines part-based models and deep learning by training pose-normalized CNNs. We show substantial improvement vs. state-of-the-art methods on challenging attribute classification tasks in unconstrained settings. Experiments confirm that our method outperforms both the best part-based methods on this problem and conventional CNNs trained on the full bounding box of the person.',\n",
              "  'authors': ['Ning Zhang 1',\n",
              "   ' Manohar Paluri 2',\n",
              "   \" Marc'Aurelio Ranzato 2\",\n",
              "   ' Trevor Darrell 1',\n",
              "   ' Lubomir Bourdev 2'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2147414309',\n",
              "  'references': ['2618530766',\n",
              "   '2168356304',\n",
              "   '2310919327',\n",
              "   '2155541015',\n",
              "   '2162915993',\n",
              "   '2546302380',\n",
              "   '1498436455',\n",
              "   '2536626143',\n",
              "   '2134270519',\n",
              "   '2098411764'],\n",
              "  'title': 'PANDA: Pose Aligned Networks for Deep Attribute Modeling'},\n",
              " {'abstract': \"Summary Background Human infection with a novel coronavirus named Middle East Respiratory Syndrome coronavirus (MERS-CoV) was first identified in Saudi Arabia and the Middle East in September, 2012, with 44 laboratory-confirmed cases as of May 23, 2013. We report detailed clinical and virological data for two related cases of MERS-CoV disease, after nosocomial transmission of the virus from one patient to another in a French hospital. Methods Patient 1 visited Dubai in April, 2013; patient 2 lives in France and did not travel abroad. Both patients had underlying immunosuppressive disorders. We tested specimens from the upper (nasopharyngeal swabs) or the lower (bronchoalveolar lavage, sputum) respiratory tract and whole blood, plasma, and serum specimens for MERS-CoV by real-time RT-PCR targeting the upE and Orf1A genes of MERS-CoV. Findings Initial clinical presentation included fever, chills, and myalgia in both patients, and for patient 1, diarrhoea. Respiratory symptoms rapidly became predominant with acute respiratory failure leading to mechanical ventilation and extracorporeal membrane oxygenation (ECMO). Both patients developed acute renal failure. MERS-CoV was detected in lower respiratory tract specimens with high viral load (eg, cycle threshold [Ct] values of 22·9 for upE and 24 for Orf1a for a bronchoalveolar lavage sample from patient 1; Ct values of 22·5 for upE and 23·9 for Orf1a for an induced sputum sample from patient 2), whereas nasopharyngeal specimens were weakly positive or inconclusive. The two patients shared the same room for 3 days. The incubation period was estimated at 9–12 days for the second case. No secondary transmission was documented in hospital staff despite the absence of specific protective measures before the diagnosis of MERS-CoV was suspected. Patient 1 died on May 28, due to refractory multiple organ failure. Interpretation Patients with respiratory symptoms returning from the Middle East or exposed to a confirmed case should be isolated and investigated for MERS-CoV with lower respiratory tract sample analysis and an assumed incubation period of 12 days. Immunosuppression should also be taken into account as a risk factor. Funding French Institute for Public Health Surveillance, ANR grant Labex Integrative Biology of Emerging Infectious Diseases, and the European Community's Seventh Framework Programme projects EMPERIE and PREDEMICS.\",\n",
              "  'authors': ['Benoit Guery 1',\n",
              "   ' Julien Poissy 1',\n",
              "   ' Loubna El Mansouf 2',\n",
              "   ' Caroline Séjourné 3',\n",
              "   ' Nicolas Ettahar 4',\n",
              "   ' Xavier Lemaire 2',\n",
              "   ' Fanny Vuotto 1',\n",
              "   ' Anne Goffard 1',\n",
              "   ' Sylvie Behillil 5',\n",
              "   ' 6',\n",
              "   ' 7',\n",
              "   ' Vincent Enouf 5',\n",
              "   ' 6',\n",
              "   ' 7',\n",
              "   ' Valérie Caro 5',\n",
              "   ' Alexandra Mailles 8',\n",
              "   ' Didier Che 8',\n",
              "   ' Jean Claude Manuguerra 5',\n",
              "   ' Daniel Mathieu 1',\n",
              "   ' Arnaud Fontanet 5',\n",
              "   ' 9',\n",
              "   ' Sylvie Van Der Werf 5',\n",
              "   ' 6',\n",
              "   ' 7'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2119775949',\n",
              "  'references': ['2166867592',\n",
              "   '2129542667',\n",
              "   '1703839189',\n",
              "   '2112147913',\n",
              "   '2113457186',\n",
              "   '1852588318',\n",
              "   '2163627712',\n",
              "   '2046153984',\n",
              "   '1690366459',\n",
              "   '1998725525'],\n",
              "  'title': 'Clinical features and viral diagnosis of two cases of infection with Middle East Respiratory Syndrome coronavirus: a report of nosocomial transmission'},\n",
              " {'abstract': 'The recent discoveries of novel human coronaviruses, including the coronavirus causing SARS, and the previously unrecognized human coronaviruses HCoV-NL63 and HCoV-HKU1, indicate that the family Coronaviridae harbors more members than was previously assumed. All human coronaviruses characterized at present are associated with respiratory illnesses, ranging from mild common colds to more severe lower respiratory tract infections. Since the etiology of a relatively large percentage of respiratory tract diseases remains unidentified, it is possible that for a certain number of these illnesses, a yet unknown viral causative agent may be found. Screening for the presence of novel coronaviruses requires the use of a method that can detect all coronaviruses known at present. In this chapter, we describe a pancoronavirus degenerate primer-based method that allows the detection of all known and possibly unknown coronaviruses by RT-PCR amplification and sequencing of a 251-bp fragment of the coronavirus polymerase gene.',\n",
              "  'authors': ['Leen Vijgen ',\n",
              "   ' Elien Moës ',\n",
              "   ' Els Keyaerts ',\n",
              "   ' Sandra Li ',\n",
              "   ' Marc Van Ranst'],\n",
              "  'date': '2008',\n",
              "  'identifier': '1593955729',\n",
              "  'references': ['2055043387',\n",
              "   '2097382368',\n",
              "   '2146396346',\n",
              "   '163498145',\n",
              "   '2084994773',\n",
              "   '2063850263',\n",
              "   '1905858949',\n",
              "   '2155523942',\n",
              "   '1998335482'],\n",
              "  'title': 'A pancoronavirus RT-PCR assay for detection of all known coronaviruses'},\n",
              " {'abstract': 'We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield significantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations.',\n",
              "  'authors': ['Pascal Vincent ',\n",
              "   ' Hugo Larochelle ',\n",
              "   ' Isabelle Lajoie ',\n",
              "   ' Yoshua Bengio ',\n",
              "   ' Pierre-Antoine Manzagol'],\n",
              "  'date': '2010',\n",
              "  'identifier': '2145094598',\n",
              "  'references': ['2136922672',\n",
              "   '2100495367',\n",
              "   '2072128103',\n",
              "   '2116064496',\n",
              "   '2025768430',\n",
              "   '2110798204',\n",
              "   '1652505363',\n",
              "   '2108384452',\n",
              "   '1479807131',\n",
              "   '1994197834'],\n",
              "  'title': 'Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion'},\n",
              " {'abstract': 'The automated categorization (or classification) of texts into predefined categories has witnessed a booming interest in the last 10 years, due to the increased availability of documents in digital form and the ensuing need to organize them. In the research community the dominant approach to this problem is based on machine learning techniques: a general inductive process automatically builds a classifier by learning, from a set of preclassified documents, the characteristics of the categories. The advantages of this approach over the knowledge engineering approach (consisting in the manual definition of a classifier by domain experts) are a very good effectiveness, considerable savings in terms of expert labor power, and straightforward portability to different domains. This survey discusses the main approaches to text categorization that fall within the machine learning paradigm. We will discuss in detail issues pertaining to three different problems, namely, document representation, classifier construction, and classifier evaluation.',\n",
              "  'authors': ['Fabrizio Sebastiani'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2118020653',\n",
              "  'references': ['1574901103',\n",
              "   '2149684865',\n",
              "   '2147152072',\n",
              "   '2435251607',\n",
              "   '2097089247',\n",
              "   '2053463056',\n",
              "   '2114535528',\n",
              "   '2005422315',\n",
              "   '2140785063',\n",
              "   '1978394996'],\n",
              "  'title': 'Machine learning in automated text categorization'},\n",
              " {'abstract': 'Visual understanding of complex urban street scenes is an enabling factor for a wide range of applications. Object detection has benefited enormously from large-scale datasets, especially in the context of deep learning. For semantic urban scene understanding, however, no current dataset adequately captures the complexity of real-world urban scenes. To address this, we introduce Cityscapes, a benchmark suite and large-scale dataset to train and test approaches for pixel-level and instance-level semantic labeling. Cityscapes is comprised of a large, diverse set of stereo video sequences recorded in streets from 50 different cities. 5000 of these images have high quality pixel-level annotations, 20 000 additional images have coarse annotations to enable methods that leverage large volumes of weakly-labeled data. Crucially, our effort exceeds previous attempts in terms of dataset size, annotation richness, scene variability, and complexity. Our accompanying empirical study provides an in-depth analysis of the dataset characteristics, as well as a performance evaluation of several state-of-the-art approaches based on our benchmark.',\n",
              "  'authors': ['Marius Cordts 1',\n",
              "   ' Mohamed Omran 2',\n",
              "   ' Sebastian Ramos 3',\n",
              "   ' Timo Rehfeld 1',\n",
              "   ' Markus Enzweiler 3',\n",
              "   ' Rodrigo Benenson 2',\n",
              "   ' Uwe Franke 3',\n",
              "   ' Stefan Roth 1',\n",
              "   ' Bernt Schiele 2'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2340897893',\n",
              "  'references': ['2618530766',\n",
              "   '2962835968',\n",
              "   '639708223',\n",
              "   '2919115771',\n",
              "   '2102605133',\n",
              "   '2117539524',\n",
              "   '1903029394',\n",
              "   '1536680647',\n",
              "   '2168356304',\n",
              "   '1861492603'],\n",
              "  'title': 'The Cityscapes Dataset for Semantic Urban Scene Understanding'},\n",
              " {'abstract': 'Class-tested and coherent, this groundbreaking new textbook teaches web-era information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. Written from a computer science perspective by three leading experts in the field, it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Although originally designed as the primary text for a graduate or advanced undergraduate course in information retrieval, the book will also create a buzz for researchers and professionals alike.',\n",
              "  'authors': ['Christopher D. Manning 1',\n",
              "   ' Prabhakar Raghavan 2',\n",
              "   ' Hinrich Schütze 3'],\n",
              "  'date': '2005',\n",
              "  'identifier': '1532325895',\n",
              "  'references': ['1888005072',\n",
              "   '2962965405',\n",
              "   '1662133657',\n",
              "   '2164019165',\n",
              "   '1521626219',\n",
              "   '2122369144',\n",
              "   '2248026759',\n",
              "   '1736726159',\n",
              "   '2150341604'],\n",
              "  'title': 'Introduction to Information Retrieval'},\n",
              " {'abstract': 'Latent variable models represent the probability density of data in a space of several dimensions in terms of a smaller number of latent, or hidden, variables. A familiar example is factor analysis which is based on a linear transformations between the latent space and the data space. In this paper we introduce a form of non-linear latent variable model called the Generative Topographic Mapping, for which the parameters of the model can be determined using the EM algorithm. GTM provides a principled alternative to the widely used Self-Organizing Map (SOM) of Kohonen (1982), and overcomes most of the significant limitations of the SOM. We demonstrate the performance of the GTM algorithm on a toy problem and on simulated data from flow diagnostics for a multi-phase oil pipeline.',\n",
              "  'authors': ['Christopher M. Bishop 1',\n",
              "   ' Markus Svensén 2',\n",
              "   ' Christopher K. I. Williams 2'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2107636931',\n",
              "  'references': ['1554663460',\n",
              "   '1679913846',\n",
              "   '2049633694',\n",
              "   '2044758663',\n",
              "   '2125027820',\n",
              "   '65738273',\n",
              "   '2146610201',\n",
              "   '2166698530',\n",
              "   '2137969290',\n",
              "   '2051719061'],\n",
              "  'title': 'GTM: the generative topographic mapping'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Nicholas Ayache ', ' Olivier D. Faugeras'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2331801068',\n",
              "  'references': ['2028539056', '2159879829', '2156484924', '2154170270'],\n",
              "  'title': 'Building, registrating, and fusing noisy visual maps'},\n",
              " {'abstract': 'We approach the problem of labeling a set of objects from a quantitative standpoint. We define a world model in terms of transition probabilities and propose a definition of a class of global criteria that combine both ambiguity and consistency. A projected gradient algorithm is developed to minimize the criterion. We show that the minimization procedure can be implemented in a highly parallel manner. Results are shown on several examples and comparisons are made with relaxation labeling techniques.',\n",
              "  'authors': ['Olivier D. Faugeras 1', ' Marc Berthod 2'],\n",
              "  'date': '1981',\n",
              "  'identifier': '1965044325',\n",
              "  'references': ['1530383550',\n",
              "   '1979622972',\n",
              "   '2136113379',\n",
              "   '1736170383',\n",
              "   '1990852520',\n",
              "   '2143101939',\n",
              "   '2012374219',\n",
              "   '2066780173',\n",
              "   '2053007711',\n",
              "   '2002202571'],\n",
              "  'title': 'Improving Consistency and Reducing Ambiguity in Stochastic Labeling: An Optimization Approach'},\n",
              " {'abstract': 'We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. SSD is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, COCO, and ILSVRC datasets confirm that SSD has competitive accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. For \\\\(300 \\\\times 300\\\\) input, SSD achieves 74.3 % mAP on VOC2007 test at 59 FPS on a Nvidia Titan X and for \\\\(512 \\\\times 512\\\\) input, SSD achieves 76.9 % mAP, outperforming a comparable state of the art Faster R-CNN model. Compared to other single stage methods, SSD has much better accuracy even with a smaller input image size. Code is available at https://github.com/weiliu89/caffe/tree/ssd.',\n",
              "  'authors': ['Wei Liu 1',\n",
              "   ' Dragomir Anguelov 2',\n",
              "   ' Dumitru Erhan 3',\n",
              "   ' Christian Szegedy 3',\n",
              "   ' Scott E. Reed 4',\n",
              "   ' Cheng-Yang Fu 1',\n",
              "   ' Alexander C. Berg 1'],\n",
              "  'date': '2016',\n",
              "  'identifier': '3106250896',\n",
              "  'references': ['2194775991',\n",
              "   '2618530766',\n",
              "   '2962835968',\n",
              "   '2097117768',\n",
              "   '639708223',\n",
              "   '1836465849',\n",
              "   '2102605133',\n",
              "   '2117539524',\n",
              "   '1903029394',\n",
              "   '2155893237'],\n",
              "  'title': 'SSD: Single Shot MultiBox Detector'},\n",
              " {'abstract': 'The \"minimum margin\" of an ensemble classifier on a given training set is, roughly speaking, the smallest vote it gives to any correct training label. Recent work has shown that the Adaboost algorithm is particularly effective at producing ensembles with large minimum margins, and theory suggests that this may account for its success at reducing generalization error. We note, however, that the problem of finding good margins is closely related to linear programming, and we use this connection to derive and test new \"LPboosting\" algorithms that achieve better minimum margins than Adaboost.However, these algorithms do not always yield better generalization performance. In fact, more often the opposite is true. We report on a series of controlled experiments which show that no simple version of the minimum-margin story can be complete. We conclude that the crucial question as to why boosting works so well in practice, and how to further improve upon it, remains mostly open.Some of our experiments are interesting for another reason: we show that Adaboost sometimes does overfit--eventually. This may take a very long time to occur, however, which is perhaps why this phenomenon has gone largely unnoticed.',\n",
              "  'authors': ['Adam J. Grove ', ' Dale Schuurmans'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2099968818',\n",
              "  'references': ['2119821739',\n",
              "   '1988790447',\n",
              "   '2125055259',\n",
              "   '2112076978',\n",
              "   '2152761983',\n",
              "   '1504694836',\n",
              "   '2982720039',\n",
              "   '1966280301',\n",
              "   '3124770806',\n",
              "   '1553313034'],\n",
              "  'title': 'Boosting in the limit: maximizing the margin of learned ensembles'},\n",
              " {'abstract': 'Recent work has demonstrated that deep neural networks are vulnerable to adversarial examples—inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. Code and pre-trained models are available at this https URL and this https URL.',\n",
              "  'authors': ['Aleksander Madry 1',\n",
              "   ' Aleksandar Makelov 1',\n",
              "   ' Ludwig Schmidt 1',\n",
              "   ' Dimitris Tsipras 1',\n",
              "   ' Adrian Vladu 2'],\n",
              "  'date': '2018',\n",
              "  'identifier': '2964253222',\n",
              "  'references': ['2963143631',\n",
              "   '2963744840',\n",
              "   '2962700793',\n",
              "   '2964301649',\n",
              "   '2962729158',\n",
              "   '3106412272',\n",
              "   '2970115835',\n",
              "   '2963060032',\n",
              "   '2963359529'],\n",
              "  'title': 'Towards Deep Learning Models Resistant to Adversarial Attacks.'},\n",
              " {'abstract': 'A detailed discussion of the standard approach to computer interpretation of line drawings as three-dimensional scenes',\n",
              "  'authors': ['D. Waltz'],\n",
              "  'date': '1975',\n",
              "  'identifier': '1597474747',\n",
              "  'references': ['2337098149',\n",
              "   '47957325',\n",
              "   '2080920426',\n",
              "   '1507849272',\n",
              "   '2038345112',\n",
              "   '1995756857',\n",
              "   '2146934839',\n",
              "   '1899309388'],\n",
              "  'title': 'Understanding Line drawings of Scenes with Shadows'},\n",
              " {'abstract': 'Speech recognition is formulated as a problem of maximum likelihood decoding. This formulation requires statistical models of the speech production process. In this paper, we describe a number of statistical models for use in speech recognition. We give special attention to determining the parameters for such models from sparse data. We also describe two decoding methods, one appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks. To illustrate the usefulness of the methods described, we review a number of decoding results that have been obtained with them.',\n",
              "  'authors': ['Lalit R. Bahl ', ' Frederick Jelinek ', ' Robert L. Mercer'],\n",
              "  'date': '1983',\n",
              "  'identifier': '1966812932',\n",
              "  'references': ['2142384583',\n",
              "   '1597533204',\n",
              "   '1575431606',\n",
              "   '2341171179',\n",
              "   '2163929346',\n",
              "   '2157477135',\n",
              "   '2029491572',\n",
              "   '2035227369',\n",
              "   '2137095888',\n",
              "   '1989226853'],\n",
              "  'title': 'A Maximum Likelihood Approach to Continuous Speech Recognition'},\n",
              " {'abstract': 'The problem discussed is the relationship between the firing of single neurons in sensory pathways and subjectively experienced sensations. The conclusions are formulated as the following five dogmas:To understand nervous function one needs to look at interactions at a cellular level, rather than either a more macroscopic or microscopic level, because behaviour depends upon the organized pattern of these intercellular interactions.The sensory system is organized to achieve as complete a representation of the sensory stimulus as possible with the minimum number of active neurons.Trigger features of sensory neurons are matched to redundant patterns of stimulation by experience as well as by developmental processes.Perception corresponds to the activity of a small selection from the very numerous high-level neurons, each of which corresponds to a pattern of external events of the order of complexity of the events symbolized by a word.High impulse frequency in such neurons corresponds to high certainty that t...',\n",
              "  'authors': ['Horace B Barlow'],\n",
              "  'date': '1972',\n",
              "  'identifier': '2013239224',\n",
              "  'references': ['1995875735',\n",
              "   '1784695092',\n",
              "   '2116360511',\n",
              "   '85152245',\n",
              "   '2167553001',\n",
              "   '2993383518',\n",
              "   '2153782322',\n",
              "   '2272360941',\n",
              "   '1988849438',\n",
              "   '2104220712'],\n",
              "  'title': 'Single units and sensation: a neuron doctrine for perceptual psychology?'},\n",
              " {'abstract': 'Let a vector of probabilities be associated with every node of a graph. These probabilities define a random variable representing the possible labels of the node. Probabilities at neighboring nodes are used iteratively to update the probabilities at a given node based on statistical relations among node labels. The results are compared with previous work on probabilistic relaxation labeling, and examples are given from the image segmentation domain. References are also given to applications of the new scheme in text processing.',\n",
              "  'authors': ['Shmuel Peleg'],\n",
              "  'date': '1980',\n",
              "  'identifier': '1990852520',\n",
              "  'references': ['1530383550',\n",
              "   '1979622972',\n",
              "   '1736170383',\n",
              "   '2053007711',\n",
              "   '2043677982',\n",
              "   '2000372906'],\n",
              "  'title': 'A New Probabilistic Relaxation Scheme'},\n",
              " {'abstract': 'Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.',\n",
              "  'authors': ['Yinhan Liu ',\n",
              "   ' Myle Ott ',\n",
              "   ' Naman Goyal ',\n",
              "   ' Jingfei Du ',\n",
              "   ' Mandar Joshi ',\n",
              "   ' Danqi Chen ',\n",
              "   ' Omer Levy ',\n",
              "   ' Mike Lewis ',\n",
              "   ' Luke Zettlemoyer ',\n",
              "   ' Veselin Stoyanov'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2965373594',\n",
              "  'references': ['2964121744',\n",
              "   '2963403868',\n",
              "   '2963341956',\n",
              "   '2251939518',\n",
              "   '2899771611',\n",
              "   '2963748441',\n",
              "   '2962784628',\n",
              "   '1840435438',\n",
              "   '2970597249',\n",
              "   '2963026768'],\n",
              "  'title': 'RoBERTa: A Robustly Optimized BERT Pretraining Approach'},\n",
              " {'abstract': \"SUMMARY We propose a new method for estimation in linear models. The 'lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.\",\n",
              "  'authors': ['Robert Tibshirani'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2135046866',\n",
              "  'references': ['2102865756',\n",
              "   '3085162807',\n",
              "   '2158940042',\n",
              "   '1594031697',\n",
              "   '2797583072',\n",
              "   '2102201073',\n",
              "   '2106706098',\n",
              "   '2117897510',\n",
              "   '2075665712',\n",
              "   '191129667'],\n",
              "  'title': 'Regression Shrinkage and Selection via the Lasso'},\n",
              " {'abstract': 'Book on statistical decision theory and sensory processes in signal detection theory and psychophysics',\n",
              "  'authors': ['David Marvin Green ', ' John Arthur Swets'],\n",
              "  'date': '1966',\n",
              "  'identifier': '1784695092',\n",
              "  'references': ['1524144700',\n",
              "   '2157825442',\n",
              "   '2164084182',\n",
              "   '2155653793',\n",
              "   '2090267299',\n",
              "   '2104960492',\n",
              "   '1978662219',\n",
              "   '2110143060',\n",
              "   '2169134378',\n",
              "   '2149273804'],\n",
              "  'title': 'Signal Detection Theory and Psychophysics'},\n",
              " {'abstract': 'background A worldwide outbreak of severe acute respiratory syndrome (SARS) has been associated with exposures originating from a single ill health care worker from Guangdong Province, China. We conducted studies to identify the etiologic agent of this outbreak. methods We received clinical specimens from patients in six countries and tested them, using virus isolation techniques, electron-microscopical and histologic studies, and molecular and serologic assays, in an attempt to identify a wide range of potential pathogens. results No classic respiratory or bacterial respiratory pathogen was consistently identified. However, a novel coronavirus was isolated from patients who met the case definition of SARS. Cytopathological features were noted microscopically in Vero E6 cells inoculated with a throat-swab specimen. Electron-microscopical examination of cultures revealed ultrastructural features characteristic of coronaviruses. Immunohistochemical and immunofluorescence staining revealed reactivity with group I coronavirus polyclonal antibodies. Consensus coronavirus primers designed to amplify a fragment of the polymerase gene by reverse transcription–polymerase chain reaction (RT-PCR) were used to obtain a sequence that clearly identified the isolate as a unique coronavirus only distantly related to previously sequenced coronaviruses. With specific diagnostic RT-PCR primers we identified several identical nucleotide sequences in 12 patients from several locations, a finding consistent with a point source outbreak. Indirect fluorescent antibody tests and enzyme-linked immunosorbent assays made with the new coronavirus isolate have been used to demonstrate a virus-specific serologic response. Preliminary studies suggest that this virus may never before have infected the U.S. population. conclusions A novel coronavirus is associated with this outbreak, and the evidence indicates that this virus has an etiologic role in SARS. The name Urbani SARS-associated coronavirus is proposed for the virus.',\n",
              "  'authors': ['Ksiazek Tg 1',\n",
              "   ' Erdman D 1',\n",
              "   ' Goldsmith Cs 1',\n",
              "   ' Zaki 1',\n",
              "   ' Peret T 1',\n",
              "   ' Emery S 1',\n",
              "   ' Tong S 1',\n",
              "   ' Urbani C 2',\n",
              "   ' Comer Ja 1',\n",
              "   ' Lim W 3',\n",
              "   ' Rollin Pe 1',\n",
              "   ' Dowell Sf 4',\n",
              "   ' Ling Ae 5',\n",
              "   ' Humphrey Cd 1',\n",
              "   ' Shieh Wj 1',\n",
              "   ' Guarner J 1',\n",
              "   ' Paddock Cd 1',\n",
              "   ' Rota P 1',\n",
              "   ' Fields B 1',\n",
              "   ' DeRisi J 6',\n",
              "   ' Yang Jy 1',\n",
              "   ' Cox N 1',\n",
              "   ' Hughes Jm 1',\n",
              "   ' LeDuc Jw 1',\n",
              "   ' Bellini Wj 1',\n",
              "   ' Anderson Lj 1'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2104548316',\n",
              "  'references': ['2106882534',\n",
              "   '2131262274',\n",
              "   '2100820722',\n",
              "   '2125251240',\n",
              "   '2463755683',\n",
              "   '2403756321',\n",
              "   '2127949919',\n",
              "   '1576737979',\n",
              "   '2128788856',\n",
              "   '2076620790'],\n",
              "  'title': 'A novel coronavirus associated with severe acute respiratory syndrome.'},\n",
              " {'abstract': 'This work presents the application of HMM adaptation techniques to the problem of Off-Line Cursive Script Recognition. Rather than training a new model for each writer, one first creates a unique model with a mixed database and then adapts it for each different writer using his own small dataset.Experiments on a publicly available benchmark database show that an adapted system has an accuracy higher than 80% even when less than 30 word samples are used during adaptation, while a system trained using the data of the single writer only needs at least 200 words in order to achieve the same performance as the adapted models.',\n",
              "  'authors': ['Alessandro Vinciarelli ', ' Samy Bengio'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2161369007',\n",
              "  'references': ['2125838338',\n",
              "   '2142069714',\n",
              "   '2146871184',\n",
              "   '2100969003',\n",
              "   '2799061466',\n",
              "   '2152928267',\n",
              "   '2092858021',\n",
              "   '2112081648',\n",
              "   '2149597185',\n",
              "   '2121981798'],\n",
              "  'title': 'Writer adaptation techniques in HMM based off-line cursive script recognition'},\n",
              " {'abstract': 'Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.',\n",
              "  'authors': ['G. Hinton 1',\n",
              "   ' Li Deng 2',\n",
              "   ' Dong Yu 2',\n",
              "   ' G. E. Dahl 1',\n",
              "   ' A. Mohamed 1',\n",
              "   ' N. Jaitly 1',\n",
              "   ' Andrew Senior 3',\n",
              "   ' V. Vanhoucke 3',\n",
              "   ' P. Nguyen 3',\n",
              "   ' T. N. Sainath 4',\n",
              "   ' B. Kingsbury 4'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2160815625',\n",
              "  'references': ['2136922672',\n",
              "   '2100495367',\n",
              "   '1533861849',\n",
              "   '2116064496',\n",
              "   '2147768505',\n",
              "   '2145094598',\n",
              "   '1993882792',\n",
              "   '44815768',\n",
              "   '1498436455',\n",
              "   '1994197834'],\n",
              "  'title': 'Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups'},\n",
              " {'abstract': 'There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.',\n",
              "  'authors': ['S. Kirkpatrick 1', ' C. D. Gelatt 1', ' M. P. Vecchi 2'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2581275558',\n",
              "  'references': ['2042986967',\n",
              "   '2022820481',\n",
              "   '2114552889',\n",
              "   '2022494241',\n",
              "   '2143037347',\n",
              "   '2056760934',\n",
              "   '2148673189',\n",
              "   '86906884',\n",
              "   '2014952973',\n",
              "   '2014068360'],\n",
              "  'title': 'Optimization by simulated annealing'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Claude E. Shannon ', ' Warren Weaver'],\n",
              "  'date': '1949',\n",
              "  'identifier': '2993383518',\n",
              "  'references': ['2140190241',\n",
              "   '1721421031',\n",
              "   '2132454116',\n",
              "   '385466589',\n",
              "   '2164998314',\n",
              "   '2102796633',\n",
              "   '2107689535',\n",
              "   '2963322354',\n",
              "   '2151376743'],\n",
              "  'title': 'The mathematical theory of communication'},\n",
              " {'abstract': '',\n",
              "  'authors': ['D. H. Hubel ', ' T. N. Wiesel'],\n",
              "  'date': '1962',\n",
              "  'identifier': '2116360511',\n",
              "  'references': ['2103212315',\n",
              "   '2253776861',\n",
              "   '2037316494',\n",
              "   '2212384750',\n",
              "   '2166025442',\n",
              "   '2110121211',\n",
              "   '2136325353',\n",
              "   '2111624873',\n",
              "   '2010554296',\n",
              "   '2418763445'],\n",
              "  'title': \"Receptive fields, binocular interaction and functional architecture in the cat's visual cortex\"},\n",
              " {'abstract': 'Simple and reproducible fingerprints of complex genomes can be generated using single arbitrarily chosen primers and the polymerase chain reaction (PCR). No prior sequence information is required. The method, arbitrarily primed PCR (AP-PCR), involves two cycles of low stringency amplification followed by PCR at higher stringency. We show that strains can be distinguished by comparing polymorphisms in genomic fingerprints. The generality of the method is demonstrated by application to twenty four strains from five species of Staphylococcus, eleven strains of Streptococcus pyogenes and three varieties of Oryza sativa (rice).',\n",
              "  'authors': ['John Welsh ', ' Michael McClelland'],\n",
              "  'date': '1990',\n",
              "  'identifier': '1963953102',\n",
              "  'references': ['2166867592',\n",
              "   '2113457186',\n",
              "   '2170881661',\n",
              "   '589702940',\n",
              "   '2029197798',\n",
              "   '1986937402',\n",
              "   '2078917493',\n",
              "   '2141047744',\n",
              "   '2145525392',\n",
              "   '2037210253'],\n",
              "  'title': 'Fingerprinting genomes using PCR with arbitrary primers'},\n",
              " {'abstract': \"Batch normalization (BN) is a fundamental unit in modern deep networks, in which a linear transformation module was designed for improving BN's flexibility of fitting complex data distributions. In this paper, we demonstrate properly enhancing this linear transformation module can effectively improve the ability of BN. Specifically, rather than using a single neuron, we propose to additionally consider each neuron's neighborhood for calculating the outputs of the linear transformation. Our method, named BNET, can be implemented with 2-3 lines of code in most deep learning libraries. Despite the simplicity, BNET brings consistent performance gains over a wide range of backbones and visual benchmarks. Moreover, we verify that BNET accelerates the convergence of network training and enhances spatial information by assigning the important neurons with larger weights accordingly. The code is available at https://github.com/yuhuixu1993/BNET.\",\n",
              "  'authors': ['Yuhui Xu ',\n",
              "   ' Lingxi Xie ',\n",
              "   ' Cihang Xie ',\n",
              "   ' Jieru Mei ',\n",
              "   ' Siyuan Qiao ',\n",
              "   ' Wei Shen ',\n",
              "   ' Hongkai Xiong ',\n",
              "   ' Alan L. Yuille'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3109745609',\n",
              "  'references': ['2194775991',\n",
              "   '2618530766',\n",
              "   '2962835968',\n",
              "   '2964121744',\n",
              "   '639708223',\n",
              "   '2919115771',\n",
              "   '1836465849',\n",
              "   '2095705004',\n",
              "   '2108598243',\n",
              "   '2806070179'],\n",
              "  'title': 'Batch Normalization with Enhanced Linear Transformation.'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Leon Bottou 1', ' 2', ' Yann Lecun'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2606594511',\n",
              "  'references': ['753012316',\n",
              "   '2147800946',\n",
              "   '2962727772',\n",
              "   '2971225054',\n",
              "   '2141504882',\n",
              "   '103531544',\n",
              "   '3120582545',\n",
              "   '2982377460',\n",
              "   '2170026903',\n",
              "   '2023791596'],\n",
              "  'title': 'Sn: A simulator for connectionist models'},\n",
              " {'abstract': 'Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis.',\n",
              "  'authors': ['Richard O. Duda ', ' Peter E. Hart'],\n",
              "  'date': '1973',\n",
              "  'identifier': '3017143921',\n",
              "  'references': ['2310919327',\n",
              "   '1746819321',\n",
              "   '1570448133',\n",
              "   '2163352848',\n",
              "   '2067191022',\n",
              "   '2110158442',\n",
              "   '1992419399',\n",
              "   '2117812871',\n",
              "   '2121647436'],\n",
              "  'title': 'Pattern classification and scene analysis'},\n",
              " {'abstract': 'A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing',\n",
              "  'authors': ['Martin A. Fischler ', ' Robert C. Bolles'],\n",
              "  'date': '1981',\n",
              "  'identifier': '2085261163',\n",
              "  'references': ['3017143921',\n",
              "   '2965369548',\n",
              "   '2168938315',\n",
              "   '2170081783',\n",
              "   '1550820742'],\n",
              "  'title': 'Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography'},\n",
              " {'abstract': 'Methods for Conceptual Clustering may be explicated in two lights. Conceptual Clustering methods may be viewed as extensions to techniques of numerical taxonomy, a collection of methods developed by social and natural scientists for creating classification schemes over object sets. Alternatively, conceptual clustering may be viewed as a form of learning by observation or concept formation, as opposed to methods of learning from examples or concept identification. In this paper we survey and compare a number of conceptual clustering methods along dimensions suggested by each of these views. The point we most wish to clarify is that conceptual clustering processes can be explicated as being composed of three distinct but inter-dependent subprocesses: the process of deriving a hierarchical classification scheme; the process of aggregating objects into individual classes; and the process of assigning conceptual descriptions to object classes. Each subprocess may be characterized along a number of dimensions related to search, thus facilitating a better understanding of the conceptual clustering process as a whole.',\n",
              "  'authors': ['Douglas Fisher ', ' Pat Langley'],\n",
              "  'date': '1985',\n",
              "  'identifier': '1564805656',\n",
              "  'references': ['2612166593',\n",
              "   '2159047538',\n",
              "   '2132513611',\n",
              "   '2009207944',\n",
              "   '1527883571',\n",
              "   '2177085946',\n",
              "   '2037591014',\n",
              "   '2021332478',\n",
              "   '2000480149',\n",
              "   '2146600388'],\n",
              "  'title': 'Approaches to conceptual clustering'},\n",
              " {'abstract': 'We present an approach to efficiently detect the 2D pose of multiple people in an image. The approach uses a nonparametric representation, which we refer to as Part Affinity Fields (PAFs), to learn to associate body parts with individuals in the image. The architecture encodes global context, allowing a greedy bottom-up parsing step that maintains high accuracy while achieving realtime performance, irrespective of the number of people in the image. The architecture is designed to jointly learn part locations and their association via two branches of the same sequential prediction process. Our method placed first in the inaugural COCO 2016 keypoints challenge, and significantly exceeds the previous state-of-the-art result on the MPII Multi-Person benchmark, both in performance and efficiency.',\n",
              "  'authors': ['Zhe Cao ', ' Tomas Simon ', ' Shih-En Wei ', ' Yaser Sheikh'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2559085405',\n",
              "  'references': [],\n",
              "  'title': 'Realtime Multi-person 2D Pose Estimation Using Part Affinity Fields'},\n",
              " {'abstract': 'From the publisher: This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. The concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally, the book and its associated web site will guide practitioners to updated literature, new applications, and on-line software.',\n",
              "  'authors': ['Nello Cristianini 1', ' John Shawe-Taylor 2'],\n",
              "  'date': '2000',\n",
              "  'identifier': '1563088657',\n",
              "  'references': [],\n",
              "  'title': 'An Introduction to Support Vector Machines and Other Kernel-based Learning Methods'},\n",
              " {'abstract': \"The increasing volume of data in modern business and science calls for more complex and sophisticated tools. Although advances in data mining technology have made extensive data collection much easier, it's still always evolving and there is a constant need for new techniques and tools that can help us transform this data into useful information and knowledge. Since the previous edition's publication, great advances have been made in the field of data mining. Not only does the third of edition of Data Mining: Concepts and Techniques continue the tradition of equipping you with an understanding and application of the theory and practice of discovering patterns hidden in large data sets, it also focuses on new, important topics in the field: data warehouses and data cube technology, mining stream, mining social networks, and mining spatial, multimedia and other complex data. Each chapter is a stand-alone guide to a critical topic, presenting proven algorithms and sound implementations ready to be used directly or with strategic modification against live data. This is the resource you need if you want to apply today's most powerful data mining techniques to meet real business challenges. * Presents dozens of algorithms and implementation examples, all in pseudo-code and suitable for use in real-world, large-scale data mining projects. * Addresses advanced topics such as mining object-relational databases, spatial databases, multimedia databases, time-series databases, text databases, the World Wide Web, and applications in several fields. *Provides a comprehensive, practical look at the concepts and techniques you need to get the most out of real business data\",\n",
              "  'authors': ['Jiawei Han 1', ' Micheline Kamber 2', ' Jian Pei 2'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2140190241',\n",
              "  'references': ['2156909104',\n",
              "   '2911964244',\n",
              "   '2912565176',\n",
              "   '2148603752',\n",
              "   '1639032689',\n",
              "   '1554944419',\n",
              "   '2102865756',\n",
              "   '2008620264',\n",
              "   '1554663460',\n",
              "   '1570448133'],\n",
              "  'title': 'Data Mining: Concepts and Techniques'},\n",
              " {'abstract': \"SUMMARY A method is proposed for estimating intra-block and inter-block weights in the analysis of incomplete block designs with block sizes not necessarily equal. The method consists of maximizing the likelihood, not of all the data, but of a set of selected error contrasts. When block sizes are equal results are identical with those obtained by the method of Nelder (1968) for generally balanced designs. Although mainly concerned with incomplete block designs the paper also gives in outline an extension of the modified maximum likelihood procedure to designs with a more complicated block structure. In this paper we consider the estimation of weights to be used in the recovery of interblock information in incomplete block designs with possibly unequal block sizes. The problem can also be thought of as one of estimating constants and components of variance from data arranged in a general two-way classification when the effects of one classification are regarded as fixed and the effects of the second classification are regarded as random. Nelder (1968) described the efficient estimation of weights in generally balanced designs, in which the blocks are usually, although not always, of equal size. Lack of balance resulting from unequal block sizes is, however, common in some experimental work, for example in animal breeding experiments. The maximum likelihood procedure described by Hartley & Rao (1967) can be used but does not give the same estimates as Nelder's method in the balanced case. As will be shown, the two methods in effect use the same weighted sums of squares of residuals but assign different expectations. In the maximum likelihood approach, expectations are taken over a conditional distribution with the treatment effects fixed at their estimated values. In contrast Nelder uses unconditional expectations. The difference between the two methods is analogous to the well-known difference between two methods of estimating the variance o2 of a normal distribution, given a random sample of n values. Both methods use the same total sum of squares of deviations. But\",\n",
              "  'authors': ['H. D. Patterson ', ' R. Thompson'],\n",
              "  'date': '1971',\n",
              "  'identifier': '2000084758',\n",
              "  'references': ['2052827106',\n",
              "   '2325014228',\n",
              "   '128947086',\n",
              "   '2331238875',\n",
              "   '2332072907'],\n",
              "  'title': 'Recovery of inter-block information when block sizes are unequal'},\n",
              " {'abstract': 'We present two real-time reverse-transcription polymerase chain reaction assays for a novel human coronavirus (CoV), targeting regions upstream of the E gene (upE) or within open reading frame (ORF)1b, respectively. Sensitivity for upE is 3.4 copies per reaction (95% confidence interval (CI): 2.5-6.9 copies) or 291 copies/mL of sample. No cross-reactivity was observed with coronaviruses OC43, NL63, 229E, SARS-CoV, nor with 92 clinical specimens containing common human respiratory viruses. We recommend using upE for screening and ORF1b for confirmation. .',\n",
              "  'authors': ['V M Corman 1',\n",
              "   ' I Eckerle 1',\n",
              "   ' T Bleicker 1',\n",
              "   ' A Zaki 2',\n",
              "   ' O Landt 3',\n",
              "   ' M Eschbach-Bludau 1',\n",
              "   ' S van Boheemen 4',\n",
              "   ' R Gopal 5',\n",
              "   ' M Ballhause 3',\n",
              "   ' T M Bestebroer 4',\n",
              "   ' D Muth 1',\n",
              "   ' M A Müller 1',\n",
              "   ' J F Drexler 1',\n",
              "   ' M Zambon 5',\n",
              "   ' A D Osterhaus 4',\n",
              "   ' R M Fouchier 4',\n",
              "   ' C Drosten 1'],\n",
              "  'date': '2012',\n",
              "  'identifier': '1703839189',\n",
              "  'references': ['2132260239',\n",
              "   '2129542667',\n",
              "   '2167080692',\n",
              "   '2069961370',\n",
              "   '1593955729',\n",
              "   '2145810580',\n",
              "   '1975169783',\n",
              "   '2105870155',\n",
              "   '2100516702',\n",
              "   '2161315652'],\n",
              "  'title': 'Detection of a novel human coronavirus by real-time reverse-transcription polymerase chain reaction'},\n",
              " {'abstract': 'Abstract In this paper, we study the problem of stochastic language modelling from the viewpoint of introducing suitable structures into the conditional probability distributions. The task of these distributions is to predict the probability of a new word by looking at M or even all predecessor words. The conventional approach is to limit M to 1 or 2 and to interpolate the resulting bigram and trigram models with a unigram model in a linear fashion. However, there are many other structures that can be used to model the probabilistic dependences between the predecessor word and the word to be predicted. The structures considered in this paper are: nonlinear interpolation as an alternative to linear interpolation; equivalence classes for word histories and single words; cache memory and word associations. For the optimal estimation of nonlinear and linear interpolation parameters, the leaving-one-out method is systematically used. For the determination of word equivalence classes in a bigram model, an automatic clustering procedure has been adapted. To capture long-distance dependences, we consider various models for word-by-word dependences; the cache model may be viewed as a special type of self-association. Experimental results are presented for two text databases, a Germany database and an English database.',\n",
              "  'authors': ['Hermann Ney ', ' Ute Essen ', ' Reinhard Kneser'],\n",
              "  'date': '1994',\n",
              "  'identifier': '2075201173',\n",
              "  'references': ['2136542423',\n",
              "   '1984052055',\n",
              "   '2158195707',\n",
              "   '1972594981',\n",
              "   '2117278770',\n",
              "   '1934041838',\n",
              "   '2142416747',\n",
              "   '2162630660',\n",
              "   '2100506586'],\n",
              "  'title': 'On structuring probabilistic dependences in stochastic language modelling'},\n",
              " {'abstract': 'Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.',\n",
              "  'authors': ['Nitish Srivastava ',\n",
              "   ' Geoffrey Hinton ',\n",
              "   ' Alex Krizhevsky ',\n",
              "   ' Ilya Sutskever ',\n",
              "   ' Ruslan Salakhutdinov'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2095705004',\n",
              "  'references': ['2618530766',\n",
              "   '2136922672',\n",
              "   '3118608800',\n",
              "   '2100495367',\n",
              "   '2135046866',\n",
              "   '2546302380',\n",
              "   '2294059674',\n",
              "   '2145094598',\n",
              "   '2025768430',\n",
              "   '2131241448'],\n",
              "  'title': 'Dropout: a simple way to prevent neural networks from overfitting'},\n",
              " {'abstract': \"Chapter 1: The Real and Complex Number Systems Introduction Ordered Sets Fields The Real Field The Extended Real Number System The Complex Field Euclidean Spaces Appendix Exercises Chapter 2: Basic Topology Finite, Countable, and Uncountable Sets Metric Spaces Compact Sets Perfect Sets Connected Sets Exercises Chapter 3: Numerical Sequences and Series Convergent Sequences Subsequences Cauchy Sequences Upper and Lower Limits Some Special Sequences Series Series of Nonnegative Terms The Number e The Root and Ratio Tests Power Series Summation by Parts Absolute Convergence Addition and Multiplication of Series Rearrangements Exercises Chapter 4: Continuity Limits of Functions Continuous Functions Continuity and Compactness Continuity and Connectedness Discontinuities Monotonic Functions Infinite Limits and Limits at Infinity Exercises Chapter 5: Differentiation The Derivative of a Real Function Mean Value Theorems The Continuity of Derivatives L'Hospital's Rule Derivatives of Higher-Order Taylor's Theorem Differentiation of Vector-valued Functions Exercises Chapter 6: The Riemann-Stieltjes Integral Definition and Existence of the Integral Properties of the Integral Integration and Differentiation Integration of Vector-valued Functions Rectifiable Curves Exercises Chapter 7: Sequences and Series of Functions Discussion of Main Problem Uniform Convergence Uniform Convergence and Continuity Uniform Convergence and Integration Uniform Convergence and Differentiation Equicontinuous Families of Functions The Stone-Weierstrass Theorem Exercises Chapter 8: Some Special Functions Power Series The Exponential and Logarithmic Functions The Trigonometric Functions The Algebraic Completeness of the Complex Field Fourier Series The Gamma Function Exercises Chapter 9: Functions of Several Variables Linear Transformations Differentiation The Contraction Principle The Inverse Function Theorem The Implicit Function Theorem The Rank Theorem Determinants Derivatives of Higher Order Differentiation of Integrals Exercises Chapter 10: Integration of Differential Forms Integration Primitive Mappings Partitions of Unity Change of Variables Differential Forms Simplexes and Chains Stokes' Theorem Closed Forms and Exact Forms Vector Analysis Exercises Chapter 11: The Lebesgue Theory Set Functions Construction of the Lebesgue Measure Measure Spaces Measurable Functions Simple Functions Integration Comparison with the Riemann Integral Integration of Complex Functions Functions of Class L2 Exercises Bibliography List of Special Symbols Index\",\n",
              "  'authors': ['Walter Rudin'],\n",
              "  'date': '1964',\n",
              "  'identifier': '2097415784',\n",
              "  'references': ['2152121970',\n",
              "   '2124758339',\n",
              "   '2137983211',\n",
              "   '2103519107',\n",
              "   '2132105090',\n",
              "   '2037710455',\n",
              "   '1975670568',\n",
              "   '1999814123',\n",
              "   '1980454827',\n",
              "   '2111616148'],\n",
              "  'title': 'Principles of mathematical analysis'},\n",
              " {'abstract': 'Abstract: We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.',\n",
              "  'authors': ['Diederik P. Kingma 1', ' Jimmy Lei Ba 2'],\n",
              "  'date': '2015',\n",
              "  'identifier': '2964121744',\n",
              "  'references': ['2963403868',\n",
              "   '2962739339',\n",
              "   '2963073614',\n",
              "   '2962793481',\n",
              "   '2331128040',\n",
              "   '2963470893',\n",
              "   '2964015378',\n",
              "   '1514535095'],\n",
              "  'title': 'Adam: A Method for Stochastic Optimization'},\n",
              " {'abstract': 'LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.',\n",
              "  'authors': ['Chih-Chung Chang ', ' Chih-Jen Lin'],\n",
              "  'date': '2011',\n",
              "  'identifier': '2153635508',\n",
              "  'references': ['2148603752',\n",
              "   '2119821739',\n",
              "   '2109943925',\n",
              "   '2172000360',\n",
              "   '1512098439',\n",
              "   '2104978738',\n",
              "   '1576520375',\n",
              "   '2087347434',\n",
              "   '2132870739',\n",
              "   '2124351082'],\n",
              "  'title': 'LIBSVM: A library for support vector machines'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Gregory L. Armstrong 1',\n",
              "   ' Duncan R. MacCannell 1',\n",
              "   ' Jill Taylor 2',\n",
              "   ' Heather A. Carleton 1',\n",
              "   ' Elizabeth B. Neuhaus 1',\n",
              "   ' Richard S. Bradbury 3',\n",
              "   ' James E. Posey 4',\n",
              "   ' Marta Gwinn 1'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3027518954',\n",
              "  'references': ['3001897055',\n",
              "   '3012538234',\n",
              "   '3013266235',\n",
              "   '3095124337',\n",
              "   '3036563213',\n",
              "   '3009375872',\n",
              "   '3023674326',\n",
              "   '3096084589',\n",
              "   '3103820312',\n",
              "   '3096165595'],\n",
              "  'title': 'Pathogen genomics in public health'},\n",
              " {'abstract': 'background Severe acute respiratory syndrome (SARS) is a condition of unknown cause that has recently been recognized in patients in Asia, North America, and Europe. This report summarizes the initial epidemiologic findings, clinical description, and diagnostic findings that followed the identification of SARS in Canada. methods SARS was first identified in Canada in early March 2003. We collected epidemiologic, clinical, and diagnostic data from each of the first 10 cases prospectively as they were identified. Specimens from all cases were sent to local, provincial, national, and international laboratories for studies to identify an etiologic agent. results The patients ranged from 24 to 78 years old; 60 percent were men. Transmission occurred only after close contact. The most common presenting symptoms were fever (in 100 percent of cases) and malaise (in 70 percent), followed by nonproductive cough (in 100 percent) and dyspnea (in 80 percent) associated with infiltrates on chest radiography (in 100 percent). Lymphopenia (in 89 percent of those for whom data were available), elevated lactate dehydrogenase levels (in 80 percent), elevated aspartate aminotransferase levels (in 78 percent), and elevated creatinine kinase levels (in 56 percent) were common. Empirical therapy most commonly included antibiotics, oseltamivir, and intravenous ribavirin. Mechanical ventilation was required in five patients. Three patients died, and five have had clinical improvement. The results of laboratory investigations were negative or not clinically significant except for the amplification of human metapneumovirus from respiratory specimens from five of nine patients and the isolation and amplification of a novel coronavirus from five of nine patients. In four cases both pathogens were isolated. conclusions SARS is a condition associated with substantial morbidity and mortality. It appears to be of viral origin, with patterns suggesting droplet or contact transmission. The role of human metapneumovirus, a novel coronavirus, or both requires further investigation.',\n",
              "  'authors': ['Susan M. Poutanen 1',\n",
              "   ' 2',\n",
              "   ' Donald E. Low 1',\n",
              "   ' Bonnie Henry 3',\n",
              "   ' Sandy Finkelstein 4',\n",
              "   ' David Rose 4',\n",
              "   ' Karen Green 1',\n",
              "   ' Raymond Tellier 5',\n",
              "   ' 6',\n",
              "   ' Ryan Draker 1',\n",
              "   ' Dena Adachi 1',\n",
              "   ' Melissa Ayers 1',\n",
              "   ' Adrienne K. Chan 1',\n",
              "   ' Danuta M. Skowronski 7',\n",
              "   ' Irving Salit 1',\n",
              "   ' Andrew E. Simor 1',\n",
              "   ' Arthur S. Slutsky 1',\n",
              "   ' Patrick W. Doyle 8',\n",
              "   ' Mel Krajden 7',\n",
              "   ' Martin Petric 7',\n",
              "   ' Robert C. Brunham 8',\n",
              "   ' Allison J. McGeer 1'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2100820722',\n",
              "  'references': ['2597070792',\n",
              "   '2161328469',\n",
              "   '2170881661',\n",
              "   '2093852073',\n",
              "   '2463755683',\n",
              "   '2152552492',\n",
              "   '2135259291',\n",
              "   '2136166622',\n",
              "   '2097665403',\n",
              "   '1898899939'],\n",
              "  'title': 'Identification of Severe Acute Respiratory Syndrome in Canada'},\n",
              " {'abstract': 'In recent years, the convolutional neural network (CNN) has achieved great success in many computer vision tasks. Partially inspired by neuroscience, CNN shares many properties with the visual system of the brain. A prominent difference is that CNN is typically a feed-forward architecture while in the visual system recurrent connections are abundant. Inspired by this fact, we propose a recurrent CNN (RCNN) for object recognition by incorporating recurrent connections into each convolutional layer. Though the input is static, the activities of RCNN units evolve over time so that the activity of each unit is modulated by the activities of its neighboring units. This property enhances the ability of the model to integrate the context information, which is important for object recognition. Like other recurrent neural networks, unfolding the RCNN through time can result in an arbitrarily deep network with a fixed number of parameters. Furthermore, the unfolded network has multiple paths, which can facilitate the learning process. The model is tested on four benchmark object recognition datasets: CIFAR-10, CIFAR-100, MNIST and SVHN. With fewer trainable parameters, RCNN outperforms the state-of-the-art models on all of these datasets. Increasing the number of parameters leads to even better performance. These results demonstrate the advantage of the recurrent structure over purely feed-forward structure for object recognition.',\n",
              "  'authors': ['Ming Liang ', ' Xiaolin Hu'],\n",
              "  'date': '2015',\n",
              "  'identifier': '1934184906',\n",
              "  'references': ['2618530766',\n",
              "   '2962835968',\n",
              "   '2097117768',\n",
              "   '2095705004',\n",
              "   '2108598243',\n",
              "   '3118608800',\n",
              "   '2310919327',\n",
              "   '2963911037',\n",
              "   '2143612262',\n",
              "   '2294059674'],\n",
              "  'title': 'Recurrent convolutional neural network for object recognition'},\n",
              " {'abstract': 'Many tasks in computer vision involve assigning a label (such as disparity) to every pixel. A common constraint is that the labels should vary smoothly almost everywhere while preserving sharp discontinuities that may exist, e.g., at object boundaries. These tasks are naturally stated in terms of energy minimization. The authors consider a wide class of energies with various smoothness constraints. Global minimization of these energy functions is NP-hard even in the simplest discontinuity-preserving case. Therefore, our focus is on efficient approximation algorithms. We present two algorithms based on graph cuts that efficiently find a local minimum with respect to two types of large moves, namely expansion moves and swap moves. These moves can simultaneously change the labels of arbitrarily large sets of pixels. In contrast, many standard algorithms (including simulated annealing) use small moves where only one pixel changes its label at a time. Our expansion algorithm finds a labeling within a known factor of the global minimum, while our swap algorithm handles more general energy functions. Both of these algorithms allow important cases of discontinuity preserving energies. We experimentally demonstrate the effectiveness of our approach for image restoration, stereo and motion. On real data with ground truth, we achieve 98 percent accuracy.',\n",
              "  'authors': ['Y. Boykov 1', ' O. Veksler 1', ' R. Zabih 2'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2143516773',\n",
              "  'references': [],\n",
              "  'title': 'Fast approximate energy minimization via graph cuts'},\n",
              " {'abstract': 'We have developed a near-real-time computer system that can locate and track a subject\\'s head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture.',\n",
              "  'authors': ['Matthew Turk ', ' Alex Pentland'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2138451337',\n",
              "  'references': [],\n",
              "  'title': 'Eigenfaces for recognition'},\n",
              " {'abstract': 'This monograph provides an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria in mind: (1) expertise or knowledge of the authors; (2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and (3) the application areas that have the potential to be impacted significantly by deep learning and that have been experiencing research growth, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.',\n",
              "  'authors': ['Li Deng ', ' Dong Yu'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2150341604',\n",
              "  'references': [],\n",
              "  'title': 'Deep Learning: Methods and Applications'},\n",
              " {'abstract': 'We are concerned with feed-forward non-linear networks (multi-layer perceptrons, or MLPs) with multiple outputs. We wish to treat the outputs of the network as probabilities of alternatives (e.g. pattern classes), conditioned on the inputs. We look for appropriate output non-linearities and for appropriate criteria for adaptation of the parameters of the network (e.g. weights). We explain two modifications: probability scoring, which is an alternative to squared error minimisation, and a normalised exponential (softmax) multi-input generalisation of the logistic non-linearity. The two modifications together result in quite simple arithmetic, and hardware implementation is not difficult either. The use of radial units (squared distance instead of dot product) immediately before the softmax output stage produces a network which computes posterior distributions over class labels based on an assumption of Gaussian within-class distributions. However the training, which uses cross-class information, can result in better performance at class discrimination than the usual within-class training method, unless the within-class distribution assumptions are actually correct.',\n",
              "  'authors': ['John S. Bridle'],\n",
              "  'date': '1990',\n",
              "  'identifier': '183625566',\n",
              "  'references': [],\n",
              "  'title': 'Probabilistic Interpretation of Feedforward Classification Network Outputs, with Relationships to Statistical Pattern Recognition'},\n",
              " {'abstract': \"Preface to the Second Edition. Preface to the First Edition. Acknowledgments for the Second Edition. Acknowledgments for the First Edition. 1. Introduction and Preview. 1.1 Preview of the Book. 2. Entropy, Relative Entropy, and Mutual Information. 2.1 Entropy. 2.2 Joint Entropy and Conditional Entropy. 2.3 Relative Entropy and Mutual Information. 2.4 Relationship Between Entropy and Mutual Information. 2.5 Chain Rules for Entropy, Relative Entropy, and Mutual Information. 2.6 Jensen's Inequality and Its Consequences. 2.7 Log Sum Inequality and Its Applications. 2.8 Data-Processing Inequality. 2.9 Sufficient Statistics. 2.10 Fano's Inequality. Summary. Problems. Historical Notes. 3. Asymptotic Equipartition Property. 3.1 Asymptotic Equipartition Property Theorem. 3.2 Consequences of the AEP: Data Compression. 3.3 High-Probability Sets and the Typical Set. Summary. Problems. Historical Notes. 4. Entropy Rates of a Stochastic Process. 4.1 Markov Chains. 4.2 Entropy Rate. 4.3 Example: Entropy Rate of a Random Walk on a Weighted Graph. 4.4 Second Law of Thermodynamics. 4.5 Functions of Markov Chains. Summary. Problems. Historical Notes. 5. Data Compression. 5.1 Examples of Codes. 5.2 Kraft Inequality. 5.3 Optimal Codes. 5.4 Bounds on the Optimal Code Length. 5.5 Kraft Inequality for Uniquely Decodable Codes. 5.6 Huffman Codes. 5.7 Some Comments on Huffman Codes. 5.8 Optimality of Huffman Codes. 5.9 Shannon-Fano-Elias Coding. 5.10 Competitive Optimality of the Shannon Code. 5.11 Generation of Discrete Distributions from Fair Coins. Summary. Problems. Historical Notes. 6. Gambling and Data Compression. 6.1 The Horse Race. 6.2 Gambling and Side Information. 6.3 Dependent Horse Races and Entropy Rate. 6.4 The Entropy of English. 6.5 Data Compression and Gambling. 6.6 Gambling Estimate of the Entropy of English. Summary. Problems. Historical Notes. 7. Channel Capacity. 7.1 Examples of Channel Capacity. 7.2 Symmetric Channels. 7.3 Properties of Channel Capacity. 7.4 Preview of the Channel Coding Theorem. 7.5 Definitions. 7.6 Jointly Typical Sequences. 7.7 Channel Coding Theorem. 7.8 Zero-Error Codes. 7.9 Fano's Inequality and the Converse to the Coding Theorem. 7.10 Equality in the Converse to the Channel Coding Theorem. 7.11 Hamming Codes. 7.12 Feedback Capacity. 7.13 Source-Channel Separation Theorem. Summary. Problems. Historical Notes. 8. Differential Entropy. 8.1 Definitions. 8.2 AEP for Continuous Random Variables. 8.3 Relation of Differential Entropy to Discrete Entropy. 8.4 Joint and Conditional Differential Entropy. 8.5 Relative Entropy and Mutual Information. 8.6 Properties of Differential Entropy, Relative Entropy, and Mutual Information. Summary. Problems. Historical Notes. 9. Gaussian Channel. 9.1 Gaussian Channel: Definitions. 9.2 Converse to the Coding Theorem for Gaussian Channels. 9.3 Bandlimited Channels. 9.4 Parallel Gaussian Channels. 9.5 Channels with Colored Gaussian Noise. 9.6 Gaussian Channels with Feedback. Summary. Problems. Historical Notes. 10. Rate Distortion Theory. 10.1 Quantization. 10.2 Definitions. 10.3 Calculation of the Rate Distortion Function. 10.4 Converse to the Rate Distortion Theorem. 10.5 Achievability of the Rate Distortion Function. 10.6 Strongly Typical Sequences and Rate Distortion. 10.7 Characterization of the Rate Distortion Function. 10.8 Computation of Channel Capacity and the Rate Distortion Function. Summary. Problems. Historical Notes. 11. Information Theory and Statistics. 11.1 Method of Types. 11.2 Law of Large Numbers. 11.3 Universal Source Coding. 11.4 Large Deviation Theory. 11.5 Examples of Sanov's Theorem. 11.6 Conditional Limit Theorem. 11.7 Hypothesis Testing. 11.8 Chernoff-Stein Lemma. 11.9 Chernoff Information. 11.10 Fisher Information and the Cram-er-Rao Inequality. Summary. Problems. Historical Notes. 12. Maximum Entropy. 12.1 Maximum Entropy Distributions. 12.2 Examples. 12.3 Anomalous Maximum Entropy Problem. 12.4 Spectrum Estimation. 12.5 Entropy Rates of a Gaussian Process. 12.6 Burg's Maximum Entropy Theorem. Summary. Problems. Historical Notes. 13. Universal Source Coding. 13.1 Universal Codes and Channel Capacity. 13.2 Universal Coding for Binary Sequences. 13.3 Arithmetic Coding. 13.4 Lempel-Ziv Coding. 13.5 Optimality of Lempel-Ziv Algorithms. Compression. Summary. Problems. Historical Notes. 14. Kolmogorov Complexity. 14.1 Models of Computation. 14.2 Kolmogorov Complexity: Definitions and Examples. 14.3 Kolmogorov Complexity and Entropy. 14.4 Kolmogorov Complexity of Integers. 14.5 Algorithmically Random and Incompressible Sequences. 14.6 Universal Probability. 14.7 Kolmogorov complexity. 14.9 Universal Gambling. 14.10 Occam's Razor. 14.11 Kolmogorov Complexity and Universal Probability. 14.12 Kolmogorov Sufficient Statistic. 14.13 Minimum Description Length Principle. Summary. Problems. Historical Notes. 15. Network Information Theory. 15.1 Gaussian Multiple-User Channels. 15.2 Jointly Typical Sequences. 15.3 Multiple-Access Channel. 15.4 Encoding of Correlated Sources. 15.5 Duality Between Slepian-Wolf Encoding and Multiple-Access Channels. 15.6 Broadcast Channel. 15.7 Relay Channel. 15.8 Source Coding with Side Information. 15.9 Rate Distortion with Side Information. 15.10 General Multiterminal Networks. Summary. Problems. Historical Notes. 16. Information Theory and Portfolio Theory. 16.1 The Stock Market: Some Definitions. 16.2 Kuhn-Tucker Characterization of the Log-Optimal Portfolio. 16.3 Asymptotic Optimality of the Log-Optimal Portfolio. 16.4 Side Information and the Growth Rate. 16.5 Investment in Stationary Markets. 16.6 Competitive Optimality of the Log-Optimal Portfolio. 16.7 Universal Portfolios. 16.8 Shannon-McMillan-Breiman Theorem (General AEP). Summary. Problems. Historical Notes. 17. Inequalities in Information Theory. 17.1 Basic Inequalities of Information Theory. 17.2 Differential Entropy. 17.3 Bounds on Entropy and Relative Entropy. 17.4 Inequalities for Types. 17.5 Combinatorial Bounds on Entropy. 17.6 Entropy Rates of Subsets. 17.7 Entropy and Fisher Information. 17.8 Entropy Power Inequality and Brunn-Minkowski Inequality. 17.9 Inequalities for Determinants. 17.10 Inequalities for Ratios of Determinants. Summary. Problems. Historical Notes. Bibliography. List of Symbols. Index.\",\n",
              "  'authors': ['Thomas M. Cover 1', ' Joy A. Thomas 2'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2099111195',\n",
              "  'references': ['2071707134',\n",
              "   '2106248279',\n",
              "   '2148963518',\n",
              "   '2032372805',\n",
              "   '2132103241',\n",
              "   '2165232124',\n",
              "   '2151795416',\n",
              "   '2790166049'],\n",
              "  'title': 'Elements of information theory'},\n",
              " {'abstract': 'In 1948 W. R. Bennett used a companding model for nonuniform quantization and proposed the formula D \\\\: = \\\\: \\\\frac{1}{12N^{2}} \\\\: \\\\int \\\\: p(x) [ E(x) ]^{-2} \\\\dx for the mean-square quantizing error where N is the number of levels, p (x) is the probability density of the input, and E \\\\prime (x) is the slope of the compressor curve. The formula, an approximation based on the assumption that the number of levels is large and overload distortion is negligible, is a useful tool for analytical studies of quantization. This paper gives a heuristic argument generalizing Bennett\\'s formula to block quantization where a vector of random variables is quantized. The approach is again based on the asymptotic situation where N , the number of quantized output vectors, is very large. Using the resulting heuristic formula, an optimization is performed leading to an expression for the minimum quantizing noise attainable for any block quantizer of a given block size k . The results are consistent with Zador\\'s results and specialize to known results for the one- and two-dimensional cases and for the case of infinite block length (k \\\\rightarrow \\\\infty) . The same heuristic approach also gives an alternate derivation of a bound of Elias for multidimensional quantization. Our approach leads to a rigorous method for obtaining upper bounds on the minimum distortion for block quantizers. In particular, for k = 3 we give a tight upper bound that may in fact be exact. The idea of representing a block quantizer by a block \"compressor\" mapping followed with an optimal quantizer for uniformly distributed random vectors is also explored. It is not always possible to represent an optimal quantizer with this block companding model.',\n",
              "  'authors': ['A. Gersho'],\n",
              "  'date': '1979',\n",
              "  'identifier': '2142228262',\n",
              "  'references': [],\n",
              "  'title': 'Asymptotically optimal block quantization'},\n",
              " {'abstract': 'This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. Fast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very deep VGG16 network 9x faster than R-CNN, is 213x faster at test-time, and achieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ (using Caffe) and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn.',\n",
              "  'authors': ['Ross Girshick'],\n",
              "  'date': '2015',\n",
              "  'identifier': '1536680647',\n",
              "  'references': [],\n",
              "  'title': 'Fast R-CNN'},\n",
              " {'abstract': 'We address the issue of compressing and indexing data. We devise a data structure whose space occupancy is a function of the entropy of the underlying data set. We call the data structure opportunistic since its space occupancy is decreased when the input is compressible and this space reduction is achieved at no significant slowdown in the query performance. More precisely, its space occupancy is optimal in an information-content sense because text T[1,u] is stored using O(H/sub k/(T))+o(1) bits per input symbol in the worst case, where H/sub k/(T) is the kth order empirical entropy of T (the bound holds for any fixed k). Given an arbitrary string P[1,p], the opportunistic data structure allows to search for the occurrences of P in T in O(p+occlog/sup /spl epsiv//u) time (for any fixed /spl epsiv/>0). If data are uncompressible we achieve the best space bound currently known (Grossi and Vitter, 2000); on compressible data our solution improves the succinct suffix array of (Grossi and Vitter, 2000) and the classical suffix tree and suffix array data structures either in space or in query time or both. We also study our opportunistic data structure in a dynamic setting and devise a variant achieving effective search and update time bounds. Finally, we show how to plug our opportunistic data structure into the Glimpse tool (Manber and Wu, 1994). The result is an indexing tool which achieves sublinear space and sublinear query time complexity.',\n",
              "  'authors': ['P. Ferragina ', ' G. Manzini'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2158322625',\n",
              "  'references': ['2160484851',\n",
              "   '2161488606',\n",
              "   '2158874082',\n",
              "   '1603784832',\n",
              "   '1529205966',\n",
              "   '1975965284',\n",
              "   '1600795850',\n",
              "   '2087721273',\n",
              "   '1965853364',\n",
              "   '2017392697'],\n",
              "  'title': 'Opportunistic data structures with applications'},\n",
              " {'abstract': 'The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.',\n",
              "  'authors': ['Jia Deng ',\n",
              "   ' Wei Dong ',\n",
              "   ' Richard Socher ',\n",
              "   ' Li-Jia Li ',\n",
              "   ' Kai Li ',\n",
              "   ' Li Fei-Fei'],\n",
              "  'date': '2009',\n",
              "  'identifier': '2108598243',\n",
              "  'references': ['2151103935',\n",
              "   '2038721957',\n",
              "   '2128017662',\n",
              "   '2110764733',\n",
              "   '1782590233',\n",
              "   '1576445103',\n",
              "   '2145607950',\n",
              "   '2141282920',\n",
              "   '2115733720',\n",
              "   '1528789833'],\n",
              "  'title': 'ImageNet: A large-scale hierarchical image database'},\n",
              " {'abstract': 'We present a generative appearance-based method for recognizing human faces under variation in lighting and viewpoint. Our method exploits the fact that the set of images of an object in fixed pose, but under all possible illumination conditions, is a convex cone in the space of images. Using a small number of training images of each face taken with different lighting directions, the shape and albedo of the face can be reconstructed. In turn, this reconstruction serves as a generative model that can be used to render (or synthesize) images of the face under novel poses and illumination conditions. The pose space is then sampled and, for each pose, the corresponding illumination cone is approximated by a low-dimensional linear subspace whose basis vectors are estimated using the generative model. Our recognition algorithm assigns to a test image the identity of the closest approximated illumination cone. Test results show that the method performs almost without error, except on the most extreme lighting directions.',\n",
              "  'authors': ['A.S. Georghiades 1', ' P.N. Belhumeur 1', ' D.J. Kriegman 2'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2123921160',\n",
              "  'references': ['2138451337',\n",
              "   '2217896605',\n",
              "   '2121647436',\n",
              "   '2152826865',\n",
              "   '2033419168',\n",
              "   '2159686933',\n",
              "   '2123977795',\n",
              "   '2115689562',\n",
              "   '2120954940',\n",
              "   '2098947662'],\n",
              "  'title': 'From few to many: illumination cone models for face recognition under variable lighting and pose'},\n",
              " {'abstract': 'We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.',\n",
              "  'authors': ['Tsung-Yi Lin 1',\n",
              "   ' Michael Maire 2',\n",
              "   ' Serge J. Belongie 1',\n",
              "   ' James Hays 3',\n",
              "   ' Pietro Perona 2',\n",
              "   ' Deva Ramanan 4',\n",
              "   ' Piotr Dollár 5',\n",
              "   ' C. Lawrence Zitnick 5'],\n",
              "  'date': '2014',\n",
              "  'identifier': '1861492603',\n",
              "  'references': ['2618530766',\n",
              "   '2102605133',\n",
              "   '2161969291',\n",
              "   '2108598243',\n",
              "   '2168356304',\n",
              "   '2963542991',\n",
              "   '3118608800',\n",
              "   '2031489346',\n",
              "   '2038721957',\n",
              "   '2110158442'],\n",
              "  'title': 'Microsoft COCO: Common Objects in Context'},\n",
              " {'abstract': 'The problem of learning a general input-output relation using a layered neural network is discussed in a statistical framework. By imposing the consistency condition that the error minimization be equivalent to a likelihood maximization for training the network, the authors arrive at a Gibbs distribution on a canonical ensemble of networks with the same architecture. This statistical description enables them to evaluate the probability of a correct prediction of an independent example, after training the network on a given training set. The prediction probability is highly correlated with the generalization ability of the network, as measured outside the training set. This suggests a general and practical criterion for training layered networks by minimizing prediction errors. The authors demonstrate the utility of this criterion for selecting the optimal architecture in the continuity problem. As a theoretical application of the statistical formalism, they discuss the question of learning curves and estimate the sufficient training size needed for correct generalization, in a simple example. >',\n",
              "  'authors': ['Tishby 1', ' Levin 1', ' Solla 2'],\n",
              "  'date': '1989',\n",
              "  'identifier': '1965770722',\n",
              "  'references': ['2581275558',\n",
              "   '2293063825',\n",
              "   '1593125407',\n",
              "   '56903235',\n",
              "   '1968908999',\n",
              "   '2012903341',\n",
              "   '2123838014',\n",
              "   '2043014754',\n",
              "   '2476694670',\n",
              "   '2161278885'],\n",
              "  'title': 'Consistent inference of probabilities in layered networks: predictions and generalizations'},\n",
              " {'abstract': 'Human coronaviruses (HCoVs) were first described in the 1960s for patients with the common cold. Since then, more HCoVs have been discovered, including those that cause severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS), two pathogens that, upon infection, can cause fatal respiratory disease in humans. It was recently discovered that dromedary camels in Saudi Arabia harbor three different HCoV species, including a dominant MERS HCoV lineage that was responsible for the outbreaks in the Middle East and South Korea during 2015. In this review we aim to compare and contrast the different HCoVs with regard to epidemiology and pathogenesis, in addition to the virus evolution and recombination events which have, on occasion, resulted in outbreaks amongst humans.',\n",
              "  'authors': ['Shuo Su 1',\n",
              "   ' Gary Wong 2',\n",
              "   ' Weifeng Shi 3',\n",
              "   ' Jun Liu 2',\n",
              "   ' 4',\n",
              "   ' Alexander C.K. Lai 5',\n",
              "   ' Jiyong Zhou 1',\n",
              "   ' Wenjun Liu 2',\n",
              "   ' Yuhai Bi 2',\n",
              "   ' George F. Gao 6'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2306794997',\n",
              "  'references': ['2166867592',\n",
              "   '2025170735',\n",
              "   '2006434809',\n",
              "   '2129542667',\n",
              "   '1993577573',\n",
              "   '2138324310',\n",
              "   '2125251240',\n",
              "   '2160011624',\n",
              "   '2115555188',\n",
              "   '2134061616'],\n",
              "  'title': 'Epidemiology, Genetic Recombination, and Pathogenesis of Coronaviruses'},\n",
              " {'abstract': 'A model for channels in which an input sequence can produce output sequences of varying length is described. An efficient computational procedure for calculating Pr \\\\{Y\\\\mid X\\\\} is devised, where X = x_1,x_2,\\\\cdots,x_M and Y = y_1,y_2,\\\\cdots,y_N are the input and output of the channel. A stack decoding algorithm for decoding on such channels is presented. The appropriate likelihood function is derived. Channels with memory are considered. Some applications to speech and character recognition are discussed.',\n",
              "  'authors': ['L. Bahl 1', ' F. Jelinek 2'],\n",
              "  'date': '1975',\n",
              "  'identifier': '2157477135',\n",
              "  'references': ['1991133427',\n",
              "   '2134587001',\n",
              "   '2035227369',\n",
              "   '2169944289',\n",
              "   '2074460300'],\n",
              "  'title': 'Decoding for channels with insertions, deletions, and substitutions with applications to speech recognition'},\n",
              " {'abstract': 'We present a method for training a similarity metric from data. The method can be used for recognition or verification applications where the number of categories is very large and not known during training, and where the number of training samples for a single category is very small. The idea is to learn a function that maps input patterns into a target space such that the L/sub 1/ norm in the target space approximates the \"semantic\" distance in the input space. The method is applied to a face verification task. The learning process minimizes a discriminative loss function that drives the similarity metric to be small for pairs of faces from the same person, and large for pairs from different persons. The mapping from raw to the target space is a convolutional network whose architecture is designed for robustness to geometric distortions. The system is tested on the Purdue/AR face database which has a very high degree of variability in the pose, lighting, expression, position, and artificial occlusions such as dark glasses and obscuring scarves.',\n",
              "  'authors': ['S. Chopra ', ' R. Hadsell ', ' Y. LeCun'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2157364932',\n",
              "  'references': ['2310919327',\n",
              "   '2053186076',\n",
              "   '2138451337',\n",
              "   '2121647436',\n",
              "   '2095757522',\n",
              "   '2994340921',\n",
              "   '2144354855',\n",
              "   '2107369107',\n",
              "   '1802356529',\n",
              "   '10021998'],\n",
              "  'title': 'Learning a similarity metric discriminatively, with application to face verification'},\n",
              " {'abstract': 'We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer.',\n",
              "  'authors': ['S. Lawrence 1',\n",
              "   ' C.L. Giles 2',\n",
              "   ' Ah Chung Tsoi 2',\n",
              "   ' A.D. Back 3'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2144354855',\n",
              "  'references': ['2124776405',\n",
              "   '1679913846',\n",
              "   '2138451337',\n",
              "   '2046079134',\n",
              "   '2115689562',\n",
              "   '2098947662',\n",
              "   '2113341759',\n",
              "   '1770825568',\n",
              "   '2095757522',\n",
              "   '2012352340'],\n",
              "  'title': 'Face recognition: a convolutional neural-network approach'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Theodosios Pavlidis'],\n",
              "  'date': '1977',\n",
              "  'identifier': '1530383550',\n",
              "  'references': ['1999478155',\n",
              "   '2132549764',\n",
              "   '2116341502',\n",
              "   '2042316011',\n",
              "   '2109863423',\n",
              "   '1972544340',\n",
              "   '2294922303',\n",
              "   '2131673214',\n",
              "   '1970800786',\n",
              "   '2109268594'],\n",
              "  'title': 'Structural pattern recognition'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Solomon Kullback'],\n",
              "  'date': '1959',\n",
              "  'identifier': '2123838014',\n",
              "  'references': ['1667950888',\n",
              "   '2163352848',\n",
              "   '2133475491',\n",
              "   '1528905581',\n",
              "   '1594031697',\n",
              "   '2124101779',\n",
              "   '2143668817',\n",
              "   '2157321686',\n",
              "   '2122361470'],\n",
              "  'title': 'Information Theory and Statistics'},\n",
              " {'abstract': 'Presents a theoretically very simple, yet efficient, multiresolution approach to gray-scale and rotation invariant texture classification based on local binary patterns and nonparametric discrimination of sample and prototype distributions. The method is based on recognizing that certain local binary patterns, termed \"uniform,\" are fundamental properties of local image texture and their occurrence histogram is proven to be a very powerful texture feature. We derive a generalized gray-scale and rotation invariant operator presentation that allows for detecting the \"uniform\" patterns for any quantization of the angular space and for any spatial resolution and presents a method for combining multiple operators for multiresolution analysis. The proposed approach is very robust in terms of gray-scale variations since the operator is, by definition, invariant against any monotonic transformation of the gray scale. Another advantage is computational simplicity as the operator can be realized with a few operations in a small neighborhood and a lookup table. Experimental results demonstrate that good discrimination can be achieved with the occurrence statistics of simple rotation invariant local binary patterns.',\n",
              "  'authors': ['T. Ojala ', ' M. Pietikainen ', ' T. Maenpaa'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2163352848',\n",
              "  'references': ['2039051707',\n",
              "   '3017143921',\n",
              "   '2098347925',\n",
              "   '2106798282',\n",
              "   '2132047332',\n",
              "   '2159988601',\n",
              "   '2021751319',\n",
              "   '1993655741',\n",
              "   '2136343973',\n",
              "   '2124353687'],\n",
              "  'title': 'Multiresolution gray-scale and rotation invariant texture classification with local binary patterns'},\n",
              " {'abstract': 'Automatic facial expression analysis is an interesting and challenging problem, and impacts important applications in many areas such as human-computer interaction and data-driven animation. Deriving an effective facial representation from original face images is a vital step for successful facial expression recognition. In this paper, we empirically evaluate facial representation based on statistical local features, Local Binary Patterns, for person-independent facial expression recognition. Different machine learning methods are systematically examined on several databases. Extensive experiments illustrate that LBP features are effective and efficient for facial expression recognition. We further formulate Boosted-LBP to extract the most discriminant LBP features, and the best recognition performance is obtained by using Support Vector Machine classifiers with Boosted-LBP features. Moreover, we investigate LBP features for low-resolution facial expression recognition, which is a critical problem but seldom addressed in the existing work. We observe in our experiments that LBP features perform stably and robustly over a useful range of low resolutions of face images, and yield promising performance in compressed low-resolution video sequences captured in real-world environments.',\n",
              "  'authors': ['Caifeng Shan 1', ' Shaogang Gong 2', ' Peter W. McOwan 2'],\n",
              "  'date': '2009',\n",
              "  'identifier': '2145310492',\n",
              "  'references': ['2148603752',\n",
              "   '2164598857',\n",
              "   '2163352848',\n",
              "   '1988790447',\n",
              "   '2109943925',\n",
              "   '2121647436',\n",
              "   '1545641654',\n",
              "   '2139916508',\n",
              "   '2098693229',\n",
              "   '2039051707'],\n",
              "  'title': 'Facial expression recognition based on Local Binary Patterns: A comprehensive study'},\n",
              " {'abstract': 'Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics.The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.',\n",
              "  'authors': ['Carl Edward Rasmussen 1', ' Christopher K I Williams 2'],\n",
              "  'date': '2005',\n",
              "  'identifier': '1746819321',\n",
              "  'references': ['2296319761',\n",
              "   '2156909104',\n",
              "   '2148603752',\n",
              "   '2170120409',\n",
              "   '1554663460',\n",
              "   '3023786531',\n",
              "   '2165363188',\n",
              "   '2117812871',\n",
              "   '2798909945',\n",
              "   '2078206416'],\n",
              "  'title': 'Gaussian Processes for Machine Learning'},\n",
              " {'abstract': '',\n",
              "  'authors': ['E.T. Jaynes'],\n",
              "  'date': '1986',\n",
              "  'identifier': '2989873570',\n",
              "  'references': ['2911546748',\n",
              "   '2143841415',\n",
              "   '1992880122',\n",
              "   '2076108528',\n",
              "   '2156297475',\n",
              "   '2126880773',\n",
              "   '2115305054',\n",
              "   '1972961786',\n",
              "   '2117670920',\n",
              "   '391985582'],\n",
              "  'title': 'Maximum Entropy and Bayesian Methods in Applied Statistics: Bayesian Methods: General Background'},\n",
              " {'abstract': \"MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.\",\n",
              "  'authors': ['Jeffrey Dean ', ' Sanjay Ghemawat'],\n",
              "  'date': '2008',\n",
              "  'identifier': '2173213060',\n",
              "  'references': ['2173213060',\n",
              "   '2119565742',\n",
              "   '2148317584',\n",
              "   '2073965851',\n",
              "   '2109722477',\n",
              "   '2104644701',\n",
              "   '1510543252',\n",
              "   '2044534358',\n",
              "   '1988243929',\n",
              "   '2045271686'],\n",
              "  'title': 'MapReduce: simplified data processing on large clusters'},\n",
              " {'abstract': \"Our present knowledge ofhow mammalian retinal ganglion-cell receptive fields are organized is based mainly on findings in the cat by Kuffler (1953). These results have since been confirmed and extended (Barlow, FitzHugh & Kuffler, 1957; Hubel, 1960; Wiesel, 1960), but up to now similar studies have not been made in primates. The retina of the monkey is of interest, since in most species, including Ateles (spider monkey) and Macaca mulatta, it is deeply pigmented and has a well defined fovea. It appears to be much closer to the human retina than to that of the cat, which has a highly reflectile tapetum and lacks a fovea. The purpose of this report is to describe the receptive fields of single optic nerve fibres in the spider monkey. In view of the monkey's ability to discriminate colours, some observations were also made on ganglion cell responses to monochromatic stimuli.\",\n",
              "  'authors': ['D. H. Hubel ', ' T. N. Wiesel'],\n",
              "  'date': '1960',\n",
              "  'identifier': '2111624873',\n",
              "  'references': ['2103212315',\n",
              "   '2037316494',\n",
              "   '2212384750',\n",
              "   '2010554296',\n",
              "   '2031864849',\n",
              "   '2086487914',\n",
              "   '2130247646',\n",
              "   '2414888802',\n",
              "   '2036401809',\n",
              "   '2416990779'],\n",
              "  'title': 'Receptive fields of optic nerve fibres in the spider monkey.'},\n",
              " {'abstract': '1 The general nature of Monte Carlo methods.- 2 Short resume of statistical terms.- 3 Random, pseudorandom, and quasirandom numbers.- 4 Direct simulation.- 5 General principles of the Monte Carlo method.- 6 Conditional Monte Carlo.- 7 Solution of linear operator equations.- 8 Radiation shielding and reactor criticality.- 9 Problems in statistical mechanics.- 10 Long polymer molecules.- 11 Percolation processes.- 12 Multivariable problems.- References.',\n",
              "  'authors': ['J. M. Hammersley ', ' D. C. Handscomb'],\n",
              "  'date': '1964',\n",
              "  'identifier': '2014208555',\n",
              "  'references': ['3102641634',\n",
              "   '2121863487',\n",
              "   '1997063559',\n",
              "   '1991252559',\n",
              "   '1979104937',\n",
              "   '2432517183',\n",
              "   '2141113219',\n",
              "   '2157082398',\n",
              "   '2136796925'],\n",
              "  'title': 'Monte Carlo methods'},\n",
              " {'abstract': 'Background. Introduction to Tree Classification. Right Sized Trees and Honest Estimates. Splitting Rules. Strengthening and Interpreting. Medical Diagnosis and Prognosis. Mass Spectra Classification. Regression Trees. Bayes Rules and Partitions. Optimal Pruning. Construction of Trees from a Learning Sample. Consistency. Bibliography. Notation Index. Subject Index.',\n",
              "  'authors': ['Leo Breiman'],\n",
              "  'date': '1983',\n",
              "  'identifier': '1594031697',\n",
              "  'references': [],\n",
              "  'title': 'Classification and regression trees'},\n",
              " {'abstract': 'Unsupervised image-to-image translation aims at learning a joint distribution of images in different domains by using images from the marginal distributions in individual domains. Since there exists an infinite set of joint distributions that can arrive the given marginal distributions, one could infer nothing about the joint distribution from the marginal distributions without additional assumptions. To address the problem, we make a shared-latent space assumption and propose an unsupervised image-to-image translation framework based on Coupled GANs. We compare the proposed framework with competing approaches and present high quality image translation results on various challenging unsupervised image translation tasks, including street scene image translation, animal image translation, and face image translation. We also apply the proposed framework to domain adaptation and achieve state-of-the-art performance on benchmark datasets. Code and additional results are available in https://github.com/mingyuliutw/unit.',\n",
              "  'authors': ['Ming-Yu Liu 1', ' Thomas Breuel 2', ' Jan Kautz 3'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2962947361',\n",
              "  'references': ['2962793481',\n",
              "   '2795155917',\n",
              "   '2984529706',\n",
              "   '2963626105',\n",
              "   '3098418424',\n",
              "   '2989855043',\n",
              "   '2970902013',\n",
              "   '2981988113'],\n",
              "  'title': 'Unsupervised Image-to-Image Translation Networks'},\n",
              " {'abstract': \"We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN.\",\n",
              "  'authors': ['Ian Goodfellow ',\n",
              "   ' David Warde-Farley ',\n",
              "   ' Mehdi Mirza ',\n",
              "   ' Aaron Courville ',\n",
              "   ' Yoshua Bengio'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2294059674',\n",
              "  'references': ['2618530766',\n",
              "   '3118608800',\n",
              "   '2310919327',\n",
              "   '1904365287',\n",
              "   '2912934387',\n",
              "   '2546302380',\n",
              "   '2131241448',\n",
              "   '2335728318',\n",
              "   '2156387975',\n",
              "   '189596042'],\n",
              "  'title': 'Maxout Networks'},\n",
              " {'abstract': 'A general-purpose computer vision system must be capable of recognizing three-dimensional (3-D) objects. This paper proposes a precise definition of the 3-D object recognition problem, discusses basic concepts associated with this problem, and reviews the relevant literature. Because range images (or depth maps) are often used as sensor input instead of intensity images, techniques for obtaining, processing, and characterizing range data are also surveyed.',\n",
              "  'authors': ['Paul J. Besl ', ' Ramesh C. Jain'],\n",
              "  'date': '1985',\n",
              "  'identifier': '1996773532',\n",
              "  'references': ['2740373864',\n",
              "   '1622620102',\n",
              "   '2083632529',\n",
              "   '2164934677',\n",
              "   '2113511941',\n",
              "   '2100185791',\n",
              "   '1587467920',\n",
              "   '2130755868',\n",
              "   '2163775665',\n",
              "   '1975470983'],\n",
              "  'title': 'Three-dimensional object recognition'},\n",
              " {'abstract': 'A real-time reverse transcription-polymerase chain reaction (RT-PCR) assay was developed to rapidly detect the severe acute respiratory syndrome-associated coronavirus (SARS-CoV). The assay, based on multiple primer and probe sets located in different regions of the SARS-CoV genome, could discriminate SARS-CoV from other human and animal coronaviruses with a potential detection limit of <10 genomic copies per reaction. The real-time RT-PCR assay was more sensitive than a conventional RT-PCR assay or culture isolation and proved suitable to detect SARS-CoV in clinical specimens. Application of this assay will aid in diagnosing SARS-CoV infection.',\n",
              "  'authors': ['Shannon L. Emery ',\n",
              "   ' Dean D. Erdman ',\n",
              "   ' Michael D. Bowen ',\n",
              "   ' Bruce R. Newton ',\n",
              "   ' Jonas M. Winchell ',\n",
              "   ' Richard F. Meyer ',\n",
              "   ' Suxiang Tong ',\n",
              "   ' Byron T. Cook ',\n",
              "   ' Brian P. Holloway ',\n",
              "   ' Karen A. McCaustland ',\n",
              "   ' Paul A. Rota ',\n",
              "   ' Bettina Bankamp ',\n",
              "   ' Luis E. Lowe ',\n",
              "   ' Thomas Ksiazek ',\n",
              "   ' William J. Bellini ',\n",
              "   ' Larry J. Anderson'],\n",
              "  'date': '2004',\n",
              "  'identifier': '1975169783',\n",
              "  'references': ['2132260239',\n",
              "   '2104548316',\n",
              "   '2131262274',\n",
              "   '2129542667',\n",
              "   '2100820722',\n",
              "   '2125251240',\n",
              "   '2116586125',\n",
              "   '2463755683',\n",
              "   '2100187217',\n",
              "   '1959254653'],\n",
              "  'title': 'Real-time reverse transcription-polymerase chain reaction assay for SARS-associated coronavirus.'},\n",
              " {'abstract': 'Abstract We present a multiresolution simultaneous autoregressive (MR-SAR) model for texture classification and segmentation. First, a multivariate rotation-invariant SAR (RISAR) model is introduced which is based on the circular autoregressive (CAR) model. Experiments show that the multivariate RISAR model outperforms the CAR model in texture classification. Then, we demonstrate that integrating the information extracted from multiresolution SAR models gives much better performance than single resolution methods in both texture classification and texture segmentation. A quality measure to evaluate individual features for the purpose of segmentation is also presented. We employ the spatial coordinates of the pixels as two additional features to remove small speckles in the segmented image, and carefully examine the role that the spatial features play in texture segmentation. Two internal indices are introduced to evaluate the unsupervised segmentation and to find the “true” number of segments or clusters existing in the textured image.',\n",
              "  'authors': ['Jianchang Mao ', ' Anil K. Jain'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2021751319',\n",
              "  'references': ['1971784203',\n",
              "   '2166982406',\n",
              "   '2049694710',\n",
              "   '2059432853',\n",
              "   '2114220616',\n",
              "   '2168962753',\n",
              "   '2065301447',\n",
              "   '2038836824',\n",
              "   '2018038558',\n",
              "   '2126397022'],\n",
              "  'title': 'Texture classification and segmentation using multiresolution simultaneous autoregressive models'},\n",
              " {'abstract': '',\n",
              "  'authors': ['James Jerome Gibson'],\n",
              "  'date': '1950',\n",
              "  'identifier': '2002010034',\n",
              "  'references': [],\n",
              "  'title': 'The perception of the visual world'},\n",
              " {'abstract': 'We describe a new method of matching statistical models of appearance to images. A set of model parameters control modes of shape and gray-level variation learned from a training set. We construct an efficient iterative matching algorithm by learning the relationship between perturbations in the model parameters and the induced image errors.',\n",
              "  'authors': ['T.F. Cootes 1', ' G.J. Edwards 2', ' C.J. Taylor 1'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2152826865',\n",
              "  'references': [],\n",
              "  'title': 'Active appearance models'},\n",
              " {'abstract': 'We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by (1) solving for correspondences between points on the two shapes, (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. Dis-similarity between two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework. Results are presented for silhouettes, trademarks, handwritten digits and the COIL dataset.',\n",
              "  'authors': ['S. Belongie ', ' J. Malik ', ' J. Puzicha'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2295106276',\n",
              "  'references': [],\n",
              "  'title': 'Matching shapes'},\n",
              " {'abstract': 'Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on the learnable activation and advanced initialization, we achieve 4.94% top-5 test error on the ImageNet 2012 classification dataset. This is a 26% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66% [33]). To our knowledge, our result is the first to surpass the reported human-level performance (5.1%, [26]) on this dataset.',\n",
              "  'authors': ['Kaiming He 1',\n",
              "   ' Xiangyu Zhang 2',\n",
              "   ' Shaoqing Ren 1',\n",
              "   ' Jian Sun 1'],\n",
              "  'date': '2015',\n",
              "  'identifier': '1677182931',\n",
              "  'references': ['2618530766',\n",
              "   '2962835968',\n",
              "   '2097117768',\n",
              "   '1836465849',\n",
              "   '2102605133',\n",
              "   '2117539524',\n",
              "   '2095705004',\n",
              "   '2108598243',\n",
              "   '2155893237',\n",
              "   '1536680647'],\n",
              "  'title': 'Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification'},\n",
              " {'abstract': 'This work focuses on algorithms which learn from examples to perform multiclass text and speech categorization tasks. Our approach is based on a new and improved family of boosting algorithms. We describe in detail an implementation, called BoosTexter, of the new boosting algorithms for text categorization tasks. We present results comparing the performance of BoosTexter and a number of other text-categorization algorithms on a variety of tasks. We conclude by describing the application of our system to automatic call-type identification from unconstrained spoken customer responses.',\n",
              "  'authors': ['Robert E. Schapire 1', ' Yoram Singer 2'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2053463056',\n",
              "  'references': ['1988790447',\n",
              "   '2112076978',\n",
              "   '1975846642',\n",
              "   '1956559956',\n",
              "   '2114535528',\n",
              "   '1670263352',\n",
              "   '2096152098',\n",
              "   '2032210760',\n",
              "   '1966280301',\n",
              "   '2067885219'],\n",
              "  'title': 'BoosTexter: A Boosting-based Systemfor Text Categorization'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Christos H. Papadimitriou 1',\n",
              "   ' Hisao Tamaki 2',\n",
              "   ' Prabhakar Raghavan 3',\n",
              "   ' Santosh Vempala 4'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2063392856',\n",
              "  'references': ['2138621811',\n",
              "   '2798909945',\n",
              "   '2147152072',\n",
              "   '1956559956',\n",
              "   '2072773380',\n",
              "   '1979750072',\n",
              "   '2013737143',\n",
              "   '2983896310',\n",
              "   '2058616517',\n",
              "   '2106285343'],\n",
              "  'title': 'Latent semantic indexing: a probabilistic analysis'},\n",
              " {'abstract': 'Bagging and boosting are methods that generate a diverse ensemble of classifiers by manipulating the training data given to a “base” learning algorithm. Breiman has pointed out that they rely for their effectiveness on the instability of the base learning algorithm. An alternative approach to generating an ensemble is to randomize the internal decisions made by the base algorithm. This general approach has been studied previously by Ali and Pazzani and by Dietterich and Kong. This paper compares the effectiveness of randomization, bagging, and boosting for improving the performance of the decision-tree algorithm C4.5. The experiments show that in situations with little or no classification noise, randomization is competitive with (and perhaps slightly superior to) bagging but not as accurate as boosting. In situations with substantial classification noise, bagging is much better than boosting, and sometimes better than randomization.',\n",
              "  'authors': ['Thomas G. Dietterich'],\n",
              "  'date': '2000',\n",
              "  'identifier': '1605688901',\n",
              "  'references': ['2912934387',\n",
              "   '2112076978',\n",
              "   '2152761983',\n",
              "   '2982720039',\n",
              "   '1966280301',\n",
              "   '2167277498',\n",
              "   '2073738917',\n",
              "   '2976840617',\n",
              "   '1562197959',\n",
              "   '1850527962'],\n",
              "  'title': 'An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees: Bagging, Boosting, and Randomization'},\n",
              " {'abstract': \"Abstract Tourists may develop attachment to a destination because of its ability in fulfilling specific goals or activity needs and/or because of its symbolic meaning and thus, attachment could be an important measure of tourist satisfaction and loyalty. Despite its significance, only limited research has been conducted to determine the likely influences of emotional associations or meanings tourists attach to the places they visit on their satisfaction and future behavior. This study therefore explores the role of attachment in predicting satisfactory holiday experiences and destination loyalty. Results of the structural equation modeling show that positive emotional and cognitive bonds with a place could indeed affect an individual's critical assessment of a destination and his/her loyalty to the place. Implications of the study are discussed.\",\n",
              "  'authors': ['Atila Yuksel ', ' Fisun Yuksel ', ' Yasin Bilim'],\n",
              "  'date': '2010',\n",
              "  'identifier': '1990168101',\n",
              "  'references': ['2036149274',\n",
              "   '1995031937',\n",
              "   '2068719957',\n",
              "   '1965574139',\n",
              "   '1574378514',\n",
              "   '1816720378',\n",
              "   '2039661695',\n",
              "   '2050251515',\n",
              "   '128107805',\n",
              "   '2005215882'],\n",
              "  'title': 'Destination attachment: Effects on customer satisfaction and cognitive, affective and conative loyalty'},\n",
              " {'abstract': 'The discovery of the hepatitis G virus (HGV) has given hepatologists a new lease on life. Just when they were becoming frustrated with the slow rate of progress in unravell ing the pathobiological consequences of hepatitis B and C virus infections, along comes another candidate virus. HGV, a single-stranded ribonucleic acid (RNA) virus that belongs to the Flaviviridae family, has a global distribution. The virus is present in 1-2% of blood donors in the USA, a frequency higher than that of either HCV or hepatitis B virus (HBV) (Alter). Even more striking is the seroprevalence of 15\"2% reported in West African residents (JMed Virol 1996; 50: 97). HGVexis t s in a chronic carrier state. The virus is transmitted parenterally and is often present in patients who have received multiple transfusions or who are on haemodialysis (N Engl J Med 1996; 334: 1485), and in intravenous drug users. There is preliminary evidence for perinatal transmission (Lancet 1996; 347: 615). HGV RNA sequences have been identified in serum from patients with non-A-E acute and chronic hepatitis and cirrhosis. Impressive data comes from Brescia, Italy, where 35% of patients with acute hepatitis and 39% of those with chronic hepatitis were positive for HGV RNA (Fiordalisi). Among blood donors the virus is more common in those with raised serum aminotransferase concentrations (3\"9%) than in those with normal concentrations (0\"8%) (ff Med Virol 1996; 50: 97). These findings imply that HGV is a human pathogen, but is it? Other information is more consistent with HGV being an innocent passenger. The great majority of individuals who become HGV-RNA positive after blood transfusion have normal serum aminotronsperase concentrations and neither they, nor those found positive for HGV RNA in other circumstances, develop liver disease during prolonged follow-up (Alter). Moreover, when serum enzyme concentrations are raised they seldom accord with levels of viraemia. HGV and HCV are often, and HGV and HBV less often, found together in serum. In those coinfected with HGV and HCV, aminotransterases run parallel to HCV rather than HGV, and the presence of the latter seems to have no effect on outcome. HGV usually accounts for only a minority of cases of acute non-A-E hepatitis, and there is no evidence yet of progression over time to chronic hepatitis, cirrhosis, or hepatocellular',\n",
              "  'authors': ['Michael C Kew ', ' Chris Kassianides'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2030133843',\n",
              "  'references': ['2083266836',\n",
              "   '2313004219',\n",
              "   '2023962288',\n",
              "   '2155517838',\n",
              "   '2075432722',\n",
              "   '1984200234'],\n",
              "  'title': 'HGV: hepatitis G virus or harmless G virus?'},\n",
              " {'abstract': 'The interactive activation model of context effects in letter perception is reviewed, elaborated, and tested. According to the model context aids the perception of target letters as they are processed in the perceptual system. The implication that the duration and timing of the context in which a letter occurs should greatly influence the perceptibility of the target is confirmed by a series of experiments demonstrating that early or enhanced presentations of word and pronounceablepseudoword contexts greatly increase the perceptibility of target letters. Also according to the model, letters in strings that share several letters with words should be equally perceptible whether they are orthographically regular and pronounceable (SLET) or irregular (SLNT) and should be much more perceptible than letters in contexts that share few letters with any word (XLQJ). This prediction is tested and confirmed. The basic results of all the experiments are accounted for, with some modification of parameters, although there are some discrepancies in detail. Several recent findings that seem to challenge the model are considered and a number of extensions are proposed.',\n",
              "  'authors': ['David E. Rumelhart ', ' James L. McClelland'],\n",
              "  'date': '1982',\n",
              "  'identifier': '2068868410',\n",
              "  'references': ['2073257493',\n",
              "   '1509703770',\n",
              "   '2007780422',\n",
              "   '2094688616',\n",
              "   '2053127376',\n",
              "   '2043013057',\n",
              "   '2040187703',\n",
              "   '2477770001',\n",
              "   '112688168',\n",
              "   '2147637089'],\n",
              "  'title': 'An interactive activation model of context effects in letter perception: II. The contextual enhancement effect and some tests and extensions of the model.'},\n",
              " {'abstract': 'Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?.',\n",
              "  'authors': ['Vladimir N. Vapnik'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2156909104',\n",
              "  'references': ['2140190241',\n",
              "   '2148603752',\n",
              "   '2164278908',\n",
              "   '2310919327',\n",
              "   '2129812935',\n",
              "   '2076063813',\n",
              "   '1746819321',\n",
              "   '1570448133',\n",
              "   '2072128103',\n",
              "   '2139212933'],\n",
              "  'title': 'The Nature of Statistical Learning Theory'},\n",
              " {'abstract': 'Abstract Fuzzy logic has gained increased attention as a methodology for managing uncertainty in a rule-based structure. In a fuzzy logic inference system, more rules can fire at any given time than in a crisp expert system. Since the propositions are modelled as possibility distributions, there is a considerable computation load on the inference engine. In this paper, a neural network structure is proposed as a means of performing fuzzy logic inference. Three variations of the network are described, but in each case, the knowledge of the rule (i.e., the antecedent and consequent clauses) are explicitly encoded in the weights of the net. The theoretical properties of this structure are developed. In fact, the network reduces to crisp modus ponens when the inputs are crisp sets. Also, under suitable conditions the degree of specificity of the consequences of the inference is a monotone function of the degree of specificity of the input. Several simulation studies are included to illustrate the performance of the fuzzy logic inference networks.',\n",
              "  'authors': ['James M. Keller 1', ' Ronald R. Yager 2', ' Hossein Tahani 1'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2083023271',\n",
              "  'references': ['2042264548',\n",
              "   '2019950953',\n",
              "   '1570082825',\n",
              "   '2157041604',\n",
              "   '179611734',\n",
              "   '2598771954',\n",
              "   '1575611982',\n",
              "   '1566211337',\n",
              "   '2046739349',\n",
              "   '37058475'],\n",
              "  'title': 'Neural network implementation of fuzzy logic'},\n",
              " {'abstract': 'The time-frequency and time-scale communities have recently developed a large number of overcomplete waveform dictionaries---stationary wavelets, wavelet packets, cosine packets, chirplets, and warplets, to name a few. Decomposition into overcomplete systems is not unique, and several methods for decomposition have been proposed, including the method of frames (MOF), matching pursuit (MP), and, for special dictionaries, the best orthogonal basis (BOB). Basis pursuit (BP) is a principle for decomposing a signal into an \"optimal\"\\' superposition of dictionary elements, where optimal means having the smallest l1 norm of coefficients among all such decompositions. We give examples exhibiting several advantages over MOF, MP, and BOB, including better sparsity and superresolution. BP has interesting relations to ideas in areas as diverse as ill-posed problems, abstract harmonic analysis, total variation denoising, and multiscale edge denoising. BP in highly overcomplete dictionaries leads to large-scale optimization problems. With signals of length 8192 and a wavelet packet dictionary, one gets an equivalent linear program of size 8192 by 212,992. Such problems can be attacked successfully only because of recent advances in linear and quadratic programming by interior-point methods. We obtain reasonable success with a primal-dual logarithmic barrier method and conjugate-gradient solver.',\n",
              "  'authors': ['Scott Shaobing Chen 1',\n",
              "   ' David L. Donoho 2',\n",
              "   ' Michael A. Saunders 2'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2078204800',\n",
              "  'references': ['2062024414',\n",
              "   '2798909945',\n",
              "   '2146842127',\n",
              "   '2099641086',\n",
              "   '2151693816',\n",
              "   '2103559027',\n",
              "   '2152328854',\n",
              "   '2156447271',\n",
              "   '2611147814',\n",
              "   '2128659236'],\n",
              "  'title': 'Atomic Decomposition by Basis Pursuit'},\n",
              " {'abstract': 'A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more.',\n",
              "  'authors': ['Vladimir Naumovich Vapnik'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2148603752',\n",
              "  'references': ['2156909104'],\n",
              "  'title': 'Statistical learning theory'},\n",
              " {'abstract': '',\n",
              "  'authors': ['V. V. Fedorov'],\n",
              "  'date': '1972',\n",
              "  'identifier': '2144578442',\n",
              "  'references': [],\n",
              "  'title': 'Theory of optimal experiments'},\n",
              " {'abstract': 'In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks.',\n",
              "  'authors': ['Jürgen Schmidhuber'],\n",
              "  'date': '2015',\n",
              "  'identifier': '2076063813',\n",
              "  'references': ['2618530766',\n",
              "   '2151103935',\n",
              "   '2097117768',\n",
              "   '2102605133',\n",
              "   '2130942839',\n",
              "   '2156909104',\n",
              "   '1663973292',\n",
              "   '2136922672',\n",
              "   '1849277567',\n",
              "   '2963542991'],\n",
              "  'title': 'Deep learning in neural networks'},\n",
              " {'abstract': \"We introduce a new interactive system: a game that is fun and can be used to create valuable output. When people play the game they help determine the contents of images by providing meaningful labels for them. If the game is played as much as popular online games, we estimate that most images on the Web can be labeled in a few months. Having proper labels associated with each image on the Web would allow for more accurate image search, improve the accessibility of sites (by providing descriptions of images to visually impaired individuals), and help users block inappropriate images. Our system makes a significant contribution because of its valuable output and because of the way it addresses the image-labeling problem. Rather than using computer vision techniques, which don't work well enough, we encourage people to do the work by taking advantage of their desire to be entertained.\",\n",
              "  'authors': ['Luis von Ahn ', ' Laura Dabbish'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2141282920',\n",
              "  'references': ['1666447063',\n",
              "   '1934863104',\n",
              "   '2166770390',\n",
              "   '1587328194',\n",
              "   '2293605478',\n",
              "   '2055225264',\n",
              "   '2050457084',\n",
              "   '181417509',\n",
              "   '2612148268'],\n",
              "  'title': 'Labeling images with a computer game'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Christopher G. Harris'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2020554914',\n",
              "  'references': ['1598123022', '2008176427'],\n",
              "  'title': 'Determination of Ego-Motion from Matched Points.'},\n",
              " {'abstract': 'This paper focuses on a comparative evaluation of a wide-range of text categorization methods, including previously published results on the Reuters corpus and new results of additional experiments. A controlled study using three classifiers, kNN, LLSF and WORD, was conducted to examine the impact of configuration variations in five versions of Reuters on the observed performance of classifiers. Analysis and empirical evidence suggest that the evaluation results on some versions of Reuters were significantly affected by the inclusion of a large portion of unlabelled documents, mading those results difficult to interpret and leading to considerable confusions in the literature. Using the results evaluated on the other versions of Reuters which exclude the unlabelled documents, the performance of twelve methods are compared directly or indirectly. For indirect compararions, kNN, LLSF and WORD were used as baselines, since they were evaluated on all versions of Reuters that exclude the unlabelled documents. As a global observation, kNN, LLSF and a neural network method had the best performances except for a Naive Bayes approach, the other learning algorithms also performed relatively well.',\n",
              "  'authors': ['Yiming Yang'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2114535528',\n",
              "  'references': ['2149706766',\n",
              "   '2435251607',\n",
              "   '1956559956',\n",
              "   '1833785989',\n",
              "   '1969572066',\n",
              "   '2060216474',\n",
              "   '2063198646',\n",
              "   '1983078185',\n",
              "   '1986913017',\n",
              "   '2071664212'],\n",
              "  'title': 'An Evaluation of Statistical Approaches to Text Categorization'},\n",
              " {'abstract': 'The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, working through a non-trivial example in detail. We describe a mechanical analogy, and discuss when SVM solutions are unique and when they are global. We describe how support vector training can be practically implemented, and discuss in detail the kernel mapping technique which is used to construct SVM solutions which are nonlinear in the data. We show how Support Vector machines can have very large (even infinite) VC dimension by computing the VC dimension for homogeneous polynomial and Gaussian radial basis function kernels. While very high VC dimension would normally bode ill for generalization performance, and while at present there exists no theory which shows that good generalization performance is guaranteed for SVMs, there are several arguments which support the observed high accuracy of SVMs, which we review. Results of some experiments which were inspired by these arguments are also presented. We give numerous examples and proofs of most of the key theorems. There is new material, and I hope that the reader will find that even old material is cast in a fresh light.',\n",
              "  'authors': ['Christopher J. C. Burges'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2139212933',\n",
              "  'references': ['2156909104',\n",
              "   '2148603752',\n",
              "   '1554663460',\n",
              "   '2119821739',\n",
              "   '2313307644',\n",
              "   '2610857016',\n",
              "   '2140095548',\n",
              "   '2797532987',\n",
              "   '2087347434',\n",
              "   '740415'],\n",
              "  'title': 'A Tutorial on Support Vector Machines for Pattern Recognition'},\n",
              " {'abstract': 'Current computational approaches to learning visual object categories require thousands of training images, are slow, cannot learn in an incremental manner and cannot incorporate prior information into the learning process. In addition, no algorithm presented in the literature has been tested on more than a handful of object categories. We present an method for learning object categories from just a few training images. It is quick and it uses prior information in a principled way. We test it on a dataset composed of images of objects belonging to 101 widely varied categories. Our proposed method is based on making use of prior information, assembled from (unrelated) object categories which were previously learnt. A generative probabilistic model is used, which represents the shape and appearance of a constellation of features belonging to the object. The parameters of the model are learnt incrementally in a Bayesian manner. Our incremental algorithm is compared experimentally to an earlier batch Bayesian algorithm, as well as to one based on maximum likelihood. The incremental and batch versions have comparable classification performance on small training sets, but incremental learning is significantly faster, making real-time learning feasible. Both Bayesian methods outperform maximum likelihood on small training sets.',\n",
              "  'authors': ['Li Fei-Fei 1', ' Rob Fergus 2', ' Pietro Perona 3'],\n",
              "  'date': '2007',\n",
              "  'identifier': '2166049352',\n",
              "  'references': ['2164598857',\n",
              "   '2124386111',\n",
              "   '2154422044',\n",
              "   '2124087378',\n",
              "   '2155511848',\n",
              "   '1516111018',\n",
              "   '1949116567',\n",
              "   '1746680969',\n",
              "   '2567948266',\n",
              "   '1699734612'],\n",
              "  'title': 'Learning generative visual models from few training examples: An incremental Bayesian approach tested on 101 object categories'},\n",
              " {'abstract': 'GARCH models have been applied in modelling the relation between conditional variance and asset risk premia. These models, however, have at least three major drawbacks in asset pricing applications: (i) Researchers beginning with Black (1976) have found a negative correlation between current returns and future returns volatility. GARCH models rule this out by assumption. (ii) GARCH models impose parameter restrictions that are often violated by estimated coefficients and that may unduly restrict the dynamics of the conditional variance process. (iii) Interpreting whether shocks to conditional variance \"persist\" or not is difficult in GARCH models, because the usual norms measuring persistence often do not agree. A new form of ARCH is proposed that meets these objections. The method is used to estimate a model of the risk premium on the CRSP Value-Weighted Market Index from 1962 to 1987.',\n",
              "  'authors': ['Daniel B. Nelson'],\n",
              "  'date': '1991',\n",
              "  'identifier': '1999814123',\n",
              "  'references': ['1999996900',\n",
              "   '2168175751',\n",
              "   '1979575715',\n",
              "   '3119264854',\n",
              "   '2061160212',\n",
              "   '2299769372',\n",
              "   '2056099894',\n",
              "   '1966268097',\n",
              "   '2058815839',\n",
              "   '3123598380'],\n",
              "  'title': 'CONDITIONAL HETEROSKEDASTICITY IN ASSET RETURNS: A NEW APPROACH'},\n",
              " {'abstract': 'In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line.',\n",
              "  'authors': ['Yoav Freund ', ' Robert E Schapire'],\n",
              "  'date': '1997',\n",
              "  'identifier': '1988790447',\n",
              "  'references': ['2112076978',\n",
              "   '1966280301',\n",
              "   '1676820704',\n",
              "   '1530699444',\n",
              "   '2165758113',\n",
              "   '2093717447',\n",
              "   '2093825590',\n",
              "   '2070534370',\n",
              "   '1520252399',\n",
              "   '2104364170'],\n",
              "  'title': 'A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting'},\n",
              " {'abstract': 'The virological features and clinical findings associated with the new human metapneumovirus (HMPV) were examined retrospectively in Canadian patients hospitalized for various respiratory conditions since 1993. Thirty-eight previously unidentified respiratory viruses isolated from rhesus monkey kindey (LLC-MK2) cells were found to be positive for HMPV by reverse-transcription polymerase chain reaction, and those strains clustered in 2 phylogenetic groups. Children aged 65 years represented 35.1% and 45.9% of the HMPV-infected cases, respectively. In hospitalized children, the most frequent diagnoses were pneumonitis (66.7%) and bronchiolitis (58.3%), whereas bronchitis and/or bronchospasm (60%) and pneumonitis (40%) were most commonly seen in elderly subjects. Of the 15 patients with pneumonitis, 4 (26.7%) had immunosuppressive conditions and 6 (40%) were infants aged <15 months. These findings suggest that HMPV can be associated with severe lower-respiratory-tract infections in very young children, the elderly, and immunocompromised patients.',\n",
              "  'authors': ['Guy Boivin 1',\n",
              "   ' Yacine Abed 1',\n",
              "   ' Gilles Pelletier 1',\n",
              "   ' Louisette Ruel 1',\n",
              "   ' Danielle Moisan 1',\n",
              "   ' Stéphanie Côté 1',\n",
              "   ' Teresa C. T. Peret 2',\n",
              "   ' Dean D. Erdman 2',\n",
              "   ' Larry J. Anderson 2'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2135259291',\n",
              "  'references': ['2170881661',\n",
              "   '2152552492',\n",
              "   '2122034291',\n",
              "   '1589490904',\n",
              "   '1907972820',\n",
              "   '2140173012',\n",
              "   '2158407455',\n",
              "   '1950423469',\n",
              "   '2166096923',\n",
              "   '2340540364'],\n",
              "  'title': 'Virological Features and Clinical Manifestations Associated with Human Metapneumovirus: A New Paramyxovirus Responsible for Acute Respiratory-Tract Infections in All Age Groups'},\n",
              " {'abstract': 'Support vector machine (SVM) is a popular technique for classication. However, beginners who are not familiar with SVM often get unsatisfactory results since they miss some easy but signicant steps. In this guide, we propose a simple procedure, which usually gives reasonable results.',\n",
              "  'authors': ['Chih-Wei Hsu ', ' Chih-Chung Chang ', ' Chih-Jen Lin'],\n",
              "  'date': '2008',\n",
              "  'identifier': '2109943925',\n",
              "  'references': ['2153635508',\n",
              "   '2156909104',\n",
              "   '2119821739',\n",
              "   '2118585731',\n",
              "   '2087347434',\n",
              "   '91932901',\n",
              "   '2142334564',\n",
              "   '2118286367',\n",
              "   '2129191766',\n",
              "   '2160072419'],\n",
              "  'title': 'A Practical Guide to Support Vector Classication'},\n",
              " {'abstract': 'The species concept is a recurrent controversial issue that preoccupies philosophers as well as biologists of all disciplines. Prokaryotic species concept has its own history and results from a series of empirical improvements parallel to the development of the techniques of analysis. Among the microbial taxonomists, there is general agreement that the species concept currently in use is useful, pragmatic and universally applicable within the prokaryotic world. However, this empirically designed concept is not encompassed by any of the, at least, 22 concepts described for eukaryotes. The species could be described as ‘a monophyletic and genomically coherent cluster of individual organisms that show a high degree of overall similarity in many independent characteristics, and is diagnosable by a discriminative phenotypic property’. We suggest to refer it as a phylo-phenetic species concept. Here, we discuss the validity of the concept in use which we believe is more pragmatic in comparison with those concepts described for eukaryotes.',\n",
              "  'authors': ['Ramon Rosselló-Mora ', ' Rudolf I. Amann'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2141047744',\n",
              "  'references': ['2805514914',\n",
              "   '1955612312',\n",
              "   '2171114940',\n",
              "   '2131988453',\n",
              "   '2132598047',\n",
              "   '1963953102',\n",
              "   '2032678548',\n",
              "   '2068687524',\n",
              "   '2118001436',\n",
              "   '2073925485'],\n",
              "  'title': 'The species concept for prokaryotes.'},\n",
              " {'abstract': 'The description of a novel type of m-gram language model is given. The model offers, via a nonlinear recursive procedure, a computation and space efficient solution to the problem of estimating probabilities from sparse data. This solution compares favorably to other proposed methods. While the method has been developed for and successfully implemented in the IBM Real Time Speech Recognizers, its generality makes it applicable in other areas where the problem of estimating probabilities from sparse data arises.',\n",
              "  'authors': ['S. Katz'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2134237567',\n",
              "  'references': ['1597533204',\n",
              "   '2159782014',\n",
              "   '1507770639',\n",
              "   '2168938909',\n",
              "   '2170967986',\n",
              "   '2082092506',\n",
              "   '1590636096'],\n",
              "  'title': 'Estimation of probabilities from sparse data for the language model component of a speech recognizer'},\n",
              " {'abstract': \"A Gaussian broadcast channel (GBC) with r single-antenna receivers and t antennas at the transmitter is considered. Both transmitter and receivers have perfect knowledge of the channel. Despite its apparent simplicity, this model is, in general, a nondegraded broadcast channel (BC), for which the capacity region is not fully known. For the two-user case, we find a special case of Marton's (1979) region that achieves optimal sum-rate (throughput). In brief, the transmitter decomposes the channel into two interference channels, where interference is caused by the other user signal. Users are successively encoded, such that encoding of the second user is based on the noncausal knowledge of the interference caused by the first user. The crosstalk parameters are optimized such that the overall throughput is maximum and, surprisingly, this is shown to be optimal over all possible strategies (not only with respect to Marton's achievable region). For the case of r>2 users, we find a somewhat simpler choice of Marton's region based on ordering and successively encoding the users. For each user i in the given ordering, the interference caused by users j>i is eliminated by zero forcing at the transmitter, while interference caused by users j<i is taken into account by coding for noncausally known interference. Under certain mild conditions, this scheme is found to be throughput-wise asymptotically optimal for both high and low signal-to-noise ratio (SNR). We conclude by providing some numerical results for the ergodic throughput of the simplified zero-forcing scheme in independent Rayleigh fading.\",\n",
              "  'authors': ['G. Caire 1', ' S. Shamai 2'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2151795416',\n",
              "  'references': ['2137775453',\n",
              "   '2130509920',\n",
              "   '2099111195',\n",
              "   '2610857016',\n",
              "   '2161872841',\n",
              "   '1989225545',\n",
              "   '2098257210',\n",
              "   '2116485279',\n",
              "   '391578156',\n",
              "   '2111992817'],\n",
              "  'title': 'On the achievable throughput of a multiantenna Gaussian broadcast channel'},\n",
              " {'abstract': 'We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.',\n",
              "  'authors': ['Ronan Collobert ',\n",
              "   ' Jason Weston 1',\n",
              "   ' Léon Bottou ',\n",
              "   ' Michael Karlen ',\n",
              "   ' Koray Kavukcuoglu 2',\n",
              "   ' Pavel Kuksa 3'],\n",
              "  'date': '2011',\n",
              "  'identifier': '2158899491',\n",
              "  'references': ['2136922672',\n",
              "   '2310919327',\n",
              "   '2147880316',\n",
              "   '2125838338',\n",
              "   '2110798204',\n",
              "   '2158139315',\n",
              "   '2159080219',\n",
              "   '2098162425',\n",
              "   '2150102617',\n",
              "   '2296073425'],\n",
              "  'title': 'Natural Language Processing (Almost) from Scratch'},\n",
              " {'abstract': 'LIBLINEAR is an open source library for large-scale linear classification. It supports logistic regression and linear support vector machines. We provide easy-to-use command-line tools and library calls for users and developers. Comprehensive documents are available for both beginners and advanced users. Experiments demonstrate that LIBLINEAR is very efficient on large sparse data sets.',\n",
              "  'authors': ['Rong-En Fan ',\n",
              "   ' Kai-Wei Chang ',\n",
              "   ' Cho-Jui Hsieh ',\n",
              "   ' Xiang-Rui Wang ',\n",
              "   ' Chih-Jen Lin'],\n",
              "  'date': '2008',\n",
              "  'identifier': '2118585731',\n",
              "  'references': ['2153635508',\n",
              "   '2097360283',\n",
              "   '2109943925',\n",
              "   '2087347434',\n",
              "   '2035720976',\n",
              "   '2150102617',\n",
              "   '2165966284',\n",
              "   '2142623206',\n",
              "   '2118286367',\n",
              "   '1602492977'],\n",
              "  'title': 'LIBLINEAR: A Library for Large Linear Classification'},\n",
              " {'abstract': 'Introduction Preliminaries and notation The what, why, and how of wavelets The continuous wavelet transform Discrete wavelet transforms: Frames Time-frequency density and orthonormal bases Orthonormal bases of wavelets and multiresolutional analysis Orthonormal bases of compactly supported wavelets More about the regularity of compactly supported wavelets Symmetry for compactly supported wavelet bases Characterization of functional spaces by means of wavelets Generalizations and tricks for orthonormal wavelet bases References Indexes.',\n",
              "  'authors': ['Ingrid Daubechies'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2062024414',\n",
              "  'references': ['2296616510',\n",
              "   '2078204800',\n",
              "   '2158940042',\n",
              "   '2099641086',\n",
              "   '2130660124',\n",
              "   '2151693816',\n",
              "   '2034139177',\n",
              "   '2186428165',\n",
              "   '2106002835'],\n",
              "  'title': 'Ten Lectures on Wavelets'},\n",
              " {'abstract': 'From 1 November 1992 through 1 May 1993 and from 1 November 1993 through 1 May 1994, we conducted a prospective surveillance study at the University of Texas M.D. Anderson Cancer Center (Houston) to evaluate the role of community respiratory virus infections in hospitalized adult bone marrow transplant (BMT) recipients. Respiratory secretions were obtained from all adult BMT recipients with acute respiratory illnesses. During these two winters, a community respiratory virus was isolated from 37 (36%) of 102 patients and 30 (26%) of 115 patients, respectively. Approximately half (49%) of these infections were due to respiratory syncytial virus (RSV) ; the remainder were due to influenza virus (18%), picornaviruses (18%), parainfluenza virus (9%), or adenovirus (6%). Fifty-eight percent of these infections were complicated by pneumonia, with an associated mortality of 51%. The pneumonias that complicated RSV infection were almost exclusively viral in origin and were associated with a mortality of 100% if not treated promptly with antiviral agents. In contrast, many of the pneumonias that complicated the other viral infections, such as influenza, appeared to be either self-limited viral pneumonias or secondary bacterial or fungal pneumonias. Community respiratory viruses are frequent causes of acute respiratory illnesses in adult BMT recipients hospitalized during the winter and are associated with substantial morbidity and mortality.',\n",
              "  'authors': ['Estella Whimbey 1',\n",
              "   ' Richard E. Champlin 2',\n",
              "   ' Robert B. Couch ',\n",
              "   ' Janet A. Englund ',\n",
              "   ' James M. Goodrich ',\n",
              "   ' Issam Raad 3',\n",
              "   ' Donna Przepiorka ',\n",
              "   ' Victor A. Lewis ',\n",
              "   ' Nadeem Mirza ',\n",
              "   ' Hasan Yousuf ',\n",
              "   ' Jeffrey J. Tarrand 4',\n",
              "   ' Gerald P. Bodey'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2140173012',\n",
              "  'references': ['2059875959',\n",
              "   '2122536566',\n",
              "   '2340540364',\n",
              "   '111873078',\n",
              "   '2413763945',\n",
              "   '2155757329',\n",
              "   '2252447992',\n",
              "   '2048526870',\n",
              "   '2142623363',\n",
              "   '2009049373'],\n",
              "  'title': 'Community Respiratory Virus Infections Among Hospitalized Adult Bone Marrow Transplant Recipients'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Floyd Ratliff'],\n",
              "  'date': '1966',\n",
              "  'identifier': '2041181954',\n",
              "  'references': ['2003370853',\n",
              "   '1996773027',\n",
              "   '2165015795',\n",
              "   '2163630896',\n",
              "   '2130355536',\n",
              "   '2124789365',\n",
              "   '2135704565',\n",
              "   '2082965189',\n",
              "   '2022060843',\n",
              "   '2151152593'],\n",
              "  'title': 'Mach bands : quantitative studies on neural networks in the retina'},\n",
              " {'abstract': 'In November 2002, a businessman from the city of Foshan in the southern Chinese province of Guangdong may have been the first victim of a mysterious illness called severe acute respiratory syndrome (SARS). Guangdong Province, an agricultural area with a population of 75 million, has thousands of farms with large and small animals, a subtropical climate, and rainfall of about 2 m per year. The first patient and many others received no international attention until February 2003, when a physician from Guangdong Province became ill while staying on the ninth floor of a hotel in Hong Kong. Twelve guests became . . .',\n",
              "  'authors': ['Richard P Wenzel ', ' Michael B Edmond'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2048093932',\n",
              "  'references': ['2116586125',\n",
              "   '3006252254',\n",
              "   '3013334176',\n",
              "   '3034510846',\n",
              "   '3014051579',\n",
              "   '3021147446',\n",
              "   '2079929038',\n",
              "   '1981110022',\n",
              "   '3014646061',\n",
              "   '2165929860'],\n",
              "  'title': 'Managing SARS amidst uncertainty.'},\n",
              " {'abstract': 'Many neural network classifiers provide outputs which estimate Bayesian a posteriori probabilities. When the estimation is accurate, network outputs can be treated as probabilities and sum to one. Simple proofs show that Bayesian probabilities are estimated when desired network outputs are 1 of M (one output unity, all others zero) and a squared-error or cross-entropy cost function is used. Results of Monte Carlo simulations performed using multilayer perceptron (MLP) networks trained with backpropagation, radial basis function (RBF) networks, and high-order polynomial networks graphically demonstrate that network outputs provide good estimates of Bayesian probabilities. Estimation accuracy depends on network complexity, the amount of training data, and the degree to which training data reflect true likelihood distributions and a priori class probabilities. Interpretation of network outputs as Bayesian probabilities allows outputs from multiple networks to be combined for higher level decision making, sim...',\n",
              "  'authors': ['Michael D. Richard ', ' Richard P. Lippmann'],\n",
              "  'date': '1991',\n",
              "  'identifier': '1980501707',\n",
              "  'references': [],\n",
              "  'title': 'Neural Network Classifiers Estimate Bayesian a posteriori Probabilities.'},\n",
              " {'abstract': 'Ten years ago, we presented the DeLone and McLean Information Systems (IS) Success Model as a framework and model for measuring the complex-dependent variable in IS research. In this paper, we discuss many of the important IS success research contributions of the last decade, focusing especially on research efforts that apply, validate, challenge, and propose enhancements to our original model. Based on our evaluation of those contributions, we propose minor refinements to the model and propose an updated DeLone and McLean IS Success Model. We discuss the utility of the updated model for measuring e-commerce system success. Finally, we make a series of recommendations regarding current and future measurement of IS success.',\n",
              "  'authors': ['William H. Delone ', ' Ephraim R. McLean'],\n",
              "  'date': '2003',\n",
              "  'identifier': '1721421031',\n",
              "  'references': ['1955934323',\n",
              "   '2057012437',\n",
              "   '1487725643',\n",
              "   '1987198869',\n",
              "   '1548408014',\n",
              "   '1587451402',\n",
              "   '2018668985',\n",
              "   '2158809862',\n",
              "   '2011457410',\n",
              "   '1998581510'],\n",
              "  'title': 'The DeLone and McLean Model of Information Systems Success: A Ten-Year Update'},\n",
              " {'abstract': 'The technology for building knowledge-based systems by inductive inference from examples has been demonstrated successfully in several practical applications. This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail. Results from recent studies show ways in which the methodology can be modified to deal with information that is noisy and/or incomplete. A reported shortcoming of the basic algorithm is discussed and two means of overcoming it are compared. The paper concludes with illustrations of current research directions.',\n",
              "  'authors': ['J. R. Quinlan'],\n",
              "  'date': '1986',\n",
              "  'identifier': '2149706766',\n",
              "  'references': ['1596324102',\n",
              "   '2159047538',\n",
              "   '18968369',\n",
              "   '1527883571',\n",
              "   '2067642555',\n",
              "   '3021257214',\n",
              "   '1488252886',\n",
              "   '2026319679',\n",
              "   '1693339475',\n",
              "   '2894813436'],\n",
              "  'title': 'Induction of Decision Trees'},\n",
              " {'abstract': 'This paper describes the construction of a system that recognizes handprinted digits, using a combination of classical techniques and neural-net methods. The system has been trained and tested on real-world data, derived from zip codes seen on actual U.S. Mail. The system rejects a small percentage of the examples as unclassifiable, and achieves a very low error rate on the remaining examples. The system compares favorably with other state-of-the art recognizers. While some of the methods are specific to this task, it is hoped that many of the techniques will be applicable to a wide range of recognition tasks.',\n",
              "  'authors': ['John S. Denker ',\n",
              "   ' W. R. Gardner ',\n",
              "   ' Hans Peter Graf ',\n",
              "   ' Donnie Henderson ',\n",
              "   ' R. E. Howard ',\n",
              "   ' W. Hubbard ',\n",
              "   ' L. D. Jackel ',\n",
              "   ' Henry S. Baird ',\n",
              "   ' Isabelle Guyon'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2157475639',\n",
              "  'references': ['3017143921',\n",
              "   '1655554306',\n",
              "   '2155818555',\n",
              "   '2116360511',\n",
              "   '2058841211',\n",
              "   '1501657095',\n",
              "   '131259011',\n",
              "   '2062361515',\n",
              "   '2044630651',\n",
              "   '2002448074'],\n",
              "  'title': 'Neural Network Recognizer for Hand-Written Zip Code Digits'},\n",
              " {'abstract': 'We introduce a challenging set of 256 object categories containing a total of 30607 images. The original Caltech-101 [1] was collected by choosing a set of object categories, downloading examples from Google Images and then manually screening out all images that did not fit the category. Caltech-256 is collected in a similar manner with several improvements: a) the number of categories is more than doubled, b) the minimum number of images in any category is increased from 31 to 80, c) artifacts due to image rotation are avoided and d) a new and larger clutter category is introduced for testing background rejection. We suggest several testing paradigms to measure classification performance, then benchmark the dataset using two simple metrics as well as a state-of-the-art spatial pyramid matching [2] algorithm. Finally we use the clutter category to train an interest detector which rejects uninformative background regions.',\n",
              "  'authors': ['Gregory Griffin ', ' Alex Holub ', ' Pietro Perona'],\n",
              "  'date': '2007',\n",
              "  'identifier': '1576445103',\n",
              "  'references': ['2618530766',\n",
              "   '2962835968',\n",
              "   '2117539524',\n",
              "   '2108598243',\n",
              "   '1861492603',\n",
              "   '2031489346',\n",
              "   '2963173190',\n",
              "   '2295107390'],\n",
              "  'title': 'Caltech-256 Object Category Dataset'},\n",
              " {'abstract': \"We propose an optimization approach to flow control where the objective is to maximize the aggregate source utility over their transmission rates. We view network links and sources as processors of a distributed computation system to solve the dual problem using a gradient projection algorithm. In this system, sources select transmission rates that maximize their own benefits, utility minus bandwidth cost, and network links adjust bandwidth prices to coordinate the sources' decisions. We allow feedback delays to be different, substantial, and time varying, and links and sources to update at different times and with different frequencies. We provide asynchronous distributed algorithms and prove their convergence in a static environment. We present measurements obtained from a preliminary prototype to illustrate the convergence of the algorithm in a slowly time-varying environment. We discuss its fairness property.\",\n",
              "  'authors': ['Steven H. Low ', ' David E. Lapsley'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2037710455',\n",
              "  'references': ['2798766386',\n",
              "   '2158733823',\n",
              "   '2753542457',\n",
              "   '2159715570',\n",
              "   '1987497363',\n",
              "   '1668270659',\n",
              "   '1970131865',\n",
              "   '2156568423',\n",
              "   '2087635921',\n",
              "   '1529768988'],\n",
              "  'title': 'Optimization flow control—I: basic algorithm and convergence'},\n",
              " {'abstract': 'From the Publisher: This text is ideal for junior-,senior-,and graduate-level courses in computer graphics and computer-aided design taught in departments of mechanical and aeronautical engineering and computer science. It presents in a unified manner an introduction to the mathematical theory underlying computer graphic applications. It covers topics of keen interest to students in engineering and computer science: transformations,projections,2-D and 3-D curve definition schemes,and surface definitions. It also includes techniques,such as B-splines,which are incorporated as part of the software in advanced engineering workstations. A basic knowledge of vector and matrix algebra and calculus is required.',\n",
              "  'authors': ['David F. Rogers ', ' J. Alan Adams'],\n",
              "  'date': '1976',\n",
              "  'identifier': '2168938315',\n",
              "  'references': ['2085261163',\n",
              "   '2128131727',\n",
              "   '2127739279',\n",
              "   '2756201449',\n",
              "   '2121859020',\n",
              "   '1536003180',\n",
              "   '1945738378',\n",
              "   '1985196743',\n",
              "   '2122928074'],\n",
              "  'title': 'Mathematical elements for computer graphics'},\n",
              " {'abstract': \"Abstract We describe a model called the TRACE model of speech perception. The model is based on the principles of interactive activation. Information processing takes place through the excitatory and inhibitory interactions of a large number of simple processing units, each working continuously to update its own activation on the basis of the activations of other units to which it is connected. The model is called the TRACE model because the network of units forms a dynamic processing structure called “the Trace,” which serves at once as the perceptual processing mechanism and as the system's working memory. The model is instantiated in two simulation programs. TRACE I, described in detail elsewhere, deals with short segments of real speech, and suggests a mechanism for coping with the fact that the cues to the identity of phonemes vary as a function of context. TRACE II, the focus of this article, simulates a large number of empirical findings on the perception of phonemes and words and on the interactions of phoneme and word perception. At the phoneme level, TRACE II simulates the influence of lexical information on the identification of phonemes and accounts for the fact that lexical effects are found under certain conditions but not others. The model also shows how knowledge of phonological constraints can be embodied in particular lexical items but can still be used to influence processing of novel, nonword utterances. The model also exhibits categorical perception and the ability to trade cues off against each other in phoneme identification. At the word level, the model captures the major positive feature of Marslen-Wilson's COHORT model of speech perception, in that it shows immediate sensitivity to information favoring one word or set of words over others. At the same time, it overcomes a difficulty with the COHORT model: it can recover from underspecification or mispronunciation of a word's beginning. TRACE II also uses lexical information to segment a stream of speech into a sequence of words and to find word beginnings and endings, and it simulates a number of recent findings related to these points. The TRACE model has some limitations, but we believe it is a step toward a psychologically and computationally adequate model of the process of speech perception.\",\n",
              "  'authors': ['James L McClelland 1', ' Jeffrey L Elman 2'],\n",
              "  'date': '1986',\n",
              "  'identifier': '2135704565',\n",
              "  'references': ['1652505363',\n",
              "   '2073257493',\n",
              "   '1490454746',\n",
              "   '2112325651',\n",
              "   '2912225506',\n",
              "   '2007780422',\n",
              "   '2098205603',\n",
              "   '2204004159',\n",
              "   '2068868410',\n",
              "   '2093527506'],\n",
              "  'title': 'The TRACE model of speech perception.'},\n",
              " {'abstract': 'Probability. Measure. Integration. Random Variables and Expected Values. Convergence of Distributions. Derivatives and Conditional Probability. Stochastic Processes. Appendix. Notes on the Problems. Bibliography. List of Symbols. Index.',\n",
              "  'authors': ['Patrick Billingsley'],\n",
              "  'date': '1979',\n",
              "  'identifier': '2056099894',\n",
              "  'references': ['2124758339',\n",
              "   '2137983211',\n",
              "   '2108207895',\n",
              "   '2338990760',\n",
              "   '1999814123',\n",
              "   '2137344397',\n",
              "   '2126311658',\n",
              "   '1541527977',\n",
              "   '2160837607',\n",
              "   '1974708997'],\n",
              "  'title': 'Probability and Measure'},\n",
              " {'abstract': 'The performance of a state-of-the-art neural network classifier for hand-written digits is compared to that of a k-nearest-neighbor classifier and to human performance. The neural network has a clear advantage over the k-nearest-neighbor method, but at the same time does not yet reach human performance. Two methods for combining neural-network ideas and the k-nearest-neighbor algorithm are proposed. Numerical experiments for these methods show an improvement in performance.',\n",
              "  'authors': ['J. Bromley ', ' E. Sackinger'],\n",
              "  'date': '1991',\n",
              "  'identifier': '1568787085',\n",
              "  'references': ['2119821739',\n",
              "   '2159737176',\n",
              "   '1548139318',\n",
              "   '2138882494',\n",
              "   '2277406607',\n",
              "   '1595098149',\n",
              "   '2010332406',\n",
              "   '2125145210',\n",
              "   '2415856871',\n",
              "   '1973224984'],\n",
              "  'title': 'Neural-Network and k-Nearest-neighbor Classifiers'},\n",
              " {'abstract': \"The process of information technology adoption and use is critical to deriving the benefits of information technology. Yet from a conceptual standpoint, few empirical studies have made a distinction between individuals' pre-adoption and post-adoption (continued use) beliefs and attitudes. This distinction is crucial in understanding and managing this process over time. The current study combines innovation diffusion and attitude theories in a theoretical framework to examine differences in pre-adoption and post-adoption beliefs and attitudes. The examination of Windows technology in a single organization indicates that users and potential adopters of information technology differ on their determinants of behavioral intention, attitude, and subjective norm. Potential adopter intention to adopt is solely determined by normative pressures, whereas user intention is solely determined by attitude. In addition, potential adopters base their attitude on a richer set of innovation characteristics than users. Whereas pre-adoption attitude is based on perceptions of usefulness, ease-of-use, result demonstrability, visibility, and trialability, post-adoption attitude is only based on instrumentality beliefs of usefulness and perceptions of image enhancements.\",\n",
              "  'authors': ['Elena Karahanna 1',\n",
              "   ' Detmar W. Straub 2',\n",
              "   ' Norman L. Chervany 3'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1548408014',\n",
              "  'references': ['1971440513',\n",
              "   '1791587663',\n",
              "   '2033943395',\n",
              "   '2057012437',\n",
              "   '1987198869',\n",
              "   '1491644571',\n",
              "   '2101419153',\n",
              "   '2100408980',\n",
              "   '2155225996',\n",
              "   '2036389121'],\n",
              "  'title': 'Information technology adoption across time: a cross-sectional comparison of pre-adoption and post-adoption beliefs'},\n",
              " {'abstract': 'This paper presents a general, trainable system for object detection in unconstrained, cluttered scenes. The system derives much of its power from a representation that describes an object class in terms of an overcomplete dictionary of local, oriented, multiscale intensity differences between adjacent regions, efficiently computable as a Haar wavelet transform. This example-based learning approach implicitly derives a model of an object class by training a support vector machine classifier using a large set of positive and negative examples. We present results on face, people, and car detection tasks using the same architecture. In addition, we quantify how the representation affects detection performance by considering several alternate representations including pixels and principal components. We also describe a real-time application of our person detection system as part of a driver assistance system.',\n",
              "  'authors': ['Constantine Papageorgiou ', ' Tomaso Poggio'],\n",
              "  'date': '2000',\n",
              "  'identifier': '1608462934',\n",
              "  'references': ['2156909104',\n",
              "   '2148603752',\n",
              "   '2139212933',\n",
              "   '2132984323',\n",
              "   '2128272608',\n",
              "   '2217896605',\n",
              "   '2140235142',\n",
              "   '2124351082',\n",
              "   '2159686933',\n",
              "   '26816478'],\n",
              "  'title': 'A Trainable System for Object Detection'},\n",
              " {'abstract': 'Over the last couple of years, face recognition researchers have been developing new techniques. These developments are being fueled by advances in computer vision techniques, computer design, sensor design, and interest in fielding face recognition systems. Such advances hold the promise of reducing the error rate in face recognition systems by an order of magnitude over Face Recognition Vendor Test (FRVT) 2002 results. The face recognition grand challenge (FRGC) is designed to achieve this performance goal by presenting to researchers a six-experiment challenge problem along with data corpus of 50,000 images. The data consists of 3D scans and high resolution still imagery taken under controlled and uncontrolled conditions. This paper describes the challenge problem, data corpus, and presents baseline performance and preliminary results on natural statistics of facial imagery.',\n",
              "  'authors': ['P.J. Phillips 1',\n",
              "   ' P.J. Flynn 2',\n",
              "   ' T. Scruggs 3',\n",
              "   ' K.W. Bowyer 2',\n",
              "   ' Jin Chang 2',\n",
              "   ' K. Hoffman 3',\n",
              "   ' J. Marques 4',\n",
              "   ' Jaesik Min 2',\n",
              "   ' W. Worek 3'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2137659841',\n",
              "  'references': ['2138451337',\n",
              "   '2102773363',\n",
              "   '2143542740',\n",
              "   '2137385871',\n",
              "   '2120838001',\n",
              "   '1555969862',\n",
              "   '138943044'],\n",
              "  'title': 'Overview of the face recognition grand challenge'},\n",
              " {'abstract': 'Practical experience has shown that in order to obtain the best possible performance, prior knowledge about invariances of a classification problem at hand ought to be incorporated into the training procedure. We describe and review all known methods for doing so in support vector machines, provide experimental results, and discuss their respective merits. One of the significant new results reported in this work is our recent achievement of the lowest reported test error on the well-known MNIST digit recognition benchmark task, with SVM training times that are also significantly faster than previous SVM methods.',\n",
              "  'authors': ['Dennis Decoste 1', ' Bernhard Schölkopf 2'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2159737176',\n",
              "  'references': ['2156909104',\n",
              "   '2148603752',\n",
              "   '2310919327',\n",
              "   '2119821739',\n",
              "   '2140095548',\n",
              "   '1512098439',\n",
              "   '2087347434',\n",
              "   '1604938182',\n",
              "   '2147800946',\n",
              "   '2151040995'],\n",
              "  'title': 'Training Invariant Support Vector Machines'},\n",
              " {'abstract': 'Motivation Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora. Results We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62% F1 score improvement), biomedical relation extraction (2.80% F1 score improvement) and biomedical question answering (12.24% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts. Availability and implementation We make the pre-trained weights of BioBERT freely available at https://github.com/naver/biobert-pretrained, and the source code for fine-tuning BioBERT available at https://github.com/dmis-lab/biobert.',\n",
              "  'authors': ['Jinhyuk Lee 1',\n",
              "   ' Wonjin Yoon 1',\n",
              "   ' Sungdong Kim 2',\n",
              "   ' Donghyeon Kim 1',\n",
              "   ' Sunkyu Kim 1',\n",
              "   ' Chan Ho So 1',\n",
              "   ' Jaewoo Kang 1'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2911489562',\n",
              "  'references': ['2919115771',\n",
              "   '2963403868',\n",
              "   '2963341956',\n",
              "   '2153579005',\n",
              "   '2250539671',\n",
              "   '2962739339',\n",
              "   '2963748441',\n",
              "   '2132339004',\n",
              "   '2525778437',\n",
              "   '2963756346'],\n",
              "  'title': 'BioBERT: a pre-trained biomedical language representation model for biomedical text mining.'},\n",
              " {'abstract': 'We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.',\n",
              "  'authors': ['Matthew D. Zeiler'],\n",
              "  'date': '2012',\n",
              "  'identifier': '6908809',\n",
              "  'references': ['2168231600',\n",
              "   '2147768505',\n",
              "   '1498436455',\n",
              "   '2120420045',\n",
              "   '19621276',\n",
              "   '1994616650'],\n",
              "  'title': 'ADADELTA: An Adaptive Learning Rate Method'},\n",
              " {'abstract': \"From the Publisher: The updated new edition of the classic Introduction to Algorithms is intended primarily for use in undergraduate or graduate courses in algorithms or data structures. Like the first edition,this text can also be used for self-study by technical professionals since it discusses engineering issues in algorithm design as well as the mathematical aspects. In its new edition,Introduction to Algorithms continues to provide a comprehensive introduction to the modern study of algorithms. The revision has been updated to reflect changes in the years since the book's original publication. New chapters on the role of algorithms in computing and on probabilistic analysis and randomized algorithms have been included. Sections throughout the book have been rewritten for increased clarity,and material has been added wherever a fuller explanation has seemed useful or new information warrants expanded coverage. As in the classic first edition,this new edition of Introduction to Algorithms presents a rich variety of algorithms and covers them in considerable depth while making their design and analysis accessible to all levels of readers. Further,the algorithms are presented in pseudocode to make the book easily accessible to students from all programming language backgrounds. Each chapter presents an algorithm,a design technique,an application area,or a related topic. The chapters are not dependent on one another,so the instructor can organize his or her use of the book in the way that best suits the course's needs. Additionally,the new edition offers a 25% increase over the first edition in the number of problems,giving the book 155 problems and over 900 exercises thatreinforcethe concepts the students are learning.\",\n",
              "  'authors': ['Thomas T. Cormen ',\n",
              "   ' Charles E. Leiserson ',\n",
              "   ' Ronald L. Rivest'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2752885492',\n",
              "  'references': ['2170102584',\n",
              "   '1660562555',\n",
              "   '2095293504',\n",
              "   '2070722739',\n",
              "   '1999478155',\n",
              "   '2017761965',\n",
              "   '2119046642',\n",
              "   '2102182691'],\n",
              "  'title': 'Introduction to Algorithms'},\n",
              " {'abstract': 'Continuous speech was treated as if produced by a finite‐state machine making a transition every centisecond. The observable output from state transitions was considered to be a power spectrum—a probabilistic function of the target state of each transition. Using this model, observed sequences of power spectra from real speech were decoded as sequences of acoustic states by means of the Viterbi trellis algorithm. The finite‐state machine used as a representation of the speech source was composed of machines representing words, combined according to a “language model.” When trained to the voice of a particular speaker, the decoder recognized seven‐digit telephone numbers correctly 96% of the time, with a better than 99% per‐digit accuracy. Results for other tests of the system, including syllable and phoneme recognition, will also be given.',\n",
              "  'authors': ['R. Bakis'],\n",
              "  'date': '1976',\n",
              "  'identifier': '1989226853',\n",
              "  'references': ['2125838338',\n",
              "   '1553004968',\n",
              "   '1966812932',\n",
              "   '2003333103',\n",
              "   '1665196592',\n",
              "   '2963460797',\n",
              "   '1990005915',\n",
              "   '2397682113',\n",
              "   '2165959773'],\n",
              "  'title': 'Continuous speech recognition via centisecond acoustic states'},\n",
              " {'abstract': 'A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance.',\n",
              "  'authors': ['D. Comaniciu ', ' P. Meer'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2067191022',\n",
              "  'references': ['2798766386',\n",
              "   '2140235142',\n",
              "   '2132549764',\n",
              "   '2099244020',\n",
              "   '2159128898',\n",
              "   '2150134853',\n",
              "   '1971784203',\n",
              "   '2999729612',\n",
              "   '2129905273',\n",
              "   '1499877760'],\n",
              "  'title': 'Mean shift: a robust approach toward feature space analysis'},\n",
              " {'abstract': 'In this paper, a system for the reading of totally unconstrained handwritten text is presented. The kernel of the system is a hidden Markov model (HMM) for handwriting recognition. The HMM is enhanced by a statistical language model. Thus linguistic knowledge beyond the lexicon level is incorporated in the recognition process. Another novel feature of the system is that the HMM is applied in such a way that the difficult problem of segmenting a line of text into individual words is avoided. A number of experiments with various language models and large vocabularies have been conducted. The language models used in the system were also analytically compared based on their perplexity.',\n",
              "  'authors': ['U.-V. Marti ', ' H. Bunke'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2092858021',\n",
              "  'references': ['2152928267',\n",
              "   '2441154163',\n",
              "   '2046485094',\n",
              "   '2172505344',\n",
              "   '2007714563',\n",
              "   '2092642599',\n",
              "   '1992152861',\n",
              "   '2103830439',\n",
              "   '1967942900',\n",
              "   '2136297401'],\n",
              "  'title': 'Using a statistical language model to improve the performance of an HMM-based cursive handwriting recognition systems'},\n",
              " {'abstract': 'This paper reports on the development of an instrument designed to measure the various perceptions that an individual may have of adopting an information technology IT innovation. This instrument is intended to be a tool for the study of the initial adoption and eventual diffusion of IT innovations within organizations. While the adoption of information technologies by individuals and organizations has been an area of substantial research interest since the early days of computerization, research efforts to date have led to mixed and inconclusive outcomes. The lack of a theoretical foundation for such research and inadequate definition and measurement of constructs have been identified as major causes for such outcomes. In a recent study examining the diffusion of new end-user IT, we decided to focus on measuring the potential adopters\\' perceptions of the technology. Measuring such perceptions has been termed a \"classic issue\" in the innovation diffusion literature, and a key to integrating the various findings of diffusion research. The perceptions of adopting were initially based on the five characteristics of innovations derived by Rogers 1983 from the diffusion of innovations literature, plus two developed specifically within this study. Of the existing scales for measuring these characteristics, very few had the requisite levels of validity and reliability. For this study, both newly created and existing items were placed in a common pool and subjected to four rounds of sorting by judges to establish which items should be in the various scales. The objective was to verify the convergent and discriminant validity of the scales by examining how the items were sorted into various construct categories. Analysis of inter-judge agreement about item placement identified both bad items as well as weaknesses in some of the constructs\\' original definitions. These were subsequently redefined. Scales for the resulting constructs were subjected to three separate field tests. Following the final test, the scales all demonstrated acceptable levels of reliability. Their validity was further checked using factor analysis, as well as conducting discriminant analysis comparing responses between adopters and nonadopters of the innovation. The result is a parsimonious, 38-item instrument comprising eight scales which provides a useful tool for the study of the initial adoption and diffusion of innovations. A short, 25 item, version of the instrument is also suggested.',\n",
              "  'authors': ['Gary C. Moore 1', ' Izak Benbasat 2'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2100408980',\n",
              "  'references': ['1791587663',\n",
              "   '1484864026',\n",
              "   '2033943395',\n",
              "   '2036389121',\n",
              "   '1990513740',\n",
              "   '2015391954',\n",
              "   '1557992034',\n",
              "   '2053154970',\n",
              "   '1985453879',\n",
              "   '1954663826'],\n",
              "  'title': 'Development of an Instrument to Measure the Perceptions of Adopting an Information Technology Innovation'},\n",
              " {'abstract': \"Constraint satisfaction is a simple but powerful tool. Constraints identify the impossible and reduce the realm of possibilities to effectively focus on the possible, allowing for a natural declarative formulation of what must be satisfied, without expressing how. The field of constraint reasoning has matured over the last three decades with contributions from a diverse community of researchers in artificial intelligence, databases and programming languages, operations research, management science, and applied mathematics. Today, constraint problems are used to model cognitive tasks in vision, language comprehension, default reasoning, diagnosis, scheduling, temporal and spatial reasoning. In Constraint Processing, Rina Dechter, synthesizes these contributions, along with her own significant work, to provide the first comprehensive examination of the theory that underlies constraint processing algorithms. Throughout, she focuses on fundamental tools and principles, emphasizing the representation and analysis of algorithms. ·Examines the basic practical aspects of each topic and then tackles more advanced issues, including current research challenges ·Builds the reader's understanding with definitions, examples, theory, algorithms and complexity analysis ·Synthesizes three decades of researchers work on constraint processing in AI, databases and programming languages, operations research, management science, and applied mathematics Table of Contents Preface; Introduction; Constraint Networks; Consistency-Enforcing Algorithms: Constraint Propagation; Directional Consistency; General Search Strategies; General Search Strategies: Look-Back; Local Search Algorithms; Advanced Consistency Methods; Tree-Decomposition Methods; Hybrid of Search and Inference: Time-Space Trade-offs; Tractable Constraint Languages; Temporal Constraint Networks; Constraint Optimization; Probabilistic Networks; Constraint Logic Programming; Bibliography\",\n",
              "  'authors': ['Rina Dechter'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2337098149',\n",
              "  'references': ['2752885492',\n",
              "   '2581275558',\n",
              "   '2159080219',\n",
              "   '2011039300',\n",
              "   '2142785340',\n",
              "   '2104670598',\n",
              "   '2057361103',\n",
              "   '1524764420',\n",
              "   '1593793857',\n",
              "   '2044560939'],\n",
              "  'title': 'Constraint Processing'},\n",
              " {'abstract': 'Vector-based models of word meaning have become increasingly popular in cognitive science. The appeal of these models lies in their ability to represent meaning simply by using distributional information under the assumption that words occurring within similar contexts are semantically similar. Despite their widespread use, vector-based models are typically directed at representing words in isolation, and methods for constructing representations for phrases or sentences have received little attention in the literature. This is in marked contrast to experimental evidence (e.g., in sentential priming) suggesting that semantic similarity is more complex than simply a relation between isolated words. This article proposes a framework for representing the meaning of word combinations in vector space. Central to our approach is vector composition, which we operationalize in terms of additive and multiplicative functions. Under this framework, we introduce a wide range of composition models that we evaluate empirically on a phrase similarity task.',\n",
              "  'authors': ['Jeff Mitchell ', ' Mirella Lapata'],\n",
              "  'date': '2010',\n",
              "  'identifier': '1984052055',\n",
              "  'references': ['2156909104',\n",
              "   '1880262756',\n",
              "   '2038721957',\n",
              "   '2132339004',\n",
              "   '1652505363',\n",
              "   '2147152072',\n",
              "   '1498436455',\n",
              "   '1587094587',\n",
              "   '1662133657',\n",
              "   '1631260214'],\n",
              "  'title': 'Composition in distributional models of semantics.'},\n",
              " {'abstract': 'Abstract The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied. A new set of image elements that are put into correspondence, the so called extremal regions , is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER). A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences. The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5×), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained.',\n",
              "  'authors': ['Jiri Matas 1',\n",
              "   ' Ondrej Chum 2',\n",
              "   ' Martin Urban 2',\n",
              "   ' Tomás Pajdla 2'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2124404372',\n",
              "  'references': ['2033819227',\n",
              "   '2124386111',\n",
              "   '1676552347',\n",
              "   '2124087378',\n",
              "   '2119747362',\n",
              "   '2165497495',\n",
              "   '2124260943',\n",
              "   '1541642243',\n",
              "   '2132332894',\n",
              "   '2143753158'],\n",
              "  'title': 'Robust wide-baseline stereo from maximally stable extremal regions'},\n",
              " {'abstract': 'A unified model for text categorization and text retrieval is introduced. We use a training set of manually categorized documents to learn word-category associations, and use these associations to predict the categories of arbitrary documents. Similarly, we use a training set of queries and their related documents to obtain empirical associations between query words and indexing terms of documents, and use these associations to predict the related documents of arbitrary queries. A Linear Least Squares Fit (LLSF) technique is employed to estimate the likelihood of these associations. Document collections from the MEDLINE database and Mayo patient records are used for studies on the effectiveness of our approach, and on how much the effectiveness depends on the choices of training data, indexing language, word-weighting scheme, and morphological canonicalization. Alternative methods are also tested on these data collections for comparison. It is evident that the LLSF approach uses the relevance information effectively within human decisions of categorization and retrieval, and achieves a semantic mapping of free texts to their representations in an indexing language. Such a semantic mapping lead to a significant improvement in categorization and retrieval, compared to alternative approaches.',\n",
              "  'authors': ['Yiming Yang ', ' Christopher G. Chute'],\n",
              "  'date': '1994',\n",
              "  'identifier': '1986913017',\n",
              "  'references': ['2798909945',\n",
              "   '2147152072',\n",
              "   '1833785989',\n",
              "   '2075665712',\n",
              "   '2000672666',\n",
              "   '133977063',\n",
              "   '2071106922',\n",
              "   '2989457786',\n",
              "   '2028962062',\n",
              "   '2090756040'],\n",
              "  'title': 'An example-based mapping method for text categorization and retrieval'},\n",
              " {'abstract': 'We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system.',\n",
              "  'authors': ['K.-K. Sung 1', ' T. Poggio 2'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2159686933',\n",
              "  'references': ['2138451337',\n",
              "   '3017143921',\n",
              "   '2098947662',\n",
              "   '2113341759',\n",
              "   '2135463994',\n",
              "   '2125848778',\n",
              "   '2104671481',\n",
              "   '1554705102',\n",
              "   '1532977286',\n",
              "   '1571461735'],\n",
              "  'title': 'Example-based learning for view-based human face detection'},\n",
              " {'abstract': 'The relationship between the three-dimensional coordinates of a point and the corresponding two-dimensional coordinates of its image, as seen by a camera, can be expressed in terms of a 3 by 4 matrix using the homogeneous coordinate system. This matrix is known more generally as the transformation matrix and can be determined experimentaily by measuring the image coordinates of six or more known paoints in space. Such a transformation can also be derived analytically from knowledge of the camera position, orientation, focal length and scaling and translation parameters in the image plane. However, the inverse problem of computing the camera location and orientation from the transformation matrix involves solution of simultaneous nonlinear equations in several variables and is considered difficult. In this paper we present a new and simple analytical technique that accomplishes this inversion rather easily. This technique works very well in practice and has considerable applications for motion tracking.',\n",
              "  'authors': ['S. Ganapathy'],\n",
              "  'date': '1984',\n",
              "  'identifier': '2122928074',\n",
              "  'references': ['2085261163',\n",
              "   '221566632',\n",
              "   '2054231002',\n",
              "   '2026124880',\n",
              "   '2017304241',\n",
              "   '2070079950',\n",
              "   '2912369374'],\n",
              "  'title': 'Decomposition of transformation matrices for robot vision'},\n",
              " {'abstract': '1. Various Aspects of Memory.- 1.1 On the Purpose and Nature of Biological Memory.- 1.1.1 Some Fundamental Concepts.- 1.1.2 The Classical Laws of Association.- 1.1.3 On Different Levels of Modelling.- 1.2 Questions Concerning the Fundamental Mechanisms of Memory.- 1.2.1 Where Do the Signals Relating to Memory Act Upon?.- 1.2.2 What Kind of Encoding is Used for Neural Signals?.- 1.2.3 What are the Variable Memory Elements?.- 1.2.4 How are Neural Signals Addressed in Memory?.- 1.3 Elementary Operations Implemented by Associative Memory.- 1.3.1 Associative Recall.- 1.3.2 Production of Sequences from the Associative Memory.- 1.3.3 On the Meaning of Background and Context.- 1.4 More Abstract Aspects of Memory.- 1.4.1 The Problem of Infinite-State Memory.- 1.4.2 Invariant Representations.- 1.4.3 Symbolic Representations.- 1.4.4 Virtual Images.- 1.4.5 The Logic of Stored Knowledge.- 2. Pattern Mathematics.- 2.1 Mathematical Notations and Methods.- 2.1.1 Vector Space Concepts.- 2.1.2 Matrix Notations.- 2.1.3 Further Properties of Matrices.- 2.1.4 Matrix Equations.- 2.1.5 Projection Operators.- 2.1.6 On Matrix Differential Calculus.- 2.2 Distance Measures for Patterns.- 2.2.1 Measures of Similarity and Distance in Vector Spaces.- 2.2.2 Measures of Similarity and Distance Between Symbol Strings.- 2.2.3 More Accurate Distance Measures for Text.- 3. Classical Learning Systems.- 3.1 The Adaptive Linear Element (Adaline).- 3.1.1 Description of Adaptation by the Stochastic Approximation.- 3.2 The Perceptron.- 3.3 The Learning Matrix.- 3.4 Physical Realization of Adaptive Weights.- 3.4.1 Perceptron and Adaline.- 3.4.2 Classical Conditioning.- 3.4.3 Conjunction Learning Switches.- 3.4.4 Digital Representation of Adaptive Circuits.- 3.4.5 Biological Components.- 4. A New Approach to Adaptive Filters.- 4.1 Survey of Some Necessary Functions.- 4.2 On the \"Transfer Function\" of the Neuron.- 4.3 Models for Basic Adaptive Units.- 4.3.1 On the Linearization of the Basic Unit.- 4.3.2 Various Cases of Adaptation Laws.- 4.3.3 Two Limit Theorems.- 4.3.4 The Novelty Detector.- 4.4 Adaptive Feedback Networks.- 4.4.1 The Autocorrelation Matrix Memory.- 4.4.2 The Novelty Filter.- 5. Self-Organizing Feature Maps.- 5.1 On the Feature Maps of the Brain.- 5.2 Formation of Localized Responses by Lateral Feedback.- 5.3 Computational Simplification of the Process.- 5.3.1 Definition of the Topology-Preserving Mapping.- 5.3.2 A Simple Two-Dimensional Self-Organizing System.- 5.4 Demonstrations of Simple Topology-Preserving Mappings.- 5.4.1 Images of Various Distributions of Input Vectors.- 5.4.2 \"The Magic TV\".- 5.4.3 Mapping by a Feeler Mechanism.- 5.5 Tonotopic Map.- 5.6 Formation of Hierarchical Representations.- 5.6.1 Taxonomy Example.- 5.6.2 Phoneme Map.- 5.7 Mathematical Treatment of Self-Organization.- 5.7.1 Ordering of Weights.- 5.7.2 Convergence Phase.- 5.8 Automatic Selection of Feature Dimensions.- 6. Optimal Associative Mappings.- 6.1 Transfer Function of an Associative Network.- 6.2 Autoassociative Recall as an Orthogonal Projection.- 6.2.1 Orthogonal Projections.- 6.2.2 Error-Correcting Properties of Projections.- 6.3 The Novelty Filter.- 6.3.1 Two Examples of Novelty Filter.- 6.3.2 Novelty Filter as an Autoassociative Memory.- 6.4 Autoassociative Encoding.- 6.4.1 An Example of Autoassociative Encoding.- 6.5 Optimal Associative Mappings.- 6.5.1 The Optimal Linear Associative Mapping.- 6.5.2 Optimal Nonlinear Associative Mappings.- 6.6 Relationship Between Associative Mapping, Linear Regression, and Linear Estimation.- 6.6.1 Relationship of the Associative Mapping to Linear Regression.- 6.6.2 Relationship of the Regression Solution to the Linear Estimator.- 6.7 Recursive Computation of the Optimal Associative Mapping.- 6.7.1 Linear Corrective Algorithms.- 6.7.2 Best Exact Solution (Gradient Projection).- 6.7.3 Best Approximate Solution (Regression).- 6.7.4 Recursive Solution in the General Case.- 6.8 Special Cases.- 6.8.1 The Correlation Matrix Memory.- 6.8.2 Relationship Between Conditional Averages and Optimal Estimator.- 7. Pattern Recognition.- 7.1 Discriminant Functions.- 7.2 Statistical Formulation of Pattern Classification.- 7.3 Comparison Methods.- 7.4 The Subspace Methods of Classification.- 7.4.1 The Basic Subspace Method.- 7.4.2 The Learning Subspace Method (LSM).- 7.5 Learning Vector Quantization.- 7.6 Feature Extraction.- 7.7 Clustering.- 7.7.1 Simple Clustering (Optimization Approach).- 7.7.2 Hierarchical Clustering (Taxonomy Approach).- 7.8 Structural Pattern Recognition Methods.- 8. More About Biological Memory.- 8.1 Physiological Foundations of Memory.- 8.1.1 On the Mechanisms of Memory in Biological Systems.- 8.1.2 Structural Features of Some Neural Networks.- 8.1.3 Functional Features of Neurons.- 8.1.4 Modelling of the Synaptic Plasticity.- 8.1.5 Can the Memory Capacity Ensue from Synaptic Changes?.- 8.2 The Unified Cortical Memory Model.- 8.2.1 The Laminar Network Organization.- 8.2.2 On the Roles of Interneurons.- 8.2.3 Representation of Knowledge Over Memory Fields.- 8.2.4 Self-Controlled Operation of Memory.- 8.3 Collateral Reading.- 8.3.1 Physiological Results Relevant to Modelling.- 8.3.2 Related Modelling.- 9. Notes on Neural Computing.- 9.1 First Theoretical Views of Neural Networks.- 9.2 Motives for the Neural Computing Research.- 9.3 What Could the Purpose of the Neural Networks be?.- 9.4 Definitions of Artificial \"Neural Computing\" and General Notes on Neural Modelling.- 9.5 Are the Biological Neural Functions Localized or Distributed?.- 9.6 Is Nonlinearity Essential to Neural Computing?.- 9.7 Characteristic Differences Between Neural and Digital Computers.- 9.7.1 The Degree of Parallelism of the Neural Networks is Still Higher than that of any \"Massively Parallel\" Digital Computer.- 9.7.2 Why the Neural Signals Cannot be Approximated by Boolean Variables.- 9.7.3 The Neural Circuits do not Implement Finite Automata.- 9.7.4 Undue Views of the Logic Equivalence of the Brain and Computers on a High Level.- 9.8 \"Connectionist Models\".- 9.9 How can the Neural Computers be Programmed?.- 10. Optical Associative Memories.- 10.1 Nonholographic Methods.- 10.2 General Aspects of Holographic Memories.- 10.3 A Simple Principle of Holographic Associative Memory.- 10.4 Addressing in Holographic Memories.- 10.5 Recent Advances of Optical Associative Memories.- Bibliography on Pattern Recognition.- References.',\n",
              "  'authors': ['Teuvo Kohonen'],\n",
              "  'date': '1984',\n",
              "  'identifier': '1991848143',\n",
              "  'references': ['2076063813',\n",
              "   '2053186076',\n",
              "   '1992419399',\n",
              "   '2141125852',\n",
              "   '2121601095',\n",
              "   '2161160262',\n",
              "   '2186428165',\n",
              "   '2153791616',\n",
              "   '2115689562'],\n",
              "  'title': 'Self Organization And Associative Memory'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Pranav Rajpurkar ',\n",
              "   ' Jian Zhang ',\n",
              "   ' Konstantin Lopyrev ',\n",
              "   ' Percy Liang'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2963748441',\n",
              "  'references': ['2108598243',\n",
              "   '1544827683',\n",
              "   '1632114991',\n",
              "   '2125436846',\n",
              "   '2964267515',\n",
              "   '2962809918',\n",
              "   '2171278097',\n",
              "   '2962790689',\n",
              "   '2251818205',\n",
              "   '2251349042'],\n",
              "  'title': 'SQuAD: 100,000+ Questions for Machine Comprehension of Text'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Dimitri Bertsekas'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2798766386',\n",
              "  'references': ['2164278908',\n",
              "   '2146502635',\n",
              "   '3029645440',\n",
              "   '2100556411',\n",
              "   '2067191022',\n",
              "   '1964357740',\n",
              "   '2109449402',\n",
              "   '1601740268',\n",
              "   '2132870739',\n",
              "   '2120340025'],\n",
              "  'title': 'Nonlinear Programming'},\n",
              " {'abstract': 'Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories. This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows. One remedy is to leverage data from other sources - such as text data - both to train visual models and to constrain their predictions. In this paper we present a new deep visual-semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text. We demonstrate that this model matches state-of-the-art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors, and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training. Semantic knowledge improves such zero-shot predictions achieving hit rates of up to 18% across thousands of novel labels never seen by the visual model.',\n",
              "  'authors': ['Andrea Frome ',\n",
              "   ' Greg S Corrado ',\n",
              "   ' Jon Shlens ',\n",
              "   ' Samy Bengio ',\n",
              "   ' Jeff Dean ',\n",
              "   \" Marc'Aurelio Ranzato \",\n",
              "   ' Tomas Mikolov'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2123024445',\n",
              "  'references': ['2618530766',\n",
              "   '2117539524',\n",
              "   '2153579005',\n",
              "   '1614298861',\n",
              "   '2108598243',\n",
              "   '2146502635',\n",
              "   '1904365287',\n",
              "   '2187089797',\n",
              "   '2168231600',\n",
              "   '2132339004'],\n",
              "  'title': 'DeViSE: A Deep Visual-Semantic Embedding Model'},\n",
              " {'abstract': 'Currently, most approaches to retrieving textual materials from scientific databases depend on a lexical match between words in users’ requests and those in or assigned to documents in a database. ...',\n",
              "  'authors': ['Michael W. Berry ', ' Susan T. Dumais ', \" Gavin W. O'Brien\"],\n",
              "  'date': '1995',\n",
              "  'identifier': '2072773380',\n",
              "  'references': ['2024165284',\n",
              "   '2042281163',\n",
              "   '2100235918',\n",
              "   '1501500081',\n",
              "   '2158997610',\n",
              "   '2134731454',\n",
              "   '1996283866',\n",
              "   '1832221731',\n",
              "   '2145360759',\n",
              "   '2063392856'],\n",
              "  'title': 'Using linear algebra for intelligent information retrieval'},\n",
              " {'abstract': 'In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.',\n",
              "  'authors': ['George Cybenko'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2103496339',\n",
              "  'references': ['1652505363',\n",
              "   '2137983211',\n",
              "   '2042264548',\n",
              "   '1971735090',\n",
              "   '2165758113',\n",
              "   '2019363670',\n",
              "   '75971611',\n",
              "   '3038830718',\n",
              "   '2066789935',\n",
              "   '18965947'],\n",
              "  'title': 'Approximation by superpositions of a sigmoidal function'},\n",
              " {'abstract': 'The extrema in a signal and its first few derivatives provide a useful general-purpose qualitative description for many kinds of signals. A fundamental problem in computing such descriptions is scale: a derivative must be taken over some neighborhood, but there is seldom a principled basis for choosing its size. Scale-space filtering is a method that describes signals qualitatively, managing the ambiguity of scale in an organized and natural way. The signal is first expanded by convolution with gaussian masks over a continuum of sizes. This \"scale-space\" image is then collapsed, using its qualitative structure, into a tree providing a concise but complete qualitative description covering all scales of observation. The description is further refined by applying a stability criterion, to identify events that persist of large changes in scale.',\n",
              "  'authors': ['Andrew P. Witkin'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2109863423',\n",
              "  'references': ['1995756857',\n",
              "   '1968245656',\n",
              "   '1530383550',\n",
              "   '2014913538',\n",
              "   '2824445807',\n",
              "   '2117900366',\n",
              "   '1574661480',\n",
              "   '1870339432',\n",
              "   '2059376358',\n",
              "   '1965555058'],\n",
              "  'title': 'Scale-space filtering'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Peter E. Hart ', ' Richard O. Duda ', ' David G. Stork'],\n",
              "  'date': '1973',\n",
              "  'identifier': '2799061466',\n",
              "  'references': ['2140190241',\n",
              "   '2171960770',\n",
              "   '2119479037',\n",
              "   '2148143831',\n",
              "   '2011430131',\n",
              "   '1625255723',\n",
              "   '2153233077',\n",
              "   '3100785508',\n",
              "   '2903158431',\n",
              "   '2121601095'],\n",
              "  'title': 'Pattern Classification'},\n",
              " {'abstract': 'The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection. This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.',\n",
              "  'authors': ['Mark Everingham 1',\n",
              "   ' Luc Gool 2',\n",
              "   ' Christopher K. Williams 3',\n",
              "   ' John Winn 4',\n",
              "   ' Andrew Zisserman 5'],\n",
              "  'date': '2010',\n",
              "  'identifier': '2031489346',\n",
              "  'references': ['2151103935',\n",
              "   '2161969291',\n",
              "   '3097096317',\n",
              "   '2162915993',\n",
              "   '2038721957',\n",
              "   '2131846894',\n",
              "   '2104974755',\n",
              "   '2110764733',\n",
              "   '1576445103',\n",
              "   '1565746575'],\n",
              "  'title': 'The Pascal Visual Object Classes (VOC) Challenge'},\n",
              " {'abstract': 'The human coronavirus NL63 (HCoV-NL63) was first identified in The Netherlands, and its circulation in France has not been investigated. We studied HCoV-NL63 infection in hospitalized children diagnosed with respiratory tract infections. From November 2002 to April 2003, we evaluated 300 respiratory specimens for HCoV-NL63. Of the 300 samples, 28 (9.3%) were positive for HCoV-NL63. The highest prevalence was found in February (18%). The main symptoms were fever (61%), rhinitis (39%), bronchiolitis (39%), digestive problems (33%), otitis (28%), pharyngitis (22%), and conjunctivitis (17%). A fragment of the spike protein gene was sequenced to determine the variety of circulating HCoV-NL63. Phylogenetic analysis indicated that strains with different genetic markers cocirculate in France.',\n",
              "  'authors': ['Astrid Vabret 1',\n",
              "   ' Thomas Mourez 1',\n",
              "   ' Julia Dina 1',\n",
              "   ' Lia van der Hoek 2',\n",
              "   ' Stéphanie Gouarin 1',\n",
              "   ' Joëlle Petitjean 1',\n",
              "   ' Jacques Brouard 1',\n",
              "   ' François Freymuth 1'],\n",
              "  'date': '2005',\n",
              "  'identifier': '1998335482',\n",
              "  'references': ['2132260239',\n",
              "   '2104548316',\n",
              "   '2170881661',\n",
              "   '2134061616',\n",
              "   '2111412754',\n",
              "   '2170933940',\n",
              "   '2010585539',\n",
              "   '2078917493',\n",
              "   '2104474203',\n",
              "   '2006012833'],\n",
              "  'title': 'Human Coronavirus NL63, France'},\n",
              " {'abstract': 'Both practitioners and academics understand that consumer loyalty and satisfaction are linked inextricably. They also understand that this relation is asymmetric. Although loyal consumers are most ...',\n",
              "  'authors': ['Richard L. Oliver'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1965574139',\n",
              "  'references': ['1561082337',\n",
              "   '3124394317',\n",
              "   '1574378514',\n",
              "   '1594945480',\n",
              "   '2102467277',\n",
              "   '2153906047',\n",
              "   '1983364918',\n",
              "   '2054347393',\n",
              "   '1966912369',\n",
              "   '2047562908'],\n",
              "  'title': 'Whence Consumer Loyalty'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Jianchao Zhu ',\n",
              "   ' Liangliang Shi 1',\n",
              "   ' Junchi Yan 2',\n",
              "   ' Hongyuan Zha 3'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3096851030',\n",
              "  'references': ['2194775991',\n",
              "   '2618530766',\n",
              "   '2962835968',\n",
              "   '2097117768',\n",
              "   '2117539524',\n",
              "   '1901129140',\n",
              "   '2099471712',\n",
              "   '2095705004',\n",
              "   '2130942839',\n",
              "   '3118608800'],\n",
              "  'title': 'AutoMix: Mixup Networks for Sample Interpolation via Cooperative Barycenter Learning.'},\n",
              " {'abstract': 'We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Moreover, since the release of the pix2pix software associated with this paper, hundreds of twitter users have posted their own artistic experiments using our system. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without handengineering our loss functions either.',\n",
              "  'authors': ['Phillip Isola ',\n",
              "   ' Jun-Yan Zhu ',\n",
              "   ' Tinghui Zhou ',\n",
              "   ' Alexei A. Efros'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2963073614',\n",
              "  'references': ['2964121744',\n",
              "   '1836465849',\n",
              "   '2117539524',\n",
              "   '1901129140',\n",
              "   '1903029394',\n",
              "   '2099471712',\n",
              "   '2133665775',\n",
              "   '2100495367',\n",
              "   '2963684088',\n",
              "   '2340897893'],\n",
              "  'title': 'Image-to-Image Translation with Conditional Adversarial Networks'},\n",
              " {'abstract': 'A method for rapid visual recognition of personal identity is described, based on the failure of a statistical test of independence. The most unique phenotypic feature visible in a person\\'s face is the detailed texture of each eye\\'s iris. The visible texture of a person\\'s iris in a real-time video image is encoded into a compact sequence of multi-scale quadrature 2-D Gabor wavelet coefficients, whose most-significant bits comprise a 256-byte \"iris code\". Statistical decision theory generates identification decisions from Exclusive-OR comparisons of complete iris codes at the rate of 4000 per second, including calculation of decision confidence levels. The distributions observed empirically in such comparisons imply a theoretical \"cross-over\" error rate of one in 131000 when a decision criterion is adopted that would equalize the false accept and false reject error rates. In the typical recognition case, given the mean observed degree of iris code agreement, the decision confidence levels correspond formally to a conditional false accept probability of one in about 10/sup 31/. >',\n",
              "  'authors': ['J.G. Daugman'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2102796633',\n",
              "  'references': ['2132984323',\n",
              "   '2049694710',\n",
              "   '2044465660',\n",
              "   '2006500012',\n",
              "   '2103384342',\n",
              "   '2040179990',\n",
              "   '2171181782',\n",
              "   '2059432853',\n",
              "   '1995875735',\n",
              "   '1499486838'],\n",
              "  'title': 'High confidence visual recognition of persons by a test of statistical independence'},\n",
              " {'abstract': 'We present a class of algorithms for independent component analysis (ICA) which use contrast functions based on canonical correlations in a reproducing kernel Hilbert space. On the one hand, we show that our contrast functions are related to mutual information and have desirable mathematical properties as measures of statistical dependence. On the other hand, building on recent developments in kernel methods, we show that these criteria and their derivatives can be computed efficiently. Minimizing these criteria leads to flexible and robust algorithms for ICA. We illustrate with simulations involving a wide variety of source distributions, showing that our algorithms outperform many of the presently known algorithms.',\n",
              "  'authors': ['Francis R. Bach ', ' Michael I. Jordan'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2124101779',\n",
              "  'references': ['2148603752',\n",
              "   '2752885492',\n",
              "   '1548802052',\n",
              "   '3023786531',\n",
              "   '2798909945',\n",
              "   '2099741732',\n",
              "   '2140095548',\n",
              "   '2108384452',\n",
              "   '2141224535',\n",
              "   '2797583072'],\n",
              "  'title': 'Kernel independent component analysis'},\n",
              " {'abstract': 'We present a new machine learning framework called \"self-taught learning\" for using unlabeled data in supervised classification tasks. We do not assume that the unlabeled data follows the same class labels or generative distribution as the labeled data. Thus, we would like to use a large number of unlabeled images (or audio samples, or text documents) randomly downloaded from the Internet to improve performance on a given image (or audio, or text) classification task. Such unlabeled data is significantly easier to obtain than in typical semi-supervised or transfer learning settings, making self-taught learning widely applicable to many practical learning problems. We describe an approach to self-taught learning that uses sparse coding to construct higher-level features using the unlabeled data. These features form a succinct input representation and significantly improve classification performance. When using an SVM for classification, we further show how a Fisher kernel can be learned for this representation.',\n",
              "  'authors': ['Rajat Raina ',\n",
              "   ' Alexis Battle ',\n",
              "   ' Honglak Lee ',\n",
              "   ' Benjamin Packer ',\n",
              "   ' Andrew Y. Ng'],\n",
              "  'date': '2007',\n",
              "  'identifier': '2122922389',\n",
              "  'references': ['1880262756',\n",
              "   '2100495367',\n",
              "   '2162915993',\n",
              "   '2053186076',\n",
              "   '2135046866',\n",
              "   '2001141328',\n",
              "   '2063978378',\n",
              "   '2147152072',\n",
              "   '2166049352',\n",
              "   '2113606819'],\n",
              "  'title': 'Self-taught learning: transfer learning from unlabeled data'},\n",
              " {'abstract': '1. It was found that an occipital evoked potential can be elicited in the human by moving a grating pattern without changing the mean light flux entering the eye. Prolonged viewing of a high contrast grating reduces the amplitude of the potential evoked by a low contrast grating. 2. This adaptation to a grating was studied psychophysically by determining the contrast threshold before and after adaptation. There is a temporary fivefold rise in contrast threshold after exposure to a high contrast grating of the same orientation and spatial frequency. 3. By determining the rise of threshold over a range of spatial frequency for a number of adapting frequencies it was found that the threshold elevation is limited to a spectrum of frequencies with a bandwidth of just over an octave at half amplitude, centred on the adapting frequency. 4. The amplitude of the effect and its bandwidth are very similar for adapting spatial frequencies between 3 c/deg. and 14 c/deg. At higher frequencies the bandwidth is slightly narrower. For lower adapting frequencies the peak of the effect stays at 3 c/deg. 5. These and other findings suggest that the human visual system may possess neurones selectively sensitive to spatial frequency and size. The orientational selectivity and the interocular transfer of the adaptation effect implicate the visual cortex as the site of these neurones. 6. This neural system may play an essential preliminary role in the recognition of complex images and generalization for magnification.',\n",
              "  'authors': ['C. Blakemore ', ' F. W. Campbell'],\n",
              "  'date': '1969',\n",
              "  'identifier': '2167553001',\n",
              "  'references': ['2116360511',\n",
              "   '2117731089',\n",
              "   '1999908130',\n",
              "   '2153782322',\n",
              "   '2080276732',\n",
              "   '1984667240',\n",
              "   '2059660738',\n",
              "   '1998896459',\n",
              "   '2071147527',\n",
              "   '2006229337'],\n",
              "  'title': 'On the existence of neurones in the human visual system selectively sensitive to the orientation and size of retinal images.'},\n",
              " {'abstract': 'Long short-term memory (LSTM; Hochreiter & Schmidhuber, 1997) can solve numerous tasks not solvable by previous learning algorithms for recurrent neural networks (RNNs). We identify a weakness of LSTM networks processing continual input streams that are not a priori segmented into subsequences with explicitly marked ends at which the network\\'s internal state could be reset. Without resets, the state may grow indefinitely and eventually cause the network to break down. Our remedy is a novel, adaptive \"forget gate\" that enables an LSTM cell to learn to reset itself at appropriate times, thus releasing internal resources. We review illustrative benchmark problems on which standard LSTM outperforms other RNN algorithms. All algorithms (including LSTM) fail to solve continual versions of these problems. LSTM with forget gates, however, easily solves them, and in an elegant way.',\n",
              "  'authors': ['Felix A. Gers ', ' Jürgen A. Schmidhuber ', ' Fred A. Cummins'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2136848157',\n",
              "  'references': ['2064675550',\n",
              "   '2107878631',\n",
              "   '2154890045',\n",
              "   '1959983357',\n",
              "   '194249466',\n",
              "   '2103452139',\n",
              "   '1674799117',\n",
              "   '1971129545',\n",
              "   '2121029939',\n",
              "   '2057653135'],\n",
              "  'title': 'Learning to Forget: Continual Prediction with LSTM'},\n",
              " {'abstract': 'The fundamental theorems on the asymptotic behavior of eigenvalues, inverses, and products of banded Toeplitz matrices and Toeplitz matrices with absolutely summable elements are derived in a tutorial manner. Mathematical elegance and generality are sacrificed for conceptual simplicity and insight in the hope of making these results available to engineers lacking either the background or endurance to attack the mathematical literature on the subject. By limiting the generality of the matrices considered, the essential ideas and results can be conveyed in a more intuitive manner without the mathematical machinery required for the most general cases. As an application the results are applied to the study of the covariance matrices and their factors of linear models of discrete time random processes.',\n",
              "  'authors': ['Robert M. Gray'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2132105090',\n",
              "  'references': ['2099111195',\n",
              "   '2128978199',\n",
              "   '2045463928',\n",
              "   '1550150926',\n",
              "   '2013348732',\n",
              "   '1519038128',\n",
              "   '2097415784',\n",
              "   '2089598668',\n",
              "   '2144181355',\n",
              "   '2796705602'],\n",
              "  'title': 'Toeplitz and circulant matrices: a review'},\n",
              " {'abstract': 'We propose and study a set of algorithms for discovering community structure in networks-natural divisions of network nodes into densely connected subgroups. Our algorithms all share two definitive features: first, they involve iterative removal of edges from the network to split it into communities, the edges removed being identified using any one of a number of possible \"betweenness\" measures, and second, these measures are, crucially, recalculated after each removal. We also propose a measure for the strength of the community structure found by our algorithms, which gives us an objective metric for choosing the number of communities into which a network should be divided. We demonstrate that our algorithms are highly effective at discovering community structure in both computer-generated and real-world network data, and show how they can be used to shed light on the sometimes dauntingly complex structure of networked systems.',\n",
              "  'authors': ['M. E. J. Newman 1', ' 2', ' M. Girvan 2', ' 3'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2095293504',\n",
              "  'references': ['2112090702',\n",
              "   '2148606196',\n",
              "   '2124637492',\n",
              "   '2752885492',\n",
              "   '1971421925',\n",
              "   '2011039300',\n",
              "   '2164727176',\n",
              "   '1976969221',\n",
              "   '3122657004',\n",
              "   '1977545325'],\n",
              "  'title': 'Finding and evaluating community structure in networks.'},\n",
              " {'abstract': 'This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.',\n",
              "  'authors': ['P. Viola 1', ' M. Jones 2'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2164598857',\n",
              "  'references': ['1988790447',\n",
              "   '2128272608',\n",
              "   '2217896605',\n",
              "   '2115763357',\n",
              "   '1975846642',\n",
              "   '2124351082',\n",
              "   '2159686933',\n",
              "   '2155511848',\n",
              "   '2101522199',\n",
              "   '1588351438'],\n",
              "  'title': 'Rapid object detection using a boosted cascade of simple features'},\n",
              " {'abstract': 'Cooperating local parallel processes can be used as aids in assigning numerical or symbolic labels to image or scene parts. Various approaches to using such processes in low-level vision are reviewed, and their advantages are discussed. Methods of designing and controlling such processes are also considered.',\n",
              "  'authors': ['Larry S. Davis 1', ' Azriel Rosenfeld 2'],\n",
              "  'date': '1980',\n",
              "  'identifier': '2080250034',\n",
              "  'references': ['1979622972',\n",
              "   '2048330959',\n",
              "   '2136113379',\n",
              "   '2008014451',\n",
              "   '1597474747',\n",
              "   '1736170383',\n",
              "   '39428922',\n",
              "   '2105038716',\n",
              "   '2032167559',\n",
              "   '2041756013'],\n",
              "  'title': 'Cooperating processes for low-level vision: a survey'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Dan Gusfield'],\n",
              "  'date': '1997',\n",
              "  'identifier': '938539187',\n",
              "  'references': ['2153233077',\n",
              "   '2107282968',\n",
              "   '2001496424',\n",
              "   '2144544802',\n",
              "   '2099256741',\n",
              "   '2137786570',\n",
              "   '2072193858',\n",
              "   '2000041758',\n",
              "   '2137721714',\n",
              "   '2081028405'],\n",
              "  'title': 'Algorithms on Strings, Trees, and Sequences: Suffix Trees and Their Uses'},\n",
              " {'abstract': 'We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.',\n",
              "  'authors': ['David M. Blei 1', ' Andrew Y. Ng 2', ' Michael I. Jordan 1'],\n",
              "  'date': '2003',\n",
              "  'identifier': '1880262756',\n",
              "  'references': ['2045656233',\n",
              "   '2147152072',\n",
              "   '2107743791',\n",
              "   '2097089247',\n",
              "   '1956559956',\n",
              "   '1516111018',\n",
              "   '1508165687',\n",
              "   '1746680969',\n",
              "   '2020842694',\n",
              "   '2063392856'],\n",
              "  'title': 'Latent dirichlet allocation'},\n",
              " {'abstract': \"Researchers often conduct mediation analysis in order to indirectly assess the effect of a proposed cause on some outcome through a proposed mediator. The utility of mediation analysis stems from its ability to go beyond the merely descriptive to a more functional understanding of the relationships among variables. A necessary component of mediation is a statistically and practically significant indirect effect. Although mediation hypotheses are frequently explored in psychological research, formal significance tests of indirect effects are rarely conducted. After a brief overview of mediation, we argue the importance of directly testing the significance of indirect effects and provide SPSS and SAS macros that facilitate estimation of the indirect effect with a normal theory approach and a bootstrap approach to obtaining confidence intervals, as well as the traditional approach advocated by Baron and Kenny (1986). We hope that this discussion and the macros will enhance the frequency of formal mediation tests in the psychology literature. Electronic copies of these macros may be downloaded from the Psychonomic Society's Web archive at www.psychonomic.org/archive/.\",\n",
              "  'authors': ['Kristopher J. Preacher 1', ' Andrew F. Hayes 2'],\n",
              "  'date': '2004',\n",
              "  'identifier': '1995031937',\n",
              "  'references': ['2102865756',\n",
              "   '1665332082',\n",
              "   '1971440513',\n",
              "   '2068719957',\n",
              "   '2104057213',\n",
              "   '1571998446',\n",
              "   '2104818169',\n",
              "   '1715619412',\n",
              "   '2044773838',\n",
              "   '2170123630'],\n",
              "  'title': 'SPSS and SAS procedures for estimating indirect effects in simple mediation models.'},\n",
              " {'abstract': 'Brains, it has recently been argued, are essentially prediction machines. They are bundles of cells that support perception and action by constantly attempting to match incoming sensory inputs with top-down expectations or predictions. This is achieved using a hierarchical generative model that aims to minimize prediction error within a bidirectional cascade of cortical processing. Such accounts offer a unifying model of perception and action, illuminate the functional role of attention, and may neatly capture the special contribution of cortical processing to adaptive success. This target article critically examines this \"hierarchical prediction machine\" approach, concluding that it offers the best clue yet to the shape of a unified science of mind and action. Sections 1 and 2 lay out the key elements and implications of the approach. Section 3 explores a variety of pitfalls and challenges, spanning the evidential, the methodological, and the more properly conceptual. The paper ends (sections 4 and 5) by asking how such approaches might impact our more general vision of mind, experience, and agency.',\n",
              "  'authors': ['Andy Clark'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2153791616',\n",
              "  'references': ['2136922672',\n",
              "   '2100495367',\n",
              "   '2072128103',\n",
              "   '2116064496',\n",
              "   '1652505363',\n",
              "   '2049633694',\n",
              "   '2029949252',\n",
              "   '2085529605',\n",
              "   '2145889472',\n",
              "   '1983578042'],\n",
              "  'title': 'Whatever next? Predictive brains, situated agents, and the future of cognitive science'},\n",
              " {'abstract': 'In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 (≫ 65%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53%).',\n",
              "  'authors': ['Kevin Jarrett ',\n",
              "   ' Koray Kavukcuoglu ',\n",
              "   \" Marc'Aurelio Ranzato \",\n",
              "   ' Yann LeCun'],\n",
              "  'date': '2009',\n",
              "  'identifier': '2546302380',\n",
              "  'references': ['2151103935',\n",
              "   '2161969291',\n",
              "   '2100495367',\n",
              "   '2310919327',\n",
              "   '2162915993',\n",
              "   '2110798204',\n",
              "   '2130325614',\n",
              "   '2097018403',\n",
              "   '2166049352',\n",
              "   '2134557905'],\n",
              "  'title': 'What is the best multi-stage architecture for object recognition?'},\n",
              " {'abstract': \"Author cocitation analysis (ACA), a special type of cocitation analysis, was introduced by White and Griffith in 1981. This technique is used to analyze the intellectual structure of a given scientific field. In 1990, McCain published a technical overview that has been largely adopted as a standard. Here, McCain notes that Pearson's correlation coefficient (Pearson's r) is often used as a similarity measure in ACA and presents some advantages of its use. The present article criticizes the use of Pearson's r in ACA and sets forth two natural requirements that a similarity measure applied in ACA should satisfy. It is shown that Pearson's r does not satisfy these requirements. Real and hypothetical data are used in order to obtain counterexamples to both requirements. It is concluded that Pearson's r is probably not an optimal choice of a similarity measure in ACA. Still, further empirical research is needed to show if, and in that case to what extent, the use of similarity measures in ACA that fulfill these requirements would lead to objectively better results In full-scale studies. Further, problems related to incomplete cocitation matrices are discussed.\",\n",
              "  'authors': ['Per Ahlgren 1', ' Bo Jarneving 1', ' Ronald Rousseau 2'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2096123611',\n",
              "  'references': ['2002664886',\n",
              "   '2072897447',\n",
              "   '2118587067',\n",
              "   '1984066943',\n",
              "   '2029520384',\n",
              "   '2129936978',\n",
              "   '2051228787',\n",
              "   '2084773904',\n",
              "   '2316114989',\n",
              "   '2091560105'],\n",
              "  'title': \"Requirements for a cocitation similarity measure, with special reference to Pearson's correlation coefficient\"},\n",
              " {'abstract': 'From the Publisher: This is the revised and greatly expanded Second Edition of the hugely popular Numerical Recipes: The Art of Scientific Computing. The product of a unique collaboration among four leading scientists in academic research and industry, Numerical Recipes is a complete text and reference book on scientific computing. In a self-contained manner it proceeds from mathematical and theoretical considerations to actual practical computer routines. With over 100 new routines (now well over 300 in all), plus upgraded versions of many of the original routines, this book is more than ever the most practical, comprehensive handbook of scientific computing available today. The book retains the informal, easy-to-read style that made the first edition so popular, with many new topics presented at the same accessible level. In addition, some sections of more advanced material have been introduced, set off in small type from the main body of the text. Numerical Recipes is an ideal textbook for scientists and engineers and an indispensable reference for anyone who works in scientific computing. Highlights of the new material include a new chapter on integral equations and inverse methods; multigrid methods for solving partial differential equations; improved random number routines; wavelet transforms; the statistical bootstrap method; a new chapter on \"less-numerical\" algorithms including compression coding and arbitrary precision arithmetic; band diagonal linear systems; linear algebra on sparse matrices; Cholesky and QR decomposition; calculation of numerical derivatives; Pade approximants, and rational Chebyshev approximation; new special functions; Monte Carlo integration in high-dimensional spaces; globally convergent methods for sets of nonlinear equations; an expanded chapter on fast Fourier methods; spectral analysis on unevenly sampled data; Savitzky-Golay smoothing filters; and two-dimensional Kolmogorov-Smirnoff tests. All this is in addition to material on such basic top',\n",
              "  'authors': ['William H. Press 1',\n",
              "   ' Brian P. Flannery 2',\n",
              "   ' Saul A. Teukolsky 3',\n",
              "   ' William T. Vetterling 4'],\n",
              "  'date': '1986',\n",
              "  'identifier': '2432517183',\n",
              "  'references': ['2051277798', '2014208555', '2063565635'],\n",
              "  'title': 'Numerical Recipes in C: The Art of Scientific Computing'},\n",
              " {'abstract': 'The receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs.',\n",
              "  'authors': ['Bruno A. Olshausen 1', ' 2', ' David J. Field 2'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2145889472',\n",
              "  'references': ['2108384452',\n",
              "   '1993845689',\n",
              "   '2180838288',\n",
              "   '2167034998',\n",
              "   '2120838001',\n",
              "   '2122925692',\n",
              "   '1914401667',\n",
              "   '2106884367',\n",
              "   '2911607583',\n",
              "   '2117731089'],\n",
              "  'title': 'Emergence of simple-cell receptive field properties by learning a sparse code for natural images'},\n",
              " {'abstract': 'This book is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory. The book also introduces Bayesian analysis of learning and relates SVMs to Gaussian Processes and other kernel based learning methods. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc. Their first introduction in the early 1990s lead to a recent explosion of applications and deepening theoretical analysis, that has now established Support Vector Machines along with neural networks as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and application of these techniques. The concepts are introduced gradually in accessible and self-contained stages, though in each stage the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally the book will equip the practitioner to apply the techniques and an associated web site will provide pointers to updated literature, new applications, and on-line software.',\n",
              "  'authors': ['Nello Cristianini ', ' J Shawe-Taylor'],\n",
              "  'date': '2000',\n",
              "  'identifier': '1601740268',\n",
              "  'references': ['2153635508',\n",
              "   '2798766386',\n",
              "   '1560724230',\n",
              "   '1485732691',\n",
              "   '100063776'],\n",
              "  'title': 'An introduction to Support Vector Machines'},\n",
              " {'abstract': 'Neurons in area la of the posterior parietal cortex of monkeys respond to both the retinal location of a visual stimulus and the position of the eyes and by combining these signals represent the spatial location of external objects. A neural network model, programmed using back-propagation learning, can decode this spatial information from area la neurons and accounts for their observed response properties.',\n",
              "  'authors': ['David Zipser 1', ' Richard A. Andersen 2'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2088744610',\n",
              "  'references': ['1652505363',\n",
              "   '1507849272',\n",
              "   '2023486727',\n",
              "   '2177960617',\n",
              "   '1860548438',\n",
              "   '1934341223',\n",
              "   '1827197145',\n",
              "   '2098933766',\n",
              "   '2086105634',\n",
              "   '1598762216'],\n",
              "  'title': 'A back-propagation programmed network that simulates response properties of a subset of posterior parietal neurons.'},\n",
              " {'abstract': 'Bayes factors have been advocated as superior to pp-values for assessing statistical evidence in data. Despite the advantages of Bayes factors and the drawbacks of pp-values, inference by pp-values is still nearly ubiquitous. One impediment to the adoption of Bayes factors is a lack of practical development, particularly a lack of ready-to-use formulas and algorithms. In this paper, we discuss and expand a set of default Bayes factor tests for ANOVA designs. These tests are based on multivariate generalizations of Cauchy priors on standardized effects, and have the desirable properties of being invariant with respect to linear transformations of measurement units. Moreover, these Bayes factors are computationally convenient, and straightforward sampling algorithms are provided. We cover models with fixed, random, and mixed effects, including random interactions, and do so for within-subject, between-subject, and mixed designs. We extend the discussion to regression models with continuous covariates. We also discuss how these Bayes factors may be applied in nonlinear settings, and show how they are useful in differentiating between the power law and the exponential law of skill acquisition. In sum, the current development makes the computation of Bayes factors straightforward for the vast majority of designs in experimental psychology.',\n",
              "  'authors': ['Jeffrey N. Rouder 1',\n",
              "   ' Richard D. Morey 2',\n",
              "   ' Paul L. Speckman 1',\n",
              "   ' Jordan M. Province 1'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2143841415',\n",
              "  'references': ['2313307644',\n",
              "   '2045656233',\n",
              "   '3015463134',\n",
              "   '1991567646',\n",
              "   '1528905581',\n",
              "   '2432517183',\n",
              "   '2083875149',\n",
              "   '1978662219',\n",
              "   '191383808',\n",
              "   '2143707047'],\n",
              "  'title': 'Default Bayes factors for ANOVA designs'},\n",
              " {'abstract': 'In this work we describe how to train a multi-layer generative model of natural images. We use a dataset of millions of tiny colour images, described in the next section. This has been attempted by several groups but without success. The models on which we focus are RBMs (Restricted Boltzmann Machines) and DBNs (Deep Belief Networks). These models learn interesting-looking filters, which we show are more useful to a classifier than the raw pixels. We train the classifier on a labeled subset that we have collected and call the CIFAR-10 dataset.',\n",
              "  'authors': ['Alex Krizhevsky'],\n",
              "  'date': '2009',\n",
              "  'identifier': '3118608800',\n",
              "  'references': ['2081580037', '2096192494', '2165225968'],\n",
              "  'title': 'Learning Multiple Layers of Features from Tiny Images'},\n",
              " {'abstract': 'A new method for real time tracking of non-rigid objects seen from a moving camera is proposed. The central computational module is based on the mean shift iterations and finds the most probable target position in the current frame. The dissimilarity between the target model (its color distribution) and the target candidates is expressed by a metric derived from the Bhattacharyya coefficient. The theoretical analysis of the approach shows that it relates to the Bayesian framework while providing a practical, fast and efficient solution. The capability of the tracker to handle in real time partial occlusions, significant clutter, and target scale variations, is demonstrated for several image sequences.',\n",
              "  'authors': ['D. Comaniciu ', ' V. Ramesh ', ' P. Meer'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2159128898',\n",
              "  'references': ['2140235142',\n",
              "   '2161406034',\n",
              "   '2914885528',\n",
              "   '1874027545',\n",
              "   '1964443764',\n",
              "   '1687797484',\n",
              "   '204885769',\n",
              "   '2168682262',\n",
              "   '2135346934',\n",
              "   '2033009866'],\n",
              "  'title': 'Real-time tracking of non-rigid objects using mean shift'},\n",
              " {'abstract': 'There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .',\n",
              "  'authors': ['Olaf Ronneberger ', ' Philipp Fischer ', ' Thomas Brox'],\n",
              "  'date': '2015',\n",
              "  'identifier': '1901129140',\n",
              "  'references': ['2618530766',\n",
              "   '2962835968',\n",
              "   '1903029394',\n",
              "   '2155893237',\n",
              "   '1677182931',\n",
              "   '1948751323',\n",
              "   '2167510172',\n",
              "   '1893585201',\n",
              "   '2148349024',\n",
              "   '2147800946'],\n",
              "  'title': 'U-Net: Convolutional Networks for Biomedical Image Segmentation'},\n",
              " {'abstract': 'Language modeling approaches to information retrieval are attractive and promising because they connect the problem of retrieval with that of language model estimation, which has been studied extensively in other application areas such as speech recognition. The basic idea of these approaches is to estimate a language model for each document, and to then rank documents by the likelihood of the query according to the estimated language model. A central issue in language model estimation is smoothing, the problem of adjusting the maximum likelihood estimator to compensate for data sparseness. In this article, we study the problem of language model smoothing and its influence on retrieval performance. We examine the sensitivity of retrieval performance to the smoothing parameters and compare several popular smoothing methods on different test collections. Experimental results show that not only is the retrieval performance generally sensitive to the smoothing parameters, but also the sensitivity pattern is affected by the query type, with performance being more sensitive to smoothing for verbose queries than for keyword queries. Verbose queries also generally require more aggressive smoothing to achieve optimal performance. This suggests that smoothing plays two different role---to make the estimated document language model more accurate and to \"explain\" the noninformative words in the query. In order to decouple these two distinct roles of smoothing, we propose a two-stage smoothing strategy, which yields better sensitivity patterns and facilitates the setting of smoothing parameters automatically. We further propose methods for estimating the smoothing parameters automatically. Evaluation on five different databases and four types of queries indicates that the two-stage smoothing method with the proposed parameter estimation methods consistently gives retrieval performance that is close to---or better than---the best results achieved using a single smoothing method and exhaustive parameter search on the test data.',\n",
              "  'authors': ['Chengxiang Zhai ', ' John Lafferty'],\n",
              "  'date': '2004',\n",
              "  'identifier': '1972594981',\n",
              "  'references': ['1978394996',\n",
              "   '2093390569',\n",
              "   '2911767655',\n",
              "   '2169213601',\n",
              "   '2158195707',\n",
              "   '1482214997',\n",
              "   '2000672666',\n",
              "   '2068905009',\n",
              "   '2062270497',\n",
              "   '2000569744'],\n",
              "  'title': 'A study of smoothing methods for language models applied to information retrieval'},\n",
              " {'abstract': 'A new method for performing a nonlinear form of principal component analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in high-dimensional feature spaces, related to input space by some nonlinear map—for instance, the space of all possible five-pixel products in 16 × 16 images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition.',\n",
              "  'authors': ['Bernhard Schölkopf 1',\n",
              "   ' Alexander Smola 2',\n",
              "   ' Klaus-Robert Müller 2'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2140095548',\n",
              "  'references': ['2156909104',\n",
              "   '2148694408',\n",
              "   '2119821739',\n",
              "   '2132549764',\n",
              "   '2087347434',\n",
              "   '2149298154',\n",
              "   '2147800946',\n",
              "   '2150796457',\n",
              "   '2008056655',\n",
              "   '2135463994'],\n",
              "  'title': 'Nonlinear component analysis as a kernel eigenvalue problem'},\n",
              " {'abstract': 'Part 1 Inference: introduction to inference for Bayesian networks, Robert Cowell advanced inference in Bayesian networks, Robert Cowell inference in Bayesian networks using nested junction trees, Uffe Kjoerulff bucket elimination - a unifying framework for probabilistic inference, R. Dechter an introduction to variational methods for graphical models, Michael I. Jordan et al improving the mean field approximation via the use of mixture distributions, Tommi S. Jaakkola and Michael I. Jordan introduction to Monte Carlo methods, D.J.C. MacKay suppressing random walls in Markov chain Monte Carlo using ordered overrelaxation, Radford M. Neal. Part 2 Independence: chain graphs and symmetric associations, Thomas S. Richardson the multiinformation function as a tool for measuring stochastic dependence, M. Studeny and J. Vejnarova. Part 3 Foundations for learning: a tutorial on learning with Bayesian networks, David Heckerman a view of the EM algorithm that justifies incremental, sparse and other variants, Radford M. Neal and Geoffrey E. Hinton. Part 4 Learning from data: latent variable models, Christopher M. Bishop stochastic algorithms for exploratory data analysis - data clustering and data visualization, Joachim M. Buhmann learning Bayesian networks with local structure, Nir Friedman and Moises Goldszmidt asymptotic model selection for directed networks with hidden variables, Dan Geiger et al a hierarchical community of experts, Geoffrey E. Hinton et al an information-theoretic analysis of hard and soft assignment methods for clustering, Michael J. Kearns et al learning hybrid Bayesian networks from data, Stefano Monti and Gregory F. Cooper a mean field learning algorithm for unsupervised neural networks, Lawrence Saul and Michael Jordan edge exclusion tests for graphical Gaussian models, Peter W.F. Smith and Joe Whittaker hepatitis B - a case study in MCMC, D.J. Spiegelhalter et al prediction with Gaussian processes - from linear regression to linear prediction and beyond, C.K.I. Williams.',\n",
              "  'authors': ['Michael I. Jordan'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1746680969',\n",
              "  'references': ['1880262756',\n",
              "   '2072128103',\n",
              "   '2116064496',\n",
              "   '2166049352',\n",
              "   '2166851633',\n",
              "   '2097089247',\n",
              "   '1755360231',\n",
              "   '1873332500'],\n",
              "  'title': 'Learning in graphical models'},\n",
              " {'abstract': 'There has been a recent revival of interest in parallel systems in which computation is performed by excitatory and inhibitory interactions within a network of relatively simple, neuronlike units [1 2 3 4]. At the early stages of visual processing, individual units can represent hypotheses about how small local fragments of the visual input should be interpreted, and interactions between units can encode knowledge about the constraints between local interpretations. Higher up in the visual system, the representational issues are more complex. This paper considers the difficulties involved in representing shapes in parallel systems, and suggests ways of overcoming them. In doing so, it provides a mechanism for shape perception and visual attention which allows a novel interpretation of the Gestalt slogan that the whole is more than the sum of its parts.',\n",
              "  'authors': ['Geoffrey F. Hinton'],\n",
              "  'date': '1981',\n",
              "  'identifier': '179212727',\n",
              "  'references': ['2121773050',\n",
              "   '2048330959',\n",
              "   '2130355536',\n",
              "   '2081519360',\n",
              "   '1594957066',\n",
              "   '2322002063',\n",
              "   '39428922',\n",
              "   '2108729336',\n",
              "   '1976645892',\n",
              "   '112688168'],\n",
              "  'title': 'Shape representation in parallel systems'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Yann LeCun ', ' Fu Jie Huang'],\n",
              "  'date': '2005',\n",
              "  'identifier': '10021998',\n",
              "  'references': ['2310919327',\n",
              "   '2147880316',\n",
              "   '2132339004',\n",
              "   '2137813581',\n",
              "   '2134557905',\n",
              "   '2008652694',\n",
              "   '2105644991',\n",
              "   '1802356529',\n",
              "   '2148099973',\n",
              "   '2175582831'],\n",
              "  'title': 'Loss Functions for Discriminative Training of Energy-Based Models.'},\n",
              " {'abstract': 'Chest CT had higher sensitivity for diagnosis of COVID-19 as compared with initial reverse-transcription polymerase chain reaction from swab samples in the epidemic area of China.',\n",
              "  'authors': ['Tao Ai 1',\n",
              "   ' Zhenlu Yang 2',\n",
              "   ' Hongyan Hou 3',\n",
              "   ' Chenao Zhan 1',\n",
              "   ' Chong Chen 1',\n",
              "   ' Wenzhi Lv 1',\n",
              "   ' Qian Tao 1',\n",
              "   ' Ziyong Sun 1',\n",
              "   ' Liming Xia 1'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3007497549',\n",
              "  'references': ['3001118548',\n",
              "   '3008818676',\n",
              "   '3004906315',\n",
              "   '3006643024',\n",
              "   '3006110666',\n",
              "   '3006354146',\n",
              "   '3003901880',\n",
              "   '3005656138',\n",
              "   '3004511262'],\n",
              "  'title': 'Correlation of Chest CT and RT-PCR Testing for Coronavirus Disease 2019 (COVID-19) in China: A Report of 1014 Cases.'},\n",
              " {'abstract': '1. The striate cortex was studied in lightly anaesthetized macaque and spider monkeys by recording extracellularly from single units and stimulating the retinas with spots or patterns of light. Most cells can be categorized as simple, complex, or hypercomplex, with response properties very similar to those previously described in the cat. On the average, however, receptive fields are smaller, and there is a greater sensitivity to changes in stimulus orientation. A small proportion of the cells are colour coded. 2. Evidence is presented for at least two independent systems of columns extending vertically from surface to white matter. Columns of the first type contain cells with common receptive-field orientations. They are similar to the orientation columns described in the cat, but are probably smaller in cross-sectional area. In the second system cells are aggregated into columns according to eye preference. The ocular dominance columns are larger than the orientation columns, and the two sets of boundaries seem to be independent. 3. There is a tendency for cells to be grouped according to symmetry of responses to movement; in some regions the cells respond equally well to the two opposite directions of movement of a line, but other regions contain a mixture of cells favouring one direction and cells favouring the other. 4. A horizontal organization corresponding to the cortical layering can also be discerned. The upper layers (II and the upper two-thirds of III) contain complex and hypercomplex cells, but simple cells are virtually absent. The cells are mostly binocularly driven. Simple cells are found deep in layer III, and in IV A and IV B. In layer IV B they form a large proportion of the population, whereas complex cells are rare. In layers IV A and IV B one finds units lacking orientation specificity; it is not clear whether these are cell bodies or axons of geniculate cells. In layer IV most cells are driven by one eye only; this layer consists of a mosaic with cells of some regions responding to one eye only, those of other regions responding to the other eye. Layers V and VI contain mostly complex and hypercomplex cells, binocularly driven. 5. The cortex is seen as a system organized vertically and horizontally in entirely different ways. In the vertical system (in which cells lying along a vertical line in the cortex have common features) stimulus dimensions such as retinal position, line orientation, ocular dominance, and perhaps directionality of movement, are mapped in sets of superimposed but independent mosaics. The horizontal system segregates cells in layers by hierarchical orders, the lowest orders (simple cells monocularly driven) located in and near layer IV, the higher orders in the upper and lower layers.',\n",
              "  'authors': ['D. H. Hubel ', ' T. N. Wiesel'],\n",
              "  'date': '1968',\n",
              "  'identifier': '2117731089',\n",
              "  'references': ['2116360511',\n",
              "   '1594551768',\n",
              "   '2103212315',\n",
              "   '2080276732',\n",
              "   '2257028141',\n",
              "   '1829900417',\n",
              "   '2253776861',\n",
              "   '2036453841',\n",
              "   '2037316494',\n",
              "   '2081360048'],\n",
              "  'title': 'Receptive fields and functional architecture of monkey striate cortex'},\n",
              " {'abstract': 'In this work, we present a novel approach to face recognition which considers both shape and texture information to represent face images. The face area is first divided into small regions from which Local Binary Pattern (LBP) histograms are extracted and concatenated into a single, spatially enhanced feature histogram efficiently representing the face image. The recognition is performed using a nearest neighbour classifier in the computed feature space with Chi square as a dissimilarity measure. Extensive experiments clearly show the superiority of the proposed scheme over all considered methods (PCA, Bayesian Intra/extrapersonal Classifier and Elastic Bunch Graph Matching) on FERET tests which include testing the robustness of the method against different facial expressions, lighting and aging of the subjects. In addition to its efficiency, the simplicity of the proposed method allows for very fast feature extraction.',\n",
              "  'authors': ['Timo Ahonen ', ' Abdenour Hadid ', ' Matti Pietikäinen'],\n",
              "  'date': '2004',\n",
              "  'identifier': '1545641654',\n",
              "  'references': ['2163352848',\n",
              "   '2138451337',\n",
              "   '1989702938',\n",
              "   '2033419168',\n",
              "   '2039051707',\n",
              "   '2120954940',\n",
              "   '1997011019',\n",
              "   '2131273085',\n",
              "   '2103560185',\n",
              "   '1598106187'],\n",
              "  'title': 'Face Recognition with Local Binary Patterns'},\n",
              " {'abstract': 'We study the common problem of approximating a target matrix with a matrix of lower rank. We provide a simple and efficient (EM) algorithm for solving weighted low-rank approximation problems, which, unlike their unweighted version, do not admit a closed-form solution in general. We analyze, in addition, the nature of locally optimal solutions that arise in this context, demonstrate the utility of accommodating the weights in reconstructing the underlying low-rank representation, and extend the formulation to non-Gaussian noise models such as logistic models. Finally, we apply the methods developed to a collaborative filtering task.',\n",
              "  'authors': ['Nathan Srebro ', ' Tommi Jaakkola'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2165395308',\n",
              "  'references': ['2117354486',\n",
              "   '1673941785',\n",
              "   '2170653751',\n",
              "   '2021680564',\n",
              "   '2135001774',\n",
              "   '1496451467',\n",
              "   '1516172206',\n",
              "   '1568698519',\n",
              "   '2139451327',\n",
              "   '2252194958'],\n",
              "  'title': 'Weighted low-rank approximations'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Martin Fishbein ', ' Icek Ajzen'],\n",
              "  'date': '1975',\n",
              "  'identifier': '2036389121',\n",
              "  'references': ['2100379340',\n",
              "   '2106096361',\n",
              "   '2099697766',\n",
              "   '1791587663',\n",
              "   '2168569455',\n",
              "   '2137247419',\n",
              "   '3041188046',\n",
              "   '2033943395',\n",
              "   '1574235309'],\n",
              "  'title': 'Belief, Attitude, Intention, and Behavior: An Introduction to Theory and Research'},\n",
              " {'abstract': 'Prevalence of the recently discovered GB virus C (GBV-C) was evaluated in a cohort of 49 Italian patients with acute or chronic hepatitis of unknown etiology (non-A-E hepatitis) and in a control group of 100 healthy blood donors. The GBV-C genomes could be detected by polymerase chain reaction (PCR) with reverse transcription in 35% of the acute and 39% of the chronic hepatitis patients ; only 1 of the control subjects had a positive response. All PCR products hybridized with a specific probe in a colorimetric assay, and the analysis of the sequences of the amplified cDNAs fully confirmed the specificity of the assay. Furthermore, the alignment of the predicted translation products identified two recurrent amino acid substitutions in 6 patients, suggesting the possible existence of at least 2 different GBV-C subtypes. Thus, GBV-C may be an important agent, contributing, at least in Italy, to a significant number of the cases of hepatitis of unknown etiology.',\n",
              "  'authors': ['Gianfranco Fiordalisi ',\n",
              "   ' Isabella Zanella ',\n",
              "   ' Giovanni Mantero ',\n",
              "   ' Alessandra Bettinardi ',\n",
              "   ' Roberto Stellini ',\n",
              "   ' Giuseppe Paraninfo ',\n",
              "   ' Gianpietro Cadeo ',\n",
              "   ' Daniele Primi'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2155517838',\n",
              "  'references': ['2094031081',\n",
              "   '2083266836',\n",
              "   '2328171401',\n",
              "   '2059372215',\n",
              "   '2132608906',\n",
              "   '1968566170',\n",
              "   '2010203103',\n",
              "   '2570729219',\n",
              "   '2054790792',\n",
              "   '2059725392'],\n",
              "  'title': 'High Prevalence of GB Virus C Infection in a Group of Italian Patients with Hepatitis of Unknown Etiology'},\n",
              " {'abstract': 'Evidence suggests that consumers often hesitate to transact with Web-based vendors because of uncertainty about vendor behavior or the perceived risk of having personal information stolen by hackers. Trust plays a central role in helping consumers overcome perceptions of risk and insecurity. Trust makes consumers comfortable sharing personal information, making purchases, and acting on Web vendor advice--behaviors essential to widespread adoption of e-commerce. Therefore, trust is critical to both researchers and practitioners. Prior research on e-commerce trust has used diverse, incomplete, and inconsistent definitions of trust, making it difficult to compare results across studies. This paper contributes by proposing and validating measures for a multidisciplinary, multidimensional model of trust in e-commerce. The model includes four high-level constructs--disposition to trust, institution-based trust, trusting beliefs, and trusting intentions--which are further delineated into 16 measurable, literature-grounded subconstructs. The psychometric properties of the measures are demonstrated through use of a hypothetical, legal advice Web site. The results show that trust is indeed a multidimensional concept. Proposed relationships among the trust constructs are tested (for internal nomological validity), as are relationships between the trust constructs and three other e-commerce constructs (for external nomological validity)--Web experience, personal innovativeness, and Web site quality. Suggestions for future research as well as implications for practice are discussed.',\n",
              "  'authors': ['D. Harrison McKnight 1',\n",
              "   ' Vivek Choudhury 2',\n",
              "   ' Charles Kacmar 3'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2110078189',\n",
              "  'references': ['1791587663',\n",
              "   '2168569455',\n",
              "   '2142175015',\n",
              "   '1992193527',\n",
              "   '2033943395',\n",
              "   '2122912498',\n",
              "   '1977775666',\n",
              "   '2130140239',\n",
              "   '2166982098',\n",
              "   '1994213885'],\n",
              "  'title': 'Developing and Validating Trust Measures for e-Commerce: An Integrative Typology'},\n",
              " {'abstract': 'We consider a logistic regression model with a Gaussian prior distribution over the parameters. We show that an accurate variational transformation can be used to obtain a closed form approximation to the posterior distribution of the parameters thereby yielding an approximate posterior predictive model. This approach is readily extended to binary graphical model with complete observations. For graphical models with incomplete observations we utilize an additional variational transformation and again obtain a closed form approximation to the posterior. Finally, we show that the dual of the regression problem gives a latent variable density model, the variational formulation of which leads to exactly solvable EM updates.',\n",
              "  'authors': ['Tommi S. Jaakkola 1', ' Michael I. Jordan 2'],\n",
              "  'date': '2000',\n",
              "  'identifier': '1496451467',\n",
              "  'references': ['2045656233',\n",
              "   '2130416410',\n",
              "   '1528905581',\n",
              "   '1516111018',\n",
              "   '2170112109',\n",
              "   '2082206048',\n",
              "   '2083380015',\n",
              "   '2331182131',\n",
              "   '1520448186',\n",
              "   '2047229728'],\n",
              "  'title': 'Bayesian parameter estimation via variational methods'},\n",
              " {'abstract': '',\n",
              "  'authors': ['M. J. Alter ',\n",
              "   ' H. S. Margolis ',\n",
              "   ' K. Krawczynski ',\n",
              "   ' F. N. Judson ',\n",
              "   ' A. Mares ',\n",
              "   ' W. J. Alexander ',\n",
              "   ' Y. H. Pin ',\n",
              "   ' J. K. Miller ',\n",
              "   ' M. A. Gerber ',\n",
              "   ' R. E. Sampliner ',\n",
              "   ' E. L. Meeks ',\n",
              "   ' M. J. Beach'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2570729219',\n",
              "  'references': ['2051126700',\n",
              "   '2029834382',\n",
              "   '2122043154',\n",
              "   '208665126',\n",
              "   '1674991100',\n",
              "   '2163575236',\n",
              "   '1612443964',\n",
              "   '2112190596',\n",
              "   '2109468737',\n",
              "   '2151278267'],\n",
              "  'title': 'The Natural History of Community-Acquired Hepatitis C in the United States'},\n",
              " {'abstract': \"During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book. This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression and path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for ``wide'' data (p bigger than n), including multiple testing and false discovery rates. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie co-developed much of the statistical modeling software and environment in R/S-PLUS and invented principal curves and surfaces. Tibshirani proposed the lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, projection pursuit and gradient boosting.\",\n",
              "  'authors': ['Trevor Hastie ', ' Robert J. Tibshirani ', ' Jerome Friedman'],\n",
              "  'date': '2005',\n",
              "  'identifier': '1554944419',\n",
              "  'references': ['2140190241',\n",
              "   '2164278908',\n",
              "   '2179438025',\n",
              "   '2122825543',\n",
              "   '2063978378',\n",
              "   '2131975293',\n",
              "   '2117756735',\n",
              "   '2087681821',\n",
              "   '2109574129'],\n",
              "  'title': 'The elements of statistical learning : data mining, inference,and prediction'},\n",
              " {'abstract': 'Torch7 is a versatile numeric computing framework and machine learning library that extends Lua. Its goal is to provide a flexible environment to design and train learning machines. Flexibility is obtained via Lua, an extremely lightweight scripting language. High performance is obtained via efficient OpenMP/SSE and CUDA implementations of low-level numeric routines. Torch7 can easily be interfaced to third-party software thanks to Lua’s light interface.',\n",
              "  'authors': ['Ronan Collobert 1',\n",
              "   ' Koray Kavukcuoglu 2',\n",
              "   ' Clément Farabet 2'],\n",
              "  'date': '2011',\n",
              "  'identifier': '753012316',\n",
              "  'references': ['2606594511'],\n",
              "  'title': 'Torch7: A Matlab-like Environment for Machine Learning'},\n",
              " {'abstract': 'Digital audio, video, images, and documents are flying through cyberspace to their respective owners. Unfortunately, along the way, individuals may choose to intervene and take this content for themselves. Digital watermarking and steganography technology greatly reduces the instances of this by limiting or eliminating the ability of third parties to decipher the content that he has taken. The many techiniques of digital watermarking (embedding a code) and steganography (hiding information) continue to evolve as applications that necessitate them do the same. The authors of this second edition provide an update on the framework for applying these techniques that they provided researchers and professionals in the first well-received edition. Steganography and steganalysis (the art of detecting hidden information) have been added to a robust treatment of digital watermarking, as many in each field research and deal with the other. New material includes watermarking with side information, QIM, and dirty-paper codes. The revision and inclusion of new material by these influential authors has created a must-own book for anyone in this profession. *This new edition now contains essential information on steganalysis and steganography *New concepts and new applications including QIM introduced *Digital watermark embedding is given a complete update with new processes and applications',\n",
              "  'authors': ['Ingemar Cox ',\n",
              "   ' Matthew Miller ',\n",
              "   ' Jeffrey Bloom ',\n",
              "   ' Jessica Fridrich ',\n",
              "   ' Ton Kalker'],\n",
              "  'date': '2007',\n",
              "  'identifier': '1524144700',\n",
              "  'references': ['2156909104',\n",
              "   '1971146923',\n",
              "   '2116467012',\n",
              "   '2159390040',\n",
              "   '1996360405',\n",
              "   '2124890704',\n",
              "   '2121393355',\n",
              "   '1525552993',\n",
              "   '2123977795',\n",
              "   '2117420234'],\n",
              "  'title': 'Digital Watermarking and Steganography'},\n",
              " {'abstract': 'Traditional econometric models assume a constant one-period forecast variance. To generalize this implausible assumption, a new class of stochastic processes called autoregressive conditional heteroscedastic (ARCH) processes are introduced in this paper. These are mean zero, serially uncorrelated processes with nonconstant variances conditional on the past, but constant unconditional variances. For such processes, the recent past gives information about the one-period forecast variance. A regression model is then introduced with disturbances following an ARCH process. Maximum likelihood estimators are described and a simple scoring iteration formulated. Ordinary least squares maintains its optimality properties in this set-up, but maximum likelihood is more efficient. The relative efficiency is calculated and can be infinite. To test whether the disturbances follow an ARCH process, the Lagrange multiplier procedure is employed. The test is based simply on the autocorrelation of the squared OLS residuals. This model is used to estimate the means and variances of inflation in the U.K. The ARCH effect is found to be significant and the estimated variances increase substantially during the chaotic seventies.',\n",
              "  'authors': ['Robert F. Engle'],\n",
              "  'date': '1982',\n",
              "  'identifier': '1979575715',\n",
              "  'references': ['2124758339',\n",
              "   '1999996900',\n",
              "   '2134752891',\n",
              "   '2798056406',\n",
              "   '1992105816',\n",
              "   '2117014758',\n",
              "   '1999814123',\n",
              "   '1586335931',\n",
              "   '2061160212',\n",
              "   '3125751739'],\n",
              "  'title': 'Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation'},\n",
              " {'abstract': 'An overview of current data gathering and analytical techniques for ACA (Author cocitation analysis) is presented. It focus primarily on a set of procedures that the research group at Drexel has found useful and discuss the range of choices possible at each step of the process. For illustration, and the results of clustering, mapping, and factor analyzing cocited authors from the subdiscipline of macroeconomics, 1972-1977. The bibliography lists more detailed presentations of the methods and fuller examples of their uses',\n",
              "  'authors': ['Katherine W. McCain'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2129936978',\n",
              "  'references': ['2270216281',\n",
              "   '2045108252',\n",
              "   '2109154616',\n",
              "   '2069078812',\n",
              "   '2963453445',\n",
              "   '2072897447',\n",
              "   '3125707221',\n",
              "   '2488172819'],\n",
              "  'title': 'Mapping authors in intellectual space: A technical overview'},\n",
              " {'abstract': 'Acute respiratory tract infections (ARIs) are leading causes of morbidity and, in developing countries, mortality in children. A multiplex reverse transcription-PCR (RT-PCR) assay was developed to allow in one test the detection of nine different microorganisms (enterovirus, influenza A and B viruses, respiratory syncytial virus [RSV], parainfluenzaviruses type 1 and type 3, adenovirus, Mycoplasma pneumoniae, and Chlamydia pneumoniae) that do not usually colonize the respiratory tracts of humans but, if present, must be assumed to be the cause of respiratory disease. Clinical samples from 1,118 children admitted to the Department of Pediatrics because of an ARI between November 1995 and April 1998 were used for a first clinical evaluation. Detection of one of the microorganisms included in the assay was achieved for 395 of 1,118 (35%) clinical samples, of which 37.5% were RSV, 20% were influenza A virus, 12.9% were adenovirus, 10.6% were enterovirus, 8.1% were M. pneumoniae, 4.3% were parainfluenzavirus type 3, 3.5% were parainfluenzavirus type 1, 2.8% were influenza B virus, and 0.2% were C. pneumoniae. Seasonal variations in the rates of detection of the different organisms were observed, as was expected from the literature. The levels of concordance with the data obtained by commercially available enzyme immunoassays were 95% for RSV and 98% for influenza A. The results show that the multiplex RT-PCR-enzyme-linked immunosorbent assay is a useful and rapid diagnostic tool for the management of children with ARI. Studies of the overall benefit of this method with regard to the use of antibiotics, the use of diagnostic procedures including additional microbiological tests, and hospitalization rate and duration are warranted.',\n",
              "  'authors': ['Britta Gröndahl ',\n",
              "   ' Wolfram Puppe ',\n",
              "   ' Andrea Hoppe ',\n",
              "   ' Inka Kühne ',\n",
              "   ' Josef A. I. Weigl ',\n",
              "   ' Heinz-Josef Schmitt'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1907972820',\n",
              "  'references': ['2144634347',\n",
              "   '2032118018',\n",
              "   '2989345970',\n",
              "   '2067476021',\n",
              "   '2163911337',\n",
              "   '1955020214',\n",
              "   '2584373698',\n",
              "   '1735834838',\n",
              "   '2120316065',\n",
              "   '1634669351'],\n",
              "  'title': 'Rapid Identification of Nine Microorganisms Causing Acute Respiratory Tract Infections by Single-Tube Multiplex Reverse Transcription-PCR: Feasibility Study'},\n",
              " {'abstract': 'Abstract Background/Aims: To investigate the possible role of HIV infection in the natural history of chronic parenterally-acquired hepatitis C. Methods: A multicenter cross-sectional study was performed in 547 patients with chronic parenterally-acquired hepatitis C with or without HIV infection (116 HIV-positive and 431 HIV-negative). Approximate duration of HCV infection was estimated in all patients included, and histologic diagnoses made at different time intervals following HVC infection were analyzed in both groups. Factors related to serum HCV-RNA levels were also investigated. Results: Histologic findings were similar in liver biopsies from both HIV-infected and noninfected patients. However, in the first 10 years, 13 out of 87 (14.9%) HIV-positive subjects developed cirrhosis, in comparison with 7 out of 272 (2.6%) in the HIV-negative group ( p p 0.001). Chronic active hepatitis (with and without cirrhosis) and long duration of HCV infection were significantly associated with higher HCV load p 500 cells/ml showed a lower HCV load than thos with p Conclusions: HIV infection modifies the natural history of chronic parenterally-acquired hepatitis C with an unusually rapid progression to cirrhosis. HIV-related immunodeficiency may be a determinant of higher hepatitis C viremia levels and more severe liver damage.',\n",
              "  'authors': ['Basilio Soto 1',\n",
              "   ' Armandó Sánchez-Quijano 1',\n",
              "   ' Luis Rodrigo 2',\n",
              "   ' Juan Angel del Olmo 3',\n",
              "   ' Manuel García-Bengoechea 4',\n",
              "   \" Jos'e Hernández-Quero 5\",\n",
              "   ' Concepción Rey 1',\n",
              "   ' María Antonia Abad 1',\n",
              "   ' Manuel Rodríguez 2',\n",
              "   ' María Sales Gilabert 3',\n",
              "   ' Francisco González 4',\n",
              "   ' P. Mirón 5',\n",
              "   ' Antonio Caruz 1',\n",
              "   ' Federico Relimpio 1',\n",
              "   ' Rafael Torronteras 1',\n",
              "   ' Manuel Leal 1',\n",
              "   ' Eduardo Lissen 1'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2051126700',\n",
              "  'references': ['2328171401',\n",
              "   '2319055243',\n",
              "   '2409827818',\n",
              "   '2437864828',\n",
              "   '1674991100',\n",
              "   '2338481731',\n",
              "   '7724156',\n",
              "   '2013638770',\n",
              "   '2082990787',\n",
              "   '3111865520'],\n",
              "  'title': 'Human immunodeficiency virus infection modified the natural history of chronic parenterally-acquired hepatitis C with an unusually rapid progression to cirrhosis'},\n",
              " {'abstract': 'Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant.',\n",
              "  'authors': ['Mitchell P. Marcus 1',\n",
              "   ' Mary Ann Marcinkiewicz 1',\n",
              "   ' Beatrice Santorini 2'],\n",
              "  'date': '1993',\n",
              "  'identifier': '1632114991',\n",
              "  'references': ['2099247782',\n",
              "   '1483126227',\n",
              "   '2439178139',\n",
              "   '2334801970',\n",
              "   '900993354',\n",
              "   '2110190189',\n",
              "   '2012837062',\n",
              "   '2121407024',\n",
              "   '2076526090',\n",
              "   '2034693287'],\n",
              "  'title': 'Building a large annotated corpus of English: the penn treebank'},\n",
              " {'abstract': 'Introduction. Survey of Existing Methods. The Kernel Method for Univariate Data. The Kernel Method for Multivariate Data. Three Important Methods. Density Estimation in Action.',\n",
              "  'authors': ['Bernard. W. Silverman'],\n",
              "  'date': '1986',\n",
              "  'identifier': '2129905273',\n",
              "  'references': [],\n",
              "  'title': 'Density estimation for statistics and data analysis'},\n",
              " {'abstract': \"Note: Includes bibliographical references, 3 appendixes and 2 indexes.- Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08\",\n",
              "  'authors': ['William H. Press ',\n",
              "   ' Saul A. Teukolsky ',\n",
              "   ' William T. Vetterling ',\n",
              "   ' Brian P. Flannery'],\n",
              "  'date': '1994',\n",
              "  'identifier': '2170120409',\n",
              "  'references': ['2249139299',\n",
              "   '1746819321',\n",
              "   '1595159159',\n",
              "   '2103546861',\n",
              "   '2132103241',\n",
              "   '2183707334',\n",
              "   '1976969221',\n",
              "   '1998674867',\n",
              "   '2047205370',\n",
              "   '2121016876'],\n",
              "  'title': 'Numerical recipes in C'},\n",
              " {'abstract': 'We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output. The deep belief network pre-training algorithm is a robust and often helpful way to initialize deep neural networks generatively that can aid in optimization and reduce generalization error. We illustrate the key components of our model, describe the procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects of various modeling choices on performance. Experiments on a challenging business search dataset demonstrate that CD-DNN-HMMs can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs, with an absolute sentence accuracy improvement of 5.8% and 9.2% (or relative error reduction of 16.0% and 23.2%) over the CD-GMM-HMMs trained using the minimum phone error rate (MPE) and maximum-likelihood (ML) criteria, respectively.',\n",
              "  'authors': ['G. E. Dahl 1', ' Dong Yu 2', ' Li Deng 2', ' A. Acero 2'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2147768505',\n",
              "  'references': ['2136922672',\n",
              "   '2100495367',\n",
              "   '2072128103',\n",
              "   '1533861849',\n",
              "   '2116064496',\n",
              "   '2546302380',\n",
              "   '2117130368',\n",
              "   '2025768430',\n",
              "   '1993882792',\n",
              "   '1498436455'],\n",
              "  'title': 'Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition'},\n",
              " {'abstract': 'One of the potent personalization technologies powering the adaptive web is collaborative filtering. Collaborative filtering (CF) is the process of filtering or evaluating items through the opinions of other people. CF technology brings together the opinions of large interconnected communities on the web, supporting filtering of substantial quantities of data. In this chapter we introduce the core concepts of collaborative filtering, its primary uses for users of the adaptive web, the theory and practice of CF algorithms, and design decisions regarding rating systems and acquisition of ratings. We also discuss how to evaluate CF systems, and the evolution of rich interaction interfaces. We close the chapter with discussions of the challenges of privacy particular to a CF recommendation service and important open research questions in the field.',\n",
              "  'authors': ['J. Ben Schafer 1',\n",
              "   ' Dan Frankowski 2',\n",
              "   ' Jon Herlocker 3',\n",
              "   ' Shilad Sen 2'],\n",
              "  'date': '2007',\n",
              "  'identifier': '2145360759',\n",
              "  'references': ['2171960770',\n",
              "   '2042281163',\n",
              "   '1971040550',\n",
              "   '2110325612',\n",
              "   '2147152072',\n",
              "   '2159094788',\n",
              "   '2155106456',\n",
              "   '2124591829',\n",
              "   '2085937320',\n",
              "   '1966553486'],\n",
              "  'title': 'Collaborative filtering recommender systems'},\n",
              " {'abstract': \"Computer systems cannot improve organizational performance if they aren't used. Unfortunately, resistance to end-user systems by managers and professionals is a widespread problem. To better predict, explain, and increase user acceptance, we need to better understand why people accept or reject computers. This research addresses the ability to predict peoples' computer acceptance from a measure of their intentions, and the ability to explain their intentions in terms of their attitudes, subjective norms, perceived usefulness, perceived ease of use, and related variables. In a longitudinal study of 107 users, intentions to use a specific system, measured after a one-hour introduction to the system, were correlated 0.35 with system use 14 weeks later. The intention-usage correlation was 0.63 at the end of this time period. Perceived usefulness strongly influenced peoples' intentions, explaining more than half of the variance in intentions at the end of 14 weeks. Perceived ease of use had a small but significant effect on intentions as well, although this effect subsided over time. Attitudes only partially mediated the effects of these beliefs on intentions. Subjective norms had no effect on intentions. These results suggest the possibility of simple but powerful models of the determinants of user acceptance, with practical value for evaluating systems and guiding managerial interventions aimed at reducing the problem of underutilized computer technology.\",\n",
              "  'authors': ['Fred D. Davis 1',\n",
              "   ' Richard P. Bagozzi 1',\n",
              "   ' Paul R. Warshaw 2'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2033943395',\n",
              "  'references': ['1491644571',\n",
              "   '1982210139',\n",
              "   '2036389121',\n",
              "   '2111230857',\n",
              "   '1557992034',\n",
              "   '112089985',\n",
              "   '3124865537',\n",
              "   '1972888601',\n",
              "   '2037021532',\n",
              "   '2177085946'],\n",
              "  'title': 'User Acceptance of Computer Technology: A Comparison of Two Theoretical Models'},\n",
              " {'abstract': 'Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method.',\n",
              "  'authors': ['Christian Ledig 1',\n",
              "   ' Lucas Theis 1',\n",
              "   ' Ferenc Huszar 2',\n",
              "   ' Jose Caballero 3',\n",
              "   ' Andrew Cunningham ',\n",
              "   ' Alejandro Acosta 4',\n",
              "   ' Andrew Aitken 2',\n",
              "   ' Alykhan Tejani 2',\n",
              "   ' Johannes Totz 2',\n",
              "   ' Zehan Wang 2',\n",
              "   ' Wenzhe Shi 2'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2963470893',\n",
              "  'references': ['2194775991',\n",
              "   '2618530766',\n",
              "   '2962835968',\n",
              "   '2964121744',\n",
              "   '2097117768',\n",
              "   '1836465849',\n",
              "   '2117539524',\n",
              "   '2099471712',\n",
              "   '1677182931',\n",
              "   '2133665775'],\n",
              "  'title': 'Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network'},\n",
              " {'abstract': 'Computational properties of use to biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.',\n",
              "  'authors': ['John J. Hopfield'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2293063825',\n",
              "  'references': ['1594524188', '2086789740', '2970228278', '2076870593'],\n",
              "  'title': 'Neural networks and physical systems with emergent collective computational abilities'},\n",
              " {'abstract': 'Action selection is a fundamental decision process for us, and depends on the state of both our body and the environment. Because signals in our sensory and motor systems are corrupted by variability or noise, the nervous system needs to estimate these states. To select an optimal action these state estimates need to be combined with knowledge of the potential costs or rewards of different action outcomes. We review recent studies that have investigated the mechanisms used by the nervous system to solve such estimation and decision problems, which show that human behaviour is close to that predicted by Bayesian Decision Theory. This theory defines optimal behaviour in a world characterized by uncertainty, and provides a coherent way of describing sensorimotor processes.',\n",
              "  'authors': ['Konrad P. Körding 1', ' Daniel M. Wolpert 2'],\n",
              "  'date': '2006',\n",
              "  'identifier': '2126880773',\n",
              "  'references': ['2165363188',\n",
              "   '2121863487',\n",
              "   '2133469585',\n",
              "   '1999874108',\n",
              "   '1969090956',\n",
              "   '3011865677',\n",
              "   '1980440818',\n",
              "   '1981578159',\n",
              "   '1956636948',\n",
              "   '2029776687'],\n",
              "  'title': 'Bayesian decision theory in sensorimotor control.'},\n",
              " {'abstract': 'The notion of stochastic lexicalized tree-adjoining grammar (SLTAG) is formally defined. The parameters of a SLTAG correspond to the probability of combining two structures each one associated with a word. The characteristics of SLTAG are unique and novel since it is lexieally sensitive (as N-gram models or Hidden Markov Models) and yet hierarchical (as stochastic context-free grammars).Then, two basic algorithms for SLTAG arc introduced: an algorithm for computing the probability of a sentence generated by a SLTAG and an inside-outside-like iterative algorithm for estimating the parameters of a SLTAG given a training corpus.Finally, we should how SLTAG enables to define a lexicalized version of stochastic context-free grammars and we report preliminary experiments showing some of the advantages of SLTAG over stochastic context-free grammars.',\n",
              "  'authors': ['Yves Schabes'],\n",
              "  'date': '1992',\n",
              "  'identifier': '1982944197',\n",
              "  'references': ['2439178139',\n",
              "   '1995875735',\n",
              "   '2077302143',\n",
              "   '1978470410',\n",
              "   '1541301615',\n",
              "   '2131986285',\n",
              "   '2047706513',\n",
              "   '2153198088',\n",
              "   '1526927911',\n",
              "   '1504046386'],\n",
              "  'title': 'Stochastic lexicalized tree-adjoining grammars'},\n",
              " {'abstract': 'Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities has made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overviewof pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval.',\n",
              "  'authors': ['A. K. Jain 1', ' M. N. Murty 2', ' P. J. Flynn 3'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1992419399',\n",
              "  'references': ['2912565176',\n",
              "   '1639032689',\n",
              "   '1497256448',\n",
              "   '2581275558',\n",
              "   '2152150600',\n",
              "   '2049633694',\n",
              "   '2133671888',\n",
              "   '1971784203',\n",
              "   '2095897464',\n",
              "   '1991848143'],\n",
              "  'title': 'Data clustering: a review'},\n",
              " {'abstract': '',\n",
              "  'authors': ['D. H. Hubel'],\n",
              "  'date': '1960',\n",
              "  'identifier': '2010554296',\n",
              "  'references': ['2104069712',\n",
              "   '3100777112',\n",
              "   '2116360511',\n",
              "   '2274452385',\n",
              "   '2091574658',\n",
              "   '2789919621',\n",
              "   '1850148372',\n",
              "   '1847297191',\n",
              "   '2010506656'],\n",
              "  'title': 'Single unit activity in lateral geniculate body and optic tract of unrestrained cats.'},\n",
              " {'abstract': 'A statistical framework is used for finding boundaries and for partitioning scenes into homogeneous regions. The model is a joint probability distribution for the array of pixel gray levels and an array of labels. In boundary finding, the labels are binary, zero, or one, representing the absence or presence of boundary elements. In partitioning, the label values are generic: two labels are the same when the corresponding scene locations are considered to belong to the same region. The distribution incorporates a measure of disparity between certain spatial features of block pairs of pixel gray levels, using the Kolmogorov-Smirnov nonparametric measures of difference between the distributions of these features. The number of model parameters is minimized by forbidding label configurations, which are assigned probability zero. The maximum a posteriori estimator of boundary placements and partitionings is examined. The forbidden states introduce constraints into the calculation of these configurations. Stochastic relaxation methods are extended to accommodate constrained optimization. >',\n",
              "  'authors': ['D. Geman 1', ' S. Geman 2', ' C. Graffigne 2', ' P. Dong 3'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2168962753',\n",
              "  'references': ['2581275558',\n",
              "   '1997063559',\n",
              "   '1554544485',\n",
              "   '2044465660',\n",
              "   '1531060698',\n",
              "   '2139762693',\n",
              "   '2154061444',\n",
              "   '2037139490',\n",
              "   '1989222601',\n",
              "   '2294259878'],\n",
              "  'title': 'Boundary detection by constrained optimization'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Yiming Yang ', ' Jan O. Pedersen'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2435251607',\n",
              "  'references': ['2118020653',\n",
              "   '2149684865',\n",
              "   '2150102617',\n",
              "   '2097089247',\n",
              "   '2167101736',\n",
              "   '2114535528',\n",
              "   '2103333826',\n",
              "   '2005422315',\n",
              "   '2052684427'],\n",
              "  'title': 'A Comparative Study on Feature Selection in Text Categorization'},\n",
              " {'abstract': 'This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images.',\n",
              "  'authors': ['K. Mikolajczyk ', ' C. Schmid'],\n",
              "  'date': '2002',\n",
              "  'identifier': '1676552347',\n",
              "  'references': ['2124386111',\n",
              "   '2124087378',\n",
              "   '2119747362',\n",
              "   '2109200236',\n",
              "   '2111308925',\n",
              "   '2165497495',\n",
              "   '1991605728',\n",
              "   '2112328181',\n",
              "   '2005433550',\n",
              "   '1970269179'],\n",
              "  'title': 'An Affine Invariant Interest Point Detector'},\n",
              " {'abstract': 'We aim to build image generation models that generalize to new domains from few examples. To this end, we first investigate the generalization properties of classic image generators, and discover that autoencoders generalize extremely well to new domains, even when trained on highly constrained data. We leverage this insight to produce a robust, unsupervised few-shot image generation algorithm, and introduce a novel training procedure based on recovering an image from data augmentations. Our Augmentation-Interpolative AutoEncoders synthesize realistic images of novel objects from only a few reference images, and outperform both prior interpolative models and supervised few-shot image generators. Our procedure is simple and lightweight, generalizes broadly, and requires no category labels or other supervision during training.',\n",
              "  'authors': ['Davis Wertheimer ', ' Omid Poursaeed ', ' Bharath Hariharan'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3108796939',\n",
              "  'references': ['2099471712',\n",
              "   '2183341477',\n",
              "   '1959608418',\n",
              "   '3118608800',\n",
              "   '2100495367',\n",
              "   '2310919327',\n",
              "   '2963684088',\n",
              "   '2962879692',\n",
              "   '2962760235',\n",
              "   '2963226019'],\n",
              "  'title': 'Augmentation-Interpolative AutoEncoders for Unsupervised Few-Shot Image Generation.'},\n",
              " {'abstract': 'Designing convolutional neural networks (CNN) for mobile devices is challenging because mobile models need to be small and fast, yet still accurate. Although significant efforts have been dedicated to design and improve mobile CNNs on all dimensions, it is very difficult to manually balance these trade-offs when there are so many architectural possibilities to consider. In this paper, we propose an automated mobile neural architecture search (MNAS) approach, which explicitly incorporate model latency into the main objective so that the search can identify a model that achieves a good trade-off between accuracy and latency. Unlike previous work, where latency is considered via another, often inaccurate proxy (e.g., FLOPS), our approach directly measures real-world inference latency by executing the model on mobile phones. To further strike the right balance between flexibility and search space size, we propose a novel factorized hierarchical search space that encourages layer diversity throughout the network. Experimental results show that our approach consistently outperforms state-of-the-art mobile CNN models across multiple vision tasks. On the ImageNet classification task, our MnasNet achieves 75.2% top-1 accuracy with 78ms latency on a Pixel phone, which is 1.8× faster than MobileNetV2 with 0.5% higher accuracy and 2.3× faster than NASNet with 1.2% higher accuracy. Our MnasNet also achieves better mAP quality than MobileNets for COCO object detection. Code is at https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet.',\n",
              "  'authors': ['Mingxing Tan ',\n",
              "   ' Bo Chen ',\n",
              "   ' Ruoming Pang ',\n",
              "   ' Vijay Vasudevan ',\n",
              "   ' Mark Sandler ',\n",
              "   ' Andrew Howard ',\n",
              "   ' Quoc V. Le'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2963918968',\n",
              "  'references': ['2194775991',\n",
              "   '1861492603',\n",
              "   '2963163009',\n",
              "   '2963420686',\n",
              "   '2964081807',\n",
              "   '2736601468',\n",
              "   '2963374479',\n",
              "   '2963125010',\n",
              "   '2810075754',\n",
              "   '2965658867'],\n",
              "  'title': 'MnasNet: Platform-Aware Neural Architecture Search for Mobile'},\n",
              " {'abstract': \"Rapid production and publication of pathogen genome sequences during emerging disease outbreaks provide crucial public health information. In resource-limited settings, especially near an outbreak epicenter, conventional deep sequencing or bioinformatics are often challenging. Here we successfully used metagenomic next generation sequencing on an iSeq100 Illumina platform paired with an open-source bioinformatics pipeline to quickly characterize Cambodia's first case of COVID-2019.\",\n",
              "  'authors': ['Jessica E Manning 1',\n",
              "   ' Jennifer A Bohl 1',\n",
              "   ' Sreyngim Lay 1',\n",
              "   ' Sophana Chea 1',\n",
              "   ' Ly Sovann 2',\n",
              "   ' Yi Sengdoeurn 2',\n",
              "   ' Seng Heng 2',\n",
              "   ' Chan Vuthy 2',\n",
              "   ' Katrina Kalantar 3',\n",
              "   ' Vida Ahyong 4',\n",
              "   ' Michelle Tan 4',\n",
              "   ' Jonathan Sheu 3',\n",
              "   ' Cristina M Tato 4',\n",
              "   ' Joseph L DeRisi 4',\n",
              "   ' Laurence Baril 5',\n",
              "   ' Veasna Duong 5',\n",
              "   ' Philippe Dussart 5',\n",
              "   ' Erik A Karlsson 5'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3009375872',\n",
              "  'references': ['3003668884',\n",
              "   '3004280078',\n",
              "   '3002533507',\n",
              "   '1975375203',\n",
              "   '3027518954',\n",
              "   '2898604559',\n",
              "   '2280128538',\n",
              "   '2999983020',\n",
              "   '2903618128'],\n",
              "  'title': 'Rapid metagenomic characterization of a case of imported COVID-19 in Cambodia.'},\n",
              " {'abstract': 'The computational power of massively parallel networks of simple processing elements resides in the communication bandwidth provided by the hardware connections between elements. These connections can allow a significant fraction of the knowledge of the system to be applied to an instance of a problem in a very short time. One kind of computation for which massively parallel networks appear to be well suited is large constraint satisfaction searches, but to use the connections efficiently two conditions must be met: First, a search technique that is suitable for parallel networks must be found. Second, there must be some way of choosing internal representations which allow the preexisting hardware connections to be used efficiently for encoding the constraints in the domain being searched. We describe a general parallel search method, based on statistical mechanics, and we show how it leads to a general learning rule for modifying the connection strengths so as to incorporate knowledge about a task domain in an efficient way. We describe some simple examples in which the learning algorithm creates internal representations that are demonstrably the most efficient way of using the preexisting connectivity structure.',\n",
              "  'authors': ['David H. Ackley 1',\n",
              "   ' Geoffrey E. Hinton 1',\n",
              "   ' Terrence J. Sejnowski 2'],\n",
              "  'date': '1988',\n",
              "  'identifier': '1507849272',\n",
              "  'references': ['2581275558',\n",
              "   '1997063559',\n",
              "   '2293063825',\n",
              "   '2112325651',\n",
              "   '2056760934',\n",
              "   '2157629899',\n",
              "   '2098205603',\n",
              "   '1597474747',\n",
              "   '2414854470',\n",
              "   '807785616'],\n",
              "  'title': 'A learning algorithm for Boltzmann machines'},\n",
              " {'abstract': 'The 2002-3 pandemic caused by severe acute respiratory syndrome coronavirus (SARS-CoV) was one of the most significant public health events in recent history. An ongoing outbreak of Middle East respiratory syndrome coronavirus suggests that this group of viruses remains a key threat and that their distribution is wider than previously recognized. Although bats have been suggested to be the natural reservoirs of both viruses, attempts to isolate the progenitor virus of SARS-CoV from bats have been unsuccessful. Diverse SARS-like coronaviruses (SL-CoVs) have now been reported from bats in China, Europe and Africa, but none is considered a direct progenitor of SARS-CoV because of their phylogenetic disparity from this virus and the inability of their spike proteins to use the SARS-CoV cellular receptor molecule, the human angiotensin converting enzyme II (ACE2). Here we report whole-genome sequences of two novel bat coronaviruses from Chinese horseshoe bats (family: Rhinolophidae) in Yunnan, China: RsSHC014 and Rs3367. These viruses are far more closely related to SARS-CoV than any previously identified bat coronaviruses, particularly in the receptor binding domain of the spike protein. Most importantly, we report the first recorded isolation of a live SL-CoV (bat SL-CoV-WIV1) from bat faecal samples in Vero E6 cells, which has typical coronavirus morphology, 99.9% sequence identity to Rs3367 and uses ACE2 from humans, civets and Chinese horseshoe bats for cell entry. Preliminary in vitro testing indicates that WIV1 also has a broad species tropism. Our results provide the strongest evidence to date that Chinese horseshoe bats are natural reservoirs of SARS-CoV, and that intermediate hosts may not be necessary for direct human infection by some bat SL-CoVs. They also highlight the importance of pathogen-discovery programs targeting high-risk wildlife groups in emerging disease hotspots as a strategy for pandemic preparedness.',\n",
              "  'authors': ['Xing Yi Ge 1',\n",
              "   ' Jia Lu Li 1',\n",
              "   ' Xing Lou Yang 1',\n",
              "   ' Aleksei A. Chmura 2',\n",
              "   ' Guangjian Zhu 2',\n",
              "   ' Jonathan H. Epstein 2',\n",
              "   ' Jonna A Mazet 3',\n",
              "   ' Ben Hu 1',\n",
              "   ' Wei Zhang 1',\n",
              "   ' Cheng Peng 1',\n",
              "   ' Yu Ji Zhang 1',\n",
              "   ' Chu Ming Luo 1',\n",
              "   ' Bing Tan 1',\n",
              "   ' Ning Wang 1',\n",
              "   ' Yan Zhu 1',\n",
              "   ' Gary Crameri 4',\n",
              "   ' Shu Yi Zhang 5',\n",
              "   ' Lin Fa Wang 4',\n",
              "   ' 6',\n",
              "   ' Peter Daszak 2',\n",
              "   ' Zheng Li Shi 1'],\n",
              "  'date': '2013',\n",
              "  'identifier': '1993577573',\n",
              "  'references': ['2166867592',\n",
              "   '2104548316',\n",
              "   '2119111857',\n",
              "   '1966238900',\n",
              "   '2103503670',\n",
              "   '2141008678',\n",
              "   '2140338292',\n",
              "   '2049975503',\n",
              "   '2101063972',\n",
              "   '1990059132'],\n",
              "  'title': 'Isolation and characterization of a bat SARS-like coronavirus that uses the ACE2 receptor'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Vikas Verma 1',\n",
              "   ' Alex Lamb 2',\n",
              "   ' Juho Kannala 1',\n",
              "   ' Yoshua Bengio 2',\n",
              "   ' David Lopez-Paz 3'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2966415767',\n",
              "  'references': ['3035160371',\n",
              "   '2970902013',\n",
              "   '2987875759',\n",
              "   '3099570996',\n",
              "   '3125645205',\n",
              "   '3035687950',\n",
              "   '3092206109',\n",
              "   '2996501936'],\n",
              "  'title': 'Interpolation Consistency Training for Semi-supervised Learning'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Rudra P. Singh ', ' Jolanta Kurz ', ' Gilles Boiteau'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2010585539',\n",
              "  'references': ['2090738619',\n",
              "   '2026996973',\n",
              "   '2141987735',\n",
              "   '2007499410',\n",
              "   '2064546869',\n",
              "   '2135985984',\n",
              "   '2106747769',\n",
              "   '2097446992',\n",
              "   '2043066204',\n",
              "   '2124801504'],\n",
              "  'title': 'J. Virol. Methods: Corrigendum to “Detection of stylet-borne and circulative potato viruses in aphids by duplex reverse transcription polymerase chain reaction” [59 (1996) 189]'},\n",
              " {'abstract': 'The problem of determining necessary conditions and sufficient conditions for a relative minimum of a function \\\\( f({x_1},{x_2},....,{x_n})\\\\) in the class of points \\\\( x = ({x_1},{x_2},....,{x_n})\\\\) Satisfying the equations \\\\( \\\\rm {g_{\\\\alpha}(X)= 0 (\\\\alpha = 1, 2,....,m),} \\\\) where the functions f and gα have continuous derivatives of at least the second order, has been satisfactorily treated [1]*. This paper proposes to take up the corresponding problem in the class of points x satisfying the inequalities \\\\( \\\\begin{array}{clcclclclcl}\\\\rm {g_{\\\\alpha}(x)\\\\geqq 0} & & & & & & \\\\rm{\\\\alpha = 1,2,...,m}\\\\end{array} \\\\) where m may be less than, equal to, or greater than n.',\n",
              "  'authors': ['William Karush'],\n",
              "  'date': '2014',\n",
              "  'identifier': '100063776',\n",
              "  'references': ['226617160'],\n",
              "  'title': 'Minima of Functions of Several Variables with Inequalities as Side Conditions'},\n",
              " {'abstract': 'We describe a model of object recognition as machine translation. In this model, recognition is a process of annotating image regions with words. Firstly, images are segmented into regions, which are classified into region types using a variety of features. A mapping between region types and keywords supplied with the images, is then learned, using a method based around EM. This process is analogous with learning a lexicon from an aligned bitext. For the implementation we describe, these words are nouns taken from a large vocabulary. On a large test set, the method can predict numerous words with high accuracy. Simple methods identify words that cannot be predicted well. We show how to cluster words that individually are difficult to predict into clusters that can be predicted well -- for example, we cannot predict the distinction between train and locomotive using the current set of features, but we can predict the underlying concept. The method is trained on a substantial collection of images. Extensive experimental results illustrate the strengths and weaknesses of the approach.',\n",
              "  'authors': ['P. Duygulu 1',\n",
              "   ' Kobus Barnard 1',\n",
              "   ' J. F. G. de Freitas 2',\n",
              "   ' David A. Forsyth 1'],\n",
              "  'date': '2002',\n",
              "  'identifier': '1666447063',\n",
              "  'references': ['2121947440',\n",
              "   '1574901103',\n",
              "   '1508960934',\n",
              "   '2006969979',\n",
              "   '1579838312',\n",
              "   '1934863104',\n",
              "   '2129765547',\n",
              "   '2293605478',\n",
              "   '1540386283',\n",
              "   '1585814348'],\n",
              "  'title': 'Object Recognition as Machine Translation: Learning a Lexicon for a Fixed Image Vocabulary'},\n",
              " {'abstract': 'This paper presents an overview of the field of recommender systems and describes the current generation of recommendation methods that are usually classified into the following three main categories: content-based, collaborative, and hybrid recommendation approaches. This paper also describes various limitations of current recommendation methods and discusses possible extensions that can improve recommendation capabilities and make recommender systems applicable to an even broader range of applications. These extensions include, among others, an improvement of understanding of users and items, incorporation of the contextual information into the recommendation process, support for multicriteria ratings, and a provision of more flexible and less intrusive types of recommendations.',\n",
              "  'authors': ['G. Adomavicius 1', ' A. Tuzhilin 2'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2171960770',\n",
              "  'references': ['1660390307',\n",
              "   '2042281163',\n",
              "   '1971040550',\n",
              "   '2110325612',\n",
              "   '2159094788',\n",
              "   '2155106456',\n",
              "   '2124591829',\n",
              "   '2085937320',\n",
              "   '1966553486',\n",
              "   '1999047234'],\n",
              "  'title': 'Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions'},\n",
              " {'abstract': \"Summary Background An epidemic of severe acute respiratory syndrome (SARS) has been associated with an outbreak of atypical pneumonia originating in Guangdong Province, People's Republic of China. We aimed to identify the causative agent in the Guangdong outbreak and describe the emergence and spread of the disease within the province. Methods We analysed epidemiological information and collected serum and nasopharyngeal aspirates from patients with SARS in Guangdong in mid-February, 2003. We did virus isolation, serological tests, and molecular assays to identify the causative agent. Findings SARS had been circulating in other cities of Guangdong Province for about 2 months before causing a major outbreak in Guangzhou, the province's capital. A novel coronavirus, SARS coronavirus (CoV), was isolated from specimens from three patients with SARS. Viral antigens were also directly detected in nasopharyngeal aspirates from these patients. 48 of 55 (87%) patients had antibodies to SARS CoV in their convalescent sera. Genetic analysis showed that the SARS CoV isolates from Guangzhou shared the same origin with those in other countries, and had a phylogenetic pathway that matched the spread of SARS to the other parts of the world. Interpretation SARS CoV is the infectious agent responsible for the epidemic outbreak of SARS in Guangdong. The virus isolated from patients in Guangdong is the prototype of the SARS CoV in other regions and countries.\",\n",
              "  'authors': ['N. S. Zhong 1',\n",
              "   ' B. J. Zheng 2',\n",
              "   ' Y. M. Li 1',\n",
              "   ' L. L. M. Poon 2',\n",
              "   ' Z. H. Xie 1',\n",
              "   ' K. H. Chan 2',\n",
              "   ' P. H. H. Li 2',\n",
              "   ' S. Y. Tan 3',\n",
              "   ' Q. Chang 1',\n",
              "   ' J. P. Xie 4',\n",
              "   ' X. Q. Liu 1',\n",
              "   ' J. Xu 1',\n",
              "   ' D. X. Li 3',\n",
              "   ' K. Y. Yuen 2',\n",
              "   ' J. S. M. Peiris 2',\n",
              "   ' Y. Guan 2'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2141877163',\n",
              "  'references': ['2104548316',\n",
              "   '2025170735',\n",
              "   '2131262274',\n",
              "   '2156434383',\n",
              "   '2100820722',\n",
              "   '2125251240',\n",
              "   '2169198329',\n",
              "   '2463755683',\n",
              "   '2163960578',\n",
              "   '2131155472'],\n",
              "  'title': \"Epidemiology and cause of severe acute respiratory syndrome (SARS) in Guangdong, People's Republic of China, in February, 2003\"},\n",
              " {'abstract': '',\n",
              "  'authors': ['Stephen Grossberg'],\n",
              "  'date': '1980',\n",
              "  'identifier': '2094688616',\n",
              "  'references': ['3017143921',\n",
              "   '1641311894',\n",
              "   '1990451873',\n",
              "   '2157904933',\n",
              "   '2204004159',\n",
              "   '2045385178',\n",
              "   '160989634',\n",
              "   '2113449040',\n",
              "   '1878893887',\n",
              "   '2076205488'],\n",
              "  'title': 'How does a brain build a cognitive code'},\n",
              " {'abstract': \"Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.\",\n",
              "  'authors': ['Sepp Hochreiter 1', ' Jürgen Schmidhuber 2'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2064675550',\n",
              "  'references': ['2107878631',\n",
              "   '2128499899',\n",
              "   '2007431958',\n",
              "   '2123716044',\n",
              "   '2154890045',\n",
              "   '2143503258',\n",
              "   '194249466',\n",
              "   '2048060899',\n",
              "   '2103452139',\n",
              "   '1674799117'],\n",
              "  'title': 'Long short-term memory'},\n",
              " {'abstract': \"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.\",\n",
              "  'authors': ['R.S. Sutton ', ' A.G. Barto'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2121863487',\n",
              "  'references': ['1639032689',\n",
              "   '2154642048',\n",
              "   '3017143921',\n",
              "   '2100677568',\n",
              "   '1535810436',\n",
              "   '1603765807',\n",
              "   '3011120880',\n",
              "   '1569320505',\n",
              "   '94523489',\n",
              "   '1540723801'],\n",
              "  'title': 'Reinforcement Learning: An Introduction'},\n",
              " {'abstract': 'The second edition of this acclaimed graduate text provides a unified treatment of two methods used in contemporary econometric research, cross section and data panel methods. By focusing on assumptions that can be given behavioral content, the book maintains an appropriate level of rigor while emphasizing intuitive thinking. The analysis covers both linear and nonlinear models, including models with dynamics and/or individual heterogeneity. In addition to general estimation frameworks (particular methods of moments and maximum likelihood), specific linear and nonlinear methods are covered in detail, including probit and logit models and their multivariate, Tobit models, models for count data, censored and missing data schemes, causal (or treatment) effects, and duration analysis. Econometric Analysis of Cross Section and Panel Data was the first graduate econometrics text to focus on microeconomic data structures, allowing assumptions to be separated into population and sampling assumptions. This second edition has been substantially updated and revised. Improvements include a broader class of models for missing data problems; more detailed treatment of cluster problems, an important topic for empirical researchers; expanded discussion of \"generalized instrumental variables\" (GIV) estimation; new coverage (based on the author\\'s own recent research) of inverse probability weighting; a more complete framework for estimating treatment effects with panel data, and a firmly established link between econometric approaches to nonlinear panel data and the \"generalized estimating equation\" literature popular in statistics and other fields. New attention is given to explaining when particular econometric methods can be applied; the goal is not only to tell readers what does work, but why certain \"obvious\" procedures do not. The numerous included exercises, both theoretical and computer-based, allow the reader to extend methods covered in the text and discover new insights.',\n",
              "  'authors': ['Jeffrey M. Wooldridge'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2124758339',\n",
              "  'references': ['2044503966',\n",
              "   '2025610165',\n",
              "   '2144357229',\n",
              "   '1973628995',\n",
              "   '2108818539',\n",
              "   '2796700885',\n",
              "   '2150291618',\n",
              "   '2098910318',\n",
              "   '1580788756',\n",
              "   '1979575715'],\n",
              "  'title': 'Econometric Analysis of Cross Section and Panel Data'},\n",
              " {'abstract': '',\n",
              "  'authors': ['George W. Snedecor'],\n",
              "  'date': '1967',\n",
              "  'identifier': '2798643531',\n",
              "  'references': ['2101508556',\n",
              "   '2168261002',\n",
              "   '2049633694',\n",
              "   '2008869160',\n",
              "   '2155163959',\n",
              "   '1992825118',\n",
              "   '2150291618',\n",
              "   '2109868644',\n",
              "   '2182722412',\n",
              "   '2013583119'],\n",
              "  'title': 'Statistical methods'},\n",
              " {'abstract': 'A relaxation process is described and is applied to the detection of smooth lines and curves in noisy, real world images. There are nine labels associated with each image point, eight labels indicating line segments at various orientations and one indicating the no-line case. Attached to each label is a probability. In the relaxation process, interaction takes place among the probabilities at neighboring points. This permits line segments in compatible orientations to strengthen one another, and incompatible segments to weaken one another. Similarly, no-line labels are reinforced by neighboring no-line labels and weakened by appropriately oriented line labels. This process converges, in only a few iterations, to a condition in which points lying on long curves have achieved high line probabilities, while other points have high no-line probabilities, There is some tendency, under this process, for curves to thicken; however, a thinning procedure can be incorporated to counteract this. The process is effective even for curves of low contrast, and even when many curves lie close to one another.',\n",
              "  'authors': ['Zucker ', ' Hummel ', ' Rosenfeld'],\n",
              "  'date': '1977',\n",
              "  'identifier': '1736170383',\n",
              "  'references': ['1968245656',\n",
              "   '1979622972',\n",
              "   '1597474747',\n",
              "   '2133138342',\n",
              "   '2140753314',\n",
              "   '38255799',\n",
              "   '2166950106',\n",
              "   '2081294768',\n",
              "   '2018383502',\n",
              "   '2011084398'],\n",
              "  'title': 'An Application of Relaxation Labeling to Line and Curve Enhancement'},\n",
              " {'abstract': 'Recommender systems have been evaluated in many, often incomparable, ways. In this article, we review the key decisions in evaluating collaborative filtering recommender systems: the user tasks being evaluated, the types of analysis and datasets being used, the ways in which prediction quality is measured, the evaluation of prediction attributes other than quality, and the user-based evaluation of the system as a whole. In addition to reviewing the evaluation strategies used by prior researchers, we present empirical results from the analysis of various accuracy metrics on one content domain where all the tested metrics collapsed roughly into three equivalence classes. Metrics within each equivalency class were strongly correlated, while metrics from different equivalency classes were uncorrelated.',\n",
              "  'authors': ['Jonathan L. Herlocker 1',\n",
              "   ' Joseph A. Konstan 2',\n",
              "   ' Loren G. Terveen 2',\n",
              "   ' John T. Riedl 2'],\n",
              "  'date': '2004',\n",
              "  'identifier': '1971040550',\n",
              "  'references': ['1660390307',\n",
              "   '2042281163',\n",
              "   '2110325612',\n",
              "   '2342091124',\n",
              "   '2155106456',\n",
              "   '2124591829',\n",
              "   '2085937320',\n",
              "   '1966553486',\n",
              "   '2341865734',\n",
              "   '1999047234'],\n",
              "  'title': 'Evaluating collaborative filtering recommender systems'},\n",
              " {'abstract': 'A large number of studies have been conducted during the last decade and a half attempting to identify those factors that contribute to information systems success. However, the dependent variable in these studies-I/S success-has been an elusive one to define. Different researchers have addressed different aspects of success, making comparisons difficult and the prospect of building a cumulative tradition for I/S research similarly elusive. To organize this diverse research, as well as to present a more integrated view of the concept of I/S success, a comprehensive taxonomy is introduced. This taxonomy posits six major dimensions or categories of I/S success-SYSTEM QUALITY, INFORMATION QUALITY, USE, USER SATISFACTION, INDIVIDUAL IMPACT, and ORGANIZATIONAL IMPACT. Using these dimensions, both conceptual and empirical studies are then reviewed a total of 180 articles are cited and organized according to the dimensions of the taxonomy. Finally, the many aspects of I/S success are drawn together into a descriptive model and its implications for future I/S research are discussed.',\n",
              "  'authors': ['William H. DeLone 1', ' Ephraim R. McLean 2'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2057012437',\n",
              "  'references': ['2136451344',\n",
              "   '2098118776',\n",
              "   '1721421031',\n",
              "   '2112042732',\n",
              "   '2114652055',\n",
              "   '1987198869',\n",
              "   '2142801253',\n",
              "   '1567491469',\n",
              "   '2111628838',\n",
              "   '2151020819'],\n",
              "  'title': 'Information Systems Success: The Quest for the Dependent Variable'},\n",
              " {'abstract': '',\n",
              "  'authors': ['R. Duncan Luce'],\n",
              "  'date': '1959',\n",
              "  'identifier': '2319178748',\n",
              "  'references': ['2152081677',\n",
              "   '1973435495',\n",
              "   '2108862644',\n",
              "   '3125353710',\n",
              "   '2143841415',\n",
              "   '1564229172',\n",
              "   '2083833236',\n",
              "   '2155488171'],\n",
              "  'title': 'Individual Choice Behavior'},\n",
              " {'abstract': 'The traditional method for assessing the severity of influenza seasons is to estimate the associated increase (i.e., excess) in pneumonia and influenza (PI however, the average seasonal risk for influenza-related P&I hospitalizations was much higher in the elderly than in persons aged <65 years. The 26 pairs of excess P&I hospitalization and mortality rates were linearly correlated. During the A(H3N2) influenza seasons after the 1968 pandemic, excess P&I hospitalizations declined among persons aged <65 years but not among the elderly. This suggests that influenza-related hospitalizations will increase disproportionately among younger persons in future pandemics.',\n",
              "  'authors': ['Lone Simonsen ',\n",
              "   ' Keiji Fukuda ',\n",
              "   ' Lawrence B. Schonberger ',\n",
              "   ' Nancy J. Cox'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2122034291',\n",
              "  'references': ['2081797984',\n",
              "   '2138064535',\n",
              "   '2024774441',\n",
              "   '1986797238',\n",
              "   '2122344713',\n",
              "   '191335643',\n",
              "   '1974047133',\n",
              "   '1956161579',\n",
              "   '2035672404',\n",
              "   '627446277'],\n",
              "  'title': 'The Impact of Influenza Epidemics on Hospitalizations'},\n",
              " {'abstract': 'Realism and Instrumentalism: Classical Statistics and VC Theory (1960-1980).- Falsifiability and Parsimony: VC Dimension and the Number of Entities (1980-2000).- Noninductive Methods of Inference: Direct Inference Instead of Generalization (2000-...).- The Big Picture.',\n",
              "  'authors': ['Vladimir Naumovich Vapnik'],\n",
              "  'date': '2006',\n",
              "  'identifier': '1530699444',\n",
              "  'references': ['2137775453',\n",
              "   '2139212933',\n",
              "   '2119821739',\n",
              "   '1988790447',\n",
              "   '2119479037',\n",
              "   '1964357740',\n",
              "   '2132549764',\n",
              "   '2087347434',\n",
              "   '607505555',\n",
              "   '1975846642'],\n",
              "  'title': 'Estimation of Dependences Based on Empirical Data'},\n",
              " {'abstract': '',\n",
              "  'authors': ['T. Tsang ',\n",
              "   ' L. Pak-Yin ',\n",
              "   ' M. Lee ',\n",
              "   ' J.-S. Wu ',\n",
              "   ' Y.-C. Wu ',\n",
              "   ' I.-H. Chiang ',\n",
              "   ' K.-T. Chen ',\n",
              "   ' K.-H. Hsu ',\n",
              "   ' T.-J. Chen ',\n",
              "   ' H.-T. Lee ',\n",
              "   ' S.-J. Twu ',\n",
              "   ' S. Chunsuttiwat ',\n",
              "   ' P. Sawanpanyalert ',\n",
              "   ' K. Ungchusak ',\n",
              "   ' A. Chaovavanich'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2463755683',\n",
              "  'references': ['2089784797'],\n",
              "  'title': 'Update: Outbreak of severe acute respiratory syndrome - Worldwide, 2003'},\n",
              " {'abstract': \"Breiman's bagging and Freund and Schapire's boosting are recent methods for improving the predictive power of classifier learning systems. Both form a set of classifiers that are combined by voting, bagging by generating replicated bootstrap samples of the data, and boosting by adjusting the weights of training instances. This paper reports results of applying both techniques to a system that learns decision trees and testing on a representative collection of datasets. While both approaches substantially improve predictive accuracy, boosting shows the greater benefit. On the other hand, boosting also produces severe degradation on some datasets. A small change to the way that boosting combines the votes of learned classifiers reduces this downside and also leads to slightly better results on most of the datasets considered.\",\n",
              "  'authors': ['J. R. Quinlan'],\n",
              "  'date': '1996',\n",
              "  'identifier': '1966280301',\n",
              "  'references': ['1988790447',\n",
              "   '2912934387',\n",
              "   '3085162807',\n",
              "   '2112076978',\n",
              "   '1676820704',\n",
              "   '1530699444',\n",
              "   '2134696506',\n",
              "   '1567276288',\n",
              "   '1539741229',\n",
              "   '1510806966'],\n",
              "  'title': 'Bagging, boosting, and C4.S'},\n",
              " {'abstract': 'In this final installment of the paper we consider the case where the signals or the messages or both are continuously variable, in contrast with the discrete nature assumed until now. To a considerable extent the continuous case can be obtained through a limiting process from the discrete case by dividing the continuum of messages and signals into a large but finite number of small regions and calculating the various parameters involved on a discrete basis. As the size of the regions is decreased these parameters in general approach as limits the proper values for the continuous case. There are, however, a few new effects that appear and also a general change of emphasis in the direction of specialization of the general results to particular cases.',\n",
              "  'authors': ['C. E. Shannon'],\n",
              "  'date': '1948',\n",
              "  'identifier': '1995875735',\n",
              "  'references': ['2054692642',\n",
              "   '2076063813',\n",
              "   '1660562555',\n",
              "   '2150498905',\n",
              "   '1964357740',\n",
              "   '2165363188',\n",
              "   '2106006415',\n",
              "   '2106864314',\n",
              "   '2790166049'],\n",
              "  'title': 'A mathematical theory of communication'},\n",
              " {'abstract': \"This paper discusses how local measurements of three-dimensional positions and surface normals (recorded by a set of tactile sensors, or by three-dimensional range sensors), may be used to identify and locate objects from among a set of known objects. The objects are modeled as polyhedra having up to six degrees of freedom relative to the sensors. We show that inconsistent hypotheses about pairings between sensed points and object surfaces can be discarded efficiently by using local constraints on distances between faces, angles between face normals, and angles (relative to the surface normals) of vectors between sensed points. We show by simulation and by mathematical bounds that the number of hypotheses consistent with these constraints is small We also show how to recover the position and orientation of the object from the sensory data. The algorithm's performance on data obtained from a triangulation range sensor is illustrated.\",\n",
              "  'authors': ['W. Eric ', ' L. Grimson ', ' Tomas Lozano-Perez'],\n",
              "  'date': '1987',\n",
              "  'identifier': '1532977286',\n",
              "  'references': ['2150500908',\n",
              "   '2130755868',\n",
              "   '2002882922',\n",
              "   '2169339783',\n",
              "   '121511052',\n",
              "   '1978578701',\n",
              "   '2022140147',\n",
              "   '1713915947',\n",
              "   '2008476021',\n",
              "   '2042463931'],\n",
              "  'title': 'Model-based recognition and localization from sparse range or tactile data'},\n",
              " {'abstract': 'To compute reliable dense depth maps, a stereo algorithm must preserve depth discontinuities and avoid gross errors. In this paper, we show how simple and parallel techniques can be combined to achieve this goal and deal with complex real world scenes. Our algorithm relies on correlation followed by interpolation. During the correlation phase the two images play a symmetric role and we use a validity criterion for the matches that eliminate gross errors: at places where the images cannot be correlated reliably, due to lack of texture of occlusions for example, the algorithm does not produce wrong matches but a very sparse disparity map as opposed to a dense one when the correlation is successful. To generate a dense depth map, the information is then propagated across the featureless areas, but not across discontinuities, by an interpolation scheme that takes image grey levels into account to preserve image features. We show that our algorithm performs very well on difficult images such as faces and cluttered ground level scenes. Because all the algorithms described here are parallel and very regular they could be implemented in hardware and lead to extremely fast stereo systems.',\n",
              "  'authors': ['Pascal Fua'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2090949637',\n",
              "  'references': ['2150134853',\n",
              "   '2740373864',\n",
              "   '2913192828',\n",
              "   '1531060698',\n",
              "   '2054536235',\n",
              "   '2130657708',\n",
              "   '2296589133',\n",
              "   '2159979951',\n",
              "   '2003945700',\n",
              "   '2474958793'],\n",
              "  'title': 'A Parallel Stereo Algorithm that Produces Dense Depth Maps and Preserves Image Features'},\n",
              " {'abstract': 'We address the question of when a network can be expected to generalize from m random training examples chosen from some arbitrary probability distribution, assuming that future test examples are drawn from the same distribution. Among our results are the following bounds on appropriate sample vs. network size. Assume 0 < e ≤ 1/8. We show that if m ≥ O(W/e log N/e) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 - e/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 1 - e of future test examples drawn from the same distribution. Conversely, for fully-connected feedforward nets with one hidden layer, any learning algorithm using fewer than Ω(W/e) random training examples will, for some distributions of examples consistent with an appropriate weight choice, fail at least some fixed fraction of the time to find a weight choice that will correctly classify more than a 1 - e fraction of the future test examples.',\n",
              "  'authors': ['Eric B. Baum 1', ' David Haussler 2'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2165758113',\n",
              "  'references': ['2147800946',\n",
              "   '3017143921',\n",
              "   '1530699444',\n",
              "   '2019363670',\n",
              "   '3036751298',\n",
              "   '2176028050',\n",
              "   '2154952480',\n",
              "   '2129113961',\n",
              "   '2010029425',\n",
              "   '2020246210'],\n",
              "  'title': 'What Size Net Gives Valid Generalization'},\n",
              " {'abstract': 'Summary Background We investigated the temporal progression of the clinical, radiological, and virological changes in a community outbreak of severe acute respiratory syndrome (SARS). Methods We followed up 75 patients for 3 weeks managed with a standard treatment protocol of ribavirin and corticosteroids, and assessed the pattern of clinical disease, viral load, risk factors for poor clinical outcome, and the usefulness of virological diagnostic methods. Findings Fever and pneumonia initially improved but 64 (85%) patients developed recurrent fever after a mean of 8·9 (SD 3·1) days, 55 (73%) had watery diarrhoea after 7·5 (2·3) days, 60 (80%) had radiological worsening after 7·4 (2·2) days, and respiratory symptoms worsened in 34 (45%) after 8·6 (3·0) days. In 34 (45%) patients, improvement of initial pulmonary lesions was associated with appearance of new radiological lesions at other sites. Nine (12%) patients developed spontaneous pneumomediastinum and 15 (20%) developed acute respiratory distress syndrome (ARDS) in week 3. Quantitative reverse-transcriptase (RT) PCR of nasopharyngeal aspirates in 14 patients (four with ARDS) showed peak viral load at day 10, and at day 15 a load lower than at admission. Age and chronic hepatitis B virus infection treated with lamivudine were independent significant risk factors for progression to ARDS (p=0·001). SARS-associated coronavirus in faeces was seen on RT-PCR in 65 (97%) of 67 patients at day 14. The mean time to seroconversion was 20 days. Interpretation The consistent clinical progression, shifting radiological infiltrates, and an inverted V viral-load profile suggest that worsening in week 2 is unrelated to uncontrolled viral replication but may be related to immunopathological damage.',\n",
              "  'authors': ['J S M Peiris 1',\n",
              "   ' C M Chu 2',\n",
              "   ' V C C Cheng 1',\n",
              "   ' K S Chan 2',\n",
              "   ' I F N Hung 1',\n",
              "   ' L L M Poon 1',\n",
              "   ' K I Law 2',\n",
              "   ' B S F Tang 1',\n",
              "   ' T Y W Hon 2',\n",
              "   ' C S Chan 2',\n",
              "   ' K H Chan 1',\n",
              "   ' J S C Ng 2',\n",
              "   ' B J Zheng 1',\n",
              "   ' W L Ng 2',\n",
              "   ' R W M Lai 2',\n",
              "   ' Y Guan 1',\n",
              "   ' Kwok-Yung Yuen 1'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2129542667',\n",
              "  'references': ['2104548316',\n",
              "   '2025170735',\n",
              "   '2131262274',\n",
              "   '2100820722',\n",
              "   '2125251240',\n",
              "   '2107978811',\n",
              "   '2161328469',\n",
              "   '2155583106',\n",
              "   '1675164605',\n",
              "   '2061759246'],\n",
              "  'title': 'Clinical progression and viral load in a community outbreak of coronavirus-associated SARS pneumonia: a prospective study.'},\n",
              " {'abstract': 'In an earlier paper, we introduced a new \"boosting\" algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that con- sistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a \"pseudo-loss\" which is a method for forcing a learning algorithm of multi-label concepts to concentrate on the labels that are hardest to discriminate. In this paper, we describe experiments we carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems. We performed two sets of experiments. The first set compared boosting to Breiman\\'s \"bagging\" method when used to aggregate various classifiers (including decision trees and single attribute- value tests). We compared the performance of the two methods on a collection of machine-learning benchmarks. In the second set of experiments, we studied in more detail the performance of boosting using a nearest-neighbor classifier on an OCR problem.',\n",
              "  'authors': ['Yoav Freund ', ' Robert E. Schapire'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2112076978',\n",
              "  'references': ['1988790447',\n",
              "   '2912934387',\n",
              "   '2125055259',\n",
              "   '1504694836',\n",
              "   '1670263352',\n",
              "   '1966280301',\n",
              "   '2093717447',\n",
              "   '2132166479',\n",
              "   '2070534370',\n",
              "   '2137291015'],\n",
              "  'title': 'Experiments with a new boosting algorithm'},\n",
              " {'abstract': 'Facial attribute editing aims to manipulate single or multiple attributes on a given face image, i.e., to generate a new face image with desired attributes while preserving other details. Recently, the generative adversarial net (GAN) and encoder–decoder architecture are usually incorporated to handle this task with promising results. Based on the encoder–decoder architecture, facial attribute editing is achieved by decoding the latent representation of a given face conditioned on the desired attributes. Some existing methods attempt to establish an attribute-independent latent representation for further attribute editing. However, such attribute-independent constraint on the latent representation is excessive because it restricts the capacity of the latent representation and may result in information loss, leading to over-smooth or distorted generation. Instead of imposing constraints on the latent representation, in this work, we propose to apply an attribute classification constraint to the generated image to just guarantee the correct change of desired attributes, i.e., to change what you want. Meanwhile, the reconstruction learning is introduced to preserve attribute-excluding details, in other words, to only change what you want. Besides, the adversarial learning is employed for visually realistic editing. These three components cooperate with each other forming an effective framework for high quality facial attribute editing, referred as AttGAN . Furthermore, the proposed method is extended for attribute style manipulation in an unsupervised manner. Experiments on two wild datasets, CelebA and LFW, show that the proposed method outperforms the state-of-the-art on realistic attribute editing with other facial details well preserved.',\n",
              "  'authors': ['Zhenliang He 1',\n",
              "   ' Wangmeng Zuo 2',\n",
              "   ' Meina Kan 1',\n",
              "   ' Shiguang Shan 1',\n",
              "   ' Xilin Chen 1'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2963626105',\n",
              "  'references': ['2964121744',\n",
              "   '1836465849',\n",
              "   '1901129140',\n",
              "   '2099471712',\n",
              "   '1959608418',\n",
              "   '2963073614',\n",
              "   '2962793481',\n",
              "   '2963684088',\n",
              "   '2096733369',\n",
              "   '2964153729'],\n",
              "  'title': 'AttGAN: Facial Attribute Editing by Only Changing What You Want'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Sotiris B. Kotsiantis'],\n",
              "  'date': '2007',\n",
              "  'identifier': '1873332500',\n",
              "  'references': ['2156909104',\n",
              "   '1570448133',\n",
              "   '2139212933',\n",
              "   '2912934387',\n",
              "   '1563088657',\n",
              "   '2119479037',\n",
              "   '1992419399',\n",
              "   '2125055259',\n",
              "   '2154642048',\n",
              "   '1515851193'],\n",
              "  'title': 'Supervised Machine Learning: A Review of Classification Techniques'},\n",
              " {'abstract': 'Adversarial examples are commonly viewed as a threat to ConvNets. Here we present an opposite perspective: adversarial examples can be used to improve image recognition models if harnessed in the right manner. We propose AdvProp, an enhanced adversarial training scheme which treats adversarial examples as additional examples, to prevent overfitting. Key to our method is the usage of a separate auxiliary batch norm for adversarial examples, as they have different underlying distributions to normal examples. We show that AdvProp improves a wide range of models on various image recognition tasks and performs better when the models are bigger. For instance, by applying AdvProp to the latest EfficientNet-B7 [28] on ImageNet, we achieve significant improvements on ImageNet (+0.7%), ImageNet-C (+6.5%), ImageNet-A (+7.0%), Stylized-ImageNet (+4.8%). With an enhanced EfficientNet-B8, our method achieves the state-of-the-art 85.5% ImageNet top-1 accuracy without extra data. This result even surpasses the best model in [20] which is trained with 3.5B Instagram images (~3000X more than ImageNet) and ~9.4X more parameters. Code and models will be made publicly available.',\n",
              "  'authors': ['Cihang Xie 1',\n",
              "   ' Mingxing Tan 2',\n",
              "   ' Boqing Gong 2',\n",
              "   ' Jiang Wang 2',\n",
              "   ' Alan L. Yuille 1',\n",
              "   ' Quoc V. Le 2'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3035743198',\n",
              "  'references': ['2194775991',\n",
              "   '2618530766',\n",
              "   '2962835968',\n",
              "   '2097117768',\n",
              "   '1836465849',\n",
              "   '2963446712',\n",
              "   '2183341477',\n",
              "   '2963207607',\n",
              "   '2964153729',\n",
              "   '2964253222'],\n",
              "  'title': 'Adversarial Examples Improve Image Recognition'},\n",
              " {'abstract': 'Cluster analysis comprises a range of methods for classifying multivariate data into subgroups. By organising multivariate data into such subgroups, clustering can help reveal the characteristics of any structure or patterns present. These techniques are applicable in a wide range of areas such as medicine, psychology and market research. This fourth edition of the highly successful Cluster Analysis represents a thorough revision of the third edition and covers new and developing areas such as classification likelihood and neural networks for clustering. Real life examples are used throughout to demonstrate the application of the theory, and figures are used extensively to illustrate graphical techniques. The book is comprehensive yet relatively non-mathematical, focusing on the practical aspects of cluster analysis.',\n",
              "  'authors': ['Brian S. Everitt ', ' Sabine Landau ', ' Morven Leese'],\n",
              "  'date': '1974',\n",
              "  'identifier': '2612166593',\n",
              "  'references': ['2148606196',\n",
              "   '1992419399',\n",
              "   '2011430131',\n",
              "   '2089458547',\n",
              "   '2164928285',\n",
              "   '2153233077',\n",
              "   '1501500081',\n",
              "   '2135000328',\n",
              "   '2011832962',\n",
              "   '2033590892'],\n",
              "  'title': 'Cluster Analysis'},\n",
              " {'abstract': 'To the Editor: The detection of hepatitis C virus (HCV) infection by enzyme immunoassay and molecular biologic techniques still leaves unidentified other hepatitis viruses that may be responsible f...',\n",
              "  'authors': ['Tatsuya Aikawa ', ' Yoshiki Sugai ', ' Hiroaki Okamoto'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2010203103',\n",
              "  'references': ['2059372215', '1968566170', '2171191174', '2089463925'],\n",
              "  'title': 'Hepatitis G infection in drug abusers with chronic hepatitis C.'},\n",
              " {'abstract': \"Experiments were made on the posterior parietal association cortical areas 5 and in 17 hemispheres of 11 monkeys, 6 M. mulatta and 5 M. arctoides. The electrical signs of the activity of single cortical cells were recorded with microelectrodes in waking animals as they carried out certain behavioral acts in response to a series of sensory cues. The behavioral paradigms were one for detection alone, and a second for detection plus projection of the arm to contact a stationary or moving target placed at arm's length. Of the 125 microelectrode penetrations made, 1,451 neurons were identified in terms of the correlation of their activity with the behavioral acts and their sensitivity or lack of it to sensory stimuli delivered passively; 180 were studied quantitatively. The locations of cortical neurons were identified in serial sections; 94 penetrations and 1,058 neurons were located with certainty. About two-thirds of the neurons of area 5 were activated by passive rotation of the limbs at their joints; of these, 82% were related to single, contralateral joints, 10% to two or more contralateral joints, 6% to ipsilateral, and 2% to joints on both sides of the body. A few of the latter were active during complex bodily postures. A large proportion of area 5 neurons were relatively insensitive to passive joint rotations, as compared with similar neurons of the postcentral gyrus, but were driven to high rates of discharge when the same joint was rotated during an active movement of the animal...\",\n",
              "  'authors': ['V. B. Mountcastle ',\n",
              "   ' J. C. Lynch ',\n",
              "   ' Apostolos P Georgopoulos ',\n",
              "   ' H. Sakata ',\n",
              "   ' C. Acuna'],\n",
              "  'date': '1975',\n",
              "  'identifier': '2177960617',\n",
              "  'references': ['2117731089',\n",
              "   '1999014668',\n",
              "   '2134598304',\n",
              "   '1598762216',\n",
              "   '1934970405',\n",
              "   '2127525246',\n",
              "   '2308727032',\n",
              "   '2253776861',\n",
              "   '2151651281',\n",
              "   '1810474833'],\n",
              "  'title': 'Posterior parietal association cortex of the monkey: command functions for operations within extrapersonal space'},\n",
              " {'abstract': 'Abstract Background/Aims: Hepatitis C virus (HCV) infection is common in liver transplant recipients, yet the effects of immunosuppression on HCV RNA levels and the relationship of HCV RNA levels to hepatic damage have not been studied. Methods: To explore these issues, we measured HCV RNA in serum by polymerase chain reaction amplification and branched DNA assay from 100 HCV-infected patients undergoing liver transplantation. Results: Mean posttransplant levels were 16-fold higher than pretransplant values (7,935,000 and 496,000 Eq/mL, respectively; n=65; P P = 0.064). Posttransplant levels were similar in patients with recurrent and acquired infection and were independent of time of sampling. Fifty percent of patients with HCV infection had normal liver biopsy specimens, and there was no strong relationship between level of viremia and degree of hepatic damage. Conclusions: HCV RNA levels increase markedly following liver transplantation. The frequent finding of viremia in the absence of histological hepatitis suggests that a \"carrier state\" is common. Absence of allograft damage in some (despite high levels of viral RNA) suggests that in immunosuppressed patients, HCV infection may be tolerated without direct hepatic damage.',\n",
              "  'authors': ['Oliver Chazouilleres 1',\n",
              "   ' Michael Kim 1',\n",
              "   ' Connie Combs 1',\n",
              "   ' Linda Ferrell 1',\n",
              "   ' Peter Bacchetti 1',\n",
              "   ' John Roberts 1',\n",
              "   ' Nancy L. Ascher 1',\n",
              "   ' Paul Neuwald 2',\n",
              "   ' Judith Wilber 2',\n",
              "   ' Mickey Urdea 2',\n",
              "   ' Stella Quan 2',\n",
              "   ' Ray Sanchez-Pescador 2',\n",
              "   ' Teresa L. Wright 1'],\n",
              "  'date': '1994',\n",
              "  'identifier': '1674991100',\n",
              "  'references': ['2328171401',\n",
              "   '2019943793',\n",
              "   '1993023565',\n",
              "   '173236885',\n",
              "   '2074530738',\n",
              "   '1581230849',\n",
              "   '2154600216',\n",
              "   '2051962144',\n",
              "   '2570729219',\n",
              "   '2335969006'],\n",
              "  'title': 'Quantitation of hepatitis C virus RNA in liver transplant recipients'},\n",
              " {'abstract': 'The first revision of this third volume is a survey of classical computer techniques for sorting and searching. It extends the treatment of data structures in Volume 1 to consider both large and small databases and internal and external memories.',\n",
              "  'authors': ['Donald Ervin Knuth'],\n",
              "  'date': '1973',\n",
              "  'identifier': '1600795850',\n",
              "  'references': ['1501077214',\n",
              "   '2142619120',\n",
              "   '2158322625',\n",
              "   '1997841190',\n",
              "   '2913618476',\n",
              "   '2155943969',\n",
              "   '2127766448',\n",
              "   '2052196304',\n",
              "   '2144982963'],\n",
              "  'title': 'Sorting and Searching'},\n",
              " {'abstract': 'We explore the use of certain image features, blockwise histograms of local orientations, used in many current object recognition algorithms, for the task of handwritten digit recognition. Existing approaches find that polynomial kernel SVMs trained on raw pixels achieve state of the art performance. However such kernel SVM approaches are impractical as they have a huge complexity at runtime. We demonstrate that with improved features a low complexity classifier, in particular an additive-kernel SVM, can achieve state of the art performance. Our approach achieves an error of 0.79% on the MNIST dataset and 3.4% error on the USPS dataset, while running at speeds comparable to the fastest algorithms on these datasets which are based on multilayer neural networks and are significantly faster and easier to train.',\n",
              "  'authors': ['Subhransu Maji ', ' Jitendra Malik'],\n",
              "  'date': '2009',\n",
              "  'identifier': '2277406607',\n",
              "  'references': ['2153635508',\n",
              "   '2161969291',\n",
              "   '2310919327',\n",
              "   '2162915993',\n",
              "   '2124386111',\n",
              "   '2118585731',\n",
              "   '2057175746',\n",
              "   '2120419212',\n",
              "   '1566135517',\n",
              "   '2166049352'],\n",
              "  'title': 'Fast and Accurate Digit Classification'},\n",
              " {'abstract': 'We investigate the use of multiple transmitting and/or receiving antennas for single user communications over the additive Gaussian channel with and without fading. We derive formulas for the capacities and error exponents of such channels, and describe computational procedures to evaluate such formulas. We show that the potential gains of such multi-antenna systems over single-antenna systems is rather large under independenceassumptions for the fades and noises at different receiving antennas.',\n",
              "  'authors': ['Emre Telatar'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2130509920',\n",
              "  'references': ['2120302973',\n",
              "   '2168571551',\n",
              "   '2126785155',\n",
              "   '1969097180',\n",
              "   '1974637548'],\n",
              "  'title': 'Capacity of Multi‐antenna Gaussian Channels'},\n",
              " {'abstract': 'The success of the von Neumann model of sequential computation is attributable to the fact that it is an efficient bridge between software and hardware: high-level languages can be efficiently compiled on to this model; yet it can be effeciently implemented in hardware. The author argues that an analogous bridge between software and hardware in required for parallel computation if that is to become as widely used. This article introduces the bulk-synchronous parallel (BSP) model as a candidate for this role, and gives results quantifying its efficiency both in implementing high-level language features and algorithms, as well as in being implemented in hardware.',\n",
              "  'authors': ['Leslie G. Valiant'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2045271686',\n",
              "  'references': ['2052207834',\n",
              "   '2143462372',\n",
              "   '1555673550',\n",
              "   '1989582918',\n",
              "   '1969008575',\n",
              "   '2107997203',\n",
              "   '2069489095',\n",
              "   '2137239103',\n",
              "   '2103012681',\n",
              "   '1544480906'],\n",
              "  'title': 'A bridging model for parallel computation'},\n",
              " {'abstract': 'We consider the class of iterative shrinkage-thresholding algorithms (ISTA) for solving linear inverse problems arising in signal/image processing. This class of methods, which can be viewed as an extension of the classical gradient algorithm, is attractive due to its simplicity and thus is adequate for solving large-scale problems even with dense matrix data. However, such methods are also known to converge quite slowly. In this paper we present a new fast iterative shrinkage-thresholding algorithm (FISTA) which preserves the computational simplicity of ISTA but with a global rate of convergence which is proven to be significantly better, both theoretically and practically. Initial promising numerical results for wavelet-based image deblurring demonstrate the capabilities of FISTA which is shown to be faster than ISTA by several orders of magnitude.',\n",
              "  'authors': ['Amir Beck 1', ' Marc Teboulle 2'],\n",
              "  'date': '2009',\n",
              "  'identifier': '2100556411',\n",
              "  'references': ['2078204800',\n",
              "   '2798766386',\n",
              "   '2109449402',\n",
              "   '2115706991',\n",
              "   '2028349405',\n",
              "   '2079724595',\n",
              "   '2006262045',\n",
              "   '1543439990',\n",
              "   '2126607811',\n",
              "   '1568307856'],\n",
              "  'title': 'A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems'},\n",
              " {'abstract': 'The Technology Acceptance Model and two variations of the Theory of Planned Behavior were compared to assess which model best helps to understand usage of information technology. The models were compared using student data collected from 786 potential users of a computer resource center. Behavior data was based on monitoring 3,780 visits to the resource center over a 12-week period. Weighted least squares estimation revealed that all three models performed well in terms of fit and were roughly equivalent in terms of their ability to explain behavior. Decomposing the belief structures in the Theory of Planned Behavior provided a moderate increase in the explanation of behavioral intention. Overall, the results indicate that the decomposed Theory of Planned Behavior provides a fuller understanding of behavioral intention by focusing on the factors that are likely to influence systems use through the application of both design and implementation strategies.',\n",
              "  'authors': ['Shirley Taylor ', ' Peter A. Todd'],\n",
              "  'date': '1995',\n",
              "  'identifier': '1987198869',\n",
              "  'references': ['2099697766',\n",
              "   '1791587663',\n",
              "   '2059334100',\n",
              "   '1992193527',\n",
              "   '2033943395',\n",
              "   '2179683524',\n",
              "   '2057012437',\n",
              "   '1987258130',\n",
              "   '1491644571',\n",
              "   '1816720378'],\n",
              "  'title': 'Understanding Information Technology Usage: A Test of Competing Models'},\n",
              " {'abstract': \"The often paradoxical relationship between investment in information technology and gains in productivity has recently been attributed to a lack of user acceptance of information technology innovations. Diverse streams of research have attempted to explain and predict user acceptance of new information technologies. A common theme underlying these various research streams is the inclusion of the perceived characteristics of an innovation as key independent variables. Furthermore, prior research has utilized different outcomes to represent user acceptance behavior. In this paper we focus on individual's perceptions about the characteristics of the target technology as explanatory and predictive variables for acceptance behavior, and present an empirical study examining the effects of these perceptions on two frequently used outcomes in the context of the innovation represented by the World Wide Web. The two outcomes examined are initial use of an innovation and intentions to continue such use in the future, that is, to routinize technology use. Two research questions motivated and guided the study. First, are the perceptions that predict initial use the same as those that predict future use intentions? Our results confirm, as hypothesized by prior research, that innovation characteristics do explain acceptance behavior. The results further reveal that the specific characteristics that are relevant for each acceptance outcome are different. The second research question asks if perceived voluntariness plays a role in technology acceptance. Results show that external pressure has an impact on adopters' acceptance behavior. Theoretical and practical implications that follow are presented.\",\n",
              "  'authors': ['Ritu Agarwal 1', ' Jayesh Prasad 2'],\n",
              "  'date': '1997',\n",
              "  'identifier': '1998581510',\n",
              "  'references': ['1791587663',\n",
              "   '2033943395',\n",
              "   '2057012437',\n",
              "   '1987198869',\n",
              "   '2100408980',\n",
              "   '2065502371',\n",
              "   '2008441192',\n",
              "   '1515402129',\n",
              "   '1490774257',\n",
              "   '1964473994'],\n",
              "  'title': 'The Role of Innovation Characteristics and Perceived Voluntariness in the Acceptance of Information Technologies'},\n",
              " {'abstract': \"Abstract A problem that arises is getting computers to perceive 3-D scenes is relating information from several different viewpoints. In particular, if the computer moves its sensor, it has to be able to predict changes in images of objects it has seen without having to completely re-recognize them. A solution to this problem has been implemented at Stanford using a calibrated camera model which expresses the relation between object space and image space as a function of the computer's control variables. The modelling problem is relatively well understood. Calibration techniques, however, are not. This article deals with these.\",\n",
              "  'authors': ['Irwin Sobel'],\n",
              "  'date': '1974',\n",
              "  'identifier': '2017304241',\n",
              "  'references': ['2039170454',\n",
              "   '2108729336',\n",
              "   '2028750032',\n",
              "   '1564308506',\n",
              "   '2144717132',\n",
              "   '1597888531',\n",
              "   '2116504721',\n",
              "   '1687134186',\n",
              "   '2002010034',\n",
              "   '2171869617'],\n",
              "  'title': 'On calibrating computer controlled cameras for perceiving 3-D scenes☆'},\n",
              " {'abstract': 'The acute respiratory distress syndrome is a common, devastating clinical syndrome of acute lung injury that affects both medical and surgical patients. Since the last review of this syndrome appeared in the Journal, 1 more uniform definitions have been devised and important advances have occurred in the understanding of the epidemiology, natural history, and pathogenesis of the disease, leading to the design and testing of new treatment strategies. This article provides an overview of the definitions, clinical features, and epidemiology of the acute respiratory distress syndrome and discusses advances in the areas of pathogenesis, resolution, and treatment. Historical Perspective and Definitions . . .',\n",
              "  'authors': ['Lorraine B. Ware ', ' Michael A. Matthay'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2093852073',\n",
              "  'references': ['2161328469',\n",
              "   '2005357317',\n",
              "   '2093216413',\n",
              "   '2062082715',\n",
              "   '2166745951',\n",
              "   '2070506007',\n",
              "   '1984406996',\n",
              "   '1766556848',\n",
              "   '2034332958',\n",
              "   '2117860495'],\n",
              "  'title': 'The acute respiratory distress syndrome'},\n",
              " {'abstract': '',\n",
              "  'authors': ['John Van Ryzin ',\n",
              "   ' Leo Breiman ',\n",
              "   ' Jerome H. Friedman ',\n",
              "   ' Richard A. Olshen ',\n",
              "   ' Charles J. Stone'],\n",
              "  'date': '1986',\n",
              "  'identifier': '3085162807',\n",
              "  'references': ['2133990480',\n",
              "   '2140190241',\n",
              "   '1570448133',\n",
              "   '2072128103',\n",
              "   '2135046866',\n",
              "   '1484413656',\n",
              "   '2158698691',\n",
              "   '2912934387',\n",
              "   '2166559705',\n",
              "   '2063978378'],\n",
              "  'title': 'Classification and Regression Trees.'},\n",
              " {'abstract': 'Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence. 1 Deep Neural Networks Deep learning methods aim at learning feature hierarchies with features from higher levels of the hierarchy formed by the composition of lower level features. They include Appearing in Proceedings of the 13 International Conference on Artificial Intelligence and Statistics (AISTATS) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 of JMLR: WC Weston et al., 2008). Much attention has recently been devoted to them (see (Bengio, 2009) for a review), because of their theoretical appeal, inspiration from biology and human cognition, and because of empirical success in vision (Ranzato et al., 2007; Larochelle et al., 2007; Vincent et al., 2008) and natural language processing (NLP) (Collobert & Weston, 2008; Mnih & Hinton, 2009). Theoretical results reviewed and discussed by Bengio (2009), suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one may need deep architectures. Most of the recent experimental results with deep architecture are obtained with models that can be turned into deep supervised neural networks, but with initialization or training schemes different from the classical feedforward neural networks (Rumelhart et al., 1986). Why are these new algorithms working so much better than the standard random initialization and gradient-based optimization of a supervised training criterion? Part of the answer may be found in recent analyses of the effect of unsupervised pretraining (Erhan et al., 2009), showing that it acts as a regularizer that initializes the parameters in a “better” basin of attraction of the optimization procedure, corresponding to an apparent local minimum associated with better generalization. But earlier work (Bengio et al., 2007) had shown that even a purely supervised but greedy layer-wise procedure would give better results. So here instead of focusing on what unsupervised pre-training or semi-supervised criteria bring to deep architectures, we focus on analyzing what may be going wrong with good old (but deep) multilayer neural networks. Our analysis is driven by investigative experiments to monitor activations (watching for saturation of hidden units) and gradients, across layers and across training iterations. We also evaluate the effects on these of choices of activation function (with the idea that it might affect saturation) and initialization procedure (since unsupervised pretraining is a particular form of initialization and it has a drastic impact).',\n",
              "  'authors': ['Xavier Glorot ', ' Yoshua Bengio'],\n",
              "  'date': '2010',\n",
              "  'identifier': '1533861849',\n",
              "  'references': ['2136922672',\n",
              "   '3118608800',\n",
              "   '2310919327',\n",
              "   '2072128103',\n",
              "   '2117130368',\n",
              "   '2025768430',\n",
              "   '2110798204',\n",
              "   '1498436455',\n",
              "   '1994197834',\n",
              "   '2131462252'],\n",
              "  'title': 'Understanding the difficulty of training deep feedforward neural networks'},\n",
              " {'abstract': 'Just as there are different interpretations of probability, leading to different kinds of inferential statements and different conclusions about statistical models and questions, so there are different theories of measurement, which in turn may lead to different kinds of statistical model and possibly different conclusions. This has led to much confusion and a long running debate about when different classes of statistical methods may legitimately be applied. This paper outlines the major theories of measurement and their relationships and describes the different kinds of models and hypotheses which may be formulated within each theory. One general conclusion is that the domains of applicability of the two major theories are typically different, and it is this which helps apparent contradictions to be avoided in most practical applications.',\n",
              "  'authors': ['David J. Hand'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2091560105',\n",
              "  'references': ['191383808',\n",
              "   '2102000606',\n",
              "   '2963261555',\n",
              "   '2523440281',\n",
              "   '2060542838',\n",
              "   '1559817689',\n",
              "   '170307911',\n",
              "   '2006407427',\n",
              "   '2051228787',\n",
              "   '2026633474'],\n",
              "  'title': 'Statistics and the theory of measurement'},\n",
              " {'abstract': 'SUMMARY A generalized form of the cross-validation criterion is applied to the choice and assessment of prediction using the data-analytic concept of a prescription. The examples used to illustrate the application are drawn from the problem areas of univariate estimation, linear regression and analysis of variance.',\n",
              "  'authors': ['M. Stone'],\n",
              "  'date': '1974',\n",
              "  'identifier': '2112081648',\n",
              "  'references': ['2084398551',\n",
              "   '2006258746',\n",
              "   '2050297026',\n",
              "   '2079100340',\n",
              "   '2092369573',\n",
              "   '2330622735',\n",
              "   '2049266248',\n",
              "   '2153890685',\n",
              "   '2066090712',\n",
              "   '2061461017'],\n",
              "  'title': 'Cross‐Validatory Choice and Assessment of Statistical Predictions'},\n",
              " {'abstract': 'The Self-Organising Map (SOM) algorithm was introduced by the author in 1981. Its theory and many applications form one of the major approaches to the contemporary artificial neural networks field, and new technologies have already been based on it. The most important practical applications are in exploratory data analysis, pattern recognition, speech analysis, robotics, industrial and medical diagnostics, instrumentation, and control, and literally hundreds of other tasks. In this monograph the mathematical preliminaries, background, basic ideas, and implications are expounded in a manner which is accessible without prior expert knowledge.',\n",
              "  'authors': ['Teuvo Kohonen'],\n",
              "  'date': '1995',\n",
              "  'identifier': '1679913846',\n",
              "  'references': ['2150926065',\n",
              "   '2122646361',\n",
              "   '2117812871',\n",
              "   '2056370875',\n",
              "   '2132549764',\n",
              "   '2169064301',\n",
              "   '2135187880',\n",
              "   '2097645701',\n",
              "   '1998025025',\n",
              "   '1501500081'],\n",
              "  'title': 'Self-Organizing Maps'},\n",
              " {'abstract': 'This paper introduces GRASP (Generic seaRch Algorithm for the Satisfiability Problem), a new search algorithm for Propositional Satisfiability (SAT). GRASP incorporates several search-pruning techniques that proved to be quite powerful on a wide variety of SAT problems. Some of these techniques are specific to SAT, whereas others are similar in spirit to approaches in other fields of Artificial Intelligence. GRASP is premised on the inevitability of conflicts during the search and its most distinguishing feature is the augmentation of basic backtracking search with a powerful conflict analysis procedure. Analyzing conflicts to determine their causes enables GRASP to backtrack nonchronologically to earlier levels in the search tree, potentially pruning large portions of the search space. In addition, by \"recording\" the causes of conflicts, GRASP can recognize and preempt the occurrence of similar conflicts later on in the search. Finally, straightforward bookkeeping of the causality chains leading up to conflicts allows GRASP to identify assignments that are necessary for a solution to be found. Experimental results obtained from a large number of benchmarks indicate that application of the proposed conflict analysis techniques to SAT algorithms can be extremely effective for a large number of representative classes of SAT instances.',\n",
              "  'authors': ['J.P. Marques-Silva 1', ' K.A. Sakallah 2'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2044560939',\n",
              "  'references': ['2011039300',\n",
              "   '1554885925',\n",
              "   '1667614912',\n",
              "   '2147096558',\n",
              "   '2048051309',\n",
              "   '1556434751',\n",
              "   '2913258176',\n",
              "   '2151720296',\n",
              "   '2135613306',\n",
              "   '1561608403'],\n",
              "  'title': 'GRASP: a search algorithm for propositional satisfiability'},\n",
              " {'abstract': 'We investigated the differential diffusion of all of the verified true and false news stories distributed on Twitter from 2006 to 2017. The data comprise ~126,000 stories tweeted by ~3 million people more than 4.5 million times. We classified news as true or false using information from six independent fact-checking organizations that exhibited 95 to 98% agreement on the classifications. Falsehood diffused significantly farther, faster, deeper, and more broadly than the truth in all categories of information, and the effects were more pronounced for false political news than for false news about terrorism, natural disasters, science, urban legends, or financial information. We found that false news was more novel than true news, which suggests that people were more likely to share novel information. Whereas false stories inspired fear, disgust, and surprise in replies, true stories inspired anticipation, sadness, joy, and trust. Contrary to conventional wisdom, robots accelerated the spread of true and false news at the same rate, implying that false news spreads more than the truth because humans, not robots, are more likely to spread it.',\n",
              "  'authors': ['Soroush Vosoughi ', ' Deb Roy ', ' Sinan Aral'],\n",
              "  'date': '2018',\n",
              "  'identifier': '2790166049',\n",
              "  'references': ['1880262756',\n",
              "   '2099111195',\n",
              "   '2131744502',\n",
              "   '3099768174',\n",
              "   '2084591134',\n",
              "   '2118836230',\n",
              "   '3125182500',\n",
              "   '2040467972',\n",
              "   '2168332560',\n",
              "   '2050619059'],\n",
              "  'title': 'The spread of true and false news online'},\n",
              " {'abstract': 'This book offers a thoroughly updated guide to the MPI (Message-Passing Interface) standard library for writing programs for parallel computers. Since the publication of the previous edition of Using MPI, parallel computing has become mainstream. Today, applications run on computers with millions of processors; multiple processors sharing memory and multicore processors with multiple hardware threads per core are common. The MPI-3 Forum recently brought the MPI standard up to date with respect to developments in hardware capabilities, core language evolution, the needs of applications, and experience gained over the years by vendors, implementers, and users. This third edition of Using MPI reflects these changes in both text and example code. The book takes an informal, tutorial approach, introducing each concept through easy-to-understand examples, including actual code in C and Fortran. Topics include using MPI in simple programs, virtual topologies, MPI datatypes, parallel libraries, and a comparison of MPI with sockets. For the third edition, example code has been brought up to date; applications have been updated; and references reflect the recent attention MPI has received in the literature. A companion volume, Using Advanced MPI, covers more advanced topics, including hybrid programming and coping with large data.',\n",
              "  'authors': ['William Gropp 1', ' Ewing Lusk 1', ' Anthony Skjellum 2'],\n",
              "  'date': '1994',\n",
              "  'identifier': '1510543252',\n",
              "  'references': ['2173213060',\n",
              "   '2154010459',\n",
              "   '1995017064',\n",
              "   '2111996486',\n",
              "   '2622263826',\n",
              "   '2816671092',\n",
              "   '2109065830',\n",
              "   '2081612620'],\n",
              "  'title': 'Using MPI: Portable Parallel Programming with the Message-Passing Interface'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Dimitri P. Bertsekas ', ' John N. Tsitsiklis'],\n",
              "  'date': '1989',\n",
              "  'identifier': '1603765807',\n",
              "  'references': ['2164278908',\n",
              "   '2121863487',\n",
              "   '2010630450',\n",
              "   '2096544401',\n",
              "   '78077100',\n",
              "   '2044212084',\n",
              "   '2963433607',\n",
              "   '2114791779',\n",
              "   '2951781666'],\n",
              "  'title': 'Parallel and Distributed Computation: Numerical Methods'},\n",
              " {'abstract': \"We present the design for the NYU Ultracomputer, a shared-memory MIMD parallel machine composed of thousands of autonomous processing elements. This machine uses an enhanced message switching network with the geometry of an Omega-network to approximate the ideal behavior of Schwartz's paracomputer model of computation and to implement efficiently the important fetch-and-add synchronization primitive. We outine the hardware that would be required to build a 4096 processor system using 1990's technology. We also discuss system software issues, and present analytic studies of the network performance. Finally, we include a sample of our effort to implement and simulate parallel variants of important scientific programs.\",\n",
              "  'authors': ['Gottlieb 1',\n",
              "   ' Grishman 2',\n",
              "   ' McAuliffe 2',\n",
              "   ' Rudolph 3',\n",
              "   ' Snir 2'],\n",
              "  'date': '1983',\n",
              "  'identifier': '1555673550',\n",
              "  'references': ['2121687577',\n",
              "   '2054739713',\n",
              "   '2164309468',\n",
              "   '2069489095',\n",
              "   '1979418125',\n",
              "   '2163820265',\n",
              "   '2047434043',\n",
              "   '1857507360',\n",
              "   '1586380695',\n",
              "   '2124339985'],\n",
              "  'title': 'The NYU Ultracomputer&#8212;Designing an MIMD Shared Memory Parallel Computer'},\n",
              " {'abstract': 'Point cloud registration is a key problem for computer vision applied to robotics, medical imaging, and other applications. This problem involves finding a rigid transformation from one point cloud into another so that they align. Iterative Closest Point (ICP) and its variants provide simple and easily-implemented iterative methods for this task, but these algorithms can converge to spurious local optima. To address local optima and other difficulties in the ICP pipeline, we propose a learning-based method, titled Deep Closest Point (DCP), inspired by recent techniques in computer vision and natural language processing. Our model consists of three parts: a point cloud embedding network, an attention-based module combined with a pointer generation layer to approximate combinatorial matching, and a differentiable singular value decomposition (SVD) layer to extract the final rigid transformation. We train our model end-to-end on the ModelNet40 dataset and show in several settings that it performs better than ICP, its variants (e.g., Go-ICP, FGR), and the recently-proposed learning-based method PointNetLK. Beyond providing a state-of-the-art registration technique, we evaluate the suitability of our learned features transferred to unseen objects. We also provide preliminary analysis of our learned model to help understand whether domain-specific and/or global features facilitate rigid registration.',\n",
              "  'authors': ['Yue Wang ', ' Justin Solomon'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2986382673',\n",
              "  'references': ['2964121744',\n",
              "   '2963403868',\n",
              "   '2963341956',\n",
              "   '2095705004',\n",
              "   '2130942839',\n",
              "   '2064675550',\n",
              "   '2899771611',\n",
              "   '2560609797',\n",
              "   '2963121255',\n",
              "   '2049981393'],\n",
              "  'title': 'Deep Closest Point: Learning Representations for Point Cloud Registration'},\n",
              " {'abstract': 'We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to ½ everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.',\n",
              "  'authors': ['Ian Goodfellow 1',\n",
              "   ' Jean Pouget-Abadie 1',\n",
              "   ' Mehdi Mirza 1',\n",
              "   ' Bing Xu 1',\n",
              "   ' David Warde-Farley 1',\n",
              "   ' Sherjil Ozair 2',\n",
              "   ' Aaron Courville 1',\n",
              "   ' Yoshua Bengio 1'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2099471712',\n",
              "  'references': ['2618530766',\n",
              "   '2136922672',\n",
              "   '1959608418',\n",
              "   '3118608800',\n",
              "   '2310919327',\n",
              "   '1904365287',\n",
              "   '2964153729',\n",
              "   '2072128103',\n",
              "   '2546302380',\n",
              "   '2294059674'],\n",
              "  'title': 'Generative Adversarial Nets'},\n",
              " {'abstract': \"We construct targeted audio adversarial examples on automatic speech recognition. Given any audio waveform, we can produce another that is over 99.9% similar, but transcribes as any phrase we choose (recognizing up to 50 characters per second of audio). We apply our white-box iterative optimization-based attack to Mozilla's implementation DeepSpeech end-to-end, and show it has a 100% success rate. The feasibility of this attack introduce a new domain to study adversarial examples.\",\n",
              "  'authors': ['Nicholas Carlini ', ' David Wagner'],\n",
              "  'date': '2018',\n",
              "  'identifier': '2964301649',\n",
              "  'references': ['2964121744',\n",
              "   '2963207607',\n",
              "   '2064675550',\n",
              "   '2964153729',\n",
              "   '2963857521',\n",
              "   '2964253222',\n",
              "   '2963542245',\n",
              "   '2127141656',\n",
              "   '2963143631',\n",
              "   '1932198206'],\n",
              "  'title': 'Audio Adversarial Examples: Targeted Attacks on Speech-to-Text'},\n",
              " {'abstract': '',\n",
              "  'authors': ['M. O. Hill ', ' A. Gifi'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2963261555',\n",
              "  'references': ['2110638361',\n",
              "   '2100235303',\n",
              "   '2113559481',\n",
              "   '2755950973',\n",
              "   '640156484',\n",
              "   '2089322632',\n",
              "   '2057498577',\n",
              "   '2168123127',\n",
              "   '1968206427',\n",
              "   '2094909687'],\n",
              "  'title': 'Nonlinear Multivariate Analysis.'},\n",
              " {'abstract': 'Two recently implemented machine-learning algorithms, RIPPER and sleeping-experts for phrases , are evaluated on a number of large text categorization problems. These algorithms both construct classifiers that allow the “context” of a word w to affect how (or even whether) the presence or absence of w will contribute to a classification. However, RIPPER and sleeping-experts differ radically in many other respects: differences include different notions as to what constitutes a context, different ways of combining contexts to construct a classifier, different methods to search for a combination of contexts, and different criteria as to what contexts should be included in such a combination. In spite of these differences, both RIPPER and sleeping-experts perform extremely well across a wide variety of categorization problems, generally outperforming previously applied learning methods. We view this result as a confirmation of the usefulness of classifiers that represent contextual information.',\n",
              "  'authors': ['William W. Cohen ', ' Yoram Singer'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1969572066',\n",
              "  'references': ['1988790447',\n",
              "   '1670263352',\n",
              "   '1619226191',\n",
              "   '2093825590',\n",
              "   '2085989833',\n",
              "   '1999138184',\n",
              "   '2060216474',\n",
              "   '2129113961',\n",
              "   '40914139',\n",
              "   '2094934653'],\n",
              "  'title': 'Context-sensitive learning methods for text categorization'},\n",
              " {'abstract': '',\n",
              "  'authors': ['I. Guyon 1',\n",
              "   ' D. Henderson ',\n",
              "   ' P. Albrecht 1',\n",
              "   ' Yann Lecun ',\n",
              "   ' J. S. Denker 1',\n",
              "   ' 2'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2607313294',\n",
              "  'references': ['2166312020',\n",
              "   '2159901481',\n",
              "   '2166469100',\n",
              "   '1986324151',\n",
              "   '2127574124',\n",
              "   '2183513372',\n",
              "   '1498655523',\n",
              "   '2045249386',\n",
              "   '2134586063',\n",
              "   '1016921196'],\n",
              "  'title': 'Writer independent and writer adaptive neural network for on-line character recognition'},\n",
              " {'abstract': 'One of the fundamental tenets of modern science is that a phenomenon cannot be claimed to be well understood until it can be characterized in quantitative terms.l Viewed in this perspective, much of what constitutes the core of scientific knowledge may be regarded as a reservoir of concepts and techniques which can be drawn upon to construct mathematical models of various types of systems and thereby yield quantitative information concerning their behavior.',\n",
              "  'authors': ['Lotfi A. Zadeh'],\n",
              "  'date': '1975',\n",
              "  'identifier': '2157041604',\n",
              "  'references': ['2041280856',\n",
              "   '2163751633',\n",
              "   '1543281322',\n",
              "   '2171715801',\n",
              "   '2333196491',\n",
              "   '2060642394',\n",
              "   '2054416947',\n",
              "   '2019529630',\n",
              "   '2005814556',\n",
              "   '2040121225'],\n",
              "  'title': 'The concept of a linguistic variable and its application to approximate reasoning—II☆'},\n",
              " {'abstract': 'First-generation reverse transcription-PCR (RT-PCR) assays for severe acute respiratory syndrome-associated coronavirus (SARS-CoV) gave false-negative results in a considerable fraction of patients. In the present study, we evaluated two second-generation, replicase (R) gene-based, real-time RT-PCR test kits—the RealArt HPA coronavirus LC kit (Artus, Hamburg, Germany) and the LightCycler SARS-CoV quantification kit (Roche, Penzberg, Germany)—and a real-time RT-PCR assay for the nucleocapsid (N) gene. Detecting the N-gene RNA might be advantageous due to its high abundance in cells. The kits achieved sensitivities of 70.8% (Artus) and 67.1% (Roche) in 66 specimens from patients with confirmed SARS (samples primarily from the upper and lower respiratory tract and stool). The sensitivity of the N-gene assay was 74.2%. The differences in all of the sensitivities were not statistically significant (P = 0.680 [analysis of variance]). Culture cells initially contained five times more N- than R-gene RNA, but the respective levels converged during 4 days of virus replication. In clinical samples the median concentrations of R- and N-gene RNA, respectively, were 1.2 × 106 and 2.8 × 106 copies/ml (sputum and endotracheal aspirates), 4.3 × 104 and 5.5 × 104 copies/ml (stool), and 5.5 × 102 and 5.2 × 102 copies/sample (throat swabs and saliva). Differences between the samples types were significant but not between the types of target RNA. All (n = 12) samples from the lower respiratory tract tested positive in all tests. In conclusion, the novel assays are more sensitive than the first-generation tests, but they still do not allow a comprehensive ruling out of SARS. Methods for the routine sampling of sputum without infection risk are needed to improve SARS RT-PCR.',\n",
              "  'authors': ['Christian Drosten 1',\n",
              "   ' Lily-Lily Chiu 2',\n",
              "   ' Marcus Panning 1',\n",
              "   ' Hoe Nam Leong 3',\n",
              "   ' Wolfgang Preiser 4',\n",
              "   ' John S. Tam 5',\n",
              "   ' Stephan Günther 1',\n",
              "   ' Stefanie Kramme 1',\n",
              "   ' Petra Emmerich 1',\n",
              "   ' Wooi Loon Ng 6',\n",
              "   ' Herbert Schmitz 1',\n",
              "   ' Evelyn S. C. Koay 6'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2145810580',\n",
              "  'references': ['2132260239',\n",
              "   '2104548316',\n",
              "   '2025170735',\n",
              "   '3022331664',\n",
              "   '2129542667',\n",
              "   '2116586125',\n",
              "   '1990049863',\n",
              "   '2168446943',\n",
              "   '1976741900',\n",
              "   '2107922358'],\n",
              "  'title': 'Evaluation of Advanced Reverse Transcription-PCR Assays and an Alternative PCR Target Region for Detection of Severe Acute Respiratory Syndrome-Associated Coronavirus'},\n",
              " {'abstract': \"The authors describe a general-purpose, representation-independent method for the accurate and computationally efficient registration of 3-D shapes including free-form curves and surfaces. The method handles the full six degrees of freedom and is based on the iterative closest point (ICP) algorithm, which requires only a procedure to find the closest point on a geometric entity to a given point. The ICP algorithm always converges monotonically to the nearest local minimum of a mean-square distance metric, and the rate of convergence is rapid during the first few iterations. Therefore, given an adequate set of initial rotations and translations for a particular class of objects with a certain level of 'shape complexity', one can globally minimize the mean-square distance metric over all six degrees of freedom by testing each initial registration. One important application of this method is to register sensed data from unfixtured rigid objects with an ideal geometric model, prior to shape inspection. Experimental results show the capabilities of the registration algorithm on point sets, curves, and surfaces. >\",\n",
              "  'authors': ['P.J. Besl ', ' H.D. McKay'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2049981393',\n",
              "  'references': ['2798909945',\n",
              "   '3124770806',\n",
              "   '2796837256',\n",
              "   '2162870748',\n",
              "   '1551207461',\n",
              "   '1993267444',\n",
              "   '1988874269',\n",
              "   '2034966370',\n",
              "   '1989871863',\n",
              "   '1996773532'],\n",
              "  'title': 'A method for registration of 3-D shapes'},\n",
              " {'abstract': '',\n",
              "  'authors': ['J. R. Quinlan 1',\n",
              "   ' P. J. Compton 2',\n",
              "   ' K. A. Horn 2',\n",
              "   ' L. Lazarus 2'],\n",
              "  'date': '1987',\n",
              "  'identifier': '1567276288',\n",
              "  'references': ['1966280301',\n",
              "   '2147169507',\n",
              "   '2136000097',\n",
              "   '2132166479',\n",
              "   '2128420091',\n",
              "   '2135190479',\n",
              "   '2083780116',\n",
              "   '1482451543',\n",
              "   '2042385018'],\n",
              "  'title': 'Inductive knowledge acquisition: a case study'},\n",
              " {'abstract': 'We present a statistical model for organizing image collections which integrates semantic information provided by associate text and visual information provided by image features. The model is very promising for information retrieval tasks such as database browsing and searching for images based on text and/or image features. Furthermore, since the model learns relationships between text and image features, it can be used for novel applications such as associating words with pictures, and unsupervised learning for object recognition.',\n",
              "  'authors': ['K. Barnard ', ' D. Forsyth'],\n",
              "  'date': '2001',\n",
              "  'identifier': '1934863104',\n",
              "  'references': ['2049633694',\n",
              "   '2160066518',\n",
              "   '2135705692',\n",
              "   '2125101937',\n",
              "   '2062270497',\n",
              "   '2155099190',\n",
              "   '1587328194',\n",
              "   '2099251025',\n",
              "   '2011549082',\n",
              "   '2166447979'],\n",
              "  'title': 'Learning the semantics of words and pictures'},\n",
              " {'abstract': 'A basic problem when deriving information from measured data, such as images, originates from the fact that objects in the world, and hence image structures, exist as meaningful entities only over ...',\n",
              "  'authors': ['Tony Lindeberg'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2112328181',\n",
              "  'references': ['2249139299',\n",
              "   '2158592639',\n",
              "   '1625255723',\n",
              "   '1676552347',\n",
              "   '2124087378',\n",
              "   '2109200236',\n",
              "   '2150769593',\n",
              "   '2020163092',\n",
              "   '2165497495',\n",
              "   '2119799051'],\n",
              "  'title': 'Scale-space theory in computer vision'},\n",
              " {'abstract': 'The problem of breaking an image into meaningful regions is considered. Bayesian decision theory is seen to provide a mechanism for including problem dependent (semantic) information in a general system. Some results are presented which make the computation feasible. A programming system based on these ideas and their application to road scenes is described.',\n",
              "  'authors': ['Yoram Yakimovsky ', ' Jerome A. Feldman'],\n",
              "  'date': '1973',\n",
              "  'identifier': '1548470819',\n",
              "  'references': ['3017143921',\n",
              "   '2006258746',\n",
              "   '2133246412',\n",
              "   '2145170747',\n",
              "   '2022286645',\n",
              "   '1559427309',\n",
              "   '1972885239',\n",
              "   '2000906577',\n",
              "   '1485035304',\n",
              "   '1591931903'],\n",
              "  'title': 'A semantics-based decision theory region analyzer'},\n",
              " {'abstract': \"Many of the most striking phenomena known from perceptual psychology are a direct result of the first levels of neural processing. In the visual systems of higher animals, the well-known center-surround response to local stimuli is responsible for some of the strongest visual illusions. For example, Mach bands, the Hermann-Hering grid illusion, and the Craik-O'Brian-Comsweet illusion can all be traced to simple inhibitory interactions between elements of the retina (Ratliff 1965). The high degree to which a perceived image is independent of the absolute illumination level can be viewed as a property of the mechanism by which incident light is transduced into an electrical signal. We present a model of the first stages of retinal processing in which these phenomena are viewed as natural by-products of the mechanism by which the system adapts to a wide range of viewing conditions. Our retinal model is implemented as a single silicon chip, which contains integrated photoreceptors and processing elements; this chip generates, in real time, outputs that correspond directly to signals observed in the corresponding levels of biological retinas.\",\n",
              "  'authors': ['Carver A. Mead ', ' Misha Mahowald'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2022060843',\n",
              "  'references': ['2111596277',\n",
              "   '2030283526',\n",
              "   '2125221899',\n",
              "   '1855465725',\n",
              "   '2098030610',\n",
              "   '2032648808',\n",
              "   '2169684433',\n",
              "   '2168092720',\n",
              "   '2008170521',\n",
              "   '2066053800'],\n",
              "  'title': 'A silicon model of early visual processing'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Vernon B. Mountcastle'],\n",
              "  'date': '1957',\n",
              "  'identifier': '2253776861',\n",
              "  'references': ['2138913040',\n",
              "   '65738273',\n",
              "   '2072522618',\n",
              "   '2079810998',\n",
              "   '2120079537',\n",
              "   '2107635023',\n",
              "   '2117940227',\n",
              "   '2012265686',\n",
              "   '2138704896',\n",
              "   '1999055090'],\n",
              "  'title': \"Modality and topographic properties of single neurons of cat's somatic sensory cortex.\"},\n",
              " {'abstract': '',\n",
              "  'authors': ['T P Powell ', ' V B Mountcastle'],\n",
              "  'date': '1959',\n",
              "  'identifier': '2418763445',\n",
              "  'references': ['2103934527',\n",
              "   '2116360511',\n",
              "   '2789500754',\n",
              "   '2138418088',\n",
              "   '2038995818',\n",
              "   '2273148818',\n",
              "   '1608247615',\n",
              "   '2009286649',\n",
              "   '2021814974',\n",
              "   '2034139708'],\n",
              "  'title': 'Some aspects of the functional organization of the cortex of the postcentral gyrus of the monkey: a correlation of findings obtained in a single unit analysis with cytoarchitecture.'},\n",
              " {'abstract': '',\n",
              "  'authors': ['R. A. Brown ', ' T. J. Hastie ', ' R. J. Tibshirani'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2797583072',\n",
              "  'references': ['2164278908',\n",
              "   '1746819321',\n",
              "   '2155965977',\n",
              "   '2135046866',\n",
              "   '1678356000',\n",
              "   '1964357740',\n",
              "   '648151759',\n",
              "   '1479807131',\n",
              "   '2166604768',\n",
              "   '2116206245'],\n",
              "  'title': 'Generalized Additive Models.'},\n",
              " {'abstract': 'The 2 groups of human coronaviruses (HCoVs) represented by the prototype strains HCoV 229E and HCoV OC43 are mostly known as viruses responsible for common cold syndrome. HCoVs are difficult to detect, and epidemiological data are rare. From October 2000 through April 2001, we tested 1803 respiratory samples for HCoV by reverse-transcriptase polymerase chain reaction. From 8 February through 27 March 2001, HCoV OC43 was detected in samples obtained from 30 (6%) of 501 patients. The other viruses detected were respiratory syncytial virus (6.1%), parainfluenza virus 3 (1%), influenza virus A (7.8%), influenza virus B (7.2%), rhinovirus (6.4%), enterovirus (1%), and adenovirus (2%). Infection with HCoV OC43 was detected in patients of all age groups. The following clinical symptoms were noted: fever (in 59.8% of patients), general symptoms (in 30%), digestive problems (in 56.8%), rhinitis (in 36.6%), pharyngitis (in 30%), laryngitis (in 3.3%), otitis (in 13.3%), bronchitis (in 16.6%), bronchiolitis (in 10%), and pneumonia (in 6.6%). This study shows that an outbreak of HCoV OC43 respiratory infection was responsible for the lower respiratory tract symptoms observed in nearly one-third of patients identified by active surveillance for coronavirus infection.',\n",
              "  'authors': ['Astrid Vabret ',\n",
              "   ' Thomas Mourez ',\n",
              "   ' Stéphanie Gouarin ',\n",
              "   ' Joëlle Petitjean ',\n",
              "   ' François Freymuth'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2006012833',\n",
              "  'references': ['2136123493',\n",
              "   '2154664055',\n",
              "   '2142706873',\n",
              "   '2061775840',\n",
              "   '2011219821',\n",
              "   '1985026938',\n",
              "   '1550670450',\n",
              "   '2026871972',\n",
              "   '2010334930',\n",
              "   '2090546946'],\n",
              "  'title': 'An Outbreak of Coronavirus OC43 Respiratory Infection in Normandy, France'},\n",
              " {'abstract': 'Algorithms based on principal component analysis (PCA) form the basis of numerous studies in the psychological and algorithmic face-recognition literature. PCA is a statistical technique and its incorporation into a face-recognition algorithm requires numerous design decisions. We explicitly state the design decisions by introducing a generic modular PCA-algorithm. This allows us to investigate these decisions, including those not documented in the literature. We experimented with different implementations of each module, and evaluated the different implementations using the September 1996 FERET evaluation protocol (the de facto standard for evaluating face-recognition algorithms). We experimented with (i) changing the illumination normalization procedure; (ii) studying effects on algorithm performance of compressing images with JPEG and wavelet compression algorithms; (iii) varying the number of eigenvectors in the representation; and (iv) changing the similarity measure in the classification process. We...',\n",
              "  'authors': ['Hyeonjoon Moon 1', ' P Jonathon Phillips 2'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2102773363',\n",
              "  'references': ['2138451337',\n",
              "   '2121647436',\n",
              "   '2033419168',\n",
              "   '2159686933',\n",
              "   '2113341759',\n",
              "   '1997011019',\n",
              "   '2012352340',\n",
              "   '2135463994',\n",
              "   '2131273085',\n",
              "   '2118774738'],\n",
              "  'title': 'Computational and performance aspects of PCA-based face-recognition algorithms.'},\n",
              " {'abstract': 'The rapid rate at which the field of digital picture processing has grown in the past five years had necessitated extensive revisions and the introduction of topics not found in the original edition.',\n",
              "  'authors': ['Azriel Rosenfeld ', ' Avinash C. Kak'],\n",
              "  'date': '1976',\n",
              "  'identifier': '1622620102',\n",
              "  'references': ['1992419399',\n",
              "   '1997063559',\n",
              "   '2061240006',\n",
              "   '2160754664',\n",
              "   '2103504761',\n",
              "   '2042316011',\n",
              "   '2003370853',\n",
              "   '1972544340',\n",
              "   '1579236455',\n",
              "   '2012554041'],\n",
              "  'title': 'Digital Picture Processing'},\n",
              " {'abstract': 'Part I What is satisfaction?. Part II Basic satisfaction mechanisms. Part III Alternative and supplementary comparative operators. Part IV Satisfaction processes and mechanisms. Part V Satisfaction consequences - what happens next?.',\n",
              "  'authors': ['Richard L. Oliver'],\n",
              "  'date': '1996',\n",
              "  'identifier': '1574378514',\n",
              "  'references': ['1965574139',\n",
              "   '2040467972',\n",
              "   '2036063909',\n",
              "   '1546702933',\n",
              "   '1973687016',\n",
              "   '1997176931',\n",
              "   '2175227141',\n",
              "   '2150563888',\n",
              "   '2163225723',\n",
              "   '2163000154'],\n",
              "  'title': 'Satisfaction: A Behavioral Perspective On The Consumer'},\n",
              " {'abstract': 'Linear inequalities were studied with some degree of generality at least as early as the time of Fourier (1824). However the first significant contribution to their theory was made by Minkowski in his Geometrie der Zalzlen in 1896. Since that time many papers have appeared in Europe, America, and Japan which have to do more or less directly with the subject. But some of these have been published in places unexpected or not easily accessible, and no general survey has appeared which attempts to take account of all of them.',\n",
              "  'authors': ['Lloyd L. Dines ', ' N. H. McCoy'],\n",
              "  'date': '2014',\n",
              "  'identifier': '226617160',\n",
              "  'references': ['2318318384', '2312521912'],\n",
              "  'title': 'On Linear Inequalities'},\n",
              " {'abstract': 'We obtain the Shannon capacity of a fading channel with channel side information at the transmitter and receiver, and at the receiver alone. The optimal power adaptation in the former case is \"water-pouring\" in time, analogous to water-pouring in frequency for time-invariant frequency-selective fading channels. Inverting the channel results in a large capacity penalty in severe fading.',\n",
              "  'authors': ['A.J. Goldsmith 1', ' P.P. Varaiya 2'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2107689535',\n",
              "  'references': ['2099111195',\n",
              "   '1969492090',\n",
              "   '1549664537',\n",
              "   '2100359132',\n",
              "   '2142901448',\n",
              "   '1983632787',\n",
              "   '1995875735',\n",
              "   '2147163807',\n",
              "   '2500704223',\n",
              "   '2117040115'],\n",
              "  'title': 'Capacity of fading channels with channel side information'},\n",
              " {'abstract': 'Surveys learning algorithms for recurrent neural networks with hidden units and puts the various techniques into a common framework. The authors discuss fixed point learning algorithms, namely recurrent backpropagation and deterministic Boltzmann machines, and nonfixed point algorithms, namely backpropagation through time, Elman\\'s history cutoff, and Jordan\\'s output feedback architecture. Forward propagation, an on-line technique that uses adjoint equations, and variations thereof, are also discussed. In many cases, the unified presentation leads to generalizations of various sorts. The author discusses advantages and disadvantages of temporally continuous neural networks in contrast to clocked ones continues with some \"tricks of the trade\" for training, using, and simulating continuous time and recurrent neural networks. The author presents some simulations, and at the end, addresses issues of computational complexity and learning speed. >',\n",
              "  'authors': ['B.A. Pearlmutter'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2154890045',\n",
              "  'references': ['2581275558',\n",
              "   '2154642048',\n",
              "   '2138484437',\n",
              "   '2110485445',\n",
              "   '2147800946',\n",
              "   '2895674046',\n",
              "   '1597286183',\n",
              "   '1535810436',\n",
              "   '2173629880',\n",
              "   '2016589492'],\n",
              "  'title': 'Gradient calculations for dynamic recurrent neural networks: a survey'},\n",
              " {'abstract': 'Abstract In principle, n -gram probabilities can be estimated from a large sample of text by counting the number of occurrences of each n -gram of interest and dividing by the size of the training sample. This method, which is known as maximum likelihood estimator (MLE), is very simple. However, it is unsuitable because n -grams which do not occur in the training sample are assigned zero probability. This is qualitatively wrong for use as a prior model, because it would never allow the n -gram, while clearly some of the unseen n -grams will occur in other texts. For non-zero frequencies, the MLE is quantitatively wrong. Moreover, at all frequencies, the MLE does not separate bigrams with the same frequency. We study two alternative methods. The first method is an enhanced version of the method due to Good and Turing (I. J. Good [1953]. Biometrika , 40 , 237–264). Under the modest assumption that the distribution of each bigram is binomial, Good provided a theoretical result that increases estimation accuracy. The second method is an enhanced version of the deleted estimation method (F. Jelinek & R. Mercer [1985]. IBM Technical Disclosure Bulletin , 28 , 2591–2594). It assumes even less, merely that the training and test corpora are generated by the same process. We emphasize three points about these methods. First, by using a second predictor of the probability in addition to the observed frequency, it is possible to estimate different probabilities for bigrams with the same frequency. We refer to this use of a second predictor as “enhancement.” With enhancement, we find 1200 significantly different probabilities (with a range of five orders of magnitude) for the group of bigrams not observed in the training text; the MLE method would not be able to distinguish any one of these bigrams from any other. The probabilities found by the enhanced methods agree quite closely in qualitative comparisons with the standard calculated from the test corpus. Second, the enhanced Good-Turing method provides accurate predictions of the variances of the standard probabilities estimated from the test corpus. Third, we introduce a refined testing method that enables us to measure the prediction errors directly and accurately and thus to study small differences between methods. We find that while the errors of both methods are small due to the large amount of data that we use, the enhanced Good-Turing method is three to four times as efficient in its use of data as the enhanced deleted estimate method. Good-Turing method is preferable to the enhanced deleted estimate method. Both methods are much better than MLE.',\n",
              "  'authors': ['Kenneth W. Church ', ' William A. Gale'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2059800182',\n",
              "  'references': ['2099247782',\n",
              "   '2134237567',\n",
              "   '2996160789',\n",
              "   '1990438144',\n",
              "   '2159782014',\n",
              "   '2168938909',\n",
              "   '2082092506'],\n",
              "  'title': 'A comparison of the enhanced Good-Turing and deleted estimation methods for estimating probabilities of English bigrams'},\n",
              " {'abstract': 'This work contains a theoretical study and computer simulations of a new self-organizing process. The principal discovery is that in a simple network of adaptive physical elements which receives signals from a primary event space, the signal representations are automatically mapped onto a set of output responses in such a way that the responses acquire the same topological order as that of the primary events. In other words, a principle has been discovered which facilitates the automatic formation of topologically correct maps of features of observable events. The basic self-organizing system is a one- or two-dimensional array of processing units resembling a network of threshold-logic units, and characterized by short-range lateral feedback between neighbouring units. Several types of computer simulations are used to demonstrate the ordering process as well as the conditions under which it fails.',\n",
              "  'authors': ['Teuvo Kohonen'],\n",
              "  'date': '1988',\n",
              "  'identifier': '65738273',\n",
              "  'references': ['2432567885',\n",
              "   '2887242076',\n",
              "   '2113653296',\n",
              "   '1539686131',\n",
              "   '1992476998',\n",
              "   '1972536405',\n",
              "   '2017811812',\n",
              "   '1993050927',\n",
              "   '2008920566',\n",
              "   '2008353316'],\n",
              "  'title': 'Self-organized formation of topologically correct feature maps'},\n",
              " {'abstract': '',\n",
              "  'authors': ['C. L. Blake'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2084812512',\n",
              "  'references': ['2111072639',\n",
              "   '2026131661',\n",
              "   '1565746575',\n",
              "   '2148143831',\n",
              "   '2011430131',\n",
              "   '2172000360',\n",
              "   '3100785508',\n",
              "   '2128906841',\n",
              "   '2017337590'],\n",
              "  'title': 'UCI Repository of machine learning databases'},\n",
              " {'abstract': 'Based on a study of the extensive literature in handprint recognition, this paper presents a survey in this challenging field. Recognition algorithms, data bases, character models, and handprint standards are examined. Achievements in the recognition of handprinted numerals, alphanumerics, Fortran, and Katakana characters are analyzed and compared. Data quality and constraints, as well as human and machine factors are also described. Characteristics, problems, and actual results on on-line recognition of handprinted characters for different applications are discussed. New emphases and directions are suggested.',\n",
              "  'authors': ['C.Y. Suen 1', ' M. Berthod 2', ' S. Mori 3'],\n",
              "  'date': '1980',\n",
              "  'identifier': '2062361515',\n",
              "  'references': ['2008313333',\n",
              "   '2155195832',\n",
              "   '2088534753',\n",
              "   '1966591781',\n",
              "   '2070771945',\n",
              "   '2000821228',\n",
              "   '1979819178',\n",
              "   '2065973527',\n",
              "   '2002448074',\n",
              "   '2120216197'],\n",
              "  'title': 'Automatic recognition of handprinted characters&#8212;The state of the art'},\n",
              " {'abstract': 'Pfam is a large collection of protein multiple sequence alignments and profile hidden Markov models. Pfam is available on the World Wide Web in the UK at http://www.sanger.ac.uk/Software/Pfam/, in Sweden at http://www.cgb.ki.se/Pfam/, in France at http://pfam.jouy.inra.fr/ and in the US at http://pfam.wustl.edu/. The latest version (6.6) of Pfam contains 3071 families, which match 69% of proteins in SWISS-PROT 39 and TrEMBL 14. Structural data, where available, have been utilised to ensure that Pfam families correspond with structural domains, and to improve domain-based annotation. Predictions of non-domain regions are now also included. In addition to secondary structure, Pfam multiple sequence alignments now contain active site residue mark-up. New search tools, including taxonomy search and domain query, greatly add to the functionality and usability of the Pfam resource.',\n",
              "  'authors': ['Marco Punta ',\n",
              "   ' Penny C. Coggill ',\n",
              "   ' Ruth Y. Eberhardt ',\n",
              "   ' Jaina Mistry ',\n",
              "   ' John G. Tate ',\n",
              "   ' Chris Boursnell ',\n",
              "   ' Ningze Pang ',\n",
              "   ' Kristoffer Forslund ',\n",
              "   ' Goran Ceric ',\n",
              "   ' Jody Clements ',\n",
              "   ' Andreas Heger ',\n",
              "   ' Liisa Holm ',\n",
              "   ' Erik L. L. Sonnhammer ',\n",
              "   ' Sean R. Eddy ',\n",
              "   ' Alex Bateman ',\n",
              "   ' Robert D. Finn'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2141885858',\n",
              "  'references': ['2158714788',\n",
              "   '2130479394',\n",
              "   '2168909179',\n",
              "   '2096525273',\n",
              "   '2141652419',\n",
              "   '2028231353',\n",
              "   '2152770371',\n",
              "   '2003144438',\n",
              "   '2085277871',\n",
              "   '2026258231'],\n",
              "  'title': 'The Pfam protein families database'},\n",
              " {'abstract': 'A Novel Coronavirus Emerging in China A novel coronavirus, designated as 2019-nCoV, emerged in Wuhan, China, at the end of 2019. Although many details of the emergence of this virus remain unknown,...',\n",
              "  'authors': ['Vincent J. Munster 1',\n",
              "   ' Marion Koopmans 2',\n",
              "   ' Neeltje van Doremalen 1',\n",
              "   ' Debby van Riel 2',\n",
              "   ' Emmie de Wit 1'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3002533507',\n",
              "  'references': ['3003668884',\n",
              "   '3012099172',\n",
              "   '3009912996',\n",
              "   '3012284084',\n",
              "   '3006645647',\n",
              "   '3015792206',\n",
              "   '3009834387',\n",
              "   '3012454642',\n",
              "   '3003901880',\n",
              "   '3012415734'],\n",
              "  'title': 'A Novel Coronavirus Emerging in China - Key Questions for Impact Assessment.'},\n",
              " {'abstract': 'Even though considerable attention has been given to the polarity of words (positive and negative) and the creation of large polarity lexicons, research in emotion analysis has had to rely on limited and small emotion lexicons. In this paper, we show how the combined strength and wisdom of the crowds can be used to generate a large, high-quality, word–emotion and word–polarity association lexicon quickly and inexpensively. We enumerate the challenges in emotion annotation in a crowdsourcing scenario and propose solutions to address them. Most notably, in addition to questions about emotions associated with terms, we show how the inclusion of a word choice question can discourage malicious data entry, help to identify instances where the annotator may not be familiar with the target term (allowing us to reject such annotations), and help to obtain annotations at sense level (rather than at word level). We conducted experiments on how to formulate the emotion-annotation questions, and show that asking if a term is associated with an emotion leads to markedly higher interannotator agreement than that obtained by asking if a term evokes an emotion.',\n",
              "  'authors': ['Saif M. Mohammad ', ' Peter D. Turney'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2040467972',\n",
              "  'references': ['2097726431',\n",
              "   '1970381522',\n",
              "   '2164777277',\n",
              "   '2168625136',\n",
              "   '1574378514',\n",
              "   '2129251351',\n",
              "   '2096423181',\n",
              "   '1966797434',\n",
              "   '2143539737',\n",
              "   '1977137834'],\n",
              "  'title': 'CROWDSOURCING A WORD–EMOTION ASSOCIATION LEXICON'},\n",
              " {'abstract': 'An introduction is given to a theory of early visual information processing. The theory has been implemented, and examples are given of images at various stages of analysis. It is argued that the first step of consequence is to compute a primitive but rich description of the grey-level changes present in an image. The description is expressed in a vocabulary of kinds of intensity change (EDGE, SHADING-EDGE, EXTENDED-EDGE, LINE, BLOB etc.). Modifying parameters are bound to the elements in the description, specifying their POSITION, ORIENTATION, TERMINATION points, CONTRAST, SIZE and FUZZINESS. This description is obtained from the intensity array by fixed techniques, and it is called the primal sketch. For most images, the primal sketch is large and unwieldy. The second important step in visual information processing is to group its contents in a way that is appropriate for later recognition. From our ability to interpret drawings with little semantic content, one may infer the presence in our perceptual equipment of symbolic processes that can define \"place-tokens\" in an image in various ways, and can group them according to certain rules. Homomorphic techniques fail to account for many of these grouping phenomena, whose explanations require mechanisms of construction rather than mechanisms of detection. The necessary grouping of elements in the primal sketch may be achieved by a mechanism that has available the processes inferred from above, together with the ability to select items by first order discriminations acting on the elements\\' parameters. Only occasionally do these mechanisms use downward-flowing information about the contents of the particular image being processed. It is argued that \"non-attentive\" vision is in practice implemented by these grouping operations and first order discriminations acting on the primal sketch. The class of computations so obtained differs slightly from the class of second order operations on the intensity array. The extraction of a form from the primal sketch using these techniques amounts to the separation of figure from ground. It is concluded that most of the separation can be carried out by using techniques that do not depend upon the particular image in question. Therefore, figure-ground separation can normally precede the description of the shape of the extracted form. Up to this point, higher-level knowledge and purpose are brought to bear on only a few of the decisions taken during the processing. This relegates the widespread use of downward-flowing information to a later stage than is found in current machine-vision programs, and implies that such knowledge should influence the control of, rather than interfering with, the actual data-processing that is taking place lower down.',\n",
              "  'authors': ['David Marr'],\n",
              "  'date': '1976',\n",
              "  'identifier': '2130355536',\n",
              "  'references': ['1968245656',\n",
              "   '2116360511',\n",
              "   '1980429329',\n",
              "   '2028750032',\n",
              "   '2119051448',\n",
              "   '2057683929',\n",
              "   '2017600612',\n",
              "   '2066548055',\n",
              "   '1967767463',\n",
              "   '2070616620'],\n",
              "  'title': 'Early processing of visual information'},\n",
              " {'abstract': 'Despite the widespread use of exploratory factor analysis in psychological research, researchers often make questionable decisions when conducting these analyses. This article reviews the major design and analytical decisions that must be made when conducting a factor analysis and notes that each of these decisions has important consequences for the obtained results. Recommendations that have been made in the methodological literature are discussed. Analyses of 3 existing empirical data sets are used to illustrate how questionable decisions in conducting factor analyses can yield problematic results. The article presents a survey of 2 prominent journals that suggests that researchers routinely conduct analyses using such questionable methods. The implications of these practices for psychological research are discussed, and the reasons for current practices are reviewed.',\n",
              "  'authors': ['Leandre R. Fabrigar ',\n",
              "   ' Duane T. Wegener ',\n",
              "   ' Robert C. MacCallum ',\n",
              "   ' Erin J. Strahan'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1977775666',\n",
              "  'references': ['1992193527',\n",
              "   '2045181804',\n",
              "   '2005092827',\n",
              "   '1971410477',\n",
              "   '2795596299',\n",
              "   '2122376319',\n",
              "   '1968524945',\n",
              "   '2006779932',\n",
              "   '1989528006',\n",
              "   '1994263489'],\n",
              "  'title': 'Evaluating the use of exploratory factor analysis in psychological research.'},\n",
              " {'abstract': \"Csiszr and Krner's book is widely regarded as a classic in the field of information theory, providing deep insights and expert treatment of the key theoretical issues. It includes in-depth coverage of the mathematics of reliable information transmission, both in two-terminal and multi-terminal network scenarios. Updated and considerably expanded, this new edition presents unique discussions of information theoretic secrecy and of zero-error information theory, including the deep connections of the latter with extremal combinatorics. The presentations of all core subjects are self contained, even the advanced topics, which helps readers to understand the important connections between seemingly different problems. Finally, 320 end-of-chapter problems, together with helpful solving hints, allow readers to develop a full command of the mathematical techniques. It is an ideal resource for graduate students and researchers in electrical and electronic engineering, computer science and applied mathematics.\",\n",
              "  'authors': ['Imre Csiszar 1', ' Janos Korner 2'],\n",
              "  'date': '2011',\n",
              "  'identifier': '1549664537',\n",
              "  'references': ['1667950888',\n",
              "   '2133475491',\n",
              "   '2098567664',\n",
              "   '2147942702',\n",
              "   '2102617152',\n",
              "   '2107689535',\n",
              "   '2098257210',\n",
              "   '2072184935',\n",
              "   '2120085609',\n",
              "   '627952176'],\n",
              "  'title': 'Information Theory: Coding Theorems for Discrete Memoryless Systems'},\n",
              " {'abstract': 'A system of cluster analysis for genome-wide expression data from DNA microarray hybridization is de- scribed that uses standard statistical algorithms to arrange genes according to similarity in pattern of gene expression. The output is displayed graphically, conveying the clustering and the underlying expression data simultaneously in a form intuitive for biologists. We have found in the budding yeast Saccharomyces cerevisiae that clustering gene expression data groups together efficiently genes of known similar function, and we find a similar tendency in human data. Thus patterns seen in genome-wide expression experiments can be inter- preted as indications of the status of cellular processes. Also, coexpression of genes of known function with poorly charac- terized or novel genes may provide a simple means of gaining leads to the functions of many genes for which information is not available currently.',\n",
              "  'authors': ['Michael B. Eisen ',\n",
              "   ' Paul T. Spellman ',\n",
              "   ' Patrick O. Brown ',\n",
              "   ' David Botstein'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2150926065',\n",
              "  'references': ['1679913846',\n",
              "   '1970156673',\n",
              "   '2165011536',\n",
              "   '2130494035',\n",
              "   '2010888033',\n",
              "   '2135951244',\n",
              "   '2030958510',\n",
              "   '2161893150',\n",
              "   '2753765968',\n",
              "   '2964646613'],\n",
              "  'title': 'Cluster analysis and display of genome-wide expression patterns'},\n",
              " {'abstract': 'Relationship marketing—establishing, developing, and maintaining successful relational exchanges—constitutes a major shift in marketing theory and practice. After conceptualizing relationship marke...',\n",
              "  'authors': ['Robert M. Morgan 1', ' Shelby D. Hunt 2'],\n",
              "  'date': '1994',\n",
              "  'identifier': '2137247419',\n",
              "  'references': ['2018201949',\n",
              "   '2122912498',\n",
              "   '2027320617',\n",
              "   '2566856888',\n",
              "   '2036389121',\n",
              "   '1991670833',\n",
              "   '2003825788',\n",
              "   '2315556200',\n",
              "   '2041090984',\n",
              "   '1994263489'],\n",
              "  'title': 'The Commitment-Trust Theory of Relationship Marketing'},\n",
              " {'abstract': 'The self-organizing map (SOM) is an automatic data-analysis method. It is widely applied to clustering problems and data exploration in industry, finance, natural sciences, and linguistics. The most extensive applications, exemplified in this paper, can be found in the management of massive textual databases and in bioinformatics. The SOM is related to the classical vector quantization (VQ), which is used extensively in digital signal processing and transmission. Like in VQ, the SOM represents a distribution of input data items using a finite set of models. In the SOM, however, these models are automatically associated with the nodes of a regular (usually two-dimensional) grid in an orderly fashion such that more similar models become automatically associated with nodes that are adjacent in the grid, whereas less similar models are situated farther away from each other in the grid. This organization, a kind of similarity diagram of the models, makes it possible to obtain an insight into the topographic relationships of data, especially of high-dimensional data items. If the data items belong to certain predetermined classes, the models (and the nodes) can be calibrated according to these classes. An unknown input item is then classified according to that node, the model of which is most similar with it in some metric used in the construction of the SOM. A new finding introduced in this paper is that an input item can even more accurately be represented by a linear mixture of a few best-matching models. This becomes possible by a least-squares fitting procedure where the coefficients in the linear mixture of models are constrained to nonnegative values.',\n",
              "  'authors': ['Teuvo Kohonen'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2079810998',\n",
              "  'references': ['1679913846',\n",
              "   '1574901103',\n",
              "   '2147152072',\n",
              "   '2015292449',\n",
              "   '2150102617',\n",
              "   '2046079134',\n",
              "   '1956559956',\n",
              "   '1991848143',\n",
              "   '65738273',\n",
              "   '2107636931'],\n",
              "  'title': 'Essentials of the self-organizing map'},\n",
              " {'abstract': 'Probability Distributions.- Linear Models for Regression.- Linear Models for Classification.- Neural Networks.- Kernel Methods.- Sparse Kernel Machines.- Graphical Models.- Mixture Models and EM.- Approximate Inference.- Sampling Methods.- Continuous Latent Variables.- Sequential Data.- Combining Models.',\n",
              "  'authors': ['Christopher M. Bishop'],\n",
              "  'date': '2006',\n",
              "  'identifier': '1663973292',\n",
              "  'references': ['2117812871', '1496357020'],\n",
              "  'title': 'Pattern Recognition and Machine Learning'},\n",
              " {'abstract': 'This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models (Bayesian networks and Markov random fields). We present a number of examples of graphical models, including the QMR-DT database, the sigmoid belief network, the Boltzmann machine, and several variants of hidden Markov models, in which it is infeasible to run exact inference algorithms. We then introduce variational methods, which exploit laws of large numbers to transform the original graphical model into a simplified graphical model in which inference is efficient. Inference in the simpified model provides bounds on probabilities of interest in the original model. We describe a general framework for generating variational transformations based on convex duality. Finally we return to the examples and demonstrate how variational algorithms can be formulated in each case.',\n",
              "  'authors': ['Michael I. Jordan 1',\n",
              "   ' Zoubin Ghahramani 2',\n",
              "   ' Tommi S. Jaakkola 3',\n",
              "   ' Lawrence K. Saul 4'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1516111018',\n",
              "  'references': ['2099111195',\n",
              "   '2159080219',\n",
              "   '1573186872',\n",
              "   '2049633694',\n",
              "   '2171265988',\n",
              "   '2982720039',\n",
              "   '1746680969',\n",
              "   '2567948266',\n",
              "   '2397866408',\n",
              "   '1993845689'],\n",
              "  'title': 'An introduction to variational methods for graphical models'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Thomas O. Jones'],\n",
              "  'date': '1996',\n",
              "  'identifier': '1966912369',\n",
              "  'references': ['2049393915',\n",
              "   '1969335813',\n",
              "   '2186356334',\n",
              "   '2745365264',\n",
              "   '2279326353',\n",
              "   '2790987883',\n",
              "   '2142128621',\n",
              "   '2183447023',\n",
              "   '2799615558',\n",
              "   '2931585265'],\n",
              "  'title': 'Why Satisfied Customers Defect'},\n",
              " {'abstract': 'In a Diversity Coding System, an information source is encoded by a number of encoders. There are a number of decoders, each of which can access a certain subset of the encoders. We study a diversity coding problem in which there are two levels of decoders. The reconstructions of the source by decoders within the same level are identical, and are subject to the same distortion criterion. Our results imply a principle of superposition when the source consists of two independent data streams. Practical codes achieving zero error can easily be constructed for this special case. A class of open problems on this topic is also suggested. >',\n",
              "  'authors': ['R.W. Yeung'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2120085609',\n",
              "  'references': ['1549664537',\n",
              "   '2141420453',\n",
              "   '2058972589',\n",
              "   '1593683169',\n",
              "   '2142901448',\n",
              "   '2099213070',\n",
              "   '2151252184',\n",
              "   '2123095296',\n",
              "   '1995875735',\n",
              "   '2164647192'],\n",
              "  'title': 'Multilevel diversity coding with distortion'},\n",
              " {'abstract': 'The goal of this paper is to present a critical survey of existing literature on human and machine recognition of faces. Machine recognition of faces has several applications, ranging from static matching of controlled photographs as in mug shots matching and credit card verification to surveillance video images. Such applications have different constraints in terms of complexity of processing requirements and thus present a wide range of different technical challenges. Over the last 20 years researchers in psychophysics, neural sciences and engineering, image processing analysis and computer vision have investigated a number of issues related to face recognition by humans and machines. Ongoing research activities have been given a renewed emphasis over the last five years. Existing techniques and systems have been tested on different sets of images of varying complexities. But very little synergism exists between studies in psychophysics and the engineering literature. Most importantly, there exists no evaluation or benchmarking studies using large databases with the image quality that arises in commercial and law enforcement applications In this paper, we first present different applications of face recognition in commercial and law enforcement sectors. This is followed by a brief overview of the literature on face recognition in the psychophysics community. We then present a detailed overview of move than 20 years of research done in the engineering community. Techniques for segmentation/location of the face, feature extraction and recognition are reviewed. Global transform and feature based methods using statistical, structural and neural classifiers are summarized. >',\n",
              "  'authors': ['R. Chellappa 1', ' C.L. Wilson 2', ' S. Sirohey 1'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2115689562',\n",
              "  'references': ['2145023731',\n",
              "   '1997063559',\n",
              "   '2100115174',\n",
              "   '2028310195',\n",
              "   '2098693229',\n",
              "   '3003662786',\n",
              "   '1991848143',\n",
              "   '2098947662',\n",
              "   '2113341759',\n",
              "   '2620619910'],\n",
              "  'title': 'Human and machine recognition of faces: a survey'},\n",
              " {'abstract': 'A simple algorithm for computing the three-dimensional structure of a scene from a correlated pair of perspective projections is described here, when the spatial relationship between the two projections is unknown. This problem is relevant not only to photographic surveying1 but also to binocular vision2, where the non-visual information available to the observer about the orientation and focal length of each eye is much less accurate than the optical information supplied by the retinal images themselves. The problem also arises in monocular perception of motion3, where the two projections represent views which are separated in time as well as space. As Marr and Poggio4 have noted, the fusing of two images to produce a three-dimensional percept involves two distinct processes: the establishment of a 1:1 correspondence between image points in the two views—the ‘correspondence problem’—and the use of the associated disparities for determining the distances of visible elements in the scene. I shall assume that the correspondence problem has been solved; the problem of reconstructing the scene then reduces to that of finding the relative orientation of the two viewpoints.',\n",
              "  'authors': ['H. C. Longuet-Higgins'],\n",
              "  'date': '1987',\n",
              "  'identifier': '1598123022',\n",
              "  'references': ['2164934677', '2048330959', '2056129841', '1603660650'],\n",
              "  'title': 'A computer algorithm for reconstructing a scene from two projections'},\n",
              " {'abstract': 'We present a novel method for generic visual categorization: the problem of identifying the object content of natural images while generalizing across variations inherent to the object class. This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches. We propose and compare two alternative implementations using different classifiers: Naive Bayes and SVM. The main advantages of the method are that it is simple, computationally efficient and intrinsically invariant. We present results for simultaneously classifying seven semantic visual categories. These results clearly demonstrate that the method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information.',\n",
              "  'authors': ['G. Csurka'],\n",
              "  'date': '2004',\n",
              "  'identifier': '1625255723',\n",
              "  'references': ['2148603752',\n",
              "   '2164598857',\n",
              "   '2124386111',\n",
              "   '2177274842',\n",
              "   '2154422044',\n",
              "   '2149684865',\n",
              "   '1676552347',\n",
              "   '2124351082',\n",
              "   '2155511848',\n",
              "   '1484228140'],\n",
              "  'title': 'Visual categorization with bags of keypoints'},\n",
              " {'abstract': 'This article reports an empirical investigation of the accuracy of rules that classify examples on the basis of a single attribute. On most datasets studied, the best of these very simple rules is as accurate as the rules induced by the majority of machine learning systems. The article explores the implications of this finding for machine learning research and applications.',\n",
              "  'authors': ['Robert C. Holte'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2132166479',\n",
              "  'references': ['2149706766',\n",
              "   '2136000097',\n",
              "   '2073308541',\n",
              "   '1604329830',\n",
              "   '1973967548',\n",
              "   '1534707631',\n",
              "   '1927345150',\n",
              "   '1570286060',\n",
              "   '1597910678',\n",
              "   '2146257637'],\n",
              "  'title': 'Very Simple Classification Rules Perform Well on Most Commonly Used Datasets'},\n",
              " {'abstract': \"E-learning is emerging as the new paradigm of modern education. Worldwide, the e-learning market has a growth rate of 35.6%, but failures exist. Little is known about why many users stop their online learning after their initial experience. Previous research done under different task environments has suggested a variety of factors affecting user satisfaction with e-Learning. This study developed an integrated model with six dimensions: learners, instructors, courses, technology, design, and environment. A survey was conducted to investigate the critical factors affecting learners' satisfaction in e-Learning. The results revealed that learner computer anxiety, instructor attitude toward e-Learning, e-Learning course flexibility, e-Learning course quality, perceived usefulness, perceived ease of use, and diversity in assessments are the critical factors affecting learners' perceived satisfaction. The results show institutions how to improve learner satisfaction and further strengthen their e-Learning implementation.\",\n",
              "  'authors': ['Pei-Chen Sun 1',\n",
              "   ' Ray J. Tsai 2',\n",
              "   ' Glenn Finger 3',\n",
              "   ' Yueh-Yang Chen 4',\n",
              "   ' Dowming Yeh 1'],\n",
              "  'date': '2008',\n",
              "  'identifier': '2142801253',\n",
              "  'references': ['1791587663',\n",
              "   '2033943395',\n",
              "   '2109526980',\n",
              "   '2057012437',\n",
              "   '2110506823',\n",
              "   '1548408014',\n",
              "   '3022468393',\n",
              "   '1980569376',\n",
              "   '1488542496',\n",
              "   '2028184439'],\n",
              "  'title': 'What drives a successful e-Learning? An empirical investigation of the critical factors influencing learner satisfaction'},\n",
              " {'abstract': '',\n",
              "  'authors': ['G. Farin'],\n",
              "  'date': '1990',\n",
              "  'identifier': '1551207461',\n",
              "  'references': ['2049981393',\n",
              "   '1969014399',\n",
              "   '2127739279',\n",
              "   '2163324644',\n",
              "   '2055171687',\n",
              "   '2111501452',\n",
              "   '2136063698',\n",
              "   '2145910025',\n",
              "   '1536003180',\n",
              "   '2988817687'],\n",
              "  'title': 'Curves and surfaces for computer aided geometric design'},\n",
              " {'abstract': 'This Perspective considers the influential notion of a canonical (cortical) microcircuit in light of recent theories about neuronal processing. Specifically, we conciliate quantitative studies of microcircuitry and the functional logic of neuronal computations. We revisit the established idea that message passing among hierarchical cortical areas implements a form of Bayesian inference—paying careful attention to the implications for intrinsic connections among neuronal populations. By deriving canonical forms for these computations, one can associate specific neuronal populations with specific computational roles. This analysis discloses a remarkable correspondence between the microcircuitry of the cortical column and the connectivity implied by predictive coding. Furthermore, it provides some intuitive insights into the functional asymmetries between feedforward and feedback connections and the characteristic frequencies over which they operate.',\n",
              "  'authors': ['Andre M. Bastos 1',\n",
              "   ' 2',\n",
              "   ' William Martin Usrey 1',\n",
              "   ' Rick A. Adams 3',\n",
              "   ' George R Mangun 1',\n",
              "   ' Pascal Fries 2',\n",
              "   ' 4',\n",
              "   ' Karl J. Friston 3'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2120079537',\n",
              "  'references': ['2148764920',\n",
              "   '1603307924',\n",
              "   '2104731571',\n",
              "   '2098580305',\n",
              "   '2170814877',\n",
              "   '1999567494',\n",
              "   '2079948225',\n",
              "   '2046198005',\n",
              "   '81409850',\n",
              "   '2094850439'],\n",
              "  'title': 'Canonical Microcircuits for Predictive Coding'},\n",
              " {'abstract': 'This paper proposes an efficient, Bezier curve based approach for the path planning of a mobile robot in a multi-agent robot soccer system. The boundary conditions required for defining the Bezier curve are compatible with the estimated initial state of the robot and the ball. The velocity of the robot along the path is varied continuously to its maximum allowable levels by keeping its acceleration within the safe limits. An obstacle avoidance scheme is incorporated for dealing with the stationary and moving obstacles. When the robot is approaching a moving obstacle in the field, it is decelerated and deviated to another Bezier path leading to the estimated target position. The radius of curvature of the path at its end points is determined from the known terminal velocity constraint of the robot.',\n",
              "  'authors': ['K. G. Jolly 1', ' R. Sreerama Kumar 2', ' R. Vijayakumar 2'],\n",
              "  'date': '2009',\n",
              "  'identifier': '1985196743',\n",
              "  'references': ['2127516259',\n",
              "   '2336918561',\n",
              "   '2111479185',\n",
              "   '2163385431',\n",
              "   '2168938315',\n",
              "   '2116647221',\n",
              "   '2156142530',\n",
              "   '2129209579',\n",
              "   '2075382431',\n",
              "   '1991482882'],\n",
              "  'title': 'A Bezier curve based path planning in a multi-agent robot soccer system without violating the acceleration limits'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Yiming Yang ', ' Xin Liu'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2005422315',\n",
              "  'references': ['2156909104',\n",
              "   '2119821739',\n",
              "   '2149684865',\n",
              "   '2435251607',\n",
              "   '2114535528',\n",
              "   '1550206324',\n",
              "   '2164641162',\n",
              "   '2137346077',\n",
              "   '1620204465',\n",
              "   '1969572066'],\n",
              "  'title': 'A re-examination of text categorization methods'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Paul Bratley ', ' Bennett L. Fox ', ' Linus E. Schrage'],\n",
              "  'date': '1983',\n",
              "  'identifier': '2051277798',\n",
              "  'references': ['2432517183',\n",
              "   '2136796925',\n",
              "   '1505119482',\n",
              "   '2108306139',\n",
              "   '2102360367',\n",
              "   '2134023402',\n",
              "   '2135014481',\n",
              "   '2156391157',\n",
              "   '2011398297',\n",
              "   '1536615069'],\n",
              "  'title': 'A guide to simulation'},\n",
              " {'abstract': 'Ordinal Optimization has emerged as an efficient technique for simulation and optimization. Exponential convergence rates can be achieved in many cases. In this paper, we present a new approach that can further enhance the efficiency of ordinal optimization. Our approach determines a highly efficient number of simulation replications or samples and significantly reduces the total simulation cost. We also compare several different allocation procedures, including a popular two-stage procedure in simulation literature. Numerical testing shows that our approach is much more efficient than all compared methods. The results further indicate that our approach can obtain a speedup factor of higher than 20 above and beyond the speedup achieved by the use of ordinal optimization for a 210-design example.',\n",
              "  'authors': ['Chun-Hung Chen 1',\n",
              "   ' Jianwu Lin 2',\n",
              "   ' Enver Yücesan 3',\n",
              "   ' Stephen E. Chick 4'],\n",
              "  'date': '2000',\n",
              "  'identifier': '1536615069',\n",
              "  'references': ['2102865756',\n",
              "   '2312970899',\n",
              "   '2051277798',\n",
              "   '2254276359',\n",
              "   '2006258746',\n",
              "   '1965288387',\n",
              "   '1525685818',\n",
              "   '2073262880',\n",
              "   '2141024956',\n",
              "   '2165138637'],\n",
              "  'title': 'Simulation Budget Allocation for Further Enhancing theEfficiency of Ordinal Optimization'},\n",
              " {'abstract': 'Introduction to support vector learning roadmap. Part 1 Theory: three remarks on the support vector method of function estimation, Vladimir Vapnik generalization performance of support vector machines and other pattern classifiers, Peter Bartlett and John Shawe-Taylor Bayesian voting schemes and large margin classifiers, Nello Cristianini and John Shawe-Taylor support vector machines, reproducing kernel Hilbert spaces, and randomized GACV, Grace Wahba geometry and invariance in kernel based methods, Christopher J.C. Burges on the annealed VC entropy for margin classifiers - a statistical mechanics study, Manfred Opper entropy numbers, operators and support vector kernels, Robert C. Williamson et al. Part 2 Implementations: solving the quadratic programming problem arising in support vector classification, Linda Kaufman making large-scale support vector machine learning practical, Thorsten Joachims fast training of support vector machines using sequential minimal optimization, John C. Platt. Part 3 Applications: support vector machines for dynamic reconstruction of a chaotic system, Davide Mattera and Simon Haykin using support vector machines for time series prediction, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel. Part 4 Extensions of the algorithm: reducing the run-time complexity in support vector machines, Edgar E. Osuna and Federico Girosi support vector regression with ANOVA decomposition kernels, Mark O. Stitson et al support vector density estimation, Jason Weston et al combining support vector and mathematical programming methods for classification, Bernhard Scholkopf et al.',\n",
              "  'authors': ['Bernhard Schölkopf ',\n",
              "   ' Christopher J. C. Burges ',\n",
              "   ' Alexander J. Smola'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1604938182',\n",
              "  'references': ['2076063813',\n",
              "   '2072128103',\n",
              "   '1964357740',\n",
              "   '1648445109',\n",
              "   '2132870739',\n",
              "   '2108995755',\n",
              "   '2165966284',\n",
              "   '2149298154',\n",
              "   '2147238549',\n",
              "   '2161920802'],\n",
              "  'title': 'Advances in kernel methods: support vector learning'},\n",
              " {'abstract': 'Multiresolution analysis and wavelets provide useful and efficient tools for representing functions at multiple levels of detail. Wavelet representations have been used in a broad range of applications, including image compression, physical simulation, and numerical analysis. In this article, we present a new class of wavelets, based on subdivision surfaces, that radically extends the class of representable functions. Whereas previous two-dimensional methods were restricted to functions difined on R 2 , the subdivision wavelets developed here may be applied to functions defined on compact surfaces of arbitrary topological type. We envision many applications of this work, including continuous level-of-detail control for graphics rendering, compression of geometric models, and acceleration of global illumination algorithms. Level-of-detail control for spherical domains is illustrated using two examples: shape approximation of a polyhedral model, and color approximation of global terrain data.',\n",
              "  'authors': ['Michael Lounsbery ', ' Tony D. DeRose ', ' Joe Warren'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2163324644',\n",
              "  'references': ['2062024414',\n",
              "   '2132984323',\n",
              "   '2011039300',\n",
              "   '2098914003',\n",
              "   '2152328854',\n",
              "   '1970352604',\n",
              "   '2103504761',\n",
              "   '3005363104',\n",
              "   '2100816864',\n",
              "   '1551207461'],\n",
              "  'title': 'Multiresolution analysis for surfaces of arbitrary topological type'},\n",
              " {'abstract': 'In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.',\n",
              "  'authors': ['K. Mikolajczyk 1', ' C. Schmid 2'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2177274842',\n",
              "  'references': ['2151103935',\n",
              "   '2033819227',\n",
              "   '2124386111',\n",
              "   '2163352848',\n",
              "   '2131846894',\n",
              "   '2057175746',\n",
              "   '2154422044',\n",
              "   '2145023731',\n",
              "   '1980911747',\n",
              "   '2145072179'],\n",
              "  'title': 'A performance evaluation of local descriptors'},\n",
              " {'abstract': 'This paper discusses a highly effective heuristic procedure for generating optimum and near-optimum solutions for the symmetric traveling-salesman problem. The procedure is based on a general approach to heuristics that is believed to have wide applicability in combinatorial optimization problems. The procedure produces optimum solutions for all problems tested, \"classical\" problems appearing in the literature, as well as randomly generated test problems, up to 110 cities. Run times grow approximately as n2; in absolute terms, a typical 100-city problem requires less than 25 seconds for one case GE635, and about three minutes to obtain the optimum with above 95 per cent confidence.',\n",
              "  'authors': ['S. Lin ', ' B. W. Kernighan'],\n",
              "  'date': '1973',\n",
              "  'identifier': '2042986967',\n",
              "  'references': ['1975442866',\n",
              "   '2161455936',\n",
              "   '2148673189',\n",
              "   '2009803313',\n",
              "   '1969186119',\n",
              "   '2037455079',\n",
              "   '2056898464',\n",
              "   '2058937865',\n",
              "   '1992928037',\n",
              "   '2106378689'],\n",
              "  'title': 'An Effective Heuristic Algorithm for the Traveling-Salesman Problem'},\n",
              " {'abstract': 'In this survey, we give an overview of invariant interest point detectors, how they evolvd over time, how they work, and what their respective strengths and weaknesses are. We begin with defining the properties of the ideal local feature detector. This is followed by an overview of the literature over the past four decades organized in different categories of feature extraction methods. We then provide a more detailed analysis of a selection of methods which had a particularly significant impact on the research field. We conclude with a summary and promising future research directions.',\n",
              "  'authors': ['Tinne Tuytelaars 1', ' Krystian Mikolajczyk 2'],\n",
              "  'date': '2008',\n",
              "  'identifier': '2042316011',\n",
              "  'references': ['2151103935',\n",
              "   '2164598857',\n",
              "   '1677409904',\n",
              "   '2119605622',\n",
              "   '2124386111',\n",
              "   '2177274842',\n",
              "   '2121947440',\n",
              "   '2131846894',\n",
              "   '2128017662',\n",
              "   '2128272608'],\n",
              "  'title': 'Local Invariant Feature Detectors: A Survey'},\n",
              " {'abstract': 'In this paper a new sequential decoding algorithm is introduced that uses stack storage at the receiver. It is much simpler to describe and analyze than the Fano algorithm, and is about six times faster than the latter at transmission rates equal to Rcomp the rate below which the average number of decoding steps is bounded by a constant. Practical problems connected with implementing the stack algorithm are discussed and a scheme is described that facilitates satisfactory performance even with limited stack storage capacity. Preliminary simulation results estimating the decoding effort and the needed stack siazree presented.',\n",
              "  'authors': ['F. Jelinek'],\n",
              "  'date': '1969',\n",
              "  'identifier': '2035227369',\n",
              "  'references': ['1577906631',\n",
              "   '2087362480',\n",
              "   '2128700225',\n",
              "   '2038058830',\n",
              "   '1496151908',\n",
              "   '2223581789',\n",
              "   '585928584',\n",
              "   '2004767718'],\n",
              "  'title': 'Fast sequential decoding algorithm using a stack'},\n",
              " {'abstract': 'Single-word vector space models have been very successful at learning lexical information. However, they cannot capture the compositional meaning of longer phrases, preventing them from a deeper understanding of language. We introduce a recursive neural network (RNN) model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Our model assigns a vector and a matrix to every node in a parse tree: the vector captures the inherent meaning of the constituent, while the matrix captures how it changes the meaning of neighboring words or phrases. This matrix-vector RNN can learn the meaning of operators in propositional logic and natural language. The model obtains state of the art performance on three different experiments: predicting fine-grained sentiment distributions of adverb-adjective pairs; classifying sentiment labels of movie reviews and classifying semantic relationships such as cause-effect or topic-message between nouns using the syntactic path between them.',\n",
              "  'authors': ['Richard Socher ',\n",
              "   ' Brody Huval ',\n",
              "   ' Christopher D. Manning ',\n",
              "   ' Andrew Y. Ng'],\n",
              "  'date': '2012',\n",
              "  'identifier': '1889268436',\n",
              "  'references': ['2251939518',\n",
              "   '2117130368',\n",
              "   '1423339008',\n",
              "   '71795751',\n",
              "   '1662133657',\n",
              "   '2097606805',\n",
              "   '2103305545',\n",
              "   '2163455955',\n",
              "   '1984052055',\n",
              "   '2151048449'],\n",
              "  'title': 'Semantic Compositionality through Recursive Matrix-Vector Spaces'},\n",
              " {'abstract': '1. An Introduction to the Use of Finite Element Procedures. 2. Vectors, Matrices and Tensors. 3. Some Basic Concepts of Engineering Analysis and an Introduction to the Finite Element Methods. 4. Formulation of the Finite Element Method -- Linear Analysis in Solid and Structural Mechanics. 5. Formulation and Calculation of Isoparametric Finite Element Matrices. 6. Finite Element Nonlinear Analysis in Solid and Structural Mechanics. 7. Finite Element Analysis of Heat Transfer, Field Problems, and Incompressible Fluid Flows. 8. Solution of Equilibrium Equations in State Analysis. 9. Solution of Equilibrium Equations in Dynamic Analysis. 10. Preliminaries to the Solution of Eigenproblems. 11. Solution Methods for Eigenproblems. 12. Implementation of the Finite Element Method. References. Index.',\n",
              "  'authors': ['Klaus-Jürgen Bathe'],\n",
              "  'date': '1995',\n",
              "  'identifier': '1573186872',\n",
              "  'references': ['1516111018',\n",
              "   '2052690618',\n",
              "   '2166575557',\n",
              "   '2320998174',\n",
              "   '2160947254',\n",
              "   '2058084172',\n",
              "   '2139933850',\n",
              "   '2145804351',\n",
              "   '2130906772',\n",
              "   '1966753479'],\n",
              "  'title': 'Finite Element Procedures'},\n",
              " {'abstract': 'ObjectiveTo compare hepatitis C virus (HCV) load in patients infected with HCV alone and those coinfected with HIV, and to evaluate the antibody response to HCV in the case of HIV infection.DesignPatients coinfected with both HCV and HIV have been shown to develop hepatic changes more rapidly, which',\n",
              "  'authors': ['Cribier B ',\n",
              "   ' Rey D ',\n",
              "   ' Schmitt C ',\n",
              "   ' Lang Jm ',\n",
              "   ' Kirn A ',\n",
              "   ' Stoll-Keller F'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2082990787',\n",
              "  'references': ['2333452860',\n",
              "   '2117261241',\n",
              "   '2156380404',\n",
              "   '2099847630',\n",
              "   '2059268470',\n",
              "   '2051126700',\n",
              "   '1983314702',\n",
              "   '1970596268',\n",
              "   '2094883696',\n",
              "   '2118108577'],\n",
              "  'title': 'High hepatitis C viraemia and impaired antibody response in patients coinfected with HIV'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Richard P. Lippmann'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2042264548',\n",
              "  'references': ['2156562940',\n",
              "   '2017224880',\n",
              "   '2536517113',\n",
              "   '2132832266',\n",
              "   '2016812413',\n",
              "   '2015634532',\n",
              "   '2113229797',\n",
              "   '3001909141',\n",
              "   '35336130',\n",
              "   '1973070179'],\n",
              "  'title': 'An introduction to computing with neural nets'},\n",
              " {'abstract': 'We develop a face recognition algorithm which is insensitive to large variation in lighting direction and facial expression. Taking a pattern classification approach, we consider each pixel in an image as a coordinate in a high-dimensional space. We take advantage of the observation that the images of a particular face, under varying illumination but fixed pose, lie in a 3D linear subspace of the high dimensional image space-if the face is a Lambertian surface without shadowing. However, since faces are not truly Lambertian surfaces and do indeed produce self-shadowing, images will deviate from this linear subspace. Rather than explicitly modeling this deviation, we linearly project the image into a subspace in a manner which discounts those regions of the face with large deviation. Our projection method is based on Fisher\\'s linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variation in lighting and facial expressions. The eigenface technique, another method based on linearly projecting the image space to a low dimensional subspace, has similar computational requirements. Yet, extensive experimental results demonstrate that the proposed \"Fisherface\" method has error rates that are lower than those of the eigenface technique for tests on the Harvard and Yale face databases.',\n",
              "  'authors': ['P.N. Belhumeur ', ' J.P. Hespanha ', ' D.J. Kriegman'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2121647436',\n",
              "  'references': ['2138451337',\n",
              "   '2098693229',\n",
              "   '2123977795',\n",
              "   '2115689562',\n",
              "   '3017143921',\n",
              "   '2098947662',\n",
              "   '2113341759',\n",
              "   '2740373864',\n",
              "   '2130259898',\n",
              "   '2159173611'],\n",
              "  'title': 'Eigenfaces vs. Fisherfaces: recognition using class specific linear projection'},\n",
              " {'abstract': 'At any one moment, many neuronal groups in our brain are active. Microelectrode recordings have characterized the activation of single neurons and fMRI has unveiled brain-wide activation patterns. Now it is time to understand how the many active neuronal groups interact with each other and how their communication is flexibly modulated to bring about our cognitive dynamics. I hypothesize that neuronal communication is mechanistically subserved by neuronal coherence. Activated neuronal groups oscillate and thereby undergo rhythmic excitability fluctuations that produce temporal windows for communication. Only coherently oscillating neuronal groups can interact effectively, because their communication windows for input and for output are open at the same times. Thus, a flexible pattern of coherence defines a flexible communication structure, which subserves our cognitive flexibility.',\n",
              "  'authors': ['Pascal Fries'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2104731571',\n",
              "  'references': ['2114104729',\n",
              "   '2170814877',\n",
              "   '2067393309',\n",
              "   '2079948225',\n",
              "   '2112332687',\n",
              "   '2159353177',\n",
              "   '2133280087',\n",
              "   '2170478537',\n",
              "   '2172274087',\n",
              "   '2085319761'],\n",
              "  'title': 'A mechanism for cognitive dynamics: neuronal communication through neuronal coherence'},\n",
              " {'abstract': 'This paper investigates two fundamental problems in computer vision: contour detection and image segmentation. We present state-of-the-art algorithms for both of these tasks. Our contour detector combines multiple local cues into a globalization framework based on spectral clustering. Our segmentation algorithm consists of generic machinery for transforming the output of any contour detector into a hierarchical region tree. In this manner, we reduce the problem of image segmentation to that of contour detection. Extensive experimental evaluation demonstrates that both our contour detection and segmentation methods significantly outperform competing algorithms. The automatically generated hierarchical segmentations can be interactively refined by user-specified annotations. Computation at multiple image resolutions provides a means of coupling our system to recognition applications.',\n",
              "  'authors': ['P Arbeláez 1', ' M Maire 2', ' C Fowlkes 3', ' J Malik 1'],\n",
              "  'date': '2011',\n",
              "  'identifier': '2110158442',\n",
              "  'references': ['2121947440',\n",
              "   '2067191022',\n",
              "   '2116040950',\n",
              "   '2124351162',\n",
              "   '1999478155',\n",
              "   '2145023731',\n",
              "   '1578099820',\n",
              "   '2169551590',\n",
              "   '2121927366',\n",
              "   '2109200236'],\n",
              "  'title': 'Contour Detection and Hierarchical Image Segmentation'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Justin Gilmer 1',\n",
              "   ' Samuel S. Schoenholz 2',\n",
              "   ' Patrick F. Riley 1',\n",
              "   ' Oriol Vinyals 1',\n",
              "   ' George E. Dahl 1'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2606780347',\n",
              "  'references': ['2962711740',\n",
              "   '3017271475',\n",
              "   '2907492528',\n",
              "   '2594183968',\n",
              "   '2786016794',\n",
              "   '2963281829',\n",
              "   '2883583109',\n",
              "   '3047863327',\n",
              "   '2890273554',\n",
              "   '3100078588'],\n",
              "  'title': 'Neural Message Passing for Quantum Chemistry'},\n",
              " {'abstract': \"This paper introduces a general Bayesian framework for obtaining sparse solutions to regression and classification tasks utilising models linear in the parameters. Although this framework is fully general, we illustrate our approach with a particular specialisation that we denote the 'relevance vector machine' (RVM), a model of identical functional form to the popular and state-of-the-art 'support vector machine' (SVM). We demonstrate that by exploiting a probabilistic Bayesian learning framework, we can derive accurate prediction models which typically utilise dramatically fewer basis functions than a comparable SVM while offering a number of additional advantages. These include the benefits of probabilistic predictions, automatic estimation of 'nuisance' parameters, and the facility to utilise arbitrary basis functions (e.g. non-'Mercer' kernels). We detail the Bayesian framework and associated learning algorithm for the RVM, and give some illustrative examples of its application along with some comparative benchmarks. We offer some explanation for the exceptional degree of sparsity obtained, and discuss and demonstrate some of the advantageous features, and potential extensions, of Bayesian relevance learning.\",\n",
              "  'authors': ['Michael E. Tipping'],\n",
              "  'date': '2001',\n",
              "  'identifier': '1648445109',\n",
              "  'references': ['2156909104',\n",
              "   '2148603752',\n",
              "   '1554663460',\n",
              "   '2078204800',\n",
              "   '2117812871',\n",
              "   '2087347434',\n",
              "   '1604938182',\n",
              "   '2102201073',\n",
              "   '1618905105',\n",
              "   '1988520084'],\n",
              "  'title': 'Sparse bayesian learning and the relevance vector machine'},\n",
              " {'abstract': 'It is shown that for many problems, particularly those in which the input data are ill-conditioned and the computation can be specified in a relative manner, biological solutions are many orders of magnitude more effective than those using digital methods. This advantage can be attributed principally to the use of elementary physical phenomena as computational primitives, and to the representation of information by the relative values of analog signals rather than by the absolute values of digital signals. This approach requires adaptive techniques to mitigate the effects of component differences. This kind of adaptation leads naturally to systems that learn about their environment. Large-scale adaptive analog systems are more robust to component degradation and failure than are more conventional systems, and they use far less power. For this reason, adaptive analog technology can be expected to utilize the full potential of wafer-scale silicon fabrication. >',\n",
              "  'authors': ['C. Mead'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2163630896',\n",
              "  'references': ['2022060843', '1987449940', '2041181954', '1978986026'],\n",
              "  'title': 'Neuromorphic electronic systems'},\n",
              " {'abstract': '',\n",
              "  'authors': ['J. A. Feldman ', ' D. H. Ballard'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2112325651',\n",
              "  'references': ['2118051273',\n",
              "   '2046863527',\n",
              "   '1507849272',\n",
              "   '2176028050',\n",
              "   '2089597841',\n",
              "   '1497599070',\n",
              "   '1731244441',\n",
              "   '2118373646',\n",
              "   '2004131797',\n",
              "   '2125360619'],\n",
              "  'title': 'Connectionist models and their properties'},\n",
              " {'abstract': 'This paper briefly reviews in a self-contained manner the perspective transformation governing 2-D images taken of a 3-D world. Using coordinates of points, direction cosines of lines on the image, or 3-D models of objects, relationships are developed that permit determination of the perspective transformation parameters in closed form, as well as the 3-D coordinates of objects. Contents. I, Introduction; I.1, 3-D Scene Analysis. II, The Perspective Transformation in 2-D. III, The Perspective Transformation in 3-D. IV, Properties of the 3-D Perspective Transformation; IV.1, Lines to Lines; IV.2, Vanishing Points. V, Image Coordinates to 3-D Coordinates; V.1, Camera Geometry; V.2, Vanishing Point to Camera Parameters; V.3, The Inverse Projective Transformation; V.4, Using the Inverse Perspective Transformation; V.5, Using the Perspective Transformation; V.6, Models. VI, Example; VI.1, Example 1; VI.2, Example 2. Acknowledgement. References.',\n",
              "  'authors': ['Robert M Haralick'],\n",
              "  'date': '1980',\n",
              "  'identifier': '2070079950',\n",
              "  'references': ['3017143921', '2108729336', '1558195771', '2116504721'],\n",
              "  'title': 'Using perspective transformations in scene analysis'},\n",
              " {'abstract': 'Based on several severe air pollution events,1-3 a temporal correlation between extremely high concentrations of particulate and sulfur oxide air pollution and acute increases in mortality was well established by the 1970s. Subsequently, epidemiological studies published between 1989 and 1996 reported health effects at unexpectedly low concentrations of particulate air pollution.4 The convergence of data from these studies, while controversial,5 prompted serious reconsideration of standards and health guidelines6-10 and led to a long-term research program designed to analyze health-related effects due to particulate pollution.11-13 In 1997, the Environmental Protection Agency adopted new ambient air quality standards that would impose regulatory limits on fine particles measuring less than 2.5 μm in diameter (PM2.5). These new standards were challenged by industry groups, blocked by a federal appeals court, but ultimately upheld by the US Supreme Court.14 Although most of the recent epidemiological research has focused on effects of short-term exposures, several studies suggest that long-term exposure may be more important in terms of overall public health.4 The new standards for long-term exposure to PM2.5 were originally based primarily on 2 prospective cohort studies,15,16 which evaluated the effects of long-term pollution exposure on mortality. Both of these studies have been subjected to much scrutiny,5 including an extensive independent audit and reanalysis of the original data.17 The larger of these 2 studies linked individual risk factor and vital status data with national ambient air pollution data.16 Our analysis uses data from the larger study and (1) doubles the follow-up time to more than 16 years and triples the number of deaths; (2) substantially expands exposure data, including gaseous copollutant data and new PM2.5 data, which have been collected since the promulgation of the new air quality standards; (3) improves control of occupational exposures; (4) incorporates dietary variables that account for total fat consumption, and consumption of vegetables, citrus, and high-fiber grains; and (5) uses recent advances in statistical modeling, including the incorporation of random effects and nonpara-metric spatial smoothing components in the Cox proportional hazards model.',\n",
              "  'authors': ['C. Arden Pope 1',\n",
              "   ' Richard T. Burnett 2',\n",
              "   ' Michael J. Thun 2',\n",
              "   ' Eugenia E. Calle ',\n",
              "   ' Daniel Krewski ',\n",
              "   ' Kazuhiko Ito ',\n",
              "   ' George D. Thurston'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2166604768',\n",
              "  'references': ['2797583072',\n",
              "   '2318698569',\n",
              "   '2323202746',\n",
              "   '2134099620',\n",
              "   '2146137933',\n",
              "   '2335637623',\n",
              "   '2024081693',\n",
              "   '2166163519',\n",
              "   '2163899311',\n",
              "   '2057968703'],\n",
              "  'title': 'Lung Cancer, Cardiopulmonary Mortality, and Long-term Exposure to Fine Particulate Air Pollution'},\n",
              " {'abstract': 'Among the major remaining challenges for generative adversarial networks (GANs) is the capacity to synthesize globally and locally coherent images with object shapes and textures indistinguishable from real images. To target this issue we propose an alternative U-Net based discriminator architecture, borrowing the insights from the segmentation literature. The proposed U-Net based architecture allows to provide detailed per-pixel feedback to the generator while maintaining the global coherence of synthesized images, by providing the global image feedback as well. Empowered by the per-pixel response of the discriminator, we further propose a per-pixel consistency regularization technique based on the CutMix data augmentation, encouraging the U-Net discriminator to focus more on semantic and structural changes between real and fake images. This improves the U-Net discriminator training, further enhancing the quality of generated samples. The novel discriminator improves over the state of the art in terms of the standard distribution and image quality metrics, enabling the generator to synthesize images with varying structure, appearance and levels of detail, maintaining global and local realism. Compared to the BigGAN baseline, we achieve an average improvement of 2.7 FID points across FFHQ, CelebA, and the proposed COCO-Animals dataset.',\n",
              "  'authors': ['Edgar Schonfeld 1', ' Bernt Schiele 2', ' Anna Khoreva 1'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3035687950',\n",
              "  'references': ['2964121744',\n",
              "   '1901129140',\n",
              "   '2099471712',\n",
              "   '1861492603',\n",
              "   '2963073614',\n",
              "   '2963684088',\n",
              "   '2963881378',\n",
              "   '2963373786',\n",
              "   '2962879692',\n",
              "   '1834627138'],\n",
              "  'title': 'A U-Net Based Discriminator for Generative Adversarial Networks'},\n",
              " {'abstract': 'We have developed three computer programs for comparisons of protein and DNA sequences. They can be used to search sequence data bases, evaluate similarity scores, and identify periodic structures based on local sequence similarity. The FASTA program is a more sensitive derivative of the FASTP program, which can be used to search protein or DNA sequence data bases and can compare a protein sequence to a DNA sequence data base by translating the DNA data base as it is searched. FASTA includes an additional step in the calculation of the initial pairwise similarity score that allows multiple regions of similarity to be joined to increase the score of related sequences. The RDF2 program can be used to evaluate the significance of similarity scores using a shuffling method that preserves local sequence composition. The LFASTA program can display all the regions of local similarity between two sequences with scores greater than a threshold, using the same scoring parameters and a similar alignment algorithm; these local similarities can be displayed as a \"graphic matrix\" plot or as individual alignments. In addition, these programs have been generalized to allow comparison of DNA or protein sequences based on a variety of alternative scoring matrices.',\n",
              "  'authors': ['William R. Pearson ', ' David J. Lipman'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2015292449',\n",
              "  'references': ['2601913882'],\n",
              "  'title': 'Improved tools for biological sequence comparison.'},\n",
              " {'abstract': \"Abstract: Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks. Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.\",\n",
              "  'authors': ['Christian Szegedy 1',\n",
              "   ' Wojciech Zaremba 2',\n",
              "   ' Ilya Sutskever 1',\n",
              "   ' Joan Bruna 2',\n",
              "   ' Dumitru Erhan 1',\n",
              "   ' Ian Goodfellow 3',\n",
              "   ' Rob Fergus 2',\n",
              "   ' 4'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2964153729',\n",
              "  'references': ['2618530766',\n",
              "   '2102605133',\n",
              "   '1614298861',\n",
              "   '2108598243',\n",
              "   '2160815625',\n",
              "   '2072128103',\n",
              "   '2120419212',\n",
              "   '2206858481',\n",
              "   '2120480077',\n",
              "   '2150165932'],\n",
              "  'title': 'Intriguing properties of neural networks'},\n",
              " {'abstract': '',\n",
              "  'authors': ['S. L. Lauritzen 1', ' D. J. Spiegelhalter 2'],\n",
              "  'date': '1990',\n",
              "  'identifier': '1593793857',\n",
              "  'references': ['1498436455',\n",
              "   '1997063559',\n",
              "   '2797148637',\n",
              "   '2155322595',\n",
              "   '2138162238',\n",
              "   '2143075689',\n",
              "   '2143474538',\n",
              "   '2166325326',\n",
              "   '1516964807',\n",
              "   '2113677269'],\n",
              "  'title': 'Local computations with probabilities on graphical structures and their application to expert systems'},\n",
              " {'abstract': 'In this paper, we discuss experiments applying machine learning techniques to the task of confusion set disambiguation, using three orders of magnitude more training data than has previously been used for any disambiguation-in-string-context problem. In an attempt to determine when current learning methods will cease to benefit from additional training data, we analyze residual errors made by learners when issues of sparse data have been significantly mitigated. Finally, in the context of our results, we discuss possible directions for the empirical natural language research community.',\n",
              "  'authors': ['Michele Banko ', ' Eric Brill'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2068017609',\n",
              "  'references': ['2097089247',\n",
              "   '1977182536',\n",
              "   '2156202195',\n",
              "   '2118996379',\n",
              "   '1953828586',\n",
              "   '2130851608',\n",
              "   '1648417313',\n",
              "   '1519443010',\n",
              "   '2119966617',\n",
              "   '1988842251'],\n",
              "  'title': 'Mitigating the paucity-of-data problem: exploring the effect of training corpus size on classifier performance for natural language processing'},\n",
              " {'abstract': 'A method is presented for the representation of (pictures of) faces. Within a specified framework the representation is ideal. This results in the characterization of a face, to within an error bound, by a relatively low-dimensional vector. The method is illustrated in detail by the use of an ensemble of pictures taken for this purpose.',\n",
              "  'authors': ['L. Sirovich ', ' M. Kirby'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2130259898',\n",
              "  'references': ['2135346934', '1587863748', '1535031115', '3040267042'],\n",
              "  'title': 'Low-dimensional procedure for the characterization of human faces'},\n",
              " {'abstract': 'This survey provides an overview of higher-order tensor decompositions, their applications, and available software. A tensor is a multidimensional or $N$-way array. Decompositions of higher-order tensors (i.e., $N$-way arrays with $N \\\\geq 3$) have applications in psycho-metrics, chemometrics, signal processing, numerical linear algebra, computer vision, numerical analysis, data mining, neuroscience, graph analysis, and elsewhere. Two particular tensor decompositions can be considered to be higher-order extensions of the matrix singular value decomposition: CANDECOMP/PARAFAC (CP) decomposes a tensor as a sum of rank-one tensors, and the Tucker decomposition is a higher-order form of principal component analysis. There are many other tensor decompositions, including INDSCAL, PARAFAC2, CANDELINC, DEDICOM, and PARATUCK2 as well as nonnegative variants of all of the above. The N-way Toolbox, Tensor Toolbox, and Multilinear Engine are examples of software packages for working with tensors.',\n",
              "  'authors': ['Tamara G. Kolda ', ' Brett W. Bader'],\n",
              "  'date': '2009',\n",
              "  'identifier': '2024165284',\n",
              "  'references': ['1902027874',\n",
              "   '2798909945',\n",
              "   '2099741732',\n",
              "   '2147152072',\n",
              "   '2013912476',\n",
              "   '2090208105',\n",
              "   '2752853835',\n",
              "   '2075665712',\n",
              "   '2072773380',\n",
              "   '2113722075'],\n",
              "  'title': 'Tensor Decompositions and Applications'},\n",
              " {'abstract': \"Abstract : Scientific discovery is a complex activity involving many different components. Our interest in discovery has led us to construct four artificial intelligence systems that address different facets of this process. BACON.6 focuses on discovering empirical laws that summarize numerical data. This program searches a space of data and a space of numerical laws, and includes methods for postulating intrinsic properties and noting common divisors. GLAUBER is concerned with discovering laws of qualitative structure, such as the hypothesis that acids react with alkalis to form salts. It searches the space of qualitative laws, using evaluation functions to focus attention on laws covering the greatest number of observed facts. STAHL attempts to determine the components of substances involved in reactions, and has been used to model the reasoning that led to the phlogiston theory. This system searches through the space of componential models, using heuristics to make plausible inferences. The final system, DALTON, is concerned with formulating structural models of chemical reactions. It searches the space of possible models, considering simple models before more complex ones and using a conservation assumption to constrain possibilities. While each of these discovery systems is interesting in its own right, we are also exploring ways in which the systems can interact to help direct each other's search processes. (Author)\",\n",
              "  'authors': ['Patrick W. Langley ',\n",
              "   ' Jan Zytkow ',\n",
              "   ' Herbert Alexander Simon ',\n",
              "   ' Gary L. Bradshaw'],\n",
              "  'date': '1984',\n",
              "  'identifier': '2146600388',\n",
              "  'references': ['2026161499',\n",
              "   '2333196491',\n",
              "   '1527883571',\n",
              "   '1483128843',\n",
              "   '2094848746',\n",
              "   '2034902322',\n",
              "   '197716421',\n",
              "   '1520441768',\n",
              "   '168224385',\n",
              "   '41262972'],\n",
              "  'title': 'The Search for Regularity: Four Aspects of Scientific Discovery'},\n",
              " {'abstract': \"To interpret visual-motion events, the underlying computation must involve internal reference to the motion status of the observer's head. We show here that layer 6 (L6) principal neurons in mouse primary visual cortex (V1) receive a diffuse, vestibular-mediated synaptic input that signals the angular velocity of horizontal rotation. Behavioral and theoretical experiments indicate that these inputs, distributed over a network of 100 L6 neurons, provide both a reliable estimate and, therefore, physiological separation of head-velocity signals. During head rotation in the presence of visual stimuli, L6 neurons exhibit postsynaptic responses that approximate the arithmetic sum of the vestibular and visual-motion response. Functional input mapping reveals that these internal motion signals arrive into L6 via a direct projection from the retrosplenial cortex. We therefore propose that visual-motion processing in V1 L6 is multisensory and contextually dependent on the motion status of the animal's head.\",\n",
              "  'authors': ['Mateo Vélez-Fort ',\n",
              "   ' Edward F. Bracey ',\n",
              "   ' Sepiedeh Keshavarzi ',\n",
              "   ' Charly V. Rousseau ',\n",
              "   ' Lee Cossell ',\n",
              "   ' Stephen C. Lenzi ',\n",
              "   ' Molly Strom ',\n",
              "   ' Troy W. Margrie'],\n",
              "  'date': '2018',\n",
              "  'identifier': '2789919621',\n",
              "  'references': ['2171332611',\n",
              "   '1975389666',\n",
              "   '2767493192',\n",
              "   '2131938193',\n",
              "   '2123213117',\n",
              "   '1972869628',\n",
              "   '2054870083',\n",
              "   '2186584449',\n",
              "   '2097237250',\n",
              "   '2164826784'],\n",
              "  'title': 'A Circuit for Integration of Head- and Visual-Motion Signals in Layer 6 of Mouse Primary Visual Cortex.'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Dana Harry Ballard ', ' Christopher M. Brown'],\n",
              "  'date': '1982',\n",
              "  'identifier': '2740373864',\n",
              "  'references': ['2121647436',\n",
              "   '2124351162',\n",
              "   '1995903777',\n",
              "   '1504381788',\n",
              "   '2914885528',\n",
              "   '2169805405',\n",
              "   '2123921160',\n",
              "   '1518138188',\n",
              "   '2167501464'],\n",
              "  'title': 'Computer Vision'},\n",
              " {'abstract': 'The COVID-19 pandemic demands the rapid identification of drug-repurpusing candidates. In the past decade, network medicine had developed a framework consisting of a series of quantitative approaches and predictive tools to study host-pathogen interactions, unveil the molecular mechanisms of the infection, identify comorbidities as well as rapidly detect drug repurpusing candidates. Here, we adapt the network-based toolset to COVID-19, recovering the primary pulmonary manifestations of the virus in the lung as well as observed comorbidities associated with cardiovascular diseases. We predict that the virus can manifest itself in other tissues, such as the reproductive system, and brain regions, moreover we predict neurological comorbidities. We build on these findings to deploy three network-based drug repurposing strategies, relying on network proximity, diffusion, and AI-based metrics, allowing to rank all approved drugs based on their likely efficacy for COVID-19 patients, aggregate all predictions, and, thereby to arrive at 81 promising repurposing candidates. We validate the accuracy of our predictions using drugs currently in clinical trials, and an expression-based validation of selected candidates suggests that these drugs, with known toxicities and side effects, could be moved to clinical trials rapidly.',\n",
              "  'authors': ['Deisy Morselli Gysi 1',\n",
              "   ' 2',\n",
              "   ' Ítalo Do Valle 1',\n",
              "   ' Marinka Zitnik 3',\n",
              "   ' Asher Ameli 1',\n",
              "   ' Xiao Gan 1',\n",
              "   ' 2',\n",
              "   ' Onur Varol 1',\n",
              "   ' Helia Sanchez 4',\n",
              "   ' Rebecca Marlene Baron 2',\n",
              "   ' Dina Ghiassian 4',\n",
              "   ' Joseph Loscalzo 2',\n",
              "   ' Albert-László Barabási 1',\n",
              "   ' 2',\n",
              "   ' 5'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3017271475',\n",
              "  'references': ['3001118548',\n",
              "   '2964121744',\n",
              "   '3005079553',\n",
              "   '3002108456',\n",
              "   '2095705004',\n",
              "   '3004280078',\n",
              "   '2101234009',\n",
              "   '3009912996',\n",
              "   '3007940623',\n",
              "   '1533861849'],\n",
              "  'title': 'Network Medicine Framework for Identifying Drug Repurposing Opportunities for COVID-19'},\n",
              " {'abstract': \"A new definition of scale-space is suggested, and a class of algorithms used to realize a diffusion process is introduced. The diffusion coefficient is chosen to vary spatially in such a way as to encourage intraregion smoothing rather than interregion smoothing. It is shown that the 'no new maxima should be generated at coarse scales' property of conventional scale space is preserved. As the region boundaries in the approach remain sharp, a high-quality edge detector which successfully exploits global information is obtained. Experimental results are shown on a number of images. Parallel hardware implementations are made feasible because the algorithm involves elementary, local operations replicated over the image. >\",\n",
              "  'authors': ['P. Perona ', ' J. Malik'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2150134853',\n",
              "  'references': ['2145023731',\n",
              "   '1997063559',\n",
              "   '2109863423',\n",
              "   '2114487471',\n",
              "   '2913192828',\n",
              "   '2022735534',\n",
              "   '2133155955',\n",
              "   '2002312729',\n",
              "   '1968245656',\n",
              "   '1973976434'],\n",
              "  'title': 'Scale-space and edge detection using anisotropic diffusion'},\n",
              " {'abstract': 'A method of determining the similarity of nouns on the basis of a metric derived from the distribution of subject, verb and object in a large text corpus is described. The resulting quasi-semantic classification of nouns demonstrates the plausibility of the distributional hypothesis, and has potential application to a variety of tasks, including automatic indexing, resolving nominal compounds, and determining the scope of modification.',\n",
              "  'authors': ['Donald Hindle'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2123084125',\n",
              "  'references': ['2099247782',\n",
              "   '1593045043',\n",
              "   '1981724541',\n",
              "   '2034274945',\n",
              "   '2111108424',\n",
              "   '1496719572',\n",
              "   '1528321674',\n",
              "   '2052690453'],\n",
              "  'title': 'NOUN CLASSIFICATION FROM PREDICATE-ARGUMENT STRUCTURES'},\n",
              " {'abstract': 'Genetic and physical maps for the 16 chromosomes of Saccharomyces cerevisiae are presented. The genetic map is the result of 40 years of genetic analysis. The physical map was produced from the results of an international systematic sequencing effort. The data for the maps are accessible electronically from the Saccharomyces Genome Database (SGD: http://genome-www.stanford.edu/Saccharomyces/).',\n",
              "  'authors': ['J. Michael Cherry 1',\n",
              "   ' Catherine Ball 1',\n",
              "   ' Shuai Weng 1',\n",
              "   ' Gail Juvik 1',\n",
              "   ' Rita Schmidt 1',\n",
              "   ' Caroline Adler 1',\n",
              "   ' Barbara Dunn 1',\n",
              "   ' Selina Dwight 1',\n",
              "   ' Linda Riles 2',\n",
              "   ' Robert K. Mortimer 3',\n",
              "   ' David Botstein 1'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2753765968',\n",
              "  'references': ['2153033225', '2051530515'],\n",
              "  'title': 'Genetic and physical maps of Saccharomyces cerevisiae'},\n",
              " {'abstract': \"A linear technique for combining equalization and coset codes on partial response channels with additive white Gaussian noise is developed. The technique, vector coding, uses a set of transmit filters or 'vectors' to partition the channel into an independent set of parallel intersymbol interference (ISI)-free channels for any given finite (or infinite) block length. The optimal transmit vectors for such channel partitioning are shown to be the eigenvectors of the channel covariance matrix for the specified block length, and the gains of the individual channels are the eigenvalues. An optimal bit allocation and energy distribution, are derived for the set of parallel channels, under an accurate extension of the continuous approximation for power in optimal multidimensional signal sets for constellations with unequal signal spacing in different dimensions. Examples are presented that demonstrate performance advantages with respect to zero-forcing decision feedback methods that use the same coset code on the same partial response channel. Only resampling the channel at an optimal rate and assuming no errors in the feedback path will bring the performance of the decision feedback methods up to the level of the vector coded system. >\",\n",
              "  'authors': ['S. Kasturia ', ' J.T. Aslanis ', ' J.M. Cioffi'],\n",
              "  'date': '1990',\n",
              "  'identifier': '1983632787',\n",
              "  'references': ['2165205968',\n",
              "   '2142901448',\n",
              "   '2112544308',\n",
              "   '2165406488',\n",
              "   '2134938338',\n",
              "   '2131086249',\n",
              "   '2060000375',\n",
              "   '2168226105',\n",
              "   '2139399084',\n",
              "   '2017458912'],\n",
              "  'title': 'Vector coding for partial response channels'},\n",
              " {'abstract': 'Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.',\n",
              "  'authors': ['R. Qi Charles ',\n",
              "   ' Hao Su ',\n",
              "   ' Mo Kaichun ',\n",
              "   ' Leonidas J. Guibas'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2560609797',\n",
              "  'references': ['603908379',\n",
              "   '1920022804',\n",
              "   '1644641054',\n",
              "   '2211722331',\n",
              "   '2160821342',\n",
              "   '2964311892',\n",
              "   '2962731536',\n",
              "   '2460657278',\n",
              "   '2099606917',\n",
              "   '2553307952'],\n",
              "  'title': 'PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Peter W. Foltz ', ' Susan T. Dumais'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2056029990',\n",
              "  'references': ['2147152072',\n",
              "   '1956559956',\n",
              "   '2000672666',\n",
              "   '2106365165',\n",
              "   '2078875869',\n",
              "   '2058616517',\n",
              "   '2083605078',\n",
              "   '2165978089',\n",
              "   '2025172185',\n",
              "   '2032840958'],\n",
              "  'title': 'Personalized information delivery: an analysis of information filtering methods'},\n",
              " {'abstract': 'Both in science and in practical affairs we reason by combining facts only inconclusively supported by evidence. Building on an abstract understanding of this process of combination, this book constructs a new theory of epistemic probability. The theory draws on the work of A. P. Dempster but diverges from Depster\\'s viewpoint by identifying his \"lower probabilities\" as epistemic probabilities and taking his rule for combining \"upper and lower probabilities\" as fundamental. The book opens with a critique of the well-known Bayesian theory of epistemic probability. It then proceeds to develop an alternative to the additive set functions and the rule of conditioning of the Bayesian theory: set functions that need only be what Choquet called \"monotone of order of infinity.\" and Dempster\\'s rule for combining such set functions. This rule, together with the idea of \"weights of evidence,\" leads to both an extensive new theory and a better understanding of the Bayesian theory. The book concludes with a brief treatment of statistical inference and a discussion of the limitations of epistemic probability. Appendices contain mathematical proofs, which are relatively elementary and seldom depend on mathematics more advanced that the binomial theorem.',\n",
              "  'authors': ['Glenn Shafer'],\n",
              "  'date': '1976',\n",
              "  'identifier': '2797148637',\n",
              "  'references': ['2101840010',\n",
              "   '2159080219',\n",
              "   '2100235918',\n",
              "   '2019950953',\n",
              "   '2038420319',\n",
              "   '2013093146',\n",
              "   '2151376743',\n",
              "   '2116817369',\n",
              "   '1604936042',\n",
              "   '1593793857'],\n",
              "  'title': 'A mathematical theory of evidence'},\n",
              " {'abstract': 'We present a framework for information retrieval that combines document models and query models using a probabilistic ranking function based on Bayesian decision theory. The framework suggests an operational retrieval model that extends recent developments in the language modeling approach to information retrieval. A language model for each document is estimated, as well as a language model for each query, and the retrieval problem is cast in terms of risk minimization. The query language model can be exploited to model user preferences, the context of a query, synonomy and word senses. While recent work has incorporated word translation models for this purpose, we introduce a new method using Markov chains defined on a set of documents to estimate the query models. The Markov chain method has connections to algorithms from link analysis and social networks. The new approach is evaluated on TREC collections and compared to the basic language modeling approach and vector space models together with query expansion using Rocchio. Significant improvements are obtained over standard query expansion methods for strong baseline TF-IDF systems, with the greatest improvements attained for short queries on Web data.',\n",
              "  'authors': ['John Lafferty ', ' Chengxiang Zhai'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2068905009',\n",
              "  'references': ['3013264884',\n",
              "   '2138621811',\n",
              "   '2147152072',\n",
              "   '2160484851',\n",
              "   '2093390569',\n",
              "   '1482214997',\n",
              "   '2062270497',\n",
              "   '2621280964',\n",
              "   '2095368471',\n",
              "   '2043909051'],\n",
              "  'title': 'Document Language Models, Query Models, and Risk Minimization for Information Retrieval'},\n",
              " {'abstract': \"1. Using the two-dimensional (2D) spatial and spectral response profiles described in the previous two reports, we test Daugman's generalization of Marcelja's hypothesis that simple receptive fields belong to a class of linear spatial filters analogous to those described by Gabor and referred to here as 2D Gabor filters. 2. In the space domain, we found 2D Gabor filters that fit the 2D spatial response profile of each simple cell in the least-squared error sense (with a simplex algorithm), and we show that the residual error is devoid of spatial structure and statistically indistinguishable from random error. 3. Although a rigorous statistical approach was not possible with our spectral data, we also found a Gabor function that fit the 2D spectral response profile of each simple cell and observed that the residual errors are everywhere small and unstructured. 4. As an assay of spatial linearity in two dimensions, on which the applicability of Gabor theory is dependent, we compare the filter parameters estimated from the independent 2D spatial and spectral measurements described above. Estimates of most parameters from the two domains are highly correlated, indicating that assumptions about spatial linearity are valid. 5. Finally, we show that the functional form of the 2D Gabor filter provides a concise mathematical expression, which incorporates the important spatial characteristics of simple receptive fields demonstrated in the previous two reports. Prominent here are 1) Cartesian separable spatial response profiles, 2) spatial receptive fields with staggered subregion placement, 3) Cartesian separable spectral response profiles, 4) spectral response profiles with axes of symmetry not including the origin, and 5) the uniform distribution of spatial phase angles. 6. We conclude that the Gabor function provides a useful and reasonably accurate description of most spatial aspects of simple receptive fields. Thus it seems that an optimal strategy has evolved for sampling images simultaneously in the 2D spatial and spatial frequency domains.\",\n",
              "  'authors': ['J. P. Jones ', ' L. A. Palmer'],\n",
              "  'date': '1987',\n",
              "  'identifier': '1914401667',\n",
              "  'references': ['2003370853',\n",
              "   '2171074980',\n",
              "   '2116360511',\n",
              "   '2138100172',\n",
              "   '2075165262',\n",
              "   '2319041464',\n",
              "   '2141572998',\n",
              "   '2017600612',\n",
              "   '2069696140',\n",
              "   '2154455356'],\n",
              "  'title': 'An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex'},\n",
              " {'abstract': 'Recently there has been a resurgence of interest in the properties of natural images. Their statistics are important not only in image compression but also for the study of sensory processing in biology, which can be viewed as satisfying certain ‘design criteria’. This review summarizes previous work on image statistics and presents our own data. Perhaps the most notable property of natural images is an invariance to scale. We present data to support this claim as well as evidence for a hierarchical invariance in natural scenes. These symmetries provide a powerful description of natural images as they greatly restrict the class of allowed distributions.',\n",
              "  'authors': ['Daniel L Ruderman'],\n",
              "  'date': '1994',\n",
              "  'identifier': '2120838001',\n",
              "  'references': ['1997063559',\n",
              "   '2100115174',\n",
              "   '2180838288',\n",
              "   '2156263007',\n",
              "   '2144520790',\n",
              "   '2103384342',\n",
              "   '2167034998',\n",
              "   '1667165204',\n",
              "   '2131329059',\n",
              "   '2098301339'],\n",
              "  'title': 'The statistics of natural images'},\n",
              " {'abstract': 'Newton Methods for Nonsmooth Equations.- Global Methods for Nonsmooth Equations.- Equation-Based Algorithms for Complementarity Problems.- Algorithms for Variational Inequalities.- Interior and Smoothing Methods.- Methods for Monotone Problems.- Notes and comments.',\n",
              "  'authors': ['Francisco Facchinei ', ' Jong-Shi Pang'],\n",
              "  'date': '2003',\n",
              "  'identifier': '1543439990',\n",
              "  'references': ['2100556411',\n",
              "   '2913535645',\n",
              "   '2114791779',\n",
              "   '2142224912',\n",
              "   '1904504745',\n",
              "   '2039050532',\n",
              "   '1977794212',\n",
              "   '2083138589',\n",
              "   '2114423093'],\n",
              "  'title': 'Finite-Dimensional Variational Inequalities and Complementarity Problems'},\n",
              " {'abstract': 'A number of recent studies have focused on the statistical properties of networked systems such as social networks and the Worldwide Web. Researchers have concentrated particularly on a few properties that seem to be common to many networks: the small-world property, power-law degree distributions, and network transitivity. In this article, we highlight another property that is found in many networks, the property of community structure, in which network nodes are joined together in tightly knit groups, between which there are only looser connections. We propose a method for detecting such communities, built around the idea of using centrality indices to find community boundaries. We test our method on computer-generated and real-world graphs whose community structure is already known and find that the method detects this known structure with high sensitivity and reliability. We also apply the method to two networks whose community structure is not well known—a collaboration network and a food web—and find that it detects significant and informative community divisions in both cases.',\n",
              "  'authors': ['M. Girvan ', ' M. E. J. Newman'],\n",
              "  'date': '2002',\n",
              "  'identifier': '1971421925',\n",
              "  'references': ['2112090702',\n",
              "   '2008620264',\n",
              "   '2164727176',\n",
              "   '1976969221',\n",
              "   '1977545325',\n",
              "   '2769133055',\n",
              "   '2144885342',\n",
              "   '2175110005',\n",
              "   '2169015768',\n",
              "   '2125315567'],\n",
              "  'title': 'Community structure in social and biological networks'},\n",
              " {'abstract': 'Recent work has shown that combining multiple versions of unstable classifiers such as trees or neural nets results in reduced test set error. One of the more effective is bagging. Here, modified training sets are formed by resampling from the original training set, classifiers constructed using these training sets and then combined by voting. Freund and Schapire propose an algorithm the basis of which is to adaptively resample and combine (hence the acronym arcing) so that the weights in the resampling are increased for those cases most often misclassified and the combining is done by weighted voting. Arcing is more successful than bagging in test set error reduction. We explore two arcing algorithms, compare them to each other and to bagging, and try to understand how arcing works. We introduce the definitions of bias and variance for a classifier as components of the test set error. Unstable classifiers can have low bias on a large range of data sets. Their problem is high variance. Combining multiple versions either through bagging or arcing reduces variance significantly.',\n",
              "  'authors': ['Leo Breiman'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2067885219',\n",
              "  'references': ['2911964244',\n",
              "   '2053463056',\n",
              "   '1966701961',\n",
              "   '3104887532',\n",
              "   '2075647286',\n",
              "   '2167917621',\n",
              "   '2032210760',\n",
              "   '1540007258',\n",
              "   '2155806188',\n",
              "   '2168020168'],\n",
              "  'title': 'Arcing classifier (with discussion and a rejoinder by the author)'},\n",
              " {'abstract': \"Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. In this review, we argue that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, Douglas–Rachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for l1 problems, proximal methods, and others. After briefly surveying the theory and history of the algorithm, we discuss applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. We also discuss general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations.\",\n",
              "  'authors': ['Stephen Boyd 1',\n",
              "   ' Neal Parikh 1',\n",
              "   ' Eric Chu 1',\n",
              "   ' Borja Peleato 1',\n",
              "   ' Jonathan Eckstein 2'],\n",
              "  'date': '2011',\n",
              "  'identifier': '2164278908',\n",
              "  'references': ['2296319761',\n",
              "   '2173213060',\n",
              "   '2156909104',\n",
              "   '2296616510',\n",
              "   '2145096794',\n",
              "   '1554944419',\n",
              "   '3029645440',\n",
              "   '2100556411',\n",
              "   '2129638195',\n",
              "   '1981420413'],\n",
              "  'title': 'Distributed Optimization and Statistical Learning Via the Alternating Direction Method of Multipliers'},\n",
              " {'abstract': 'More than three decades of research have demonstrated a role for hippocampal place cells in representation of the spatial environment in the brain. New studies have shown that place cells are part of a broader circuit for dynamic representation of self-location. A key component of this network is the entorhinal grid cells, which, by virtue of their tessellating firing fields, may provide the elements of a path integration-based neural map. Here we review how place cells and grid cells may form the basis for quantitative spatiotemporal representation of places, routes, and associated experiences during behavior and in memory. Because these cell types have some of the most conspicuous behavioral correlates among neurons in nonsensory cortical systems, and because their spatial firing structure reflects computations internally in the system, studies of entorhinal-hippocampal representations may offer considerable insight into general principles of cortical network dynamics.',\n",
              "  'authors': ['Edvard I. Moser ', ' Emilio Kropff ', ' May-Britt Moser'],\n",
              "  'date': '2008',\n",
              "  'identifier': '2123213117',\n",
              "  'references': ['2293063825',\n",
              "   '1970792572',\n",
              "   '22297218',\n",
              "   '2112938540',\n",
              "   '2129789527',\n",
              "   '2008936540',\n",
              "   '1980576528',\n",
              "   '2092580449',\n",
              "   '2115107366',\n",
              "   '2168101731'],\n",
              "  'title': \"Place Cells, Grid Cells, and the Brain's Spatial Representation System\"},\n",
              " {'abstract': 'We present distributed algorithms that can be used by multiple agents to align their estimates with a particular value over a network with time-varying connectivity. Our framework is general in that this value can represent a consensus value among multiple agents or an optimal solution of an optimization problem, where the global objective function is a combination of local agent objective functions. Our main focus is on constrained problems where the estimates of each agent are restricted to lie in different convex sets. To highlight the effects of constraints, we first consider a constrained consensus problem and present a distributed \"projected consensus algorithm\" in which agents combine their local averaging operation with projection on their individual constraint sets. This algorithm can be viewed as a version of an alternating projection method with weights that are varying over time and across agents. We establish convergence and convergence rate results for the projected consensus algorithm. We next study a constrained optimization problem for optimizing the sum of local objective functions of the agents subject to the intersection of their local constraint sets. We present a distributed \"projected subgradient algorithm\" which involves each agent performing a local averaging operation, taking a subgradient step to minimize its own objective function, and projecting on its constraint set. We show that, with an appropriately selected stepsize rule, the agent estimates generated by this algorithm converge to the same optimal solution for the cases when the weights are constant and equal, and when the weights are time-varying but all agents have the same constraint set.',\n",
              "  'authors': ['A. Nedic 1', ' A. Ozdaglar 2', ' P.A. Parrilo 2'],\n",
              "  'date': '2010',\n",
              "  'identifier': '2114791779',\n",
              "  'references': ['2107396783',\n",
              "   '2165744313',\n",
              "   '2044212084',\n",
              "   '1543439990',\n",
              "   '2015410655',\n",
              "   '1583497301',\n",
              "   '1603765807',\n",
              "   '2101517602',\n",
              "   '2145574455',\n",
              "   '2106221286'],\n",
              "  'title': 'Constrained Consensus and Optimization in Multi-Agent Networks'},\n",
              " {'abstract': \"Abstract : The relationship between 'learning' in adaptive layered networks and the fitting of data with high dimensional surfaces is discussed. This leads naturally to a picture of 'generalization in terms of interpolation between known data points and suggests a rational approach to the theory of such networks. A class of adaptive networks is identified which makes the interpolation scheme explicit. This class has the property that learning is equivalent to the solution of a set of linear equations. These networks thus represent nonlinear relationships while having a guaranteed learning rule. Great Britain.\",\n",
              "  'authors': ['David S. Broomhead ', ' David Lowe'],\n",
              "  'date': '1988',\n",
              "  'identifier': '94523489',\n",
              "  'references': ['2121863487',\n",
              "   '1993717606',\n",
              "   '2093229042',\n",
              "   '2143956139',\n",
              "   '2155399784',\n",
              "   '2149723649',\n",
              "   '2133321814',\n",
              "   '1998442441',\n",
              "   '2113442785',\n",
              "   '2150535417'],\n",
              "  'title': 'Radial Basis Functions, Multi-Variable Functional Interpolation and Adaptive Networks'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Humberto R. Maturana ',\n",
              "   ' J. Y. Lettvin ',\n",
              "   ' W. S. McCulloch ',\n",
              "   ' W. H. Pitts'],\n",
              "  'date': '1960',\n",
              "  'identifier': '2166025442',\n",
              "  'references': ['2118017998',\n",
              "   '2212384750',\n",
              "   '2110185620',\n",
              "   '2027446612',\n",
              "   '2092722834',\n",
              "   '2047856470',\n",
              "   '2005177462',\n",
              "   '1678355425',\n",
              "   '2396767078',\n",
              "   '841599558'],\n",
              "  'title': 'Anatomy and Physiology of Vision in the Frog (Rana pipiens)'},\n",
              " {'abstract': 'Original orange cloth cover, 345 pages, 182 figures in text. This is an original printing in 1950. The Nathan Library holds a copy of the 1964 reprint (cat No 509).',\n",
              "  'authors': ['Kenneth N. Ogle'],\n",
              "  'date': '1950',\n",
              "  'identifier': '1603660650',\n",
              "  'references': ['1598123022',\n",
              "   '2113059272',\n",
              "   '2105096388',\n",
              "   '2122566683',\n",
              "   '2158527951',\n",
              "   '3105592015',\n",
              "   '388780593',\n",
              "   '2137627454',\n",
              "   '2156387357'],\n",
              "  'title': 'Researches in binocular vision.'},\n",
              " {'abstract': 'This is a reprint of the orginal book released in 1968. Our primary goal in this book is to sharpen the skill, sophistication, and in- tuition of the reader in the interpretation of mental test data, and in the construction and use of mental tests both as instruments of psychological theory and as tools in the practical problems of selection, evaluation, and guidance. We seek to do this by exposing the reader to some psychologically meaningful statistical theories of mental test scores. Although this book is organized in terms of test-score theories and models, the practical applications and limitations of each model studied receive substantial emphasis, and these discussions are presented in as nontechnical a manner as we have found possible. Since this book catalogues a host of test theory models and formulas, it may serve as a reference handbook. Also, for a limited group of specialists, this book aims to provide a more rigorous foundation for further theoretical research than has heretofore been available.One aim of this book is to present statements of the assumptions, together with derivations of the implications, of a selected group of statistical models that the authors believe to be useful as guides in the practices of test construction and utilization. With few exceptions we have given a complete proof for each major result presented in the book. In many cases these proofs are simpler, more complete, and more illuminating than those originally offered. When we have omitted proofs or parts of proofs, we have generally provided a reference containing the omitted argument. We have left some proofs as exercises for the reader, but only when the general method of proof has already been demonstrated. At times we have proved only special cases of more generally stated theorems, when the general proof affords no additional insight into the problem and yet is substantially more complex mathematically.',\n",
              "  'authors': ['Frederic M. Lord ', ' Melvin R. Novick ', ' Allan Birnbaum'],\n",
              "  'date': '1968',\n",
              "  'identifier': '2084398551',\n",
              "  'references': ['2125001590',\n",
              "   '2112336497',\n",
              "   '2141403362',\n",
              "   '1655534105',\n",
              "   '1704942559',\n",
              "   '2108096958',\n",
              "   '1594874760',\n",
              "   '2560821290',\n",
              "   '2129375743'],\n",
              "  'title': 'Statistical Theories of Mental Test Scores'},\n",
              " {'abstract': 'In this paper, neural network- and feature-based approaches are introduced to overcome current shortcomings in the automated integration of topology design and shape optimization. The topology optimization results are reconstructed in terms of features, which consist of attributes required for automation and integration in subsequent applications. Features are defined as cost-efficient simple shapes for manufacturing. A neural network-based image-processing technique is presented to match the arbitrarily shaped holes inside the structure with predefined features. The effectiveness of the proposed approach in integrating topology design and shape optimization is demonstrated with several experimental examples.',\n",
              "  'authors': ['A. R. Yildiz ', ' N. Öztürk ', ' N. Kaya ', ' F. Öztürk'],\n",
              "  'date': '2003',\n",
              "  'identifier': '1973070179',\n",
              "  'references': ['2042264548',\n",
              "   '2069697210',\n",
              "   '2122397978',\n",
              "   '2086674516',\n",
              "   '1989201748',\n",
              "   '1989581196',\n",
              "   '2118555989',\n",
              "   '2004945242',\n",
              "   '1973282871',\n",
              "   '2003756933'],\n",
              "  'title': 'Integrated optimal topology design and shape optimization using neural networks'},\n",
              " {'abstract': 'In this second part of a two-part paper, we explore the power and complexity of the g=fKP and g=vKP class of look-ahead operators which can be used to speed up the tree search in the consistent labeling problem. For a specified K and P we show that the fixedpoint power of g=fKP and g=vKP is the same, that g=fKP+1 is at least as powerful as g=fKP, and that g=vK+1p is at least as powerful at g=fKP. Finally, we define a minimal compatibility relation and show how the standard tree search procedure for finding all the consistent labelings is quicker for a minimal relation. This leads to the concept of grading the complexity of compatibility relations according to how much look-ahead work it requires to reduce them to minimal relations and suggests that the reason look-ahead operators, such as Waltz filtering, work so well is that the compatibility relations used in practice are not very complex and are reducible to minimal or near minimal relations by a g=fKP or g=vKP look-ahead operator with small value for parameter P.',\n",
              "  'authors': ['Robert M. Haralick ', ' Linda G. Shapiro'],\n",
              "  'date': '1979',\n",
              "  'identifier': '2105038716',\n",
              "  'references': ['1622620102',\n",
              "   '2036265926',\n",
              "   '1979622972',\n",
              "   '2135432705',\n",
              "   '2126359798',\n",
              "   '2119456262',\n",
              "   '2970719582',\n",
              "   '1736170383',\n",
              "   '2072755230',\n",
              "   '2042119491'],\n",
              "  'title': 'The Consistent Labeling Problem: Part II'},\n",
              " {'abstract': '[Read before The Royal Statistical Society at a meeting organized by the Research Section on Wednesday, May 5th, 2004, Professor J. T. Kent in the Chair ] Summary. A new procedure is proposed for clustering attribute value data. When used in conjunction with conventional distance-based clustering algorithms this procedure encourages those algorithms to detect automatically subgroups of objects that preferentially cluster on subsets of the attribute variables rather than on all of them simultaneously. The relevant attribute subsets for each individual cluster can be different and partially (or completely) overlap with those of other clusters. Enhancements for increasing sensitivity for detecting especially low cardinality groups clustering on a small subset of variables are discussed. Applications in different domains, including gene expression arrays, are presented.',\n",
              "  'authors': ['Jerome H. Friedman 1', ' Jacqueline J. Meulman 2'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2094909687',\n",
              "  'references': ['2150926065',\n",
              "   '1548802052',\n",
              "   '1971784203',\n",
              "   '2999729612',\n",
              "   '1493454437',\n",
              "   '1524704912',\n",
              "   '2082503527',\n",
              "   '1840338487',\n",
              "   '2913066018',\n",
              "   '1992402718'],\n",
              "  'title': 'Clustering objects on subsets of attributes (with discussion)'},\n",
              " {'abstract': 'We discuss an old distributed algorithm for reaching consensus that has received a fair amount of recent attention. In this algorithm, a number of agents exchange their values asynchronously and form weighted averages with (possibly outdated) values possessed by their neighbors. We overview existing convergence results, and establish some new ones, for the case of unbounded intercommunication intervals.',\n",
              "  'authors': ['V.D. Blondel 1',\n",
              "   ' J.M. Hendrickx 2',\n",
              "   ' A. Olshevsky 3',\n",
              "   ' J.N. Tsitsiklis 3'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2145574455',\n",
              "  'references': ['2107396783',\n",
              "   '2165744313',\n",
              "   '2125668987',\n",
              "   '2613173048',\n",
              "   '2015410655',\n",
              "   '1603765807',\n",
              "   '2101517602',\n",
              "   '2295244470',\n",
              "   '2166417226',\n",
              "   '2154834860'],\n",
              "  'title': 'Convergence in Multiagent Coordination, Consensus, and Flocking'},\n",
              " {'abstract': 'An overview of statistical decision theory, which emphasizes the use and application of the philosophical ideas and mathematical structure of decision theory. The text assumes a knowledge of basic probability theory and some advanced calculus is also required.',\n",
              "  'authors': ['James O Berger'],\n",
              "  'date': '1993',\n",
              "  'identifier': '1988520084',\n",
              "  'references': ['1648445109',\n",
              "   '1479807131',\n",
              "   '2030536784',\n",
              "   '46659105',\n",
              "   '2110575115',\n",
              "   '2136518234',\n",
              "   '2149760002',\n",
              "   '2008047653',\n",
              "   '1608826770',\n",
              "   '2004014148'],\n",
              "  'title': 'Statistical Decision Theory and Bayesian Analysis'},\n",
              " {'abstract': 'The notion of perceptual coding, which is based on the concept of distortion masking by the signal being compressed, is developed. Progress in this field as a result of advances in classical coding theory, modeling of human perception, and digital signal processing, is described. It is proposed that fundamental limits in the science can be expressed by the semiquantitative concepts of perceptual entropy and the perceptual distortion-rate function, and current compression technology is examined in that framework. Problems and future research directions are summarized. >',\n",
              "  'authors': ['N. Jayant ', ' J. Johnston ', ' R. Safranek'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2144520790',\n",
              "  'references': ['2098914003',\n",
              "   '2140196014',\n",
              "   '1492380776',\n",
              "   '1970352604',\n",
              "   '2115907784',\n",
              "   '2129652681',\n",
              "   '2134383396',\n",
              "   '2149072817',\n",
              "   '2913399920',\n",
              "   '2043843997'],\n",
              "  'title': 'Signal compression based on models of human perception'},\n",
              " {'abstract': 'The state of the art in data compression is arithmetic coding, not the better-known Huffman method. Arithmetic coding gives greater compression, is faster for adaptive models, and clearly separates the model from the channel encoding.',\n",
              "  'authors': ['Ian H. Witten ', ' Radford M. Neal ', ' John G. Cleary'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2129652681',\n",
              "  'references': ['2122962290',\n",
              "   '1990653637',\n",
              "   '1995875735',\n",
              "   '2161628678',\n",
              "   '1975965284',\n",
              "   '2119047110',\n",
              "   '2107927941',\n",
              "   '2165564574',\n",
              "   '2079729471',\n",
              "   '2038649859'],\n",
              "  'title': 'Arithmetic coding for data compression'},\n",
              " {'abstract': 'We introduce the Generalized2 Linear2 Model, a statistical estimator which combines features of nonlinear regression and factor analysis. A (GL)2M approximately decomposes a rectangular matrix X into a simpler representation f(g(A)h(B)). Here A and B are low-rank matrices, while f, g, and h arc link functions. (GL)2Ms include many useful models as special cases, including principal components analysis, exponential-family PCA, the infomax formulation of independent components analysis, linear regression, and generalized linear models. They also include new and interesting special cases, one of which we describe below. We also present an iterative procedure which optimizes the parameters of a (GL)2M. This procedure reduces to well-known algorithms for some of the special cases listed above; for other special cases, it is new.',\n",
              "  'authors': ['Geoffrey J. Gordon'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2252194958',\n",
              "  'references': ['2138621811',\n",
              "   '2138451337',\n",
              "   '1528905581',\n",
              "   '2158997610',\n",
              "   '2138835141',\n",
              "   '2137234026',\n",
              "   '2131865378',\n",
              "   '2135001774',\n",
              "   '2154727088',\n",
              "   '1506832649'],\n",
              "  'title': 'Generalized^2 Linear^2 Models'},\n",
              " {'abstract': 'The genomic sequences of severe acute respiratory syndrome coronaviruses from human and palm civet of the 2003/2004 outbreak in the city of Guangzhou, China, were nearly identical. Phylogenetic analysis suggested an independent viral invasion from animal to human in this new episode. Combining all existing data but excluding singletons, we identified 202 single-nucleotide variations. Among them, 17 are polymorphic in palm civets only. The ratio of nonsynonymous/synonymous nucleotide substitution in palm civets collected 1 yr apart from different geographic locations is very high, suggesting a rapid evolving process of viral proteins in civet as well, much like their adaptation in the human host in the early 2002–2003 epidemic. Major genetic variations in some critical genes, particularly the Spike gene, seemed essential for the transition from animal-to-human transmission to human-to-human transmission, which eventually caused the first severe acute respiratory syndrome outbreak of 2002/2003.',\n",
              "  'authors': ['Huai-Dong Song ',\n",
              "   ' Chang-Chun Tu ',\n",
              "   ' Guo-Wei Zhang ',\n",
              "   ' Sheng-Yue Wang ',\n",
              "   ' Kui Zheng ',\n",
              "   ' Lian-Cheng Lei ',\n",
              "   ' Qiu-Xia Chen ',\n",
              "   ' Yu-Wei Gao ',\n",
              "   ' Hui-Qiong Zhou ',\n",
              "   ' Hua Xiang ',\n",
              "   ' Hua-Jun Zheng ',\n",
              "   ' Shur-Wern Wang Chern ',\n",
              "   ' Feng Cheng ',\n",
              "   ' Chun-Ming Pan ',\n",
              "   ' Hua Xuan ',\n",
              "   ' Sai-Juan Chen ',\n",
              "   ' Hui-Ming Luo ',\n",
              "   ' Duan-Hua Zhou ',\n",
              "   ' Yu-Fei Liu ',\n",
              "   ' Jian-Feng He ',\n",
              "   ' Peng-Zhe Qin ',\n",
              "   ' Ling-Hui Li ',\n",
              "   ' Yu-Qi Ren ',\n",
              "   ' Wen-Jia Liang ',\n",
              "   ' Ye-Dong Yu ',\n",
              "   ' Larry Anderson ',\n",
              "   ' Ming Wang ',\n",
              "   ' Rui-Heng Xu ',\n",
              "   ' Xin-Wei Wu ',\n",
              "   ' Huan-Ying Zheng ',\n",
              "   ' Jin-Ding Chen ',\n",
              "   ' Guodong Liang ',\n",
              "   ' Yang Gao ',\n",
              "   ' Ming Liao ',\n",
              "   ' Ling Fang ',\n",
              "   ' Li-Yun Jiang ',\n",
              "   ' Hui Li ',\n",
              "   ' Fang Chen ',\n",
              "   ' Biao Di ',\n",
              "   ' Li-Juan He ',\n",
              "   ' Jin-Yan Lin ',\n",
              "   ' Suxiang Tong ',\n",
              "   ' Xiangang Kong ',\n",
              "   ' Lin Du ',\n",
              "   ' Pei Hao ',\n",
              "   ' Hua Tang ',\n",
              "   ' Andrea Bernini ',\n",
              "   ' Xiao-Jing Yu ',\n",
              "   ' Ottavia Spiga ',\n",
              "   ' Zong-Ming Guo +9'],\n",
              "  'date': '2005',\n",
              "  'identifier': '1990059132',\n",
              "  'references': ['2097706568',\n",
              "   '2132260239',\n",
              "   '2104548316',\n",
              "   '2156434383',\n",
              "   '2116586125',\n",
              "   '2169198329',\n",
              "   '1966238900',\n",
              "   '2134061616',\n",
              "   '2159857626',\n",
              "   '1967669339'],\n",
              "  'title': 'Cross-host evolution of severe acute respiratory syndrome coronavirus in palm civet and human'},\n",
              " {'abstract': 'Abstract The authors develop a framework for understanding the behaviors and practices of service providers that build or deplete consumer trust and the mechanisms that convert consumer trust into value and loyalty in relational exchanges. The proposed framework (1) uses a multidimensional conceptualization for the trustworthiness construct; (2) incorporates two distinct facets of consumer trust, namely, frontline employees and management policies and practices; and (3) specifies value as a key mediator of the trust–loyalty relationship. The authors test the proposed model using data from two service contexts—retail clothing (N = 264) and nonbusiness airline travel (N = 113). The results support a tripartite view of trustworthiness evaluations along operational competence, operational benevolence, and problem-solving orientation dimensions. Moreover, the authors find evidence of contingent asymmetric relationships between trustworthiness dimensions and consumer trust. For frontline employees, benevolent b...',\n",
              "  'authors': ['Deepak Sirdeshmukh ', ' Jagdip Singh ', ' Barry Sabol'],\n",
              "  'date': '2002',\n",
              "  'identifier': '1973687016',\n",
              "  'references': ['2137247419',\n",
              "   '2142175015',\n",
              "   '2133469585',\n",
              "   '1979907230',\n",
              "   '1987258130',\n",
              "   '2030483771',\n",
              "   '1574378514',\n",
              "   '2046752514',\n",
              "   '2170430750',\n",
              "   '3011865677'],\n",
              "  'title': 'Consumer Trust, Value, and Loyalty in Relational Exchanges:'},\n",
              " {'abstract': 'This article describes a method for reducing the shape distortions due to scale-space smoothing that arise in the computation of 3-D shape cues using operators (derivatives) defined from scale-space representation. More precisely, we are concerned with a general class of methods for deriving 3-D shape cues from a 2-D image data based on the estimation of locally linearized deformations of brightness patterns. This class constitutes a common framework for describing several problems in computer vision (such as shape-from-texture, shape-from disparity-gradients, and motion estimation) and for expressing different algorithms in terms of similar types of visual front-end-operations. It is explained how surface orientation estimates will be biased due to the use of rotationally symmetric smoothing in the image domain. These effects can be reduced by extending the linear scale-space concept into an affine Gaussian scalespace representation and by performing affine shape adaptation of the smoothing kernels. This improves the accuracy of the surface orientation estimates, since the image descriptors, on which the methods are based, will be relative invariant under affine transformations, and the error thus confined to the higher-order terms in the locally linearized perspective transformation. A straightforward algorithm is presented for performing shape adaptation in practice. Experiments on real and synthetic images with known orientation demonstrate that in the presence of moderately high noise levels the accuracy is improved by typically one order of magnitude.',\n",
              "  'authors': ['Tony Lindeberg ', ' Jonas Gårding'],\n",
              "  'date': '1997',\n",
              "  'identifier': '1970269179',\n",
              "  'references': ['2150134853',\n",
              "   '2109200236',\n",
              "   '1991113069',\n",
              "   '2109863423',\n",
              "   '2112328181',\n",
              "   '1938714998',\n",
              "   '2022735534',\n",
              "   '1495971627',\n",
              "   '2065164181',\n",
              "   '2022133743'],\n",
              "  'title': \"Shape-adapted smoothing in estimation of 3-D shape cues from affine deformations of local 2-D brightness structure'\"},\n",
              " {'abstract': 'The technique of iterative weighted linear regression can be used to obtain maximum likelihood estimates of the parameters with observations distributed according to some exponential family and systematic effects that can be made linear by a suitable transformation. A generalization of the analysis of variance is given for these models using log- likelihoods. These generalized linear models are illustrated by examples relating to four distributions; the Normal, Binomial (probit analysis, etc.), Poisson (contingency tables) and gamma (variance components).',\n",
              "  'authors': ['Peter McCullagh 1', ' John Ashworth Nelder 2'],\n",
              "  'date': '1983',\n",
              "  'identifier': '1528905581',\n",
              "  'references': ['2995133996',\n",
              "   '2074673068',\n",
              "   '2796930440',\n",
              "   '2556205749',\n",
              "   '2777019853',\n",
              "   '2102041666',\n",
              "   '2798510847',\n",
              "   '2801490189',\n",
              "   '2082102453',\n",
              "   '2123838014'],\n",
              "  'title': 'Generalized Linear Models'},\n",
              " {'abstract': 'Publisher Summary This chapter focuses on general purpose parallel architectures. Multiprocessor parallel computation has been considered in the context of problems with large inherent parallelism. The results suggest that the XPRAM might turn out to be an appropriate aspiration for the parallel computer architect much as the von Neumann model is in the sequential case. It is conceptually simple, capturing as it does the idea of message passing synchronized in bulk. It is a suitable host on to which higher-level communication and storage management functions can be efficiently compiled. Furthermore, it is a promising candidate for efficient implementation in foreseeable technologies. An XPRAM with ρ processors executes operations in supersteps. In each superstep, each processor executes a number of local instructions and sends or receives some messages that implement global read or write instructions. XPRAM embodies the principle of bulk-synchrony, that is, the processors should be barrier synchronized at regular time intervals long enough for several packets to be transmitted between a pair of nodes.',\n",
              "  'authors': ['L. G. Valiant'],\n",
              "  'date': '1991',\n",
              "  'identifier': '1544480906',\n",
              "  'references': ['2058972589',\n",
              "   '1964602554',\n",
              "   '2061171222',\n",
              "   '2052207834',\n",
              "   '2087977509',\n",
              "   '2143462372',\n",
              "   '2177671275',\n",
              "   '2134008688',\n",
              "   '2073491596',\n",
              "   '1969008575'],\n",
              "  'title': 'General purpose parallel architectures'},\n",
              " {'abstract': 'Abstract It is clear that the learning speed of feedforward neural networks is in general far slower than required and it has been a major bottleneck in their applications for past decades. Two key reasons behind may be: (1) the slow gradient-based learning algorithms are extensively used to train neural networks, and (2) all the parameters of the networks are tuned iteratively by using such learning algorithms. Unlike these conventional implementations, this paper proposes a new learning algorithm called e xtreme l earning m achine (ELM) for s ingle-hidden l ayer f eedforward neural n etworks (SLFNs) which randomly chooses hidden nodes and analytically determines the output weights of SLFNs. In theory, this algorithm tends to provide good generalization performance at extremely fast learning speed. The experimental results based on a few artificial and real benchmark function approximation and classification problems including very large complex applications show that the new algorithm can produce good generalization performance in most cases and can learn thousands of times faster than conventional popular learning algorithms for feedforward neural networks. 1',\n",
              "  'authors': ['Guang-Bin Huang ', ' Qin-Yu Zhu ', ' Chee Kheong Siew'],\n",
              "  'date': '2006',\n",
              "  'identifier': '2111072639',\n",
              "  'references': ['2124776405',\n",
              "   '2084812512',\n",
              "   '2112076978',\n",
              "   '2172000360',\n",
              "   '2982720039',\n",
              "   '2061065224',\n",
              "   '2099579348',\n",
              "   '1988115241',\n",
              "   '2139055047',\n",
              "   '1604591429'],\n",
              "  'title': 'Extreme learning machine: Theory and applications'},\n",
              " {'abstract': 'A program that tags each word in an input sentence with the most likely part of speech has been written. The program uses a linear-time dynamic programming algorithm to find an assignment of parts of speech to words that optimizes the product of (a) lexical probabilities (probability of observing part of speech i given word i) and (b) contextual probabilities (probability of observing part of speech i given n following parts of speech). Program performance is encouraging; a 400-word sample is presented and is judged to be 99.5% correct. >',\n",
              "  'authors': ['K.W. Church'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2099247782',\n",
              "  'references': ['2134237567',\n",
              "   '2155818555',\n",
              "   '1571096757',\n",
              "   '1981724541',\n",
              "   '2055438451',\n",
              "   '1526508180',\n",
              "   '2124479173'],\n",
              "  'title': 'A stochastic parts program and noun phrase parser for unrestricted text'},\n",
              " {'abstract': \"Statistical learning theory was introduced in the late 1960's. Until the 1990's it was a purely theoretical analysis of the problem of function estimation from a given collection of data. In the middle of the 1990's new types of learning algorithms (called support vector machines) based on the developed theory were proposed. This made statistical learning theory not only a tool for the theoretical analysis but also a tool for creating practical algorithms for estimating multidimensional functions. This article presents a very general overview of statistical learning theory including both theoretical and algorithmic aspects of the theory. The goal of this overview is to demonstrate how the abstract learning theory established conditions for generalization which are more general than those discussed in classical statistical paradigms and how the understanding of these conditions inspired new algorithmic approaches to function estimation problems.\",\n",
              "  'authors': ['V.N. Vapnik'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2149298154',\n",
              "  'references': ['2156909104',\n",
              "   '2119821739',\n",
              "   '2154642048',\n",
              "   '2140095548',\n",
              "   '2087347434',\n",
              "   '1604938182',\n",
              "   '2146766088',\n",
              "   '26816478',\n",
              "   '2156512439',\n",
              "   '2007154098'],\n",
              "  'title': 'An overview of statistical learning theory'},\n",
              " {'abstract': 'We describe ways in which the transmission control protocol of the Internet may evolve to support heterogeneous applications. We show that by appropriately marking packets at overloaded resources and by charging a fixed small amount for each mark received, end-nodes are provided with the necessary information and the correct incentive to use the network efficiently.',\n",
              "  'authors': ['R. J. Gibbens ', ' F. P. Kelly'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2087635921',\n",
              "  'references': ['2158733823',\n",
              "   '2753542457',\n",
              "   '2159715570',\n",
              "   '1987497363',\n",
              "   '1990920914',\n",
              "   '2126880366',\n",
              "   '1970131865',\n",
              "   '2156568423',\n",
              "   '3013767507',\n",
              "   '2145581668'],\n",
              "  'title': 'Resource pricing and the evolution of congestion control'},\n",
              " {'abstract': 'The viruses associated most frequently with the \"common cold\" are rhinoviruses and coronaviruses. The first prospective cohort study to determine the prevalence of rhinovirus and coronavirus infections in patients of all ages hospitalized for acute respiratory illnesses is described. Hospital admissions for acute respiratory illnesses were identified, and cell culture for rhinovirus and serologic assays on paired sera for coronaviruses 229E and OC43 were performed. A total of 61 infections with rhinoviruses and coronaviruses were identified from 1198 respiratory illnesses (5.1%); in addition, 9 additional infections associated with >/=1 other respiratory viruses were identified. Of those infected with only rhinovirus or coronavirus, underlying cardiopulmonary diseases were present in 35% of the patients aged 35 years. The predominant clinical syndromes varied by age: pneumonia and bronchiolitis in children aged <5 years; exacerbations of asthma in older children and young adults; and pneumonia and exacerbations of chronic obstructive pulmonary disease and congestive heart failure in older adults. Therefore, rhinovirus and coronavirus infections in hospitalized patients were associated with lower respiratory tract illnesses in all age groups.',\n",
              "  'authors': ['Hana M. El-Sahly ',\n",
              "   ' Robert L. Atmar ',\n",
              "   ' William P. Glezen ',\n",
              "   ' Stephen B. Greenberg'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2154664055',\n",
              "  'references': ['1964779747',\n",
              "   '2127062009',\n",
              "   '2136123493',\n",
              "   '1520164477',\n",
              "   '1980185618',\n",
              "   '2148710849',\n",
              "   '2016357017',\n",
              "   '2091249799',\n",
              "   '2019621692',\n",
              "   '2098388207'],\n",
              "  'title': 'Spectrum of Clinical Illness in Hospitalized Patients with “Common Cold” Virus Infections'},\n",
              " {'abstract': 'In this article we explore the behavior of Twitter users under an emergency situation. In particular, we analyze the activity related to the 2010 earthquake in Chile and characterize Twitter in the hours and days following this disaster. Furthermore, we perform a preliminary study of certain social phenomenons, such as the dissemination of false rumors and confirmed news. We analyze how this information propagated through the Twitter network, with the purpose of assessing the reliability of Twitter as an information source under extreme circumstances. Our analysis shows that the propagation of tweets that correspond to rumors differs from tweets that spread news because rumors tend to be questioned more than news by the Twitter community. This result shows that it is posible to detect rumors by using aggregate analysis on tweets.',\n",
              "  'authors': ['Marcelo Mendoza ', ' Barbara Poblete ', ' Carlos Castillo'],\n",
              "  'date': '2010',\n",
              "  'identifier': '2050619059',\n",
              "  'references': ['2101196063',\n",
              "   '2081212507',\n",
              "   '1973921702',\n",
              "   '2050237388',\n",
              "   '2020360881',\n",
              "   '2130673724',\n",
              "   '2070722606',\n",
              "   '2169523845',\n",
              "   '2243503220'],\n",
              "  'title': 'Twitter under crisis: can we trust what we RT?'},\n",
              " {'abstract': 'The purpose of model selection algorithms such as All Subsets, Forward Selection and Backward Elimination is to choose a linear model on the basis of the same set of data to which the model will be applied. Typically we have available a large collection of possible covariates from which we hope to select a parsimonious set for the efficient prediction of a response variable. Least Angle Regression (LARS), a new model selection algorithm, is a useful and less greedy version of traditional forward selection methods. Three main properties are derived: (1) A simple modification of the LARS algorithm implements the Lasso, an attractive version of ordinary least squares that constrains the sum of the absolute regression coefficients; the LARS modification calculates all possible Lasso estimates for a given problem, using an order of magnitude less computer time than previous methods. (2) A different LARS modification efficiently implements Forward Stagewise linear regression, another promising new model selection method; this connection explains the similar numerical results previously observed for the Lasso and Stagewise, and helps us understand the properties of both methods, which are seen as constrained versions of the simpler LARS algorithm. (3) A simple approximation for the degrees of freedom of a LARS estimate is available, from which we derive a Cp estimate of prediction error; this allows a principled choice among the range of possible LARS estimates. LARS and its variants are computationally efficient: the paper describes a publicly available algorithm that requires only the same order of magnitude of computational effort as ordinary least squares applied to the full set of covariates.',\n",
              "  'authors': ['Bradley Efron 1',\n",
              "   ' Trevor Hastie 1',\n",
              "   ' Iain Johnstone 1',\n",
              "   ' Robert Tibshirani 1',\n",
              "   ' Hemant Ishwaran 2',\n",
              "   ' Keith Knight 3',\n",
              "   ' Jean Michel Loubes 4',\n",
              "   ' 5',\n",
              "   ' Pascal Massart 4',\n",
              "   ' 6',\n",
              "   ' David Madigan 7',\n",
              "   ' Greg Ridgeway 7',\n",
              "   ' 8',\n",
              "   ' Saharon Rosset 1',\n",
              "   ' 9',\n",
              "   ' J. I. Zhu 10',\n",
              "   ' Robert A. Stine 11',\n",
              "   ' Berwin A. Turlach 12',\n",
              "   ' Sanford Weisberg 13'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2063978378',\n",
              "  'references': ['1554944419',\n",
              "   '2110065044',\n",
              "   '2135046866',\n",
              "   '1988790447',\n",
              "   '2912934387',\n",
              "   '1678356000',\n",
              "   '2798909945',\n",
              "   '3085162807',\n",
              "   '2158940042',\n",
              "   '1594031697'],\n",
              "  'title': 'Least angle regression'},\n",
              " {'abstract': '',\n",
              "  'authors': ['M. Gluck'],\n",
              "  'date': '1985',\n",
              "  'identifier': '2277957941',\n",
              "  'references': ['1570448133',\n",
              "   '2073308541',\n",
              "   '2115657355',\n",
              "   '1990643970',\n",
              "   '2002767255',\n",
              "   '2115346774',\n",
              "   '2733722625',\n",
              "   '2139580617',\n",
              "   '2122943553',\n",
              "   '2988864014'],\n",
              "  'title': 'Information, Uncertainty and the Utility of Categories'},\n",
              " {'abstract': 'Topical crawling is a young and creative area of research that holds the promise of benefiting from several sophisticated data mining techniques. The use of classification algorithms to guide topical crawlers has been sporadically suggested in the literature. No systematic study, however, has been done on their relative merits. Using the lessons learned from our previous crawler evaluation studies, we experiment with multiple versions of different classification schemes. The crawling process is modeled as a parallel best-first search over a graph defined by the Web. The classifiers provide heuristics to the crawler thus biasing it towards certain portions of the Web graph. Our results show that Naive Bayes is a weak choice for guiding a topical crawler when compared with Support Vector Machine or Neural Network. Further, the weak performance of Naive Bayes can be partly explained by extreme skewness of posterior probabilities generated by it. We also observe that despite similar performances, different topical crawlers cover subspaces on the Web with low overlap.',\n",
              "  'authors': ['Gautam Pant 1', ' Padmini Srinivasan 2'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2017224880',\n",
              "  'references': ['2156909104',\n",
              "   '3029645440',\n",
              "   '2139212933',\n",
              "   '2154642048',\n",
              "   '1512098439',\n",
              "   '2098162425',\n",
              "   '2137983211',\n",
              "   '2042264548',\n",
              "   '2435251607',\n",
              "   '1604938182'],\n",
              "  'title': 'Learning to crawl: Comparing classification schemes'},\n",
              " {'abstract': 'Valid measurement scales for predicting user acceptance of computers are in short supply. Most subjective measures used in practice are unvalidated, and their relationship to system usage is unknown. The present research develops and validates new scales for two specific variables, perceived usefulness and perceived ease of use, which are hypothesized to be fundamental determinants of user acceptance. Definitions of these two variables were used to develop scale items that were pretested for content validity and then tested for reliability and construct validity in two studies involving a total of 152 users and four application programs. The measures were refined and streamlined, resulting in two six-item scales with reliabilities of .98 for usefulness and .94 for ease of use. The scales exhibited hgih convergent, discriminant, and factorial validity. Perceived usefulness was significnatly correlated with both self-reported current usage r = .63, Study 1) and self-predicted future usage r = .85, Study 2). Perceived ease of use was also significantly correlated with current usage r = .45, Study 1) and future usage r = .59, Study 2). In both studies, usefulness had a signficnatly greater correaltion with usage behavior than did ease of use. Regression analyses suggest that perceived ease of use may actually be a causal antecdent to perceived usefulness, as opposed to a parallel, direct determinant of system usage. Implications are drawn for future research on user acceptance.',\n",
              "  'authors': ['Fred D. Davis'],\n",
              "  'date': '1989',\n",
              "  'identifier': '1791587663',\n",
              "  'references': ['2033943395',\n",
              "   '1982210139',\n",
              "   '2036389121',\n",
              "   '2131664240',\n",
              "   '1991691398',\n",
              "   '2111230857',\n",
              "   '1557992034',\n",
              "   '112089985',\n",
              "   '2037057633',\n",
              "   '2092488901'],\n",
              "  'title': 'Perceived usefulness, perceived ease of use, and user acceptance of information technology'},\n",
              " {'abstract': 'Abstract During the last decade, Convolutional Neural Networks (CNNs) have become the de facto standard for various Computer Vision and Machine Learning operations. CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and millions of parameters have the ability to learn complex objects and patterns providing that they can be trained on a massive size visual database with ground-truth labels. With a proper training, this unique ability makes them the primary tool for various engineering applications for 2D signals such as images and video frames. Yet, this may not be a viable option in numerous applications over 1D signals especially when the training data is scarce or application specific. To address this issue, 1D CNNs have recently been proposed and immediately achieved the state-of-the-art performance levels in several applications such as personalized biomedical data classification and early diagnosis, structural health monitoring, anomaly detection and identification in power electronics and electrical motor fault detection. Another major advantage is that a real-time and low-cost hardware implementation is feasible due to the simple and compact configuration of 1D CNNs that perform only 1D convolutions (scalar multiplications and additions). This paper presents a comprehensive review of the general architecture and principals of 1D CNNs along with their major engineering applications, especially focused on the recent progress in this field. Their state-of-the-art performance is highlighted concluding with their unique properties. The benchmark datasets and the principal 1D CNN software used in those applications are also publicly shared in a dedicated website. While there has not been a paper on the review of 1D CNNs and its applications in the literature, this paper fulfills this gap.',\n",
              "  'authors': ['Serkan Kiranyaz 1',\n",
              "   ' Onur Avci 2',\n",
              "   ' Osama Abdeljaber 3',\n",
              "   ' Turker Ince 4',\n",
              "   ' Moncef Gabbouj 5',\n",
              "   ' Daniel J. Inman 6'],\n",
              "  'date': '2021',\n",
              "  'identifier': '3100777112',\n",
              "  'references': ['2618530766',\n",
              "   '2964121744',\n",
              "   '2095705004',\n",
              "   '2100495367',\n",
              "   '2160815625',\n",
              "   '2163352848',\n",
              "   '1498436455',\n",
              "   '1995562189',\n",
              "   '2598457882',\n",
              "   '1554576613'],\n",
              "  'title': '1D convolutional neural networks and applications: A survey'},\n",
              " {'abstract': 'The detection of viral pathogens is of critical importance in biology, medicine, and agriculture. Unfortunately, existing techniques to screen for a broad spectrum of viruses suffer from severe limitations. To facilitate the comprehensive and unbiased analysis of viral prevalence in a given biological setting, we have developed a genomic strategy for highly parallel viral screening. The cornerstone of this approach is a long oligonucleotide (70-mer) DNA microarray capable of simultaneously detecting hundreds of viruses. Using virally infected cell cultures, we were able to efficiently detect and identify many diverse viruses. Related viral serotypes could be distinguished by the unique pattern of hybridization generated by each virus. Furthermore, by selecting microarray elements derived from highly conserved regions within viral families, individual viruses that were not explicitly represented on the microarray were still detected, raising the possibility that this approach could be used for virus discovery. Finally, by using a random PCR amplification strategy in conjunction with the microarray, we were able to detect multiple viruses in human respiratory specimens without the use of sequence-specific or degenerate primers. This method is versatile and greatly expands the spectrum of detectable viruses in a single assay while simultaneously providing the capability to discriminate among viral subtypes.',\n",
              "  'authors': ['David Wang 1',\n",
              "   ' Laurent Coscoy 2',\n",
              "   ' Maxine Zylberberg 2',\n",
              "   ' Pedro C. Avila 2',\n",
              "   ' Homer A. Boushey 2',\n",
              "   ' Don Ganem 2',\n",
              "   ' Joseph L. DeRisi 2'],\n",
              "  'date': '2002',\n",
              "  'identifier': '1576737979',\n",
              "  'references': ['2055043387',\n",
              "   '1502936039',\n",
              "   '1549647993',\n",
              "   '2028318125',\n",
              "   '2137089963',\n",
              "   '2099369211',\n",
              "   '2169391021',\n",
              "   '2033380151',\n",
              "   '2037142940',\n",
              "   '2133247102'],\n",
              "  'title': 'Microarray-based detection and genotyping of viral pathogens'},\n",
              " {'abstract': 'Sparse coding provides a class of algorithms for finding succinct representations of stimuli; given only unlabeled input data, it discovers basis functions that capture higher-level features in the data. However, finding sparse codes remains a very difficult computational problem. In this paper, we present efficient sparse coding algorithms that are based on iteratively solving two convex optimization problems: an L1-regularized least squares problem and an L2-constrained least squares problem. We propose novel algorithms to solve both of these optimization problems. Our algorithms result in a significant speedup for sparse coding, allowing us to learn larger sparse codes than possible with previously described algorithms. We apply these algorithms to natural images and demonstrate that the inferred sparse codes exhibit end-stopping and non-classical receptive field surround suppression and, therefore, may provide a partial explanation for these two phenomena in V1 neurons.',\n",
              "  'authors': ['Honglak Lee ',\n",
              "   ' Alexis Battle ',\n",
              "   ' Rajat Raina ',\n",
              "   ' Andrew Y. Ng'],\n",
              "  'date': '2006',\n",
              "  'identifier': '2113606819',\n",
              "  'references': ['2063978378',\n",
              "   '2078204800',\n",
              "   '2145889472',\n",
              "   '2105464873',\n",
              "   '2140499889',\n",
              "   '2004915807',\n",
              "   '2101933716',\n",
              "   '16591383',\n",
              "   '2074376560',\n",
              "   '2146672645'],\n",
              "  'title': 'Efficient sparse coding algorithms'},\n",
              " {'abstract': '1. Introduction. Definition and Purpose. Basic Limitations of the Conventional Approach. Spread Spectrum Principles. Organization of the Book. 2. Random and Pseudorandom Signal Generation. Purpose. Pseudorandom Sequences. Maximal Length Linear Shift Register Sequences. Randomness Properties of MLSR Sequences. Conclusion. Generating Pseudorandom Signals (Pseudonoise) from Pseudorandom Sequences. First- and Second-Order Statistics of Demodulator Output in Multiple Access Interference. Statistics for QPSK Modulation by Pseudorandom Sequences. Examples. Bound for Bandlimited Spectrum. Error Probability for BPSK or QPSK with Constant Signals in Additive Gaussian Noise and Interference. Appendix 2A: Optimum Receiver Filter for Bandlimited Spectrum. 3. Synchronization of Pseudorandom Signals. Purpose. Acquisition of Pseudorandom Signal Timing. Hypothesis Testing for BPSK Spreading. Hypothesis Testing for QPSK Spreading. Effect of Frequency Error. Additional Degradation When N is Much Less Than One Period. Detection and False Alarm Probabilities. Fixed Signals in Gaussian Noise (L=1). Fixed Signals in Gaussian Noise with Postdetection Integration (L>1). Rayleigh Fading Signals (L>/=1). The Search Procedure and Acquisition Time. Single-Pass Serial Search (Simplified). Single-Pass Serial Search (Complete). Multiple Dwell Serial Search. Time Tracking of Pseudorandom Signals. Early-Late Gate Measurement Statistics. Time Tracking Loop. Carrier Synchronization. Appendix 3A: Likelihood Functions and Probability Expressions. Bayes and Neyman-Pearson Hypothesis Testing. Coherent Reception in Additive White Gaussian Noise. Noncoherent Reception in AWGN for Unfaded Signals. Noncoherent Reception of Multiple Independent Observations of Unfaded Signals in AWGN. Noncoherent Reception of Rayleigh-Faded Signals in AWGN. 4. Modulation and Demodulation of Spread Spectrum Signals in Multipath and Multiple Access Interference. Purpose. Chernoff and Battacharyya Bounds. Bounds for Gaussian Noise Channel. Chernoff Bound for Time-Synchronous Multiple Access Interference with BPSK Spreading. Chernoff Bound for Time-Synchronous Multiple Access Interference with QPSK Spreading. Improving the Chernoff Bound by a Factor of 2. Multipath Propagation: Signal Structure and Exploitation. Pilot-Aided Coherent Multipath Demodulation. Chernoff Bounds on Error Probability for Coherent Demodulation with Known Path Parameters. Rayleigh and Rician Fading Multipath Components. Noncoherent Reception. Quasi-optimum Noncoherent Multipath Reception for M-ary Orthogonal Modulation. Performance Bounds. Search Performance for Noncoherent Orthogonal M-ary Demodulators. Power Measurement and Control for Noncoherent Orthogonal M-ary Demodulators. Power Control Loop Performance. Power Control Implications. Appendix 4A: Chernoff Bound with Imperfect Parameter Estimates. 5. Coding and Interleaving. Purpose. Interleaving to Achieve Diversity. Forward Error Control Coding - Another Means to Exploit Redundancy. Convolutional Code Structure. Maximum Likelihood Decoder - Viterbi Algorithm. Generalization of the Preceding Example. Convolutional Code Performance Evaluation. Error Probability for Tailed-off Block. Bit Error Probability. Generalizations of Error Probability Computation. Catastrophic Codes. Generalization to Arbitrary Memoryless Channels - Coherent and Noncoherent. Error Bounds for Binary-Input, Output-Symmetric Channels with Integer Metrics. A Near-Optimal Class of Codes for Coherent Spread Spectrum Multiple Access. Implementation. Decoder Implementation. Generating Function and Performance. Performance Comparison and Applicability. Orthogonal Convolutional Codes for Noncoherent Demodulation of Rayleigh Fading Signals. Implementation. Performance for L-Path Rayleigh Fading. Conclusions and Caveats. Appendix 5A: Improved Bounds for Symmetric Memoryless Channels and the AWGN Channel. Appendix 5B: Upper Bound on Free Distance of Rate 1/n Convolutional Codes. 6. Capacity, Coverage, and Control of Spread Spectrum Multiple Access Networks. General. Reverse Link Power Control. Multiple Cell Pilot Tracking and Soft Handoff. Other-Cell Interference. Propagation Model. Single-Cell Reception - Hard Handoff. Soft Handoff Reception by the Better of the Two Nearest Cells. Soft Handoff Reception by the Best of Multiple Cells. Cell Coverage Issues with Hard and Soft Handoff. Hard Handoff. Soft Handoff. Erlang Capacity of Reverse Links. Erlang Capacity for Conventional Assigned-Slot Multiple Access. Spread Spectrum Multiple Access Outage - Single Cell and Perfect Power Control. Outage with Multiple-Cell Interference. Outage with Imperfect Power Control. An Approximate Explicit Formula for Capacity with Imperfect Power Control. Designing for Minimum Transmitted Power. Capacity Requirements for Initial Accesses. Erlang Capacity of Forward Links. Forward Link Power Allocation. Soft Handoff Impact on Forward Link. Orthogonal Signals for Same-Cell Users. Interference Reduction with Multisectored and Distributed Antennas. Interference Cancellation. Epilogue. References and Bibliography. Index.',\n",
              "  'authors': ['Andrew J. Viterbi'],\n",
              "  'date': '1995',\n",
              "  'identifier': '1525552993',\n",
              "  'references': ['2155174176',\n",
              "   '2123629701',\n",
              "   '1524144700',\n",
              "   '2113271807',\n",
              "   '2161647295',\n",
              "   '2129609617',\n",
              "   '2106069707',\n",
              "   '2095796369',\n",
              "   '2136979582',\n",
              "   '1995319790'],\n",
              "  'title': 'CDMA: Principles of Spread Spectrum Communication'},\n",
              " {'abstract': 'Abstract Decision trees are a widely-known formalism for expressing classification knowledge and yet their straightforward use can be criticized on several grounds. Results are categorical and so do not convey potential uncertainties in classification. Small changes in the attribute values of a case being classified may result in sudden and inappropriate changes to the assigned class. Missing or imprecise information may apparently prevent a case being classified at all. This paper outlines extensions to the way a case is classified by a decision tree that address these shortcomings.',\n",
              "  'authors': ['J.R. Quinlan'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2096059947',\n",
              "  'references': ['3085162807', '2149706766', '2128420091', '1567276288'],\n",
              "  'title': 'DECISION TREES AS PROBABILISTIC CLASSIFIERS'},\n",
              " {'abstract': 'An important form of learning from observation is constructing a classification of given objects or situations. Traditional techniques for this purpose, developed in cluster analysis and numerical taxonomy, are often inadequate because they arrange objects into classes solely on the basis of a numerical measure of object similarity. Such a measure is a function only of compared objects and does not take into consideration any global properties or concepts characterizing object classes. Consequently, the obtained classes may have no simple conceptual description and may be difficult to interpret.',\n",
              "  'authors': ['Ryszard S. Michalski ', ' Robert E. Stepp'],\n",
              "  'date': '1983',\n",
              "  'identifier': '1527883571',\n",
              "  'references': ['2067642555',\n",
              "   '2265027053',\n",
              "   '1507003511',\n",
              "   '121244562',\n",
              "   '2582933108',\n",
              "   '866674215',\n",
              "   '2983597079'],\n",
              "  'title': 'Learning from Observation: Conceptual Clustering'},\n",
              " {'abstract': 'MPI (Message Passing Interface) is a specification for a standard library for message passing that was defined by the MPI Forum, a broadly based group of parallel computer vendors, library writers, and applications specialists. Multiple implementations of MPI have been developed. In this paper, we describe MPICH, unique among existing implementations in its design goal of combining portability with high performance. We document its portability and performance and describe the architecture by which these features are simultaneously achieved. We also discuss the set of tools that accompany the free distribution of MPICH, which constitute the beginnings of a portable parallel programming environment. A project of this scope inevitably imparts lessons about parallel computing, the specification being followed, the current hardware and software environment for parallel computing, and project management; we describe those we have learned. Finally, we discuss future developments for MPICH, including those necessary to accommodate extensions to the MPI Standard now being contemplated by the MPI Forum.',\n",
              "  'authors': ['William Gropp 1',\n",
              "   ' Ewing Lusk 1',\n",
              "   ' Nathan Doss 2',\n",
              "   ' Anthony Skjellum 2'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2081612620',\n",
              "  'references': ['1575350781',\n",
              "   '1510543252',\n",
              "   '1589918049',\n",
              "   '2752853835',\n",
              "   '1570906644',\n",
              "   '2114728910',\n",
              "   '2415611842',\n",
              "   '2171453084',\n",
              "   '1964564149',\n",
              "   '2010269868'],\n",
              "  'title': 'A high-performance, portable implementation of the MPI message passing interface standard'},\n",
              " {'abstract': 'Abstract Most previous attempts at producing word classes (thesauri) by statistical analysis have used very limited distributional information such as word co-occurrence in a document or a sentence. This paper describes an automatic procedure which uses the syntactic relations as the basis for grouping words into classes. It forms classes by grouping together nouns that occur as subject (or object) of the same verbs, and similarly by grouping together verbs occurring with the same subject or object. The program was applied to a small corpus of sentences in a subfield of pharmacology. This procedure yielded the word classes for the subfield, in good agreement with the word classes recognized by pharmacologists. The word classes can be used to describe the informational patterns that occur in texts of the subfield, to disambiguate parses of a sentence, and perhaps to improve the performance of current information retrieval systems.',\n",
              "  'authors': ['Lynette Hirschman ', ' Ralph Grishman ', ' Naomi Sager'],\n",
              "  'date': '1975',\n",
              "  'identifier': '2052690453',\n",
              "  'references': ['2107668593',\n",
              "   '1572870503',\n",
              "   '1574071943',\n",
              "   '2089505529',\n",
              "   '2397766707',\n",
              "   '2099112161',\n",
              "   '1980142140',\n",
              "   '2064612869',\n",
              "   '1986803784',\n",
              "   '1798975372'],\n",
              "  'title': 'Grammatically-based automatic word class formation'},\n",
              " {'abstract': 'The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a \"black art\" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm\\'s generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.',\n",
              "  'authors': ['Jasper Snoek 1', ' Hugo Larochelle 2', ' Ryan P Adams 3'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2131241448',\n",
              "  'references': ['3118608800',\n",
              "   '1746819321',\n",
              "   '2141125852',\n",
              "   '2097998348',\n",
              "   '2106411961',\n",
              "   '2951665052',\n",
              "   '60686164',\n",
              "   '2165599843',\n",
              "   '2099201756',\n",
              "   '1973333099'],\n",
              "  'title': 'Practical Bayesian Optimization of Machine Learning Algorithms'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Gerard Salton ', ' Michael J. McGill'],\n",
              "  'date': '1983',\n",
              "  'identifier': '1956559956',\n",
              "  'references': ['1880262756',\n",
              "   '2140190241',\n",
              "   '2031489346',\n",
              "   '2037227137',\n",
              "   '1902027874',\n",
              "   '2031454541',\n",
              "   '2110325612',\n",
              "   '2147152072',\n",
              "   '2158266063',\n",
              "   '2107743791'],\n",
              "  'title': 'Introduction to Modern Information Retrieval'},\n",
              " {'abstract': 'Abstract Aim We estimated the number of people worldwide with diabetes for the years 2010 and 2030. Methods Studies from 91 countries were used to calculate age- and sex-specific diabetes prevalences, which were applied to national population estimates, to determine national diabetes prevalences for all 216 countries for 2010 and 2030. Studies were identified using Medline, and contact with all national and regional International Diabetes Federation offices. Studies were included if diabetes prevalence was assessed using a population-based methodology, and was based on World Health Organization or American Diabetes Association diagnostic criteria for at least three separate age-groups within the 20–79 year range. Self-report or registry data were used if blood glucose assessment was not available. Results The world prevalence of diabetes among adults (aged 20–79 years) will be 6.4%, affecting 285 million adults, in 2010, and will increase to 7.7%, and 439 million adults by 2030. Between 2010 and 2030, there will be a 69% increase in numbers of adults with diabetes in developing countries and a 20% increase in developed countries. Conclusion These predictions, based on a larger number of studies than previous estimates, indicate a growing burden of diabetes, particularly in developing countries.',\n",
              "  'authors': ['J.E. Shaw ', ' R.A. Sicree ', ' P.Z. Zimmet'],\n",
              "  'date': '2010',\n",
              "  'identifier': '2101508556',\n",
              "  'references': ['2520432709',\n",
              "   '2020267609',\n",
              "   '2345903479',\n",
              "   '2031484324',\n",
              "   '2798643531',\n",
              "   '2146536851',\n",
              "   '2131377217',\n",
              "   '2115951150',\n",
              "   '2006625394',\n",
              "   '2050456578'],\n",
              "  'title': 'Global estimates of the prevalence of diabetes for 2010 and 2030.'},\n",
              " {'abstract': 'Severe acute respiratory syndrome coronavirus (SARS-CoV) and Middle East respiratory syndrome coronavirus (MERS-CoV) are two highly transmissible and pathogenic viruses that emerged in humans at the beginning of the 21st century. Both viruses likely originated in bats, and genetically diverse coronaviruses that are related to SARS-CoV and MERS-CoV were discovered in bats worldwide. In this Review, we summarize the current knowledge on the origin and evolution of these two pathogenic coronaviruses and discuss their receptor usage; we also highlight the diversity and potential of spillover of bat-borne coronaviruses, as evidenced by the recent spillover of swine acute diarrhoea syndrome coronavirus (SADS-CoV) to pigs. Coronaviruses have a broad host range and distribution, and some highly pathogenic lineages have spilled over to humans and animals. Here, Cui, Li and Shi explore the viral factors that enabled the emergence of diseases such as severe acute respiratory syndrome and Middle East respiratory syndrome.',\n",
              "  'authors': ['Jie Cui 1', ' Fang Li 2', ' Zheng Li Shi 1'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2903899730',\n",
              "  'references': ['2144081223',\n",
              "   '2166867592',\n",
              "   '2111211467',\n",
              "   '2470646526',\n",
              "   '2132260239',\n",
              "   '2104548316',\n",
              "   '2306794997',\n",
              "   '1993577573',\n",
              "   '2775086803',\n",
              "   '2119111857'],\n",
              "  'title': 'Origin and evolution of pathogenic coronaviruses'},\n",
              " {'abstract': 'A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms.',\n",
              "  'authors': ['Bernhard E. Boser 1',\n",
              "   ' Isabelle M. Guyon 2',\n",
              "   ' Vladimir N. Vapnik 2'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2087347434',\n",
              "  'references': ['3017143921',\n",
              "   '2171277043',\n",
              "   '1530699444',\n",
              "   '2165758113',\n",
              "   '3124770806',\n",
              "   '2154579312',\n",
              "   '2076118331',\n",
              "   '2086472796',\n",
              "   '2111494971',\n",
              "   '1965770722'],\n",
              "  'title': 'A training algorithm for optimal margin classifiers'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Hwee Tou Ng 1', ' Wei Boon Goh 2', ' Kok Leong Low 2'],\n",
              "  'date': '1997',\n",
              "  'identifier': '1983078185',\n",
              "  'references': ['1969572066',\n",
              "   '2060216474',\n",
              "   '2094934653',\n",
              "   '2058982198',\n",
              "   '3037715718',\n",
              "   '1594962278',\n",
              "   '1993934121',\n",
              "   '1539741229',\n",
              "   '2049384587',\n",
              "   '2127994451'],\n",
              "  'title': 'Feature selection, perceptron learning, and a usability case study for text categorization'},\n",
              " {'abstract': \"Abstract: Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.\",\n",
              "  'authors': ['Ian J. Goodfellow ', ' Jonathon Shlens ', ' Christian Szegedy'],\n",
              "  'date': '2015',\n",
              "  'identifier': '2963207607',\n",
              "  'references': ['2963857521',\n",
              "   '2964253222',\n",
              "   '2604763608',\n",
              "   '3102564565',\n",
              "   '2180612164',\n",
              "   '2243397390',\n",
              "   '2964082701'],\n",
              "  'title': 'Explaining and Harnessing Adversarial Examples'},\n",
              " {'abstract': 'In this article, we provide guidance for substantive researchers on the use of structural equation modeling in practice for theory testing and development. We present a comprehensive, two-step modeling approach that employs a series of nested models and sequential chi-square difference tests. We discuss the comparative advantages of this approach over a one-step approach. Considerations in specification, assessment of fit, and respecification of measurement models using confirmatory factor analysis are reviewed. As background to the two-step approach, the distinction between exploratory and confirmatory analysis, the distinction between complementary approaches for theory testing versus predictive application, and some developments in estimation methods also are discussed.',\n",
              "  'authors': ['James C. Anderson 1', ' David W. Gerbing 2'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2122912498',\n",
              "  'references': ['2149608872',\n",
              "   '1989528006',\n",
              "   '1976927254',\n",
              "   '2041465237',\n",
              "   '2164085284',\n",
              "   '2042539525',\n",
              "   '2580989708',\n",
              "   '2024233657',\n",
              "   '2056453713',\n",
              "   '2024509488'],\n",
              "  'title': 'STRUCTURAL EQUATION MODELING IN PRACTICE: A REVIEW AND RECOMMENDED TWO-STEP APPROACH'},\n",
              " {'abstract': \"Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.\",\n",
              "  'authors': ['Ilya Sutskever ', ' Oriol Vinyals ', ' Quoc V. Le'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2130942839',\n",
              "  'references': ['2618530766',\n",
              "   '2964308564',\n",
              "   '2157331557',\n",
              "   '2310919327',\n",
              "   '2064675550',\n",
              "   '2101105183',\n",
              "   '179875071',\n",
              "   '2147768505',\n",
              "   '2132339004',\n",
              "   '1753482797'],\n",
              "  'title': 'Sequence to Sequence Learning with Neural Networks'},\n",
              " {'abstract': 'We consider the problem of minimizing the sum of a smooth function and a separable convex function. This problem includes as special cases bound-constrained optimization and smooth optimization with l1-regularization. We propose a (block) coordinate gradient descent method for solving this class of nonsmooth separable problems. We establish global convergence and, under a local Lipschitzian error bound assumption, linear convergence for this method. The local Lipschitzian error bound holds under assumptions analogous to those for constrained smooth optimization, e.g., the convex function is polyhedral and the smooth function is (nonconvex) quadratic or is the composition of a strongly convex function with a linear mapping. We report numerical experience with solving the l1-regularization of unconstrained optimization problems from More et al. in ACM Trans. Math. Softw. 7, 17–41, 1981 and from the CUTEr set (Gould and Orban in ACM Trans. Math. Softw. 29, 373–394, 2003). Comparison with L-BFGS-B and MINOS, applied to a reformulation of the l1-regularized problem as a bound-constrained optimization problem, is also reported.',\n",
              "  'authors': ['Paul Tseng ', ' Sangwoon Yun'],\n",
              "  'date': '2008',\n",
              "  'identifier': '2039050532',\n",
              "  'references': ['3029645440',\n",
              "   '2078204800',\n",
              "   '2138019504',\n",
              "   '2158940042',\n",
              "   '2077658674',\n",
              "   '2079724595',\n",
              "   '1543439990',\n",
              "   '2106398669',\n",
              "   '2123737232',\n",
              "   '2137226992'],\n",
              "  'title': 'A coordinate gradient descent method for nonsmooth separable minimization'},\n",
              " {'abstract': 'SUMMARY 1.Thecontrast thresholds ofavariety ofgrating patterns havebeen measured overawiderangeofspatial frequencies. 2.Contrast thresholds forthedetection ofgratings whoseluminance profiles aresine, square, rectangular orsaw-tooth wavescanbesimply related using Fourier theory. 3.Overawiderangeofspatial frequencies thecontrast threshold ofa grating isdetermined onlybytheamplitude ofthefundamental Fourier component ofitswaveform. 4.Gratings ofcomplex waveformcannotbedistinguished fromsinewavegratings until their contrast hasbeenraised toalevel atwhichthe higher harmonic components reach their independent threshold. 5.Thesefindings canbeexplained bytheexistence within thenervous system oflinearly operating independent mechanisms selectively sensitive tolimited ranges ofspatial frequencies.',\n",
              "  'authors': ['F. W. Campbell ', ' J. G. Robson'],\n",
              "  'date': '1968',\n",
              "  'identifier': '1999908130',\n",
              "  'references': ['2153782322', '2003198209', '1997191187', '2031864849'],\n",
              "  'title': 'Application of fourier analysis to the visibility of gratings'},\n",
              " {'abstract': 'The statistics of gray-level di!erences have been successfully used in a number of texture analysis studies. In this paper we propose to use signed gray-level di!erences and their multidimensional distributions for texture description. The present approach has important advantages compared to earlier related approaches based on gray level cooccurrence matrices or histograms of absolute gray-level di!erences. Experiments with di$cult texture classi\"cation and supervised texture segmentation problems show that our approach provides a very good and robust performance in comparison with the mainstream paradigms such as cooccurrence matrices, Gaussian Markov random \"elds, or Gabor \"ltering. ( 2001 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.',\n",
              "  'authors': ['Timo Ojala 1',\n",
              "   ' Kimmo Valkealahti 2',\n",
              "   ' Erkki Oja 3',\n",
              "   ' Matti Pietikäinen 1'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2132047332',\n",
              "  'references': ['2125148312',\n",
              "   '2039051707',\n",
              "   '1564419782',\n",
              "   '2098347925',\n",
              "   '2911956715',\n",
              "   '2059432853',\n",
              "   '1487718662',\n",
              "   '2163363072',\n",
              "   '2038836824',\n",
              "   '2117395697'],\n",
              "  'title': 'Texture discrimination with multidimensional distributions of signed gray-level differences'},\n",
              " {'abstract': '',\n",
              "  'authors': ['David D. Lewis 1',\n",
              "   ' Robert E. Schapire 1',\n",
              "   ' James P. Callan 2',\n",
              "   ' Ron Papka 2'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2060216474',\n",
              "  'references': ['1956559956',\n",
              "   '1978394996',\n",
              "   '2895674046',\n",
              "   '3017143921',\n",
              "   '2000672666',\n",
              "   '2085989833',\n",
              "   '1969572066',\n",
              "   '2000569744',\n",
              "   '2069317438',\n",
              "   '2002664886'],\n",
              "  'title': 'Training algorithms for linear text classifiers'},\n",
              " {'abstract': 'An interconnection pattern of processing elements, the cube-connected cycles (CCC), is introduced which can be used as a general purpose parallel processor. Because its design complies with present technological constraints, the CCC can also be used in the layout of many specialized large scale integrated circuits (VLSI). By combining the principles of parallelism and pipelining, the CCC can emulate the cube-connected machine and the shuffle-exchange network with no significant degradation of performance but with a more compact structure. We describe in detail how to program the CCC for efficiently solving a large class of problems that include Fast Fourier transform, sorting, permutations, and derived algorithms.',\n",
              "  'authors': ['Franco P. Preparata 1', ' Jean Vuillemin 2'],\n",
              "  'date': '1981',\n",
              "  'identifier': '2073491596',\n",
              "  'references': ['1655990431',\n",
              "   '2752853835',\n",
              "   '1666015432',\n",
              "   '1976284552',\n",
              "   '2141389982',\n",
              "   '3027900649',\n",
              "   '2132733020',\n",
              "   '2067002313',\n",
              "   '1585714998',\n",
              "   '2066104460'],\n",
              "  'title': 'The cube-connected cycles: a versatile network for parallel computation'},\n",
              " {'abstract': 'Privacy becomes a crucial issue when outsourcing the training of machine learning (ML) models to cloud-based platforms offering machine-learning services. While solutions based on cryptographic primitives have been developed, they incur a significant loss in accuracy or training efficiency, and require modifications to the backend architecture. A key challenge we tackle in this paper is the design of image obfuscation schemes that provide enough privacy without significantly degrading the accuracy of the ML model and the efficiency of the training process. In this endeavor, we address another challenge that has persisted so far: quantifying the degree of privacy provided by visual obfuscation mechanisms. We compare the ability of state-of-the-art full-reference quality metrics to concur with human subjects in terms of the degree of obfuscation introduced by a range of techniques. By relying on user surveys and two image datasets, we show that two existing image quality metrics are also well suited to measure the level of privacy in accordance with human subjects as well as AI-based recognition, and can therefore be used for quantifying privacy resulting from obfuscation. With the ability to quantify privacy, we show that we can provide adequate privacy protection to the training image set at the cost of only a few percentage points loss in accuracy.',\n",
              "  'authors': ['Mathilde Raynal ',\n",
              "   ' Radhakrishna Achanta ',\n",
              "   ' Mathias Humbert'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3094150121',\n",
              "  'references': ['2194775991',\n",
              "   '2964121744',\n",
              "   '2133665775',\n",
              "   '2183341477',\n",
              "   '2158698691',\n",
              "   '1973948212',\n",
              "   '2118858186',\n",
              "   '2473418344',\n",
              "   '2963981733',\n",
              "   '2963399829'],\n",
              "  'title': 'Image Obfuscation for Privacy-Preserving Machine Learning.'},\n",
              " {'abstract': 'Experimental introduction of RNA into cells can be used in certain biological systems to interfere with the function of an endogenous gene. Such effects have been proposed to result from a simple antisense mechanism that depends on hybridization between the injected RNA and endogenous messenger RNA transcripts. RNA interference has been used in the nematode Caenorhabditis elegans to manipulate gene expression. Here we investigate the requirements for structure and delivery of the interfering RNA. To our surprise, we found that double-stranded RNA was substantially more effective at producing interference than was either strand individually. After injection into adult animals, purified single strands had at most a modest effect, whereas double-stranded mixtures caused potent and specific interference. The effects of this interference were evident in both the injected animals and their progeny. Only a few molecules of injected double-stranded RNA were required per affected cell, arguing against stochiometric interference with endogenous mRNA and suggesting that there could be a catalytic or amplification component in the interference process.',\n",
              "  'authors': ['Andrew Fire 1',\n",
              "   ' SiQun Xu 1',\n",
              "   ' Mary K. Montgomery 1',\n",
              "   ' Steven A. Kostas 1',\n",
              "   ' 2',\n",
              "   ' Samuel E. Driver 3',\n",
              "   ' Craig C. Mello 3'],\n",
              "  'date': '1998',\n",
              "  'identifier': '1647075334',\n",
              "  'references': ['2032579724',\n",
              "   '2034831897',\n",
              "   '2149871164',\n",
              "   '1944127002',\n",
              "   '1992194142',\n",
              "   '1989952069',\n",
              "   '1594381468',\n",
              "   '1581412826',\n",
              "   '2151068726',\n",
              "   '2022846624'],\n",
              "  'title': 'Potent and specific genetic interference by double-stranded RNA in Caenorhabditis elegans'},\n",
              " {'abstract': 'The statistical tests used in the analysis of structural equation models with unobservable variables and measurement error are examined. A drawback of the commonly applied chi square test, in addit...',\n",
              "  'authors': ['Claes Fornell 1', ' David F. Larcker 2'],\n",
              "  'date': '1981',\n",
              "  'identifier': '1987258130',\n",
              "  'references': ['2149608872',\n",
              "   '2024509488',\n",
              "   '2030741364',\n",
              "   '2124634097',\n",
              "   '2005423324',\n",
              "   '1983799715',\n",
              "   '2116958223',\n",
              "   '1990967863',\n",
              "   '2315698671',\n",
              "   '2317858760'],\n",
              "  'title': 'Evaluating Structural Equation Models with Unobservable Variables and Measurement Error'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Paul Simon Rosenbloom'],\n",
              "  'date': '1983',\n",
              "  'identifier': '197716421',\n",
              "  'references': ['2140243223',\n",
              "   '1966028617',\n",
              "   '1993448335',\n",
              "   '2179193338',\n",
              "   '42833667',\n",
              "   '2163514996',\n",
              "   '2176609118',\n",
              "   '2022247428',\n",
              "   '2207077738'],\n",
              "  'title': 'The chunking of goal hierarchies: a model of practice and stimulus-response compatibility'},\n",
              " {'abstract': 'In the past several years, the speed of standard processors has reached the point where interesting problems requiring visual tracking can be carried out on standard workstations. However, relatively little attention has been devoted to developing visual tracking technology in its own right. In this article, we describe X Vision, a modular, portable framework for visual tracking. X Vision is designed to be a programming environment for real-time vision which provides high performance on standard workstations outfitted with a simple digitizer. X Vision consists of a small set of image-level tracking primitives, and a framework for combining tracking primitives to form complex tracking systems. Efficiency and robustness are achieved by propagating geometric and temporal constraints to the feature detection level, where image warping and specialized image processing are combined to perform feature detection quickly and robustly. Over the past several years, we have used X Vision to construct several vision-based systems. We present some of these applications as an illustration of how useful, robust tracking systems can be constructed by simple combinations of a few basic primitives combined with the appropriate task-specific constraints.',\n",
              "  'authors': ['Gregory D. Hager ', ' Kentaro Toyama'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2028539056',\n",
              "  'references': ['2104095591',\n",
              "   '2130103520',\n",
              "   '1564419782',\n",
              "   '2118877769',\n",
              "   '2753461371',\n",
              "   '2086921140',\n",
              "   '2121009299',\n",
              "   '2130657708',\n",
              "   '2109269337',\n",
              "   '1530454533'],\n",
              "  'title': 'X Vision'},\n",
              " {'abstract': 'Abstract This paper gives an input independent average linear time algorithm for storage and retrieval on keys. The algorithm makes a random choice of hash function from a suitable class of hash functions. Given any sequence of inputs the expected time (averaging over all functions in the class) to store and retrieve elements is linear in the length of the sequence. The number of references to the data base required by the algorithm for any input is extremely close to the theoretical minimum for any possible hash function with randomly distributed inputs. We present three suitable classes of hash functions which also can be evaluated rapidly. The ability to analyze the cost of storage and retrieval without worrying about the distribution of the input allows as corollaries improvements on the bounds of several algorithms.',\n",
              "  'authors': ['J.Lawrence Carter ', ' Mark N. Wegman'],\n",
              "  'date': '1979',\n",
              "  'identifier': '2052207834',\n",
              "  'references': ['1655990431',\n",
              "   '2752853835',\n",
              "   '1600795850',\n",
              "   '1964053266',\n",
              "   '2087966340',\n",
              "   '2059442002',\n",
              "   '2027085566',\n",
              "   '1568754185',\n",
              "   '2114141110',\n",
              "   '1970824574'],\n",
              "  'title': 'Universal classes of hash functions'},\n",
              " {'abstract': 'Properties of the receptive fields of simple cells in macaque cortex were compared with properties of independent component filters generated by independent component analysis (ICA) on a large set of natural images. Histograms of spatial frequency bandwidth, orientation tuning bandwidth, aspect ratio and length of the receptive fields match well. This indicates that simple cells are well tuned to the expected statistics of natural stimuli. There is no match, however, in calculated and measured distributions for the peak of the spatial frequency response: the filters produced by ICA do not vary their spatial scale as much as simple cells do, but are fixed to scales close to the finest ones allowed by the sampling lattice. Possible ways to resolve this discrepancy are discussed.',\n",
              "  'authors': ['J H van Hateren 1', ' A van der Schaaf 2'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2101933716',\n",
              "  'references': ['2145889472',\n",
              "   '2019502123',\n",
              "   '2105464873',\n",
              "   '2137234026',\n",
              "   '2180838288',\n",
              "   '2022735534',\n",
              "   '2167034998',\n",
              "   '2120838001',\n",
              "   '2170319235',\n",
              "   '2042755403'],\n",
              "  'title': 'Independent component filters of natural images compared with simple cells in primary visual cortex'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Gene H. Golub'],\n",
              "  'date': '1983',\n",
              "  'identifier': '2798909945',\n",
              "  'references': ['2296616510',\n",
              "   '2164278908',\n",
              "   '2145096794',\n",
              "   '1746819321',\n",
              "   '2127271355',\n",
              "   '2121947440',\n",
              "   '2167667767',\n",
              "   '3102641634'],\n",
              "  'title': 'Matrix computations'},\n",
              " {'abstract': 'While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams.',\n",
              "  'authors': ['Janez Demšar'],\n",
              "  'date': '2006',\n",
              "  'identifier': '1565746575',\n",
              "  'references': ['2084812512',\n",
              "   '2115012618',\n",
              "   '2009543464',\n",
              "   '1966280301',\n",
              "   '2167277498',\n",
              "   '2121044470',\n",
              "   '1585743408',\n",
              "   '2030360178',\n",
              "   '2024081693',\n",
              "   '1524761913'],\n",
              "  'title': 'Statistical Comparisons of Classifiers over Multiple Data Sets'},\n",
              " {'abstract': 'Markov chain Monte Carlo methods for Bayesian computation have until recently been restricted to problems where the joint distribution of all variables has a density with respect to some fixed standard underlying measure. They have therefore not been available for application to Bayesian model determination, where the dimensionality of the parameter vector is typically not fixed. This paper proposes a new framework for the construction of reversible Markov chain samplers that jump between parameter subspaces of differing dimensionality, which is flexible and entirely constructive. It should therefore have wide applicability in model determination problems. The methodology is illustrated with applications to multiple change-point analysis in one and two dimensions, and to a Bayesian comparison of binomial experiments.',\n",
              "  'authors': ['Peter J. Green'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2106706098',\n",
              "  'references': ['1997063559',\n",
              "   '2116044718',\n",
              "   '2136796925',\n",
              "   '1988684120',\n",
              "   '2111051773',\n",
              "   '1582801283',\n",
              "   '1555683961',\n",
              "   '2138309709',\n",
              "   '2171166366',\n",
              "   '1989457171'],\n",
              "  'title': 'Reversible jump Markov chain Monte Carlo computation and Bayesian model determination'},\n",
              " {'abstract': 'There are a number of collocational constraints in natural languages that ought to play a more important role in natural language parsers. Thus, for example, it is hard for most parsers to take advantage of the fact that wine is typically drunk, produced, and sold, but (probably) not pruned. So too, it is hard for a parser to know which verbs go with which prepositions (e.g., set up) and which nouns fit together to form compound noun phrases (e.g., computer programmer). This paper will attempt to show that many of these types of concerns can be addressed with syntactic methods (symbol pushing), and need not require explicit semantic interpretation. We have found that it is possible to identify many of these interesting co-occurrence relations by computing simple summary statistics over millions of words of text. This paper will summarize a number of experiments carried out by various subsets of the authors over the last few years. The term collocation will be used quite broadly to include constraints on SVO (subject verb object) triples, phrasal verbs, compound noun phrases, and psycholinguistic notions of word association (e.g., doctorinurse).',\n",
              "  'authors': ['Kenneth Church ',\n",
              "   ' William Gale ',\n",
              "   ' Patrick Hanks ',\n",
              "   ' Donald Hindle'],\n",
              "  'date': '1989',\n",
              "  'identifier': '1990438144',\n",
              "  'references': ['2099247782',\n",
              "   '1593045043',\n",
              "   '2441154163',\n",
              "   '2017580301',\n",
              "   '2155818555',\n",
              "   '1571096757',\n",
              "   '1605351056',\n",
              "   '2059000558',\n",
              "   '2111108424',\n",
              "   '623622508'],\n",
              "  'title': 'Parsing, word associations and typical predicate-argument relations'},\n",
              " {'abstract': '',\n",
              "  'authors': ['D. E. Goldberg'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2152150600',\n",
              "  'references': ['2076063813',\n",
              "   '1595159159',\n",
              "   '1992419399',\n",
              "   '2107941094',\n",
              "   '1998674867',\n",
              "   '2144317842',\n",
              "   '2125899728',\n",
              "   '1577668191',\n",
              "   '1820051232',\n",
              "   '2125213524'],\n",
              "  'title': 'Genetic Algorithms in Search'},\n",
              " {'abstract': 'We propose a fully homomorphic encryption scheme -- i.e., a scheme that allows one to evaluate circuits over encrypted data without being able to decrypt. Our solution comes in three steps. First, we provide a general result -- that, to construct an encryption scheme that permits evaluation of arbitrary circuits, it suffices to construct an encryption scheme that can evaluate (slightly augmented versions of) its own decryption circuit; we call a scheme that can evaluate its (augmented) decryption circuit bootstrappable. Next, we describe a public key encryption scheme using ideal lattices that is almost bootstrappable. Lattice-based cryptosystems typically have decryption algorithms with low circuit complexity, often dominated by an inner product computation that is in NC1. Also, ideal lattices provide both additive and multiplicative homomorphisms (modulo a public-key ideal in a polynomial ring that is represented as a lattice), as needed to evaluate general circuits. Unfortunately, our initial scheme is not quite bootstrappable -- i.e., the depth that the scheme can correctly evaluate can be logarithmic in the lattice dimension, just like the depth of the decryption circuit, but the latter is greater than the former. In the final step, we show how to modify the scheme to reduce the depth of the decryption circuit, and thereby obtain a bootstrappable encryption scheme, without reducing the depth that the scheme can evaluate. Abstractly, we accomplish this by enabling the encrypter to start the decryption process, leaving less work for the decrypter, much like the server leaves less work for the decrypter in a server-aided cryptosystem.',\n",
              "  'authors': ['Craig Gentry'],\n",
              "  'date': '2009',\n",
              "  'identifier': '2031533839',\n",
              "  'references': ['1996360405',\n",
              "   '2132172731',\n",
              "   '2007466965',\n",
              "   '1798609567',\n",
              "   '2108834246',\n",
              "   '1675339804',\n",
              "   '1590823599',\n",
              "   '2067264567',\n",
              "   '3030755847',\n",
              "   '2141040012'],\n",
              "  'title': 'Fully homomorphic encryption using ideal lattices'},\n",
              " {'abstract': 'The extrema in a signal and its first few derivatives provide a useful general purpose qualitative description for many kinds of signals. A fundamental problem in computing such descriptions is scale: a derivative must be taken over some neighborhood, but there is seldom a principled basis for choosing its size. Scale-space filtering is a method that describes signals qualitatively, managing the ambiguity of scale in an organized and natural way. The signal is first expanded by convolution with gaussian masks over a continuum of sizes. This \"scale-space\" image is then collapsed, using its qualitative structure, into a tree providing a concise but complete qualitative description covering all scales of observation. The description is further refined by applying a stability criterion, to identify events that persist of large changes in scale.',\n",
              "  'authors': ['A. Witkin'],\n",
              "  'date': '1984',\n",
              "  'identifier': '2133155955',\n",
              "  'references': ['2740373864',\n",
              "   '1622620102',\n",
              "   '1995756857',\n",
              "   '1968245656',\n",
              "   '1530383550',\n",
              "   '1973976434',\n",
              "   '2117900366',\n",
              "   '1965555058'],\n",
              "  'title': 'Scale-space filtering: A new approach to multi-scale description'},\n",
              " {'abstract': '1 Compositional data: some challenging problems.- 1.1 Introduction.- 1.2 Geochemical compositions of rocks.- 1.3 Sediments at different depths.- 1.4 Ternary diagrams.- 1.5 Partial analyses and subcompositions.- 1.6 Supervisory behaviour.- 1.7 Household budget surveys.- 1.8 Steroid metabolite patterns in adults and children.- 1.9 Activity patterns of a statistician.- 1.10 Calibration of white-cell compositions.- 1.11 Fruit evaluation.- 1.12 Firework mixtures.- 1.13 Clam ecology.- 1.14 Bibliographic notes.- Problems.- 2 The simplex as sample space.- 2.1 Choice of sample space.- 2.2 Compositions and simplexes.- 2.3 Spaces, vectors, matrices.- 2.4 Bases and compositions.- 2.5 Subcompositions.- 2.6 Amalgamations.- 2.7 Partitions.- 2.8 Perturbations.- 2.9 Geometrical representations of compositional data.- 2.10 Bibliographic notes.- Problems.- 3 The special difficulties of compositional data analysis.- 3.1 Introduction.- 3.2 High dimensionality.- 3.3 Absence of an interpretable covariance structure.- 3.4 Difficulty of parametric modelling.- 3.5 The mixture variation difficulty.- 3.6 Bibliographic notes.- Problems.- 4 Covariance structure.- 4.1 Fundamentals.- 4.2 Specification of the covariance structure.- 4.3 The compositional variation array.- 4.4 Recovery of the compositional variation array from the crude mean vector and covariance matrix.- 4.5 Subcompositional analysis.- 4.6 Matrix specifications of covariance structures.- 4.7 Some important elementary matrices.- 4.8 Relationships between the matrix specifications.- 4.9 Estimated matrices for hongite compositions.- 4.10 Logratios and logcontrasts.- 4.11 Covariance structure of a basis.- 4.12 Commentary.- 4.13 Bibliographic notes.- Problems.- 5 Properties of matrix covariance specifications.- 5.1 Logratio notation.- 5.2 Logcontrast variances and covariances.- 5.3 Permutations.- 5.4 Properties of P and QP matrices.- 5.5 Permutation invariants involving ?.- 5.6 Covariance matrix inverses.- 5.7 Subcompositions.- 5.8 Equivalence of characteristics of ?, ?, ?.- 5.9 Logratio-uncorrelated compositions.- 5.10 Isotropic covariance structures.- 5.11 Bibliographic notes.- Problems.- 6 Logistic normal distributions on the simplex.- 6.1 Introduction.- 6.2 The additive logistic normal class.- 6.3 Density function.- 6.4 Moment properties.- 6.5 Composition of a lognormal basis.- 6.6 Class-preserving properties.- 6.7 Conditional subcompositional properties.- 6.8 Perturbation properties.- 6.9 A central limit theorem.- 6.10 A characterization by logcontrasts.- 6.11 Relationships with the Dirichlet class.- 6.12 Potential for statistical analysis.- 6.13 The multiplicative logistic normal class.- 6.14 Partitioned logistic normal classes.- 6.15 Some notation.- 6.16 Bibliographic notes.- Problems.- 7 Logratio analysis of compositions.- 7.1 Introduction.- 7.2 Estimation of ? and ?.- 7.3 Validation: tests of logistic normality.- 7.4 Hypothesis testing strategy and techniques.- 7.5 Testing hypotheses about ? and ?.- 7.6 Logratio linear modelling.- 7.7 Testing logratio linear hypotheses.- 7.8 Further aspects of logratio linear modelling.- 7.9 An application of logratio linear modelling.- 7.10 Predictive distributions, atypicality indices and outliers.- 7.11 Statistical discrimination.- 7.12 Conditional compositional modelling.- 7.13 Bibliographic notes.- Problems.- 8 Dimension-reducing techniques.- 8.1 Introduction.- 8.2 Crude principal component analysis.- 8.3 Logcontrast principal component analysis.- 8.4 Applications of logcontrast principal component analysis.- 8.5 Subcompositional analysis.- 8.6 Applications of subcompositional analysis.- 8.7 Canonical component analysis.- 8.8 Bibliographic notes.- Problems.- 9 Bases and compositions.- 9.1 Fundamentals.- 9.2 Covariance relationships.- 9.3 Principal and canonical component comparisons.- 9.4 Distributional relationships.- 9.5 Compositional invariance.- 9.6 An application to household budget analysis.- 9.7 An application to clinical biochemistry.- 9.8 Reappraisal of an early shape and size analysis.- 9.9 Bibliographic notes.- Problems.- 10 Subcompositions and partitions.- 10.1 Introduction.- 10.2 Complete subcompositional independence.- 10.3 Partitions of order 1.- 10.4 Ordered sequences of partitions.- 10.5 Caveat.- 10.6 Partitions of higher order.- 10.7 Bibliographic notes.- Problems.- 11 Irregular compositional data.- 11.1 Introduction.- 11.2 Modelling imprecision in compositions.- 11.3 Analysis of sources of imprecision.- 11.4 Imprecision and tests of independence.- 11.5 Rounded or trace zeros.- 11.6 Essential zeros.- 11.7 Missing components.- 11.8 Bibliographic notes.- Problems.- 12 Compositions in a covariate role.- 12.1 Introduction.- 12.2 Calibration.- 12.3 A before-and-after treatment problem.- 12.4 Experiments with mixtures.- 12.5 An application to firework mixtures.- 12.6 Classification from compositions.- 12.7 An application to geological classification.- 12.8 Bibliographic notes.- Problems.- 13 Further distributions on the simplex.- 13.1 Some generalizations of the Dirichlet class.- 13.2 Some generalizations of the logistic normal classes.- 13.3 Recapitulation.- 13.4 The Ad(?,B) class.- 13.5 Maximum likelihood estimation.- 13.6 Neutrality and partition independence.- 13.7 Subcompositional independence.- 13.8 A generalized lognormal gamma distribution with compositional in variance.- 13.9 Discussion.- 13.10 Bibliographic notes.- Problems.- 14 Miscellaneous problems.- 14.1 Introduction.- 14.2 Multi-way compositions.- 14.3 Multi-stage compositions.- 14.4 Multiple compositions.- 14.5 Kernel density estimation for compositional data.- 14.6 Compositional stochastic processes.- 14.7 Relation to Bayesian statistical analysis.- 14.8 Compositional and directional data.- Problems.- Appendices.- A Algebraic properties of elementary matrices.- B Bibliography.- C Computer software for compositional data analysis.- D Data sets.- Author index.',\n",
              "  'authors': ['J Aitchison'],\n",
              "  'date': '1986',\n",
              "  'identifier': '2166325326',\n",
              "  'references': ['1983118771',\n",
              "   '2322520740',\n",
              "   '1982712545',\n",
              "   '2015967939',\n",
              "   '1968269771',\n",
              "   '1967980037',\n",
              "   '2087022010',\n",
              "   '2049520417',\n",
              "   '2016276961',\n",
              "   '1494488080'],\n",
              "  'title': 'The Statistical Analysis of Compositional Data'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Jerome H. Friedman'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2102201073',\n",
              "  'references': ['2798909945',\n",
              "   '3085162807',\n",
              "   '2146766088',\n",
              "   '2162870748',\n",
              "   '2017977879',\n",
              "   '133977063',\n",
              "   '2091886411',\n",
              "   '2040615655',\n",
              "   '3000332379',\n",
              "   '2002113995'],\n",
              "  'title': 'Multivariate Adaptive Regression Splines'},\n",
              " {'abstract': 'Binary response variables special logistical analyses some complications some related approaches more complex responses. Appendices: Theoretical background Choice of explanatory variables in multiple regression Review of computational aspects Further results and exercises.',\n",
              "  'authors': ['D. R. Cox ', ' E. J. Snell'],\n",
              "  'date': '1970',\n",
              "  'identifier': '2082102453',\n",
              "  'references': ['2037139573',\n",
              "   '2150865892',\n",
              "   '1528905581',\n",
              "   '2102201073',\n",
              "   '2106578604',\n",
              "   '2111578514',\n",
              "   '2319962899',\n",
              "   '2112621029',\n",
              "   '2131987814',\n",
              "   '1964475341'],\n",
              "  'title': 'analysis of binary data'},\n",
              " {'abstract': 'We sequenced the 29,751-base genome of the severe acute respiratory syndrome (SARS)-associated coronavirus known as the Tor2 isolate. The genome sequence reveals that this coronavirus is only moderately related to other known coronaviruses, including two human coronaviruses, HCoV-OC43 and HCoV-229E. Phylogenetic analysis of the predicted viral proteins indicates that the virus does not closely resemble any of the three previously known groups of coronaviruses. The genome sequence will aid in the diagnosis of SARS virus infection in humans and potential animal hosts (using polymerase chain reaction and immunological tests), in the development of antivirals (including neutralizing antibodies), and in the identification of putative epitopes for vaccine development.',\n",
              "  'authors': ['Marco A. Marra ',\n",
              "   ' Steven J. M. Jones 1',\n",
              "   ' Caroline R. Astell 1',\n",
              "   ' Robert A. Holt 1',\n",
              "   ' Angela Brooks-Wilson 1',\n",
              "   ' Yaron S. N. Butterfield 1',\n",
              "   ' Jaswinder Khattra 1',\n",
              "   ' Jennifer K. Asano 1',\n",
              "   ' Sarah A. Barber 1',\n",
              "   ' Susanna Y. Chan 1',\n",
              "   ' Alison Cloutier 1',\n",
              "   ' Shaun M. Coughlin 1',\n",
              "   ' Doug Freeman 1',\n",
              "   ' Noreen Girn 1',\n",
              "   ' Obi L. Griffith ',\n",
              "   ' Stephen R. Leach 1',\n",
              "   ' Michael Mayo 1',\n",
              "   ' Helen McDonald 1',\n",
              "   ' Stephen B. Montgomery 1',\n",
              "   ' Pawan K. Pandoh 1',\n",
              "   ' Anca S. Petrescu 1',\n",
              "   ' A. Gordon Robertson 1',\n",
              "   ' Jacqueline E. Schein 1',\n",
              "   ' Asim Siddiqui 1',\n",
              "   ' Duane E. Smailus 1',\n",
              "   ' Jeff M. Stott 1',\n",
              "   ' George S. Yang 1',\n",
              "   ' Francis Plummer 2',\n",
              "   ' Anton Andonov 2',\n",
              "   ' Harvey Artsob 2',\n",
              "   ' Nathalie Bastien 2',\n",
              "   ' Kathy Bernard 2',\n",
              "   ' Timothy F. Booth 2',\n",
              "   ' Donnie Bowness 2',\n",
              "   ' Martin Czub 2',\n",
              "   ' Michael Drebot 2',\n",
              "   ' Lisa Fernando 2',\n",
              "   ' Ramon Flick 2',\n",
              "   ' Michael Garbutt 2',\n",
              "   ' Michael Gray 2',\n",
              "   ' Allen Grolla 2',\n",
              "   ' Steven Jones 2',\n",
              "   ' Heinz Feldmann 2',\n",
              "   ' Adrienne Meyers 2',\n",
              "   ' Amin Kabani 2',\n",
              "   ' Yan Li 2',\n",
              "   ' Susan Normand 2',\n",
              "   ' Ute Stroher 2',\n",
              "   ' Graham A. Tipples 2',\n",
              "   ' Shaun Tyler 2 +9'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2169198329',\n",
              "  'references': ['2158714788',\n",
              "   '2106882534',\n",
              "   '2141885858',\n",
              "   '2015292449',\n",
              "   '2116586125',\n",
              "   '2171091522',\n",
              "   '2166699767',\n",
              "   '2022366078',\n",
              "   '2114083522',\n",
              "   '205578041'],\n",
              "  'title': 'The Genome Sequence of the SARS-associated Coronavirus'},\n",
              " {'abstract': \"This approach aims to optimize the kernel parameters and to efficiently reduce the number of support vectors, so that the generalization error can be reduced drastically. The proposed methodology suggests the use of a new model selection criterion based on the estimation of the probability of error of the SVM classifier. For comparison, we considered two more model selection criteria: GACV ('Generalized Approximate Cross-Validation') and VC ('Vapnik-Chernovenkis') dimension. These criteria are algebraic estimates of upper bounds of the expected error. For the former, we also propose a new minimization scheme. The experiments conducted on a bi-class problem show that we can adequately choose the SVM hyper-parameters using the empirical error criterion. Moreover, it turns out that the criterion produces a less complex model with fewer support vectors. For multi-class data, the optimization strategy is adapted to the one-against-one data partitioning. The approach is then evaluated on images of handwritten digits from the USPS database.\",\n",
              "  'authors': ['N. E. Ayat 1', ' M. Cheriet 2', ' C. Y. Suen 1'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2138882494',\n",
              "  'references': ['2119821739',\n",
              "   '1563088657',\n",
              "   '3023786531',\n",
              "   '1510073064',\n",
              "   '2140095548',\n",
              "   '1601740268',\n",
              "   '1576520375',\n",
              "   '1604938182',\n",
              "   '2124351082',\n",
              "   '2145295623'],\n",
              "  'title': 'Automatic model selection for the optimization of SVM kernels'},\n",
              " {'abstract': 'Abstract: Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures.',\n",
              "  'authors': ['Joan Bruna 1',\n",
              "   ' Wojciech Zaremba 1',\n",
              "   ' Arthur Szlam 2',\n",
              "   ' Yann LeCun 1'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2964311892',\n",
              "  'references': ['2618530766',\n",
              "   '1554944419',\n",
              "   '2310919327',\n",
              "   '2160815625',\n",
              "   '2132914434',\n",
              "   '1578099820',\n",
              "   '2156718197',\n",
              "   '2962820688',\n",
              "   '1999192586',\n",
              "   '2147860648'],\n",
              "  'title': 'Spectral Networks and Locally Connected Networks on Graphs'},\n",
              " {'abstract': 'ABSTRACT A novel human coronavirus (HCoV-EMC/2012) was isolated from a man with acute pneumonia and renal failure in June 2012. This report describes the complete genome sequence, genome organization, and expression strategy of HCoV-EMC/2012 and its relation with known coronaviruses. The genome contains 30,119 nucleotides and contains at least 10 predicted open reading frames, 9 of which are predicted to be expressed from a nested set of seven subgenomic mRNAs. Phylogenetic analysis of the replicase gene of coronaviruses with completely sequenced genomes showed that HCoV-EMC/2012 is most closely related to Tylonycteris bat coronavirus HKU4 (BtCoV-HKU4) and Pipistrellus bat coronavirus HKU5 (BtCoV-HKU5), which prototype two species in lineage C of the genus Betacoronavirus . In accordance with the guidelines of the International Committee on Taxonomy of Viruses, and in view of the 75% and 77% amino acid sequence identity in 7 conserved replicase domains with BtCoV-HKU4 and BtCoV-HKU5, respectively, we propose that HCoV-EMC/2012 prototypes a novel species in the genus Betacoronavirus . HCoV-EMC/2012 may be most closely related to a coronavirus detected in Pipistrellus pipistrellus in The Netherlands, but because only a short sequence from the most conserved part of the RNA-dependent RNA polymerase-encoding region of the genome was reported for this bat virus, its genetic distance from HCoV-EMC remains uncertain. HCoV-EMC/2012 is the sixth coronavirus known to infect humans and the first human virus within betacoronavirus lineage C. IMPORTANCE Coronaviruses are capable of infecting humans and many animal species. Most infections caused by human coronaviruses are relatively mild. However, the outbreak of severe acute respiratory syndrome (SARS) caused by SARS-CoV in 2002 to 2003 and the fatal infection of a human by HCoV-EMC/2012 in 2012 show that coronaviruses are able to cause severe, sometimes fatal disease in humans. We have determined the complete genome of HCoV-EMC/2012 using an unbiased virus discovery approach involving next-generation sequencing techniques, which enabled subsequent state-of-the-art bioinformatics, phylogenetics, and taxonomic analyses. By establishing its complete genome sequence, HCoV-EMC/2012 was characterized as a new genotype which is closely related to bat coronaviruses that are distant from SARS-CoV. We expect that this information will be vital to rapid advancement of both clinical and vital research on this emerging pathogen.',\n",
              "  'authors': ['Sander van Boheemen 1',\n",
              "   ' Miranda de Graaf 1',\n",
              "   ' Chris Lauber 2',\n",
              "   ' Theo M. Bestebroer 1',\n",
              "   ' V. Stalin Raj 1',\n",
              "   ' Ali Moh Zaki 3',\n",
              "   ' Albert D. M. E. Osterhaus 1',\n",
              "   ' Bart L. Haagmans 1',\n",
              "   ' Alexander E. Gorbalenya 2',\n",
              "   ' 4',\n",
              "   ' Eric J. Snijder 2',\n",
              "   ' Ron A. M. Fouchier 1'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2113457186',\n",
              "  'references': ['2166867592',\n",
              "   '1483247593',\n",
              "   '2111211467',\n",
              "   '2132260239',\n",
              "   '2082928585',\n",
              "   '1981646999',\n",
              "   '2127774996',\n",
              "   '1703839189',\n",
              "   '2116586125',\n",
              "   '2169198329'],\n",
              "  'title': 'Genomic Characterization of a Newly Discovered Coronavirus Associated with Acute Respiratory Distress Syndrome in Humans'},\n",
              " {'abstract': '1. Fundamentals of Speech Recognition. 2. The Speech Signal: Production, Perception, and Acoustic-Phonetic Characterization. 3. Signal Processing and Analysis Methods for Speech Recognition. 4. Pattern Comparison Techniques. 5. Speech Recognition System Design and Implementation Issues. 6. Theory and Implementation of Hidden Markov Models. 7. Speech Recognition Based on Connected Word Models. 8. Large Vocabulary Continuous Speech Recognition. 9. Task-Oriented Applications of Automatic Speech Recognition.',\n",
              "  'authors': ['Lawrence Rabiner ', ' Biing-Hwang Juang'],\n",
              "  'date': '1993',\n",
              "  'identifier': '1560013842',\n",
              "  'references': ['2519091744',\n",
              "   '2121601095',\n",
              "   '2030536784',\n",
              "   '2161406034',\n",
              "   '2120340025',\n",
              "   '2133824856',\n",
              "   '2081681829',\n",
              "   '1508165687',\n",
              "   '2099019320',\n",
              "   '2154278880'],\n",
              "  'title': 'Fundamentals of speech recognition'},\n",
              " {'abstract': 'Abstract A model of information processing in reading is described in which visual information is transformed through a series of processing stages involving visual, phonological and episodic memory systems until it is finally comprehended in the semantic system. The processing which occurs at each stage is assumed to be learned and the degree of this learning is evaluated with respect to two criteria: accuracy and automaticity . At the accuracy level of performance, attention is assumed to be necessary for processing; at the automatic level it is not. Experimental procedures are described which attempt to measure the degree of automaticity achieved in perceptual and associative learning tasks. Factors which may influence the development of automaticity in reading are discussed.',\n",
              "  'authors': ['David LaBerge ', ' S.Jay Samuels'],\n",
              "  'date': '1974',\n",
              "  'identifier': '2045597501',\n",
              "  'references': ['1984314602',\n",
              "   '3041214984',\n",
              "   '1967670055',\n",
              "   '1773016195',\n",
              "   '2075213419',\n",
              "   '1987124984',\n",
              "   '2010085418',\n",
              "   '2240086165',\n",
              "   '1976707985',\n",
              "   '2139109112'],\n",
              "  'title': 'Toward a theory of automatic information processing in reading'},\n",
              " {'abstract': '',\n",
              "  'authors': ['David H. Hubel'],\n",
              "  'date': '1957',\n",
              "  'identifier': '2037316494',\n",
              "  'references': ['2086916200', '1993352479', '1968581987', '2439991237'],\n",
              "  'title': 'Tungsten Microelectrode for Recording from Single Units.'},\n",
              " {'abstract': 'The fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of scale is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by representing image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to select local appropriate scales for further analysis. This article proposes a systematic methodology for dealing with this problem. A framework is presented for generating hypotheses about interesting scale levels in image data, based on a general principle stating that local extrema over scales of different combinations of γ-normalized derivatives are likely candidates to correspond to interesting structures. Specifically, it is shown how this idea can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure. Support for the proposed approach is given in terms of a general theoretical investigation of the behaviour of the scale selection method under rescalings of the input pattern and by integration with different types of early visual modules, including experiments on real-world and synthetic data. Support is also given by a detailed analysis of how different types of feature detectors perform when integrated with a scale selection mechanism and then applied to characteristic model patterns. Specifically, it is described in detail how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation. In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottleneck. It is argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to automatically analyse complex unknown environments.',\n",
              "  'authors': ['Tony Lindeberg'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2109200236',\n",
              "  'references': [],\n",
              "  'title': 'Feature Detection with Automatic Scale Selection'},\n",
              " {'abstract': 'Abstract Unitary responses to sinusoidal gratings either moving or alternating in phase have been investigated in the optic tract, lateral geniculate body and visual cortex of the cat as a function of the spatial frequency, position of the grating with respect to the cell receptive field and grating contrast. From the retina to the simple cells of the cortex there is a progressive narrowing of the spatial frequency band at which the cells are sensitive. The response of simple cells changes systematically with the position of an alteranting grating on the cell receptive field. The response of cells of the retina, geniculate body and visual cortex increases monotonically when the contrast of the grating is increased. For the simple cortical cells and for a part of complex cells there is a linear relation between the amplitude of the response and the logarithm of grating contrast.',\n",
              "  'authors': ['Lamberto Maffei ', ' Adriana Fiorentini'],\n",
              "  'date': '1973',\n",
              "  'identifier': '2017600612',\n",
              "  'references': [],\n",
              "  'title': 'The visual cortex as a spatial frequency analyser'},\n",
              " {'abstract': \"This paper analyses the stability and fairness of two classes of rate control algorithm for communication networks. The algorithms provide natural generalisations to large-scale networks of simple additive increase/multiplicative decrease schemes, and are shown to be stable about a system optimum characterised by a proportional fairness criterion. Stability is established by showing that, with an appropriate formulation of the overall optimisation problem, the network's implicit objective function provides a Lyapunov function for the dynamical system defined by the rate control algorithm. The network's optimisation problem may be cast in primal or dual form: this leads naturally to two classes of algorithm, which may be interpreted in terms of either congestion indication feedback signals or explicit rates based on shadow prices. Both classes of algorithm may be generalised to include routing control, and provide natural implementations of proportionally fair pricing.\",\n",
              "  'authors': ['Frank P. Kelly ', ' A. K. Maulloo ', ' David Kim Hong Tan'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2159715570',\n",
              "  'references': ['2753542457',\n",
              "   '1987497363',\n",
              "   '2156568423',\n",
              "   '3013767507',\n",
              "   '2145581668',\n",
              "   '105261775',\n",
              "   '2742470390',\n",
              "   '2913042775',\n",
              "   '2099917081',\n",
              "   '1801395439'],\n",
              "  'title': 'Rate control for communication networks: shadow prices, proportional fairness and stability'},\n",
              " {'abstract': 'tion’, implying that most patients ‘should’ receive a particular action. In contrast, level 2 guidelines are essentially ‘suggestions’ and are deemed to be ‘weak’ or discretionary, recognising that management decisions may vary in different clinical contexts. Each recommendation was further graded from A to D by the quality of evidence underpinning them, with grade A referring to a high quality of evidence whilst grade D recognised a ‘very low’ evidence base. The overall strength and quality of the supporting evidence is summarised in table 1 . The guidelines focused on 4 key domains: (1) AKI definition, (2) prevention and treatment of AKI, (3) contrastinduced AKI (CI-AKI) and (4) dialysis interventions for the treatment of AKI. The full summary of clinical practice statements is available at www.kdigo.org, but a few key recommendation statements will be highlighted here.',\n",
              "  'authors': ['Arif Khwaja'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2026274122',\n",
              "  'references': ['1967300023',\n",
              "   '2131419242',\n",
              "   '2143432233',\n",
              "   '2117958746',\n",
              "   '1531106656',\n",
              "   '2157775267',\n",
              "   '2028701043',\n",
              "   '2111704803',\n",
              "   '2135163018',\n",
              "   '2042074736'],\n",
              "  'title': 'KDIGO clinical practice guidelines for acute kidney injury.'},\n",
              " {'abstract': 'Our possessions are a major contributor to and reflection of our identities. A variety of evidence is presented supporting this simple and compelling premise. Related streams of research are identified and drawn upon in developing this concept and implications are derived for consumer behavior. Because the construct of extended self involves consumer behavior rather than buyer behavior, it appears to be a much richer construct than previous formulations positing a relationship between self-concept and consumer brand choice.',\n",
              "  'authors': ['Russell W. Belk'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2054347393',\n",
              "  'references': ['2051268679',\n",
              "   '2032498967',\n",
              "   '3124068636',\n",
              "   '1558305536',\n",
              "   '1520548237',\n",
              "   '1720881856',\n",
              "   '2167030552',\n",
              "   '1967058415',\n",
              "   '2093958576',\n",
              "   '2062307453'],\n",
              "  'title': 'Possessions and the extended self.'},\n",
              " {'abstract': 'A review of prior, relevant literature is an essential feature of any academic project. An effective review creates a firm foundation for advancing knowledge. It facilitates theory development, closes areas where a plethora of research exists, and uncovers areas where research is needed.',\n",
              "  'authors': ['Jane Webster 1', ' Richard T. Watson 2'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2111628838',\n",
              "  'references': ['2098118776',\n",
              "   '2057012437',\n",
              "   '2115497642',\n",
              "   '2128677857',\n",
              "   '2090054320',\n",
              "   '2095654817',\n",
              "   '2068899020',\n",
              "   '2044744663',\n",
              "   '2120489714',\n",
              "   '1496596930'],\n",
              "  'title': 'Analyzing the past to prepare for the future: writing a literature review'},\n",
              " {'abstract': 'Dark brown calf leather cover, 240 x 160 mm, gold stamped on the front and back with the heraldic crest of Pembroke College, Oxford, and gold stamped with the book title on the spine, 874 pages and one page addendum. A pocket formed by the back paste down contains five of originally eight folding plates. There are pencil notes in English in a few margins. The book is volume 9 in the series Allgemeine Encylopaedie der Physik edited by Gustav Karsten. (see page facing the title page). Digital images of the missing plates are on a CD held in the Pamphlet and Ephemera filing cabinet under Catalogue number 2924 together with print-outs of the images. They were copied courtesy of the BOA Museum Curator, Neil Handley, from a copy of this book in the Library of the the College of Optometrists, London. Images of this missing plates are on the Museum iPhoto',\n",
              "  'authors': ['Hermann Ludwig Ferdinand von Helmholtz'],\n",
              "  'date': '2015',\n",
              "  'identifier': '1641311894',\n",
              "  'references': ['2153791616',\n",
              "   '2127958135',\n",
              "   '2125663122',\n",
              "   '2137620073',\n",
              "   '2070461647',\n",
              "   '2129245434',\n",
              "   '1932937519',\n",
              "   '2095651675',\n",
              "   '2613546176',\n",
              "   '2151582777'],\n",
              "  'title': 'Handbuch der physiologischen Optik'},\n",
              " {'abstract': \"We formulate a theoretical model in which we postulate that if customers' behavior is perceived as not optimal, customers will adjust this behavior based on their current satisfaction and payment equity. Furthermore, customers will also include new experiences. In our empirical study we particularly investigate customer referrals and the amount of services purchased. Our results show positive effects of current satisfaction and payment equity on referrals, while also changes in satisfaction and payment equity affect customer referrals. With respect to the amount of services purchased, our estimation results reveal a positive significant effect of only changes in satisfaction.\",\n",
              "  'authors': ['Peter C. Verhoef ', ' Philip Hans Franses ', ' Bas Donkers'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2142128621',\n",
              "  'references': ['1979907230',\n",
              "   '2102467277',\n",
              "   '1997176931',\n",
              "   '1983364918',\n",
              "   '2081774187',\n",
              "   '1966912369',\n",
              "   '2139921829',\n",
              "   '3121411908',\n",
              "   '2014818400',\n",
              "   '190529148'],\n",
              "  'title': 'Changing Perceptions and Changing Behavior in Customer Relationships'},\n",
              " {'abstract': 'Given a set of objects in a scene whose identifications are ambiguous, it is often possible to use relationships among the objects to reduce or eliminate the ambiguity. A striking example of this approach was given by Waltz [13]. This paper formulates the ambiguity-reduction process in terms of iterated parallel operations (i.e., relaxation operations) performed on an array of (object, identification) data. Several different models of the process are developed, convergence properties of these models are established, and simple examples are given.',\n",
              "  'authors': ['Azriel Rosenfeld ', ' Robert A. Hummel ', ' Steven W. Zucker'],\n",
              "  'date': '1976',\n",
              "  'identifier': '1979622972',\n",
              "  'references': ['2042119491', '2018646682', '2489172749', '2018030206'],\n",
              "  'title': 'Scene Labeling by Relaxation Operations'},\n",
              " {'abstract': 'Sleep replay of awake experience in the cortex and hippocampus has been proposed to be involved in memory consolidation. However, whether temporally structured replay occurs in the cortex and whether the replay events in the two areas are related are unknown. Here we studied multicell spiking patterns in both the visual cortex and hippocampus during slow-wave sleep in rats. We found that spiking patterns not only in the cortex but also in the hippocampus were organized into frames, defined as periods of stepwise increase in neuronal population activity. The multicell firing sequences evoked by awake experience were replayed during these frames in both regions. Furthermore, replay events in the sensory cortex and hippocampus were coordinated to reflect the same experience. These results imply simultaneous reactivation of coherent memory traces in the cortex and hippocampus during sleep that may contribute to or reflect the result of the memory consolidation process.',\n",
              "  'authors': ['Daoyun Ji ', ' Matthew A Wilson'],\n",
              "  'date': '2007',\n",
              "  'identifier': '2168101731',\n",
              "  'references': ['2163815564',\n",
              "   '1970792572',\n",
              "   '2129789527',\n",
              "   '1984214648',\n",
              "   '2071290167',\n",
              "   '2079150153',\n",
              "   '1536357320',\n",
              "   '2129217278',\n",
              "   '1853766545',\n",
              "   '2119624849'],\n",
              "  'title': 'Coordinated memory replay in the visual cortex and hippocampus during sleep'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Alexander Waibel ',\n",
              "   ' Toshiyuki Hanazawa ',\n",
              "   ' Geoffrey Hinton ',\n",
              "   ' Kiyohiro Shikano ',\n",
              "   ' Kevin J. Lang'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2173629880',\n",
              "  'references': ['2217896605',\n",
              "   '2973127116',\n",
              "   '1606209288',\n",
              "   '2970350205',\n",
              "   '3007502375',\n",
              "   '2019202657',\n",
              "   '2098694627',\n",
              "   '3016138882',\n",
              "   '3115898234'],\n",
              "  'title': 'Phoneme recognition using time-delay neural networks'},\n",
              " {'abstract': 'Background: A high frequency of virus infections has been recently pointed out in the exacerbations of asthma in children. Objectives: To confirm this, using conventional and molecular detection methods, and expanding the study to younger children. Study design: One hundred and thirty-two nasal aspirates from 75 children hospitalized for a severe attack of asthma were studied (32 infants, mean age 9.1 months; and 43 children, mean age 5.6 years). According to the virus, a viral isolation technique, immunofluorescence assays (IFA) or both were used for the detection of rhinovirus, enterovirus, respiratory syncytial (RS) virus, adenovirus, coronavirus 229E, influenza and parainfluenza virus. Polymerase chain reaction (PCR) assays were used for the detection of rhinovirus, enterovirus, RS virus, adenovirus, coronavirus 229E and OC43, Chlamydia pneumoniae and Mycoplasma pneumoniae. Results: Using IFA and viral isolation techniques, viruses were detected in 33.3% of cases, and by PCR techniques, nucleic acid sequences of virus, Chlamydia pneumoniae and Mycoplasma pneumoniae were obtained in 71.9% of cases. The combination of conventional and molecular techniques detects 81.8% of positive samples. Two organisms were identified in the same nasal sample in 20.4% of the cases. The percentage of detections was higher (85.9%) in the younger group than in the other (77%). The most frequently detected agents were rhinovirus (46.9%) and RS virus (21.2%). Using PCR rather than conventional techniques, the detection rates were increased 5.8- and 1.6-fold in rhinovirus and RS virus infections, respectively. The detection levels of the other organisms are as follows: 9.8, 5.1, 4.5, 4.5, 4.5, 3.7, and 2.2% for enterovirus, influenza virus, Chlamydia pneumoniae, adenovirus, coronavirus, parainfluenza virus, and Mycoplasma pneumoniae, respectively. Conclusion: These results confirm the previously reported high frequency of rhinovirus detection in asthmatic exacerbations in children. They also point out the frequency of RS virus detection, and emphasize the fact that PCR assays may be necessary to diagnose respiratory infections in asthma.',\n",
              "  'authors': ['François Freymuth 1',\n",
              "   ' Astrid Vabret 1',\n",
              "   ' Jacques Brouard 2',\n",
              "   ' Fabienne Toutain 2',\n",
              "   ' Renaud Verdon 3',\n",
              "   ' Joelle Petitjean 1',\n",
              "   ' Stéphanie Gouarin 1',\n",
              "   ' Jean François Duhamel 2',\n",
              "   ' Bernard Guillois 2'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2011219821',\n",
              "  'references': ['1964779747',\n",
              "   '1980185618',\n",
              "   '2023239553',\n",
              "   '2082696402',\n",
              "   '2135637080',\n",
              "   '1930676032',\n",
              "   '2005859055',\n",
              "   '1795525407',\n",
              "   '2138116758',\n",
              "   '1986762984'],\n",
              "  'title': 'Detection of viral, Chlamydia pneumoniae and Mycoplasma pneumoniae infections in exacerbations of asthma in children'},\n",
              " {'abstract': \"L'A. passe en revue les techniques de visualisation utilisees pour representer de facon cartographique la structure de domaine des disciplines scientifiques, et pour soutenir la recherche d'information et la classification. Un bref historique montre que la visualisation des domaines de connaissances s'enracine dans des disciplines telles que la scientometrie, la bibliometrie et l'analyse de citations, ainsi que la visualisation scientifique. L'A. analyse les principales etapes du processus de visualisation des domaines de connaissances : unites d'analyse, mesures, similarites entre unites. Differentes techniques couramment utilisees pour l'analyse et la visualisation des connaissances sont passees en revue : techniques de reduction de la dimensionnalite, analyse par clusters, configuration spatiale, visualisation et conception d'interaction. Differentes approches sont appliquees pour engendrer et comparer diverses representations cartographiques de la recherche sur la visualisation des domaines de connaissances. Ces cartes mettent en valeur les relations entre l'analyse de citations, la bibliometrie, la semantique et la visualisation de l'information. Augmenter l'accessibilite de la visualisation des domaines aupres des non-experts, appliquer la visualisation des domaines de connaissances pour mieux repondre a des questions pragmatiques, favoriser la collaboration et la diffusion des resultats entre chercheurs, developper des algorithmes plus robustes, comptent parmi les directions de recherche les plus prometteuses.\",\n",
              "  'authors': ['Katy Börner 1', ' Chaomei Chen 2', ' Kevin W. Boyack 3'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2045108252',\n",
              "  'references': ['2140190241',\n",
              "   '2008620264',\n",
              "   '2053186076',\n",
              "   '2138621811',\n",
              "   '2001141328',\n",
              "   '1660390307',\n",
              "   '1679913846',\n",
              "   '2147152072',\n",
              "   '2078206416',\n",
              "   '2046079134'],\n",
              "  'title': 'Visualizing Knowledge Domains.'},\n",
              " {'abstract': \"The clinical performance of a laboratory test can be described in terms of diagnostic accuracy, or the ability to correctly classify subjects into clinically relevant subgroups. Diagnostic accuracy refers to the quality of the information provided by the classification device and should be distinguished from the usefulness, or actual practical value, of the information. Receiver-operating characteristic (ROC) plots provide a pure index of accuracy by demonstrating the limits of a test's ability to discriminate between alternative states of health over the complete spectrum of operating conditions. Furthermore, ROC plots occupy a central or unifying position in the process of assessing and using diagnostic tools. Once the plot is generated, a user can readily go on to many other activities such as performing quantitative ROC analysis and comparisons of tests, using likelihood ratio to revise the probability of disease in individual subjects, selecting decision thresholds, using logistic-regression analysis, using discriminant-function analysis, or incorporating the tool into a clinical strategy by using decision analysis.\",\n",
              "  'authors': ['Mark H. Zweig ', ' Gregory Campbell'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2104960492',\n",
              "  'references': ['2157825442',\n",
              "   '2328176404',\n",
              "   '1990748933',\n",
              "   '2102150307',\n",
              "   '1968114652',\n",
              "   '2035950812',\n",
              "   '1554701668',\n",
              "   '1784695092',\n",
              "   '2060136512',\n",
              "   '2339926369'],\n",
              "  'title': 'Receiver-operating characteristic (ROC) plots: a fundamental evaluation tool in clinical medicine.'},\n",
              " {'abstract': 'The experimental evidence accumulated over the past 20 years indicates that textindexing systems based on the assignment of appropriately weighted single terms produce retrieval results that are superior to those obtainable with other more elaborate text representations. These results depend crucially on the choice of effective term weighting systems. This paper summarizes the insights gained in automatic term weighting, and provides baseline single term indexing models with which other more elaborate content analysis procedures can be compared.',\n",
              "  'authors': ['Gerard Salton ', ' Christopher Buckley'],\n",
              "  'date': '1988',\n",
              "  'identifier': '1978394996',\n",
              "  'references': ['1956559956',\n",
              "   '2043909051',\n",
              "   '2083605078',\n",
              "   '2068632118',\n",
              "   '3090556797',\n",
              "   '2095396650',\n",
              "   '2075006521',\n",
              "   '11171803',\n",
              "   '3091372544',\n",
              "   '1557757161'],\n",
              "  'title': 'Term Weighting Approaches in Automatic Text Retrieval'},\n",
              " {'abstract': 'In practice the relevant details of images exist only over a restricted range of scale. Hence it is important to study the dependence of image structure on the level of resolution. It seems clear enough that visual perception treats images on several levels of resolution simultaneously and that this fact must be important for the study of perception. However, no applicable mathematically formulated theory to deal with such problems appers to exist. In this paper it is shown that any image can be embedded in a one-parameter family of derived images (with resolution as the parameter) in essentially only one unique way if the constraint that no spurious detail should be generated when the resolution is diminished, is applied. The structure of this family is governed by the well known diffusion equation (a parabolic, linear, partial differential equation of the second order). As such the structure fits into existing theories that treat the front end of the visual system as a continuous tack of homogeneous layer, characterized by iterated local processing schemes. When resolution is decreased the images becomes less articulated because the extrem (“light and dark blobs”) disappear one after the other. This erosion of structure is a simple process that is similar in every case. As a result any image can be described as a juxtaposed and nested set of light and dark blobs, wherein each blod has a limited range of resolution in which it manifests itself. The structure of the family of derived images permits a derivation of the sampling density required to sample the image at multiple scales of resolution. The natural scale along the resolution axis (leading to an informationally uniform sampling density) is logarithmic, thus the structure is apt for the description of size invariances.',\n",
              "  'authors': ['Jan J. Koenderink'],\n",
              "  'date': '1984',\n",
              "  'identifier': '2022735534',\n",
              "  'references': ['2109863423',\n",
              "   '2003370853',\n",
              "   '1587069887',\n",
              "   '2036259465',\n",
              "   '2078377537',\n",
              "   '2019222286',\n",
              "   '2117900366',\n",
              "   '2025203539',\n",
              "   '2069918285',\n",
              "   '2032159165'],\n",
              "  'title': 'The structure of images'},\n",
              " {'abstract': 'This is a comprehensive introduction to theoretical linguistics. It presupposes no previous knowledge and terms are defined as they are introduced; but it gives a rigorous and technical treatment of a wide range of topics, and brings the reader to an advanced level of understanding. Since its first publication in 1968 Introduction to Theoretical Linguistics has been one of the classic introductions to the discipline. In a field which is often seen as rapidly moving, it will continue to be used by students seeking an overview of the central areas of linguistics - phonetics and phonology, grammar and semantics - and to be of great value to anyone interested in the ways in which theory can help to explain the key problems of human language.',\n",
              "  'authors': ['John Lyons'],\n",
              "  'date': '1968',\n",
              "  'identifier': '2029491572',\n",
              "  'references': ['1966812932',\n",
              "   '2171161819',\n",
              "   '1973826788',\n",
              "   '646297848',\n",
              "   '2038542953',\n",
              "   '2115867364',\n",
              "   '2019529630',\n",
              "   '2020026127',\n",
              "   '2041818183',\n",
              "   '2069712901'],\n",
              "  'title': 'Introduction to Theoretical Linguistics'},\n",
              " {'abstract': 'Abstract Project scheduling is concerned with single-item or small batch production where scarce resources have to be allocated to dependent activities over time. Applications can be found in diverse industries such as construction engineering, software development, etc. Also, project scheduling is increasingly important for make-to-order companies where the capacities have been cut down in order to meet lean management concepts. Likewise, project scheduling is very attractive for researchers, because the models in this area are rich and, hence, difficult to solve. For instance, the resource-constrained project scheduling problem contains the job shop scheduling problem as a special case. So far, no classification scheme exists which is compatible with what is commonly accepted in machine scheduling. Also, a variety of symbols are used by project scheduling researchers in order to denote one and the same subject. Hence, there is a gap between machine scheduling on the one hand and project scheduling on the other with respect to both, viz. a common notation and a classification scheme. As a matter of fact, in project scheduling, an ever growing number of papers is going to be published and it becomes more and more difficult for the scientific community to keep track of what is really new and relevant. One purpose of our paper is to close this gap. That is, we provide a classification scheme, i.e. a description of the resource environment, the activity characteristics, and the objective function, respectively, which is compatible with machine scheduling and which allows to classify the most important models dealt with so far. Also, we propose a unifying notation. The second purpose of this paper is to review some of the recent developments. More specifically, we review exact and heuristic algorithms for the single-mode and the multi-mode case, for the time–cost tradeoff problem, for problems with minimum and maximum time lags, for problems with other objectives than makespan minimization and, last but not least, for problems with stochastic activity durations.',\n",
              "  'authors': ['Peter Brucker 1',\n",
              "   ' Andreas Drexl 2',\n",
              "   ' Rolf H. Möhring 3',\n",
              "   ' Klaus Neumann 4',\n",
              "   ' Erwin Pesch 5'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2038345112',\n",
              "  'references': ['2341350247',\n",
              "   '2043193943',\n",
              "   '2090359754',\n",
              "   '1488422606',\n",
              "   '1988095917',\n",
              "   '1973131489',\n",
              "   '2158814833',\n",
              "   '2125266303',\n",
              "   '2130272456',\n",
              "   '1969848548'],\n",
              "  'title': 'Resource-constrained project scheduling: Notation, classification, models, and methods'},\n",
              " {'abstract': \"Human respiratory syncytial virus (HRSV) is a major cause of serious lower respiratory tract illness in infants, young children, and the elderly. To characterize the circulation patterns of HRSV strains, nucleotide sequencing of the C-terminal region of the G protein gene was performed on 34-53 isolates obtained from 5 communities during 1 epidemic year, representing distinct geographical locations in North America. Phylogenetic analysis revealed that 5-7 HRSV genotypes, including 1 or 2 predominant strains, circulated in each community. The patterns of genotypes were distinct between communities, and less diversity was seen between strains of the same genotype within than between communities. These findings are consistent with HRSV outbreaks' being community based in nature, although transmission of viruses between communities may occur. Several strains are probably introduced or circulate endemically in communities each year, and local factors-possibly immunity induced by previous years' strains-determine which strains predominate during an HRSV season.\",\n",
              "  'authors': ['Teresa C. T. Peret 1',\n",
              "   ' Caroline B. Hall 2',\n",
              "   ' Gregory W. Hammond 3',\n",
              "   ' Pedro A. Piedra 4',\n",
              "   ' Gregory A. Storch 5',\n",
              "   ' Wayne M. Sullender 6',\n",
              "   ' Cecilia Tsou 1',\n",
              "   ' Larry J. Anderson 1'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2166096923',\n",
              "  'references': ['2106882534',\n",
              "   '2150297520',\n",
              "   '2164997158',\n",
              "   '2060132446',\n",
              "   '2158407455',\n",
              "   '2121831414',\n",
              "   '2119627949',\n",
              "   '1974542809',\n",
              "   '2081114699',\n",
              "   '1525273492'],\n",
              "  'title': 'Circulation Patterns of Group A and B Human Respiratory Syncytial Virus Genotypes in 5 Communities in North America'},\n",
              " {'abstract': 'Summary: We have developed a new software package, Molecular Evolutionary Genetics Analysis version 2 (MEGA2), for exploring and analyzing aligned DNA or protein sequences from an evolutionary perspective. MEGA2 vastly extends the capabilities of MEGA version 1 by: (1) facilitating analyses of large datasets; (2) enabling creation and analyses of groups of sequences; (3) enabling specification of domains and genes; (4) expanding the repertoire of statistical methods for molecular evolutionary studies; and (5) adding new modules for visual representation of input data and output results on the Microsoft Windows platform. Availability: http://www.megasoftware.net.',\n",
              "  'authors': ['Sudhir Kumar 1',\n",
              "   ' Koichiro Tamura 2',\n",
              "   ' Ingrid B. Jakobsen 3',\n",
              "   ' Masatoshi Nei 3'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2156434383',\n",
              "  'references': ['1487781539',\n",
              "   '2097403532',\n",
              "   '2235442146',\n",
              "   '2002446259',\n",
              "   '1997170579'],\n",
              "  'title': 'MEGA2 : Molecular evolutionary genetics analysis software'},\n",
              " {'abstract': 'Collaborative filtering or recommender systems use a database about user preferences to predict additional topics or products a new user might like. In this paper we describe several algorithms designed for this task, including techniques based on correlation coefficients, vector-based similarity calculations, and statistical Bayesian methods. We compare the predictive accuracy of the various methods in a set of representative problem domains. We use two basic classes of evaluation metrics. The first characterizes accuracy over a set of individual predictions in terms of average absolute deviation. The second estimates the utility of a ranked list of suggested items. This metric uses an estimate of the probability that a user will see a recommendation in an ordered list. Experiments were run for datasets associated with 3 application areas, 4 experimental protocols, and the 2 evaluation metr rics for the various algorithms. Results indicate that for a wide range of conditions, Bayesian networks with decision trees at each node and correlation methods outperform Bayesian-clustering and vector-similarity methods. Between correlation and Bayesian networks, the preferred method depends on the nature of the dataset, nature of the application (ranked versus one-by-one presentation), and the availability of votes with which to make predictions. Other considerations include the size of database, speed of predictions, and learning time.',\n",
              "  'authors': ['John S. Breese ', ' David Heckerman ', ' Carl Kadie'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2110325612',\n",
              "  'references': ['2155106456',\n",
              "   '2049633694',\n",
              "   '2341865734',\n",
              "   '1956559956',\n",
              "   '1524704912',\n",
              "   '2066590388',\n",
              "   '1567331820',\n",
              "   '1864566053',\n",
              "   '2031636842',\n",
              "   '1557657228'],\n",
              "  'title': 'Empirical analysis of predictive algorithms for collaborative filtering'},\n",
              " {'abstract': '',\n",
              "  'authors': ['M. Burrows ', ' D. J. Wheeler'],\n",
              "  'date': '1994',\n",
              "  'identifier': '2161488606',\n",
              "  'references': ['2107745473',\n",
              "   '2158874082',\n",
              "   '2122962290',\n",
              "   '1990653637',\n",
              "   '1975965284',\n",
              "   '2012603689',\n",
              "   '2121252285'],\n",
              "  'title': 'A Block-sorting Lossless Data Compression Algorithm'},\n",
              " {'abstract': 'From the Publisher: Pattern recognition has long been studied in relation to many different (and mainly unrelated) applications, such as remote sensing, computer vision, space research, and medical imaging. In this book Professor Ripley brings together two crucial ideas in pattern recognition; statistical methods and machine learning via neural networks. Unifying principles are brought to the fore, and the author gives an overview of the state of the subject. Many examples are included to illustrate real problems in pattern recognition and how to overcome them.This is a self-contained account, ideal both as an introduction for non-specialists readers, and also as a handbook for the more expert reader.',\n",
              "  'authors': ['Brian D. Ripley ', ' N. L. Hjort'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2117812871',\n",
              "  'references': ['2156909104',\n",
              "   '1554663460',\n",
              "   '2119821739',\n",
              "   '1988790447',\n",
              "   '2912934387',\n",
              "   '1679913846',\n",
              "   '2112076978',\n",
              "   '1971784203',\n",
              "   '2046079134',\n",
              "   '2147800946'],\n",
              "  'title': 'Pattern recognition and neural networks'},\n",
              " {'abstract': 'This paper describes the statistical similarities among mediation, confounding, and suppression. Each is quantified by measuring the change in the relationship between an independent and a dependent variable after adding a third variable to the analysis. Mediation and confounding are identical statistically and can be distinguished only on conceptual grounds. Methods to determine the confidence intervals for confounding and suppression effects are proposed based on methods developed for mediated effects. Although the statistical estimation of effects and standard errors is the same, there are important conceptual differences among the three types of effects.',\n",
              "  'authors': ['David P. MacKinnon ',\n",
              "   ' Jennifer L. Krull ',\n",
              "   ' Chondra M. Lockwood'],\n",
              "  'date': '2000',\n",
              "  'identifier': '1715619412',\n",
              "  'references': ['1971440513',\n",
              "   '1524326598',\n",
              "   '1491644571',\n",
              "   '2159401492',\n",
              "   '2517346518',\n",
              "   '1989314580',\n",
              "   '1976876708',\n",
              "   '2323444743',\n",
              "   '1989351453',\n",
              "   '1971383683'],\n",
              "  'title': 'Equivalence of the Mediation, Confounding and Suppression Effect'},\n",
              " {'abstract': 'Abstract Recent developments promise to increase greatly the popularity of maximum likelihood (ml) as a technique for estimating variance components. Patterson and Thompson (1971) proposed a restricted maximum likelihood (reml) approach which takes into account the loss in degrees of freedom resulting from estimating fixed effects. Miller (1973) developed a satisfactory asymptotic theory for ml estimators of variance components. There are many iterative algorithms that can be considered for computing the ml or reml estimates. The computations on each iteration of these algorithms are those associated with computing estimates of fixed and random effects for given values of the variance components.',\n",
              "  'authors': ['David A. Harville'],\n",
              "  'date': '1977',\n",
              "  'identifier': '1982585616',\n",
              "  'references': ['2986444355',\n",
              "   '2403035479',\n",
              "   '2798510847',\n",
              "   '2000084758',\n",
              "   '1982126198',\n",
              "   '128740895',\n",
              "   '2013866489',\n",
              "   '21072975',\n",
              "   '2072857774',\n",
              "   '2334647599'],\n",
              "  'title': 'Maximum Likelihood Approaches to Variance Component Estimation and to Related Problems'},\n",
              " {'abstract': 'Two-dimensional spatial linear filters are constrained by general uncertainty relations that limit their attainable information resolution for orientation, spatial frequency, and two-dimensional (2D) spatial position. The theoretical lower limit for the joint entropy, or uncertainty, of these variables is achieved by an optimal 2D filter family whose spatial weighting functions are generated by exponentiated bivariate second-order polynomials with complex coefficients, the elliptic generalization of the one-dimensional elementary functions proposed in Gabor’s famous theory of communication [ J. Inst. Electr. Eng.93, 429 ( 1946)]. The set includes filters with various orientation bandwidths, spatial-frequency bandwidths, and spatial dimensions, favoring the extraction of various kinds of information from an image. Each such filter occupies an irreducible quantal volume (corresponding to an independent datum) in a four-dimensional information hyperspace whose axes are interpretable as 2D visual space, orientation, and spatial frequency, and thus such a filter set could subserve an optimally efficient sampling of these variables. Evidence is presented that the 2D receptive-field profiles of simple cells in mammalian visual cortex are well described by members of this optimal 2D filter family, and thus such visual neurons could be said to optimize the general uncertainty relations for joint 2D-spatial–2D-spectral information resolution. The variety of their receptive-field dimensions and orientation and spatial-frequency bandwidths, and the correlations among these, reveal several underlying constraints, particularly in width/length aspect ratio and principal axis organization, suggesting a polar division of labor in occupying the quantal volumes of information hyperspace. Such an ensemble of 2D neural receptive fields in visual cortex could locally embed coarse polar mappings of the orientation–frequency plane piecewise within the global retinotopic mapping of visual space, thus efficiently representing 2D spatial visual information by localized 2D spectral signatures.',\n",
              "  'authors': ['John G. Daugman'],\n",
              "  'date': '1985',\n",
              "  'identifier': '2006500012',\n",
              "  'references': ['2116360511',\n",
              "   '2029683515',\n",
              "   '2135587681',\n",
              "   '2138100172',\n",
              "   '1999908130',\n",
              "   '2143057036',\n",
              "   '2022491393',\n",
              "   '2027914108',\n",
              "   '2047496335',\n",
              "   '2017600612'],\n",
              "  'title': 'Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two-dimensional visual cortical filters.'},\n",
              " {'abstract': 'From the Publisher: This book represents the most comprehensive treatment available of neural networks from an engineering perspective. Thorough, well-organized, and completely up to date, it examines all the important aspects of this emerging technology, including the learning process, back-propagation learning, radial-basis function networks, self-organizing systems, modular networks, temporal processing and neurodynamics, and VLSI implementation of neural networks. Written in a concise and fluid manner, by a foremost engineering textbook author, to make the material more accessible, this book is ideal for professional engineers and graduate students entering this exciting field. Computer experiments, problems, worked examples, a bibliography, photographs, and illustrations reinforce key concepts.',\n",
              "  'authors': ['Simon Haykin'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2124776405',\n",
              "  'references': ['2071707134',\n",
              "   '2111072639',\n",
              "   '1964357740',\n",
              "   '2026131661',\n",
              "   '2097308346',\n",
              "   '2118978333',\n",
              "   '2108384452',\n",
              "   '2132549764',\n",
              "   '2153233077',\n",
              "   '1596717185'],\n",
              "  'title': 'Neural Networks: A Comprehensive Foundation'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Arthur Chickering ', ' Zelda Gamson'],\n",
              "  'date': '1991',\n",
              "  'identifier': '3022468393',\n",
              "  'references': ['2120873112',\n",
              "   '2010950062',\n",
              "   '2163728131',\n",
              "   '1970496636',\n",
              "   '2102984706',\n",
              "   '2031087893',\n",
              "   '2764097240',\n",
              "   '3125126645',\n",
              "   '2129532980',\n",
              "   '2110228222'],\n",
              "  'title': 'Seven principles for good practice in undergraduate education'},\n",
              " {'abstract': 'Two hundred young adults with common colds were studied during a 10-month period. Virus culture, antigen detection, PCR, and serology with paired samples were used to identify the infection. Viral etiology was established for 138 of the 200 patients (69%). Rhinoviruses were detected in 105 patients, coronavirus OC43 or 229E infection was detected in 17, influenza A or B virus was detected in 12, and single infections with parainfluenza virus, respiratory syncytial virus, adenovirus, and enterovirus were found in 14 patients. Evidence for bacterial infection was found in seven patients. Four patients had a rise in antibodies against Chlamydia pneumoniae, one had a rise in antibodies against Haemophilus influenzae, one had a rise in antibodies against Streptococcus pneumoniae, and one had immunoglobulin M antibodies against Mycoplasma pneumoniae. The results show that although approximately 50% of episodes of the common cold were caused by rhinoviruses, the etiology can vary depending on the epidemiological situation with regard to circulating viruses. Bacterial infections were rare, supporting the concept that the common cold is almost exclusively a viral disease.',\n",
              "  'authors': ['Mika J. Mäkelä 1',\n",
              "   ' Tuomo Puhakka 1',\n",
              "   ' Olli Ruuskanen 1',\n",
              "   ' Maija Leinonen 2',\n",
              "   ' Pekka Saikku 2',\n",
              "   ' Marko Kimpimäki 3',\n",
              "   ' Soile Blomqvist 3',\n",
              "   ' Timo Hyypiä 4',\n",
              "   ' Pertti Arstila 4'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2127062009',\n",
              "  'references': ['2055750915',\n",
              "   '2337555053',\n",
              "   '2098388207',\n",
              "   '163073849',\n",
              "   '2146133178',\n",
              "   '2032842024',\n",
              "   '1856165804',\n",
              "   '2018812376',\n",
              "   '1830634530',\n",
              "   '1699035432'],\n",
              "  'title': 'Viruses and Bacteria in the Etiology of the Common Cold'},\n",
              " {'abstract': 'In acute hepatitis C virus infection, 50 to 70% of patients develop chronic disease. Considering the low rate of spontaneous viral clearance during chronic hepatitis C infection, the first few months of interaction between the patient’s immune system and the viral population seem to be crucial in determining the outcome of infection. We previously reported the association between a strong and sustained CD4 1 T-cell response to nonstructural protein 3 (NS3) of the hepatitis C virus and a self-limited course of acute hepatitis C infection. In this study, we identify an immunodominant CD4 1 T-cell epitope (amino acids 1248 to 1261) that was recognized by the majority (14 of 23) of NS3-specific CD4 1 T-cell clones from four of five patients with acute hepatitis C infection. This epitope can be presented to CD4 1 T cells by HLA-DR4, -DR11, -DR12, -DR13, and -DR16. HLA-binding studies revealed a high binding affinity for 10 of 13 common HLA-DR alleles. Two additional CD4 1 T-cell epitopes, amino acids 1388 to 1407 and amino acids 1450 to 1469, showed a very narrow pattern of binding to individual HLA-DR alleles. Our data suggest that the NS3-specific CD4 1 T-cell response in acute hepatitis C infection is dominated by a single, promiscuous peptide epitope which could become a promising candidate for the development of a CD4 1 T-cell vaccine. Hepatitis C virus (HCV) infection has an estimated worldwide prevalence of 0.3 to 1.5% and is a leading cause of chronic hepatitis, cirrhosis, and hepatocellular carcinoma (1, 15). More than 50% of acute infections lead to chronic disease (2), and once chronic infection is established, spontaneous recovery is exceptional. Therefore, characterization of the antiviral immune response during the first few weeks of acute hepatitis C infection in patients with self-limited disease as opposed to those developing chronic hepatitis C may allow the identification of successful antiviral immune strategies. In two recent studies of patients with acute hepatitis C infection, a strong association between a vigorous and sustained HCVspecific CD4 1 T-cell response and a self-limited course of acute hepatitis C infection could be demonstrated (5, 16). Although the CD4 1 T-cell response was directed against several HCV antigens (core, E2, nonstructural protein 3 [NS3], NS4, and NS5), in the majority of patients with self-limited disease, the response to NS3 was frequently strongest and was detected most consistently. In this study, we identify one immunodominant CD4 1 T-cell epitope within the NS3 protein that is recognized by the majority of patients with self-limited acute hepatitis C infection and which binds promiscuously to the most common HLA-DR alleles.',\n",
              "  'authors': ['H M Diepolder ',\n",
              "   ' J T Gerlach ',\n",
              "   ' R Zachoval ',\n",
              "   ' R M Hoffmann ',\n",
              "   ' M C Jung ',\n",
              "   ' E A Wierenga ',\n",
              "   ' S Scholz ',\n",
              "   ' T Santantonio ',\n",
              "   ' M Houghton ',\n",
              "   ' S Southwood ',\n",
              "   ' A Sette ',\n",
              "   ' G R Pape'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2163575236',\n",
              "  'references': ['2066124462',\n",
              "   '2328171401',\n",
              "   '2083331853',\n",
              "   '2163682172',\n",
              "   '2079377965',\n",
              "   '2013740977',\n",
              "   '2084446925',\n",
              "   '1582747522',\n",
              "   '2055219788',\n",
              "   '2570729219'],\n",
              "  'title': 'Immunodominant CD4+ T-cell epitope within nonstructural protein 3 in acute hepatitis C virus infection.'},\n",
              " {'abstract': 'OBJECTIVES This study aimed at determining the protection factors (PFs) provided by N95 filtering facepiece respirators and surgical masks against particles representing bacterial and viral size ranges (aerodynamic size: 0.04-1.3 mum). METHODS The protection levels of N95 filtering facepiece respirators (four models) and surgical masks (three models) were investigated while they were donned by 12 subjects performing the OSHA (US Occupational Safety and Health Administration) fit-testing exercises in a test chamber. RESULTS About 29% of N95 respirators and approximately 100% of surgical masks had PFs <10, which is the assigned PF designated for this type of respirator by the OSHA. On average, the PFs of N95 respirators were 8-12 times greater than those of surgical masks. The minimum PFs were observed in the size range of 0.04-0.2 mum. No significant difference in PF results was found between N95 respirators with and without an exhalation valve. CONCLUSIONS The study indicates that N95 filtering facepiece respirators may not achieve the expected protection level against bacteria and viruses. An exhalation valve on the N95 respirator does not affect the respiratory protection; it appears to be an appropriate alternative to reduce the breathing resistance.',\n",
              "  'authors': ['Shu-An Lee 1', ' Sergey A. Grinshpun 2', ' Tiina Reponen 2'],\n",
              "  'date': '2008',\n",
              "  'identifier': '1981110022',\n",
              "  'references': ['2104548316',\n",
              "   '1833207062',\n",
              "   '2142176189',\n",
              "   '2278820503',\n",
              "   '2074399085',\n",
              "   '2048093932',\n",
              "   '1984150661',\n",
              "   '2101731507',\n",
              "   '2063309334',\n",
              "   '2146286772'],\n",
              "  'title': 'Respiratory Performance Offered by N95 Respirators and Surgical Masks: Human Subject Evaluation with NaCl Aerosol Representing Bacterial and Viral Particle Size Range'},\n",
              " {'abstract': 'The diffusion of an innovation traditionally has been defined as the process by which that innovation is “communicated through certain channels over time among the members of a social system” (Rogers, 1983, p. 5). As such, the diffusion process consists of four key elements: innovation, communication channels, time, and the social system.',\n",
              "  'authors': ['Vijay Mahajan 1', ' Eitan Muller 2', ' Frank M. Bass 3'],\n",
              "  'date': '1990',\n",
              "  'identifier': '1964473994',\n",
              "  'references': ['2796700885',\n",
              "   '2136883754',\n",
              "   '2265720734',\n",
              "   '1983629797',\n",
              "   '2316166305',\n",
              "   '2074661292',\n",
              "   '2168966530',\n",
              "   '1505037116',\n",
              "   '2090254306',\n",
              "   '2070457089'],\n",
              "  'title': 'New Product Diffusion Models in Marketing: A Review and Directions for Research:'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Dimitri P. Bertsekas ',\n",
              "   ' Angelia Nedić ',\n",
              "   ' Asuman E. Ozdaglar'],\n",
              "  'date': '2003',\n",
              "  'identifier': '1583497301',\n",
              "  'references': ['2124608575',\n",
              "   '2145834571',\n",
              "   '2120340025',\n",
              "   '1993962865',\n",
              "   '2030546921',\n",
              "   '2138993731',\n",
              "   '2044212084'],\n",
              "  'title': 'Convex Analysis and Optimization'},\n",
              " {'abstract': 'Underestimation of pneumonia and influenza (P&I) mortality during influenza epidemics was explored in 38 P&U associated deaths among a population of adults during two influenza A (H3N2) epidemics. Pneumonia or influenza was mentioned on 32 (84 per cent) of the death certificates. However, based on rules for assigning cause of death, only nine (24 per cent, SE = 7) and 23 (61 per cent, SE = 8) of the cases would have been included in P&I mortality statistics compiled by the National Center for Health Statistics and the Center for Disease Control, respectively.',\n",
              "  'authors': ['W H Barker ', ' J P Mullooly'],\n",
              "  'date': '1981',\n",
              "  'identifier': '2035672404',\n",
              "  'references': [],\n",
              "  'title': 'Underestimation of the role of pneumonia and influenza in causing excess mortality.'},\n",
              " {'abstract': 'Preface.PART I: OVERVIEW AND BASIC APPROACHES.Introduction.Missing Data in Experiments.Complete-Case and Available-Case Analysis, Including Weighting Methods.Single Imputation Methods.Estimation of Imputation Uncertainty.PART II: LIKELIHOOD-BASED APPROACHES TO THE ANALYSIS OF MISSING DATA.Theory of Inference Based on the Likelihood Function.Methods Based on Factoring the Likelihood, Ignoring the Missing-Data Mechanism.Maximum Likelihood for General Patterns of Missing Data: Introduction and Theory with Ignorable Nonresponse.Large-Sample Inference Based on Maximum Likelihood Estimates.Bayes and Multiple Imputation.PART III: LIKELIHOOD-BASED APPROACHES TO THE ANALYSIS OF MISSING DATA: APPLICATIONS TO SOME COMMON MODELS.Multivariate Normal Examples, Ignoring the Missing-Data Mechanism.Models for Robust Estimation.Models for Partially Classified Contingency Tables, Ignoring the Missing-Data Mechanism.Mixed Normal and Nonnormal Data with Missing Values, Ignoring the Missing-Data Mechanism.Nonignorable Missing-Data Models.References.Author Index.Subject Index.',\n",
              "  'authors': ['Roderick J A Little ', ' Donald B Rubin'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2044758663',\n",
              "  'references': ['2115709314',\n",
              "   '2962897886',\n",
              "   '2115098571',\n",
              "   '2134843796',\n",
              "   '2156267802',\n",
              "   '2065974896',\n",
              "   '2110755408',\n",
              "   '2116810060',\n",
              "   '1994682257'],\n",
              "  'title': 'Statistical Analysis with Missing Data'},\n",
              " {'abstract': 'The newest version of MUMmer easily handles comparisons of large eukaryotic genomes at varying evolutionary distances, as demonstrated by applications to multiple genomes. Two new graphical viewing tools provide alternative ways to analyze genome alignments. The new system is the first version of MUMmer to be released as open-source software. This allows other developers to contribute to the code base and freely redistribute the code. The MUMmer sources are available at http://www.tigr.org/software/mummer.',\n",
              "  'authors': ['Stefan Kurtz 1',\n",
              "   ' Adam Phillippy 2',\n",
              "   ' Arthur L Delcher 2',\n",
              "   ' Michael Smoot 3',\n",
              "   ' Martin Shumway 2',\n",
              "   ' Corina Antonescu 2',\n",
              "   ' Steven L Salzberg 2'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2107282968',\n",
              "  'references': ['2158714788',\n",
              "   '2055043387',\n",
              "   '2151464048',\n",
              "   '2015292449',\n",
              "   '1990061958',\n",
              "   '2166265186',\n",
              "   '2142619120',\n",
              "   '2164075646',\n",
              "   '2610179052',\n",
              "   '2110132014'],\n",
              "  'title': 'Versatile and open software for comparing large genomes'},\n",
              " {'abstract': 'Training a support vector machine SVM leads to a quadratic optimization problem with bound constraints and one linear equality constraint. Despite the fact that this type of problem is well understood, there are many issues to be considered in designing an SVM learner. In particular, for large learning tasks with many training examples on the shelf optimization techniques for general quadratic programs quickly become intractable in their memory and time requirements. SVM light is an implementation of an SVM learner which addresses the problem of large tasks. This chapter presents algorithmic and computational results developed for SVM light V 2.0, which make large-scale SVM training more practical. The results give guidelines for the application of SVMs to large domains.',\n",
              "  'authors': ['Thorsten Joachims'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1576520375',\n",
              "  'references': ['2153635508',\n",
              "   '2161969291',\n",
              "   '2168356304',\n",
              "   '1880262756',\n",
              "   '2166706824',\n",
              "   '1964357740',\n",
              "   '2108646579',\n",
              "   '2120419212',\n",
              "   '2172000360'],\n",
              "  'title': 'Making large scale SVM learning practical'},\n",
              " {'abstract': 'This paper presents a survey on off-line Cursive Word Recognition. The approaches to the problem are described in detail. Each step of the process leading from raw data to the final result is analyzed. This survey is divided into two parts, the first one dealing with the general aspects of Cursive Word Recognition, the second one focusing on the applications presented in the literature.',\n",
              "  'authors': ['Alessandro Vinciarelli'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2162395775',\n",
              "  'references': ['1560013842',\n",
              "   '2142069714',\n",
              "   '1508165687',\n",
              "   '1564419782',\n",
              "   '2142384583',\n",
              "   '2100659887',\n",
              "   '2092858021',\n",
              "   '2073257493',\n",
              "   '1991133427',\n",
              "   '2163374925'],\n",
              "  'title': 'A survey on off-line Cursive Word recognition'},\n",
              " {'abstract': 'Unsupervised word representations are very useful in NLP tasks both as inputs to learning algorithms and as extra word features in NLP systems. However, most of these models are built with only local context and one representation per word. This is problematic because words are often polysemous and global context can also provide useful information for learning word meanings. We present a new neural network architecture which 1) learns word embeddings that better capture the semantics of words by incorporating both local and global document context, and 2) accounts for homonymy and polysemy by learning multiple embeddings per word. We introduce a new dataset with human judgments on pairs of words in sentential context, and evaluate our model on it, showing that our model outperforms competitive baselines and other neural language models.',\n",
              "  'authors': ['Eric Huang ',\n",
              "   ' Richard Socher ',\n",
              "   ' Christopher Manning ',\n",
              "   ' Andrew Ng'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2164019165',\n",
              "  'references': ['1532325895',\n",
              "   '2117130368',\n",
              "   '2132339004',\n",
              "   '2118020653',\n",
              "   '2158139315',\n",
              "   '1423339008',\n",
              "   '71795751',\n",
              "   '2081580037',\n",
              "   '1970381522',\n",
              "   '2120779048'],\n",
              "  'title': 'Improving Word Representations via Global Context and Multiple Word Prototypes'},\n",
              " {'abstract': 'A general method, suitable for fast computing machines, for investigating such properties as equations of state for substances consisting of interacting individual molecules is described. The method consists of a modified Monte Carlo integration over configuration space. Results for the two‐dimensional rigid‐sphere system have been obtained on the Los Alamos MANIAC and are presented here. These results are compared to the free volume equation of state and to a four‐term virial coefficient expansion.',\n",
              "  'authors': ['Nicholas Metropolis ',\n",
              "   ' Arianna W. Rosenbluth ',\n",
              "   ' Marshall N. Rosenbluth ',\n",
              "   ' Augusta H. Teller ',\n",
              "   ' Edward Teller'],\n",
              "  'date': '1953',\n",
              "  'identifier': '2056760934',\n",
              "  'references': ['2052864234'],\n",
              "  'title': 'Equation of state calculations by fast computing machines'},\n",
              " {'abstract': \"Human linguistic annotation is crucial for many natural language processing tasks but can be expensive and time-consuming. We explore the use of Amazon's Mechanical Turk system, a significantly cheaper and faster method for collecting annotations from a broad base of paid non-expert contributors over the Web. We investigate five tasks: affect recognition, word similarity, recognizing textual entailment, event temporal ordering, and word sense disambiguation. For all five, we show high agreement between Mechanical Turk non-expert annotations and existing gold standard labels provided by expert labelers. For the task of affect recognition, we also show that using non-expert labels for training machine learning algorithms can be as effective as using gold standard annotations from experts. We propose a technique for bias correction that significantly improves annotation quality on two tasks. We conclude that many large labeling tasks can be effectively designed and carried out in this method at a fraction of the usual expense.\",\n",
              "  'authors': ['Rion Snow 1',\n",
              "   \" Brendan O'Connor 2\",\n",
              "   ' Daniel Jurafsky 1',\n",
              "   ' Andrew Ng 1'],\n",
              "  'date': '2008',\n",
              "  'identifier': '1970381522',\n",
              "  'references': ['2141282920',\n",
              "   '1632114991',\n",
              "   '2151401338',\n",
              "   '2158847908',\n",
              "   '2525127255',\n",
              "   '2149489787',\n",
              "   '2115792525',\n",
              "   '2125943921',\n",
              "   '1659833910',\n",
              "   '2130158090'],\n",
              "  'title': 'Cheap and Fast -- But is it Good? Evaluating Non-Expert Annotations for Natural Language Tasks'},\n",
              " {'abstract': 'The Burrows—Wheeler Transform (also known as Block-Sorting) is at the base of compression algorithms that are the state of the art in lossless data compression. In this paper, we analyze two algorithms that use this technique. The first one is the original algorithm described by Burrows and Wheeler, which, despite its simplicity outperforms the Gzip compressor. The second one uses an additional run-length encoding step to improve compression. We prove that the compression ratio of both algorithms can be bounded in terms of the k th order empirical entropy of the input string for any k ≥ 0. We make no assumptions on the input and we obtain bounds which hold in the worst case that is for every possible input string. All previous results for Block-Sorting algorithms were concerned with the average compression ratio and have been established assuming that the input comes from a finite-order Markov source.',\n",
              "  'authors': ['Giovanni Manzini'],\n",
              "  'date': '2001',\n",
              "  'identifier': '1965853364',\n",
              "  'references': ['2158322625',\n",
              "   '2129652681',\n",
              "   '2161488606',\n",
              "   '2072210981',\n",
              "   '2013697960',\n",
              "   '1975965284',\n",
              "   '2135771747',\n",
              "   '2089319476',\n",
              "   '2138026948',\n",
              "   '1847634394'],\n",
              "  'title': 'An analysis of the Burrows—Wheeler transform'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Patrick Krolak 1', ' Wayne Felts 1', ' George Marble 2'],\n",
              "  'date': '1971',\n",
              "  'identifier': '1992928037',\n",
              "  'references': ['2123241324', '2037455079', '2106378689', '77679884'],\n",
              "  'title': 'A man-machine approach toward solving the traveling salesman problem'},\n",
              " {'abstract': \"We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points.\",\n",
              "  'authors': ['E. Osuna ', ' R. Freund ', ' F. Girosit'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2124351082',\n",
              "  'references': ['2156909104',\n",
              "   '2119821739',\n",
              "   '2087347434',\n",
              "   '2159686933',\n",
              "   '26816478',\n",
              "   '2159173611',\n",
              "   '2137346077',\n",
              "   '2084844503',\n",
              "   '2056695679',\n",
              "   '2125713050'],\n",
              "  'title': 'Training support vector machines: an application to face detection'},\n",
              " {'abstract': \"Abstract A proposed theory of planned behavior, an extension of Ajzen and Fishbein's (1980, Understanding attitudes and predicting social behavior . Englewood-Cliffs, NJ: Prentice-Hall) theory of reasoned action, was tested in two experiments. The extended theory incorporates perceived control over behavioral achievement as a determinant of intention (Version 1) as well as behavior (Version 2). In Experiment 1, college students' attendance of class lectures was recorded over a 6-week period; in Experiment 2, the behavioral goal was getting an “A” in a course. Attitudes, subjective norms, perceived behavioral control, and intentions were assessed halfway through the period of observation in the first experiment, and at two points in time in the second experiment. The results were evaluated by means of hierarchical regression analyses. As expected, the theory of planned behavior permitted more accurate prediction of intentions and goal attainment than did the theory of reasoned action. In both experiments, perceived behavioral control added significantly to the prediction of intentions. Its contribution to the prediction of behavior was significant in the second wave of Experiment 2, at which time the students' perceptions of behavioral control had become quite accurate. Contrary to expectations, there was little evidence for interactions between perceived behavioral control and the theory's other independent variables.\",\n",
              "  'authors': ['Icek Ajzen 1', ' Thomas J Madden 2'],\n",
              "  'date': '1986',\n",
              "  'identifier': '1490774257',\n",
              "  'references': ['2179683524',\n",
              "   '1491644571',\n",
              "   '1517229207',\n",
              "   '1982210139',\n",
              "   '2036389121',\n",
              "   '2100826189',\n",
              "   '1981018178',\n",
              "   '2069736034',\n",
              "   '2164715962',\n",
              "   '2056877099'],\n",
              "  'title': 'Prediction of goal-directed behavior: Attitudes, intentions, and perceived behavioral control'},\n",
              " {'abstract': 'A multiple sequence alignment program, MAFFT, has been developed. The CPU time is drastically reduced as compared with existing methods. MAFFT includes two novel techniques. (i) Homo logous regions are rapidly identified by the fast Fourier transform (FFT), in which an amino acid sequence is converted to a sequence composed of volume and polarity values of each amino acid residue. (ii) We propose a simplified scoring system that performs well for reducing CPU time and increasing the accuracy of alignments even for sequences having large insertions or extensions as well as distantly related sequences of similar length. Two different heuristics, the progressive method (FFT-NS-2) and the iterative refinement method (FFT-NS-i), are implemented in MAFFT. The performances of FFT-NS-2 and FFT-NS-i were compared with other methods by computer simulations and benchmark tests; the CPU time of FFT-NS-2 is drastically reduced as compared with CLUSTALW with comparable accuracy. FFT-NS-i is over 100 times faster than T-COFFEE, when the number of input sequences exceeds 60, without sacrificing the accuracy.',\n",
              "  'authors': ['Kazutaka Katoh ',\n",
              "   ' Kazuharu Misawa ',\n",
              "   ' Kei‐ichi Kuma ',\n",
              "   ' Takashi Miyata'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2127774996',\n",
              "  'references': ['2158714788',\n",
              "   '2106882534',\n",
              "   '2313307644',\n",
              "   '3097169496',\n",
              "   '2015292449',\n",
              "   '2144362290',\n",
              "   '2065461553',\n",
              "   '2032678548',\n",
              "   '2087064593',\n",
              "   '2045391589'],\n",
              "  'title': 'MAFFT: a novel method for rapid multiple sequence alignment based on fast Fourier transform'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Arthur S. Slutsky ', ' Lorraine N. Tremblay'],\n",
              "  'date': '1998',\n",
              "  'identifier': '1898899939',\n",
              "  'references': ['2143748013',\n",
              "   '2005929586',\n",
              "   '2062082715',\n",
              "   '1766556848',\n",
              "   '1993947411',\n",
              "   '2085911628',\n",
              "   '2005999688',\n",
              "   '2048519644',\n",
              "   '2125764762',\n",
              "   '2077539093'],\n",
              "  'title': 'Multiple system organ failure. Is mechanical ventilation a contributing factor'},\n",
              " {'abstract': 'The physical phenomena which will ultimately limit MOS circuit miniaturization are considered. It is found that the minimum MOS transistor size is determined by gate oxide breakdown and drain-source punch-through. Other factors which limit device size are drain-substrate breakdown, drain ‘corner’ breakdown and substrate doping fluctuations. However these limitations are less severe than the oxide breakdown limitation mentioned above. Power dissipation and metal migration limit the frequency and/or packing density of fully dynamic and of complementary MOS circuits. In static non-complementary circuits, power dissipation is the principal limitation of the number of circuit functions per chip. The channel length of a minimum size MOS transistor is a factor of 10 smaller than that of the smallest present day devices. The tolerances required to manufacture such a transistor are compatible with electron beam masking techniques. It is thus possible to envision fully dynamic silicon chips with up to 10^7–10^8 MOS transistors per cm^2.',\n",
              "  'authors': ['B. Hoeneisen ', ' C. A. Mead'],\n",
              "  'date': '1972',\n",
              "  'identifier': '1987449940',\n",
              "  'references': ['1980584607',\n",
              "   '2156691787',\n",
              "   '1978918623',\n",
              "   '2001515825',\n",
              "   '2128586193',\n",
              "   '2545788242',\n",
              "   '2148017340',\n",
              "   '2578766647',\n",
              "   '2053386137',\n",
              "   '2032015322'],\n",
              "  'title': 'Fundamental limitations in microelectronics—I. MOS technology'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Tomaso Poggio ', ' Vincent Torre ', ' Christof Koch'],\n",
              "  'date': '1991',\n",
              "  'identifier': '1531060698',\n",
              "  'references': ['2105096388',\n",
              "   '2165810248',\n",
              "   '2000523160',\n",
              "   '65138405',\n",
              "   '2129855380'],\n",
              "  'title': 'Computational vision and regularization theory'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Peter Cheeseman ', ' John Stutz'],\n",
              "  'date': '1996',\n",
              "  'identifier': '1524704912',\n",
              "  'references': ['1570448133',\n",
              "   '2110325612',\n",
              "   '2153233077',\n",
              "   '2097089247',\n",
              "   '2186428165',\n",
              "   '1501500081',\n",
              "   '2108991785',\n",
              "   '2134731454',\n",
              "   '1977496278'],\n",
              "  'title': 'Bayesian classification (AutoClass): theory and results'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Ian H. Witten 1', ' Alistair Moffat 2', ' Timothy C. Bell 3'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2621280964',\n",
              "  'references': ['1570448133',\n",
              "   '1993692165',\n",
              "   '2160279333',\n",
              "   '2138662031',\n",
              "   '1512843916',\n",
              "   '2068905009',\n",
              "   '2088386938',\n",
              "   '2066595497',\n",
              "   '2140453381',\n",
              "   '1968927634'],\n",
              "  'title': 'Managing gigabytes (2nd ed.): compressing and indexing documents and images'},\n",
              " {'abstract': 'We present a simple self-training method that achieves 88.4% top-1 accuracy on ImageNet, which is 2.0% better than the state-of-the-art model that requires 3.5B weakly labeled Instagram images. On robustness test sets, it improves ImageNet-A top-1 accuracy from 61.0% to 83.7%, reduces ImageNet-C mean corruption error from 45.7 to 28.3, and reduces ImageNet-P mean flip rate from 27.8 to 12.2. To achieve this result, we first train an EfficientNet model on labeled ImageNet images and use it as a teacher to generate pseudo labels on 300M unlabeled images. We then train a larger EfficientNet as a student model on the combination of labeled and pseudo labeled images. We iterate this process by putting back the student as the teacher. During the generation of the pseudo labels, the teacher is not noised so that the pseudo labels are as accurate as possible. However, during the learning of the student, we inject noise such as dropout, stochastic depth and data augmentation via RandAugment to the student so that the student generalizes better than the teacher.',\n",
              "  'authors': ['Qizhe Xie 1',\n",
              "   ' Minh-Thang Luong 1',\n",
              "   ' Eduard Hovy 2',\n",
              "   ' Quoc V. Le 1'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3035160371',\n",
              "  'references': ['2194775991',\n",
              "   '2618530766',\n",
              "   '2962835968',\n",
              "   '2097117768',\n",
              "   '2095705004',\n",
              "   '2963446712',\n",
              "   '2183341477',\n",
              "   '2963207607',\n",
              "   '2964153729',\n",
              "   '2963373786'],\n",
              "  'title': 'Self-Training With Noisy Student Improves ImageNet Classification'},\n",
              " {'abstract': 'This completely revised second edition presents an introduction to statistical pattern recognition. Pattern recognition in general covers a wide range of problems: it is applied to engineering problems, such as character readers and wave form analysis as well as to brain modeling in biology and psychology. Statistical decision and estimation, which are the main subjects of this book, are regarded as fundamental to the study of pattern recognition. This book is appropriate as a text for introductory courses in pattern recognition and as a reference book for workers in the field. Each chapter contains computer projects as well as exercises.',\n",
              "  'authors': ['Keinosuke Fukunaga'],\n",
              "  'date': '1972',\n",
              "  'identifier': '2135346934',\n",
              "  'references': ['2067191022',\n",
              "   '1992419399',\n",
              "   '2132103241',\n",
              "   '2117812871',\n",
              "   '2132549764',\n",
              "   '2121601095',\n",
              "   '2041823554',\n",
              "   '2159128898',\n",
              "   '2161160262',\n",
              "   '2136040699'],\n",
              "  'title': 'Introduction to Statistical Pattern Recognition'},\n",
              " {'abstract': \"Foreword.Preface.PART ONE. SURVEY OF PROBABILITY THEORY.Chapter 1. Introduction.Chapter 2. Experiments, Sample Spaces, and Probability.2.1 Experiments and Sample Spaces.2.2 Set Theory.2.3 Events and Probability.2.4 Conditional Probability.2.5 Binomial Coefficients.Exercises.Chapter 3. Random Variables, Random Vectors, and Distributions Functions.3.1 Random Variables and Their Distributions.3.2 Multivariate Distributions.3.3 Sums and Integrals.3.4 Marginal Distributions and Independence.3.5 Vectors and Matrices.3.6 Expectations, Moments, and Characteristic Functions.3.7 Transformations of Random Variables.3.8 Conditional Distributions.Exercises.Chapter 4. Some Special Univariate Distributions.4.1 Introduction.4.2 The Bernoulli Distributions.4.3 The Binomial Distribution.4.4 The Poisson Distribution.4.5 The Negative Binomial Distribution.4.6 The Hypergeometric Distribution.4.7 The Normal Distribution.4.8 The Gamma Distribution.4.9 The Beta Distribution.4.10 The Uniform Distribution.4.11 The Pareto Distribution.4.12 The t Distribution.4.13 The F Distribution.Exercises.Chapter 5. Some Special Multivariate Distributions.5.1 Introduction.5.2 The Multinomial Distribution.5.3 The Dirichlet Distribution.5.4 The Multivariate Normal Distribution.5.5 The Wishart Distribution.5.6 The Multivariate t Distribution.5.7 The Bilateral Bivariate Pareto Distribution.Exercises.PART TWO. SUBJECTIVE PROBABILITY AND UTILITY.Chapter 6. Subjective Probability.6.1 Introduction.6.2 Relative Likelihood.6.3 The Auxiliary Experiment.6.4 Construction of the Probability Distribution.6.5 Verification of the Properties of a Probability Distribution.6.6 Conditional Likelihoods.Exercises.Chapter 7. Utility.7.1 Preferences Among Rewards.7.2 Preferences Among Probability Distributions.7.3 The Definitions of a Utility Function.7.4 Some Properties of Utility Functions.7.5 The Utility of Monetary Rewards.7.6 Convex and Concave Utility Functions.7.7 The Anxiomatic Development of Utility.7.8 Construction of the Utility Function.7.9 Verification of the Properties of a Utility Function.7.10 Extension of the Properties of a Utility Function to the Class ?E.Exercises.PART THREE. STATISTICAL DECISION PROBLEMS.Chapter 8. Decision Problems.8.1 Elements of a Decision Problem.8.2 Bayes Risk and Bayes Decisions.8.3 Nonnegative Loss Functions.8.4 Concavity of the Bayes Risk.8.5 Randomization and Mixed Decisions.8.6 Convex Sets.8.7 Decision Problems in Which ~2 and D Are Finite.8.8 Decision Problems with Observations.8.9 Construction of Bayes Decision Functions.8.10 The Cost of Observation.8.11 Statistical Decision Problems in Which Both ? and D contains Two Points.8.12 Computation of the Posterior Distribution When the Observations Are Made in More Than One Stage.Exercises.Chapter 9. Conjugate Prior Distributions.9.1 Sufficient Statistics.9.2 Conjugate Families of Distributions.9.3 Construction of the Conjugate Family.9.4 Conjugate Families for Samples from Various Standard Distributions.9.5 Conjugate Families for Samples from a Normal Distribution.9.6 Sampling from a Normal Distribution with Unknown Mean and Unknown Precision.9.7 Sampling from a Uniform Distribution.9.8 A Conjugate Family for Multinomial Observations.9.9 Conjugate Families for Samples from a Multivariate Normal Distribution.9.10 Multivariate Normal Distributions with Unknown Mean Vector and Unknown Precision matrix.9.11 The Marginal Distribution of the Mean Vector.9.12 The Distribution of a Correlation.9.13 Precision Matrices Having an Unknown Factor.Exercises.Chapter 10. Limiting Posterior Distributions.10.1 Improper Prior Distributions.10.2 Improper Prior Distributions for Samples from a Normal Distribution.10.3 Improper Prior Distributions for Samples from a Multivariate Normal Distribution.10.4 Precise Measurement.10.5 Convergence of Posterior Distributions.10.6 Supercontinuity.10.7 Solutions of the Likelihood Equation.10.8 Convergence of Supercontinuous Functions.10.9 Limiting Properties of the Likelihood Function.10.10 Normal Approximation to the Posterior Distribution.10.11 Approximation for Vector Parameters.10.12 Posterior Ratios.Exercises.Chapter 11. Estimation, Testing Hypotheses, and linear Statistical Models.11.1 Estimation.11.2 Quadratic Loss.11.3 Loss Proportional to the Absolute Value of the Error.11.4 Estimation of a Vector.11.5 Problems of Testing Hypotheses.11.6 Testing a Simple Hypothesis About the Mean of a Normal Distribution.11.7 Testing Hypotheses about the Mean of a Normal Distribution.11.8 Deciding Whether a Parameter Is Smaller or larger Than a Specific Value.11.9 Deciding Whether the Mean of a Normal Distribution Is Smaller or larger Than a Specific Value.11.10 Linear Models.11.11 Testing Hypotheses in Linear Models.11.12 Investigating the Hypothesis That Certain Regression Coefficients Vanish.11.13 One-Way Analysis of Variance.Exercises.PART FOUR. SEQUENTIAL DECISIONS.Chapter 12. Sequential Sampling.12.1 Gains from Sequential Sampling.12.2 Sequential Decision Procedures.12.3 The Risk of a Sequential Decision Procedure.12.4 Backward Induction.12.5 Optimal Bounded Sequential Decision procedures.12.6 Illustrative Examples.12.7 Unbounded Sequential Decision Procedures.12.8 Regular Sequential Decision Procedures.12.9 Existence of an Optimal Procedure.12.10 Approximating an Optimal Procedure by Bounded Procedures.12.11 Regions for Continuing or Terminating Sampling.12.12 The Functional Equation.12.13 Approximations and Bounds for the Bayes Risk.12.14 The Sequential Probability-ratio Test.12.15 Characteristics of Sequential Probability-ratio Tests.12.16 Approximating the Expected Number of Observations.Exercises.Chapter 13. Optimal Stopping.13.1 Introduction.13.2 The Statistician's Reward.13.3 Choice of the Utility Function.13.4 Sampling Without Recall.13.5 Further Problems of Sampling with Recall and Sampling without Recall.13.6 Sampling without Recall from a Normal Distribution with Unknown Mean.13.7 Sampling with Recall from a Normal Distribution with Unknown Mean.13.8 Existence of Optimal Stopping Rules.13.9 Existence of Optimal Stopping Rules for Problems of Sampling with Recall and Sampling without Recall.13.10 Martingales.13.11 Stopping Rules for Martingales.13.12 Uniformly Integrable Sequences of Random Variables.13.13 Martingales Formed from Sums and Products of Random Variables.13.14 Regular Supermartingales.13.15 Supermartingales and General Problems of Optimal Stopping.13.16 Markov Processes.13.17 Stationary Stopping Rules for Markov Processes.13.18 Entrance-fee Problems.13.19 The Functional Equation for a Markov Process.Exercises.Chapter 14. Sequential Choice of Experiments.14.1 Introduction.14.2 Markovian Decision Processes with a Finite Number of Stages.14.3 Markovian Decision Processes with an Infinite Number of Stages.14.4 Some Betting Problems.14.5 Two-armed-bandit Problems.14.6 Two-armed-bandit Problems When the Value of One Parameter Is Known.14.7 Two-armed-bandit Problems When the Parameters Are Dependent.14.8 Inventory Problems.14.9 Inventory Problems with an Infinite Number of Stages.14.10 Control Problems.14.11 Optimal Control When the Process Cannot Be Observed without Error.14.12 Multidimensional Control Problems.14.13 Control Problems with Actuation Errors.14.14 Search Problems.14.15 Search Problems with Equal Costs.14.16 Uncertainty Functions and Statistical Decision Problems.14.17 Sufficient Experiments.14.18 Examples of Sufficient Experiments.Exercises.References.Supplementary Bibliography.Name Index.Subject Index.\",\n",
              "  'authors': ['Morris Herman DeGroot'],\n",
              "  'date': '1970',\n",
              "  'identifier': '2006258746',\n",
              "  'references': ['1479807131',\n",
              "   '1817561967',\n",
              "   '2171265988',\n",
              "   '2110575115',\n",
              "   '2008906462',\n",
              "   '2028995298',\n",
              "   '1593793857',\n",
              "   '2044535354',\n",
              "   '2100969003',\n",
              "   '2147664181'],\n",
              "  'title': 'Optimal Statistical Decisions'},\n",
              " {'abstract': 'This paper compares the performance of several classifier algorithms on a standard database of handwritten digits. We consider not only raw accuracy, but also training time, recognition time, and memory requirements. When available, we report measurements of the fraction of patterns that must be rejected so that the remaining patterns have misclassification rates less than a given threshold.',\n",
              "  'authors': ['L. Bottou 1',\n",
              "   ' C. Cortes 2',\n",
              "   ' 3',\n",
              "   ' J.S. Denker 2',\n",
              "   ' 4',\n",
              "   ' H. Drucker 4',\n",
              "   ' 5',\n",
              "   ' I. Guyon 4',\n",
              "   ' L.D. Jackel ',\n",
              "   ' Y. LeCun ',\n",
              "   ' U.A. Muller ',\n",
              "   ' E. Sackinger 4',\n",
              "   ' P. Simard 2',\n",
              "   ' 6',\n",
              "   ' V. Vapnik'],\n",
              "  'date': '1994',\n",
              "  'identifier': '2168228682',\n",
              "  'references': ['2087347434',\n",
              "   '2093717447',\n",
              "   '2137291015',\n",
              "   '2166501286',\n",
              "   '2056763477',\n",
              "   '2162363099',\n",
              "   '2093465006',\n",
              "   '2151328054'],\n",
              "  'title': 'Comparison of classifier methods: a case study in handwritten digit recognition'},\n",
              " {'abstract': \"Modular toolkit for Data Processing (MDP) is a data processing framework written in Python. From the user's perspective, MDP is a collection of supervised and unsupervised learning algorithms and other data processing units that can be combined into data processing sequences and more complex feed-forward network architectures. Computations are performed efficiently in terms of speed and memory requirements. From the scientific developer's perspective, MDP is a modular framework, which can easily be expanded. The implementation of new algorithms is easy and intuitive. The new implemented units are then automatically integrated with the rest of the library. MDP has been written in the context of theoretical research in neuroscience, but it has been designed to be helpful in any context where trainable data processing algorithms are used. Its simplicity on the user's side, the variety of readily available algorithms, and the reusability of the implemented units make it also a useful educational tool.\",\n",
              "  'authors': ['Tiziano Zito 1',\n",
              "   ' Niko Wilbert 2',\n",
              "   ' Laurenz Wiskott 2',\n",
              "   ' Pietro Berkes 3'],\n",
              "  'date': '2008',\n",
              "  'identifier': '2047804403',\n",
              "  'references': ['1663973292',\n",
              "   '2136922672',\n",
              "   '1554663460',\n",
              "   '2156838815',\n",
              "   '2167217202',\n",
              "   '2138754805',\n",
              "   '2148856562',\n",
              "   '1511812886',\n",
              "   '2102724320',\n",
              "   '2156141384'],\n",
              "  'title': 'Modular toolkit for Data Processing (MDP): a Python data processing framework'},\n",
              " {'abstract': 'The human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. Here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. We also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence.',\n",
              "  'authors': ['Eric S. Lander 1',\n",
              "   ' Lauren M. Linton 1',\n",
              "   ' Bruce Birren 1',\n",
              "   ' Chad Nusbaum 1',\n",
              "   ' Michael C. Zody 1',\n",
              "   ' Jennifer Baldwin 1',\n",
              "   ' Keri Devon 1',\n",
              "   ' Ken Dewar 1',\n",
              "   ' Michael Doyle 1',\n",
              "   ' William Fitzhugh 1',\n",
              "   ' Roel Funke 1',\n",
              "   ' Diane Gage 1',\n",
              "   ' Katrina Harris 1',\n",
              "   ' Andrew Heaford 1',\n",
              "   ' John Howland 1',\n",
              "   ' Lisa Kann 1',\n",
              "   ' Jessica Lehoczky 1',\n",
              "   ' Rosie Levine 1',\n",
              "   ' Paul McEwan 1',\n",
              "   ' Kevin McKernan 1',\n",
              "   ' James Meldrim 1',\n",
              "   ' Jill P. Mesirov 1',\n",
              "   ' Cher Miranda 1',\n",
              "   ' William Morris 1',\n",
              "   ' Jerome Naylor 1',\n",
              "   ' Christina Raymond 1',\n",
              "   ' Mark Rosetti 1',\n",
              "   ' Ralph Santos 1',\n",
              "   ' Andrew Sheridan 1',\n",
              "   ' Carrie Sougnez 1',\n",
              "   ' Nicole Stange-Thomann 1',\n",
              "   ' Nikola Stojanovic 1',\n",
              "   ' Aravind Subramanian 1',\n",
              "   ' Dudley Wyman 1',\n",
              "   ' Jane Rogers ',\n",
              "   ' John Sulston ',\n",
              "   ' Rachael Ainscough ',\n",
              "   ' Stephan Beck ',\n",
              "   ' David Bentley ',\n",
              "   ' John Burton ',\n",
              "   ' Christopher Clee ',\n",
              "   ' Nigel Carter ',\n",
              "   ' Alan Coulson ',\n",
              "   ' Rebecca Deadman ',\n",
              "   ' Panos Deloukas ',\n",
              "   ' Andrew Dunham ',\n",
              "   ' Ian Dunham ',\n",
              "   ' Richard Durbin ',\n",
              "   ' Lisa French ',\n",
              "   ' Darren Grafham +199'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2168909179',\n",
              "  'references': ['2158714788',\n",
              "   '2141885858',\n",
              "   '2165460636',\n",
              "   '2121016876',\n",
              "   '2119923823',\n",
              "   '1971403296',\n",
              "   '2061008984',\n",
              "   '2166187656',\n",
              "   '1965265115',\n",
              "   '1493217831'],\n",
              "  'title': 'Initial sequencing and analysis of the human genome.'},\n",
              " {'abstract': 'PREFACE 1. OVERVIEW 2. TEXT COMPRESSION 3. INDEXING 4. QUERYING 5. INDEX CONSTRUCTION 6. IMAGE COMPRESSION 7. TEXTUAL IMAGES 8. MIXED TEXT AND IMAGES 9. IMPLEMENTATION 10. THE INFORMATION EXPLOSION A. GUIDE TO THE MG SYSTEM B. GUIDE TO THE NZDL REFERENCES INDEX',\n",
              "  'authors': ['I.H. Witten ', ' A. Moffat ', ' T.C. Bell'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2160484851',\n",
              "  'references': ['2130350995'],\n",
              "  'title': 'Managing Gigabytes: Compressing and Indexing Documents and Images'},\n",
              " {'abstract': 'Firstly, the paper proposes an axiomatic definition for the notion of \"segmentation\" in image processing, which is based on the idea of a maximal partition. Then a key theorem links segmentation with connection, on the one hand, and with connective criteria on the other one. A series of lattice properties are then developed. In a last part, two examples of segmentations are proposed.',\n",
              "  'authors': ['J. Serra'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2294922303',\n",
              "  'references': ['2121947440',\n",
              "   '2067191022',\n",
              "   '1533162639',\n",
              "   '2116040950',\n",
              "   '1992419399',\n",
              "   '2132984323',\n",
              "   '2132103241',\n",
              "   '1999478155',\n",
              "   '2109364787',\n",
              "   '2145023731'],\n",
              "  'title': 'Image segmentation'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Bernard Widrow ', ' Marcian E. Hoff'],\n",
              "  'date': '1988',\n",
              "  'identifier': '1535810436',\n",
              "  'references': ['2117812871',\n",
              "   '2154642048',\n",
              "   '2121863487',\n",
              "   '2042264548',\n",
              "   '114517082',\n",
              "   '2166851633',\n",
              "   '2025605741',\n",
              "   '2604319603',\n",
              "   '1570963478'],\n",
              "  'title': 'Adaptive switching circuits'},\n",
              " {'abstract': 'Some patients with positive chest CT findings may present with negative results of real-time reverse-transcription polymerase chain reaction (RT-PCR) tests for coronavirus disease 2019 (COVID-19). In this study, the authors present chest CT findings from five patients with COVID-19 infection who had initial negative RT-PCR results. All five patients had typical imaging findings, including ground-glass opacity (five patients) and/or mixed ground-glass opacity and mixed consolidation (two patients). After isolation for presumed COVID-19 pneumonia, all patients were eventually confirmed to have COVID-19 infection by means of repeated swab tests. A combination of repeated swab tests and CT scanning may be helpful for individuals with a high clinical suspicion of COVID-19 infection but negative findings at RT-PCR screening.',\n",
              "  'authors': ['Xingzhi Xie ',\n",
              "   ' Zheng Zhong ',\n",
              "   ' Wei Zhao ',\n",
              "   ' Chao Zheng ',\n",
              "   ' Fei Wang ',\n",
              "   ' Jun Liu'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3006110666',\n",
              "  'references': ['3004906315', '3005272159', '2112136274', '2056155046'],\n",
              "  'title': 'Chest CT for Typical Coronavirus Disease 2019 (COVID-19) Pneumonia: Relationship to Negative RT-PCR Testing.'},\n",
              " {'abstract': 'The travelling salesman problem is a classical problem in the field of combinatorial optimization, concerned with efficient methods for maximizing or minimizing a function of many independent variables. Given the positions of N cities, which in the simplest case lie in the plane, what is the shortest closed tour in which each city can be visited once? We describe how a parallel analogue algorithm, derived from a formal model for the establishment of topographically ordered projections in the brain, can be applied to the travelling salesman problem. Using an iterative procedure, a circular closed path is gradually elongated non-uniformly until it eventually passes sufficiently near to all the cities to define a tour. This produces shorter tour lengths than another recent parallel analogue algorithm, scales well with the size of the problem, and is naturally extendable to a large class of optimization problems involving topographic mappings between geometrical structures.',\n",
              "  'authors': ['Richard Durbin 1', ' 2', ' David Willshaw 3'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2051719061',\n",
              "  'references': ['2581275558',\n",
              "   '1991848143',\n",
              "   '307896644',\n",
              "   '2042986967',\n",
              "   '2071609006',\n",
              "   '2022306346',\n",
              "   '2023810448',\n",
              "   '2055569927',\n",
              "   '2017811812',\n",
              "   '2070097792'],\n",
              "  'title': 'An analogue approach to the travelling salesman problem using an elastic net method'},\n",
              " {'abstract': '',\n",
              "  'authors': ['D. G. Pelli 1', ' J. G. Robson 2', ' A. J. Wilkins 2'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2124789365',\n",
              "  'references': ['1999908130',\n",
              "   '2109951815',\n",
              "   '2041129645',\n",
              "   '2079721233',\n",
              "   '2727420541',\n",
              "   '2041181954',\n",
              "   '1972389866',\n",
              "   '2040364818',\n",
              "   '1596190887',\n",
              "   '1549272285'],\n",
              "  'title': 'THE DESIGN OF A NEW LETTER CHART FOR MEASURING CONTRAST SENSITIVITY'},\n",
              " {'abstract': 'Thesis (Ph. D.)--Massachusetts Institute of Technology, Dept. of Electrical Engineering, 1963.',\n",
              "  'authors': ['Lawrence G. Roberts'],\n",
              "  'date': '1963',\n",
              "  'identifier': '2108729336',\n",
              "  'references': ['2110158442',\n",
              "   '2099046646',\n",
              "   '2342277278',\n",
              "   '2612706635',\n",
              "   '2096600681',\n",
              "   '1495971627',\n",
              "   '2131806657'],\n",
              "  'title': 'MACHINE PERCEPTION OF THREE-DIMENSIONAL SOLIDS,'},\n",
              " {'abstract': 'Preface Table of Notation Part 1: Unconstrained Optimization Introduction Structure of Methods Newton-like Methods Conjugate Direction Methods Restricted Step Methods Sums of Squares and Nonlinear Equations Part 2: Constrained Optimization Introduction Linear Programming The Theory of Constrained Optimization Quadratic Programming General Linearly Constrained Optimization Nonlinear Programming Other Optimization Problems Non-Smooth Optimization References Subject Index.',\n",
              "  'authors': ['Roger Fletcher'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2077658674',\n",
              "  'references': ['3029645440',\n",
              "   '2139212933',\n",
              "   '2120145199',\n",
              "   '1964357740',\n",
              "   '2123871098',\n",
              "   '1596717185',\n",
              "   '2030723843',\n",
              "   '1804110266',\n",
              "   '1993170675',\n",
              "   '2614081736'],\n",
              "  'title': 'Practical Methods of Optimization'},\n",
              " {'abstract': 'A method for automated construction of classifications called conceptual clustering is described and compared to methods used in numerical taxonomy. This method arranges objects into classes representing certain descriptive concepts, rather than into classes defined solely by a similarity metric in some a priori defined attribute space. A specific form of the method is conjunctive conceptual clustering, in which descriptive concepts are conjunctive statements involving relations on selected object attributes and optimized according to an assumed global criterion of clustering quality. The method, implemented in program CLUSTER/2, is tested together with 18 numerical taxonomy methods on two exemplary problems: 1) a construction of a classification of popular microcomputers and 2) the reconstruction of a classification of selected plant disease categories. In both experiments, the majority of numerical taxonomy methods (14 out of 18) produced results which were difficult to interpret and seemed to be arbitrary. In contrast to this, the conceptual clustering method produced results that had a simple interpretation and corresponded well to solutions preferred by people.',\n",
              "  'authors': ['Ryszard S. Michalski ', ' Robert E. Stepp'],\n",
              "  'date': '1983',\n",
              "  'identifier': '2037591014',\n",
              "  'references': ['2067642555', '1515824999', '1480242538', '2121895897'],\n",
              "  'title': 'Automated Construction of Classifications: Conceptual Clustering Versus Numerical Taxonomy'},\n",
              " {'abstract': '',\n",
              "  'authors': ['C. Merz'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2982720039',\n",
              "  'references': ['2111072639',\n",
              "   '2063978378',\n",
              "   '2011430131',\n",
              "   '2172000360',\n",
              "   '2017337590',\n",
              "   '1975846642',\n",
              "   '1605688901',\n",
              "   '2141695047',\n",
              "   '2140785063'],\n",
              "  'title': 'UCI Repository of Machine Learning Databases'},\n",
              " {'abstract': \"An approach to the detection and identification of human faces is presented, and a working, near-real-time face recognition system which tracks a subject's head and then recognizes the person by comparing characteristics of the face to those of known individuals is described. This approach treats face recognition as a two-dimensional recognition problem, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. Face images are projected onto a feature space ('face space') that best encodes the variation among known face images. The face space is defined by the 'eigenfaces', which are the eigenvectors of the set of faces; they do not necessarily correspond to isolated features such as eyes, ears, and noses. The framework provides the ability to learn to recognize new faces in an unsupervised manner. >\",\n",
              "  'authors': ['M.A. Turk ', ' A.P. Pentland'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2098693229',\n",
              "  'references': ['2138451337',\n",
              "   '2125848778',\n",
              "   '2130259898',\n",
              "   '2055712799',\n",
              "   '2125999363',\n",
              "   '1507699566',\n",
              "   '1998186877',\n",
              "   '2169718527'],\n",
              "  'title': 'Face recognition using eigenfaces'},\n",
              " {'abstract': 'We propose a network architecture which uses a single internal layer of locally-tuned processing units to learn both classification tasks and real-valued function approximations (Moody and Darken 1988). We consider training such networks in a completely supervised manner, but abandon this approach in favor of a more computationally efficient hybrid learning method which combines self-organized and supervised learning. Our networks learn faster than backpropagation for two reasons: the local representations ensure that only a few units respond to any given input, thus reducing computational overhead, and the hybrid learning rules are linear rather than nonlinear, thus leading to faster convergence. Unlike many existing methods for data analysis, our network architecture and learning rules are truly adaptive and are thus appropriate for real-time use.',\n",
              "  'authors': ['John Moody ', ' Christian J. Darken'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2171277043',\n",
              "  'references': ['2042264548',\n",
              "   '2143956139',\n",
              "   '2150593711',\n",
              "   '23758216',\n",
              "   '1524100745',\n",
              "   '2084544490',\n",
              "   '2034099719',\n",
              "   '2127218421',\n",
              "   '2072773743',\n",
              "   '2007700211'],\n",
              "  'title': 'Fast learning in networks of locally-tuned processing units'},\n",
              " {'abstract': 'Preface. Acknowledgements. Introduction. References. List of Structures. Index of Abbreviations. Diagrams.',\n",
              "  'authors': ['George Paxinos ', ' Charles Watson'],\n",
              "  'date': '1983',\n",
              "  'identifier': '2163815564',\n",
              "  'references': ['2027740042',\n",
              "   '2145132952',\n",
              "   '1627229807',\n",
              "   '2046960533',\n",
              "   '2154853638',\n",
              "   '2133565799',\n",
              "   '2168101731',\n",
              "   '2147164277',\n",
              "   '2129028793',\n",
              "   '2017934537'],\n",
              "  'title': 'The Rat Brain in Stereotaxic Coordinates'},\n",
              " {'abstract': 'We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated. >',\n",
              "  'authors': ['Pentland ', ' Moghaddam ', ' Starner'],\n",
              "  'date': '1994',\n",
              "  'identifier': '2098947662',\n",
              "  'references': ['2138451337',\n",
              "   '2113341759',\n",
              "   '2135463994',\n",
              "   '2138313032',\n",
              "   '2130506643',\n",
              "   '2157418942',\n",
              "   '2112684592',\n",
              "   '1993867646',\n",
              "   '2121863133',\n",
              "   '2030234875'],\n",
              "  'title': 'View-based and modular eigenspaces for face recognition'},\n",
              " {'abstract': 'This paper presents a cross-lingual voice conversion framework that adopts a modularized neural network. The modularized neural network has a common input structure that is shared for both languages, and two separate output modules, one for each language. The idea is motivated by the fact that phonetic systems of languages are similar because humans share a common vocal production system, but acoustic renderings, such as prosody and phonotactic, vary a lot from language to language. The modularized neural network is trained to map Phonetic PosteriorGram (PPG) to acoustic features for multiple speakers. It is conditioned on a speaker i-vector to generate the desired target voice. We validated the idea between English and Mandarin languages in objective and subjective tests. In addition, mixed-lingual PPG derived from a unified English-Mandarin acoustic model is proposed to capture the linguistic information from both languages. It is found that our proposed modularized neural network significantly outperforms the baseline approaches in terms of speech quality and speaker individuality, and mixed-lingual PPG representation further improves the conversion performance.',\n",
              "  'authors': ['Yi Zhou ',\n",
              "   ' Xiaohai Tian ',\n",
              "   ' Emre Yilmaz ',\n",
              "   ' Rohan Kumar Das ',\n",
              "   ' Haizhou Li'],\n",
              "  'date': '2019',\n",
              "  'identifier': '3007502375',\n",
              "  'references': ['2150769028',\n",
              "   '1524333225',\n",
              "   '1494198834',\n",
              "   '2914746235',\n",
              "   '2120605154',\n",
              "   '2624871570',\n",
              "   '2173629880',\n",
              "   '2402146185',\n",
              "   '2514741789',\n",
              "   '2471520273'],\n",
              "  'title': 'A Modularized Neural Network with Language-Specific Output Layers for Cross-Lingual Voice Conversion'},\n",
              " {'abstract': 'Behavioral and clinical studies have long implicated the posterior parietal cortex of primates in spatial perception and spatially oriented behavior. However, recordings from single neurons in behaving monkeys by different laboratories have resulted in divergent views with some ascribing a largely motor and others a largely sensory role for this region. We have designed paradigms to separate the sensory and motor components of the neural activity and have found that the cells in this area respond to both sensory stimulation and motor behavior. Thus, it is likely that this area is not solely sensory or motor, but rather is involved in higher order aspects of sensory-motor integration.',\n",
              "  'authors': ['R. A. Andersen ', ' Gregory K Essick ', ' R. M. Siegel'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2086105634',\n",
              "  'references': ['2023486727',\n",
              "   '2177960617',\n",
              "   '2406002377',\n",
              "   '1827197145',\n",
              "   '2098933766',\n",
              "   '2005616541',\n",
              "   '1599111961',\n",
              "   '2127525246',\n",
              "   '2416185849',\n",
              "   '1921997297'],\n",
              "  'title': 'Neurons of area 7 activated by both visual stimuli and oculomotor behavior.'},\n",
              " {'abstract': 'This paper investigates a novel computational problem, namely the Composite Residuosity Class Problem, and its applications to public-key cryptography. We propose a new trapdoor mechanism and derive from this technique three encryption schemes : a trapdoor permutation and two homomorphic probabilistic encryption schemes computationally comparable to RSA. Our cryptosystems, based on usual modular arithmetics, are provably secure under appropriate assumptions in the standard model.',\n",
              "  'authors': ['Pascal Paillier'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2132172731',\n",
              "  'references': ['1996360405',\n",
              "   '2156186849',\n",
              "   '2052267638',\n",
              "   '2108834246',\n",
              "   '1529862094',\n",
              "   '2138784757',\n",
              "   '2770583616',\n",
              "   '2164409696',\n",
              "   '2106287110',\n",
              "   '2105564033'],\n",
              "  'title': 'Public-key cryptosystems based on composite degree residuosity classes'},\n",
              " {'abstract': \"We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model's ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines.\",\n",
              "  'authors': ['Richard Socher ',\n",
              "   ' Jeffrey Pennington ',\n",
              "   ' Eric H. Huang ',\n",
              "   ' Andrew Y. Ng ',\n",
              "   ' Christopher D. Manning'],\n",
              "  'date': '2011',\n",
              "  'identifier': '71795751',\n",
              "  'references': ['1880262756',\n",
              "   '2097726431',\n",
              "   '2117130368',\n",
              "   '2166706824',\n",
              "   '2132339004',\n",
              "   '2155328222',\n",
              "   '2158139315',\n",
              "   '1423339008',\n",
              "   '2114524997',\n",
              "   '2022204871'],\n",
              "  'title': 'Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions'},\n",
              " {'abstract': 'Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.',\n",
              "  'authors': ['Sam T. Roweis 1', ' Lawrence K. Saul 2'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2053186076',\n",
              "  'references': ['1902027874',\n",
              "   '2610857016',\n",
              "   '1991848143',\n",
              "   '2107636931',\n",
              "   '2121122425',\n",
              "   '2122538988',\n",
              "   '2047870719',\n",
              "   '2070320140',\n",
              "   '1513400187',\n",
              "   '2019020850'],\n",
              "  'title': 'Nonlinear dimensionality reduction by locally linear embedding.'},\n",
              " {'abstract': 'Spike (S) proteins of coronaviruses, including the coronavirus that causes severe acute respiratory syndrome (SARS), associate with cellular receptors to mediate infection of their target cells. Here we identify a metallopeptidase, angiotensin-converting enzyme 2 (ACE2), isolated from SARS coronavirus (SARS-CoV)-permissive Vero E6 cells, that efficiently binds the S1 domain of the SARS-CoV S protein. We found that a soluble form of ACE2, but not of the related enzyme ACE1, blocked association of the S1 domain with Vero E6 cells. 293T cells transfected with ACE2, but not those transfected with human immunodeficiency virus-1 receptors, formed multinucleated syncytia with cells expressing S protein. Furthermore, SARS-CoV replicated efficiently on ACE2-transfected but not mock-transfected 293T cells. Finally, anti-ACE2 but not anti-ACE1 antibody blocked viral replication on Vero E6 cells. Together our data indicate that ACE2 is a functional receptor for SARS-CoV.',\n",
              "  'authors': ['Wenhui Li 1',\n",
              "   ' Michael J. Moore 1',\n",
              "   ' Natalya Vasilieva 2',\n",
              "   ' Jianhua Sui 3',\n",
              "   ' Swee Kee Wong 1',\n",
              "   ' Michael A. Berne 4',\n",
              "   ' Mohan Somasundaran 5',\n",
              "   ' John L. Sullivan 5',\n",
              "   ' Katherine Luzuriaga 5',\n",
              "   ' Thomas C. Greenough 5',\n",
              "   ' Hyeryun Choe 2',\n",
              "   ' Michael Farzan 1'],\n",
              "  'date': '2003',\n",
              "  'identifier': '1966238900',\n",
              "  'references': ['2132260239',\n",
              "   '2104548316',\n",
              "   '2116586125',\n",
              "   '2169198329',\n",
              "   '2168446943',\n",
              "   '1976741900',\n",
              "   '1757215199',\n",
              "   '2025672718',\n",
              "   '1965019797',\n",
              "   '2000040025'],\n",
              "  'title': 'Angiotensin-converting enzyme 2 is a functional receptor for the SARS coronavirus.'},\n",
              " {'abstract': 'Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD), also called algorithmic differentiation or simply \"auto-diff\", is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational uid dynamics, atmospheric sciences, and engineering design optimization. Until very recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other\\'s results. Despite its relevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names \"dynamic computational graphs\" and \"differentiable programming\". We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main implementation techniques. By precisely defining the main differentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms \"autodiff\", \"automatic differentiation\", and \"symbolic differentiation\" as these are encountered more and more in machine learning settings.',\n",
              "  'authors': ['Atılım Günes Baydin 1',\n",
              "   ' Barak A. Pearlmutter 2',\n",
              "   ' Alexey Andreyevich Radul 3',\n",
              "   ' Jeffrey Mark Siskind 4'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2962727772',\n",
              "  'references': ['2618530766',\n",
              "   '2964121744',\n",
              "   '2919115771',\n",
              "   '2964308564',\n",
              "   '2161969291',\n",
              "   '1959608418',\n",
              "   '2146502635',\n",
              "   '2310919327',\n",
              "   '2076063813',\n",
              "   '1746819321'],\n",
              "  'title': 'Automatic differentiation in machine learning: a survey'},\n",
              " {'abstract': 'Due to the simplicity of their implementations, least square support vector machine (LS-SVM) and proximal support vector machine (PSVM) have been widely used in binary classification applications. The conventional LS-SVM and PSVM cannot be used in regression and multiclass classification applications directly, although variants of LS-SVM and PSVM have been proposed to handle such cases. This paper shows that both LS-SVM and PSVM can be simplified further and a unified learning framework of LS-SVM, PSVM, and other regularization algorithms referred to extreme learning machine (ELM) can be built. ELM works for the “generalized” single-hidden-layer feedforward networks (SLFNs), but the hidden layer (or called feature mapping) in ELM need not be tuned. Such SLFNs include but are not limited to SVM, polynomial network, and the conventional feedforward neural networks. This paper shows the following: 1) ELM provides a unified learning platform with a widespread type of feature mappings and can be applied in regression and multiclass classification applications directly; 2) from the optimization method point of view, ELM has milder optimization constraints compared to LS-SVM and PSVM; 3) in theory, compared to ELM, LS-SVM and PSVM achieve suboptimal solutions and require higher computational complexity; and 4) in theory, ELM can approximate any target continuous function and classify any disjoint regions. As verified by the simulation results, ELM tends to have better scalability and achieve similar (for regression and binary class cases) or much better (for multiclass cases) generalization performance at much faster learning speed (up to thousands times) than traditional SVM and LS-SVM.',\n",
              "  'authors': ['Guang-Bin Huang 1',\n",
              "   ' Hongming Zhou 1',\n",
              "   ' Xiaojian Ding 2',\n",
              "   ' Rui Zhang 1'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2026131661',\n",
              "  'references': ['2124776405',\n",
              "   '2119821739',\n",
              "   '2109363337',\n",
              "   '2111072639',\n",
              "   '2084812512',\n",
              "   '2154053567',\n",
              "   '2172000360',\n",
              "   '1498436455',\n",
              "   '1596717185',\n",
              "   '2047028564'],\n",
              "  'title': 'Extreme Learning Machine for Regression and Multiclass Classification'},\n",
              " {'abstract': 'Abstract The following study both synthesizes and builds on the efforts to conceptualize the effects of quality, satisfaction, and value on consumers’ behavioral intentions. Specifically, it reports an empirical assessment of a model of service encounters that simultaneously considers the direct effects of these variables on behavioral intentions. The study builds on recent advances in services marketing theory and assesses the relationships between the identified constructs across multiple service industries. Several competing theories are also considered and compared to the research model. A number of notable findings are reported including the empirical verification that service quality, service value, and satisfaction may all be directly related to behavioral intentions when all of these variables are considered collectively. The results further suggest that the indirect effects of the service quality and value constructs enhanced their impact on behavioral intentions.',\n",
              "  'authors': ['J.Joseph Cronin 1', ' Michael K Brady 2', ' G.Tomas M Hult 1'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2036063909',\n",
              "  'references': ['2071666535',\n",
              "   '2059334100',\n",
              "   '1689771227',\n",
              "   '2122912498',\n",
              "   '2026368098',\n",
              "   '1965574139',\n",
              "   '1979907230',\n",
              "   '1987258130',\n",
              "   '2028809046',\n",
              "   '1574378514'],\n",
              "  'title': 'Assessing the effects of quality, value, and customer satisfaction on consumer behavioral intentions in service environments'},\n",
              " {'abstract': 'This manual addresses the linguistic issues that arise in connection with annotating texts by part of speech (\"tagging\"). Section 2 is an alphabetical list of the parts of speech encoded in the annotation systems of the Penn Treebank Project, along with their corresponding abbreviations (\"tags\") and some information concerning their definition. This section allows you to find an unfamiliar tag by looking up a familiar part of speech. Section 3 recapitulates the information in Section 2, but this time the information is alphabetically ordered by tags. This is the section to consult in order to find out what an unfamiliar tag means. Since the parts of speech are probably familiar to you from high school English, you should have little difficulty in assimilating the tags themselves. However, it is often quite difficult to decide which tag is appropriate in a particular context. The two sections 4 and 5 therefore include examples and guidelines on how to tag problematic cases. If you are uncertain about whether a given tag is correct or not, refer to these sections in order to ensure a consistently annotated text. Section 4 discusses parts of speech that are easily confused and gives guidelines on how to tag such cases, while Section 5 contains an alphabetical list of specific problematic words and collocations. Finally, Section 6 discusses some general tagging conventions. One general rule, however, is so important that we state it here. Many texts are not models of good prose, and some contain outright errors and slips of the pen. Do not be tempted to correct a tag to what it would be if the text were correct; rather, it is the incorrect word that should be tagged correctly. Disciplines Computer Sciences Comments University of Pennsylvania Department of Computer and Information Science Technical Report No. MSCIS-90-47. This technical report is available at ScholarlyCommons: http://repository.upenn.edu/cis_reports/570 Part-of-S peech Tagging Guidelines For The Penn Treebank Project (3rd Revision) MS-CIS-90-47 LINC LAB 178',\n",
              "  'authors': ['Beatrice Santorini'],\n",
              "  'date': '1990',\n",
              "  'identifier': '900993354',\n",
              "  'references': ['2108646579',\n",
              "   '1632114991',\n",
              "   '2293771131',\n",
              "   '2542192908',\n",
              "   '1988931981',\n",
              "   '1515847863',\n",
              "   '1482328859',\n",
              "   '2127002961'],\n",
              "  'title': 'Part-of-Speech Tagging Guidelines for the Penn Treebank Project (3rd Revision)'},\n",
              " {'abstract': 'We consider problems involving groups of data where each observation within a group is a draw from a mixture model and where it is desirable to share mixture components between groups. We assume that the number of mixture components is unknown a priori and is to be inferred from the data. In this setting it is natural to consider sets of Dirichlet processes, one for each group, where the well-known clustering property of the Dirichlet process provides a nonparametric prior for the number of mixture components within each group. Given our desire to tie the mixture models in the various groups, we consider a hierarchical model, specifically one in which the base measure for the child Dirichlet processes is itself distributed according to a Dirichlet process. Such a base measure being discrete, the child Dirichlet processes necessarily share atoms. Thus, as desired, the mixture models in the different groups necessarily share mixture components. We discuss representations of hierarchical Dirichlet processes ...',\n",
              "  'authors': ['Yee Whye Teh ',\n",
              "   ' Michael I. Jordan ',\n",
              "   ' Matthew J. Beal ',\n",
              "   ' David M. Blei'],\n",
              "  'date': '2006',\n",
              "  'identifier': '2158266063',\n",
              "  'references': ['1880262756',\n",
              "   '2098126593',\n",
              "   '2125838338',\n",
              "   '2152664025',\n",
              "   '2110755408',\n",
              "   '2009570821',\n",
              "   '1956559956',\n",
              "   '2011832962',\n",
              "   '2890040444',\n",
              "   '2115979064'],\n",
              "  'title': 'Hierarchical Dirichlet Processes'},\n",
              " {'abstract': 'Abstract An overview of the self-organizing map algorithm, on which the papers in this issue are based, is presented in this article.',\n",
              "  'authors': ['Teuvo Kohonen'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2046079134',\n",
              "  'references': ['1545214528', '2125798790', '2606886058'],\n",
              "  'title': 'The Self-Organizing Map'},\n",
              " {'abstract': '(1969). The Senses Considered as Perceptual Systems. Studies in Art Education: Vol. 10, No. 3, pp. 63-65.',\n",
              "  'authors': ['James Jerome Gibson'],\n",
              "  'date': '1966',\n",
              "  'identifier': '2039170454',\n",
              "  'references': ['2153791616',\n",
              "   '2119859848',\n",
              "   '2620619910',\n",
              "   '2104880015',\n",
              "   '1928882148',\n",
              "   '2143131345',\n",
              "   '2109995759',\n",
              "   '2175951718',\n",
              "   '2113183384'],\n",
              "  'title': 'The senses considered as perceptual systems'},\n",
              " {'abstract': 'A 2.91-billion base pair (bp) consensus sequence of the euchromatic portion of the human genome was generated by the whole-genome shotgun sequencing method. The 14.8-billion bp DNA sequence was generated over 9 months from 27,271,853 high-quality sequence reads (5.11-fold coverage of the genome) from both ends of plasmid clones made from the DNA of five individuals. Two assembly strategies—a whole-genome assembly and a regional chromosome assembly—were used, each combining sequence data from Celera and the publicly funded genome effort. The public data were shredded into 550-bp segments to create a 2.9-fold coverage of those genome regions that had been sequenced, without including biases inherent in the cloning and assembly procedure used by the publicly funded group. This brought the effective coverage in the assemblies to eightfold, reducing the number and size of gaps in the final assembly over what would be obtained with 5.11-fold coverage. The two assembly strategies yielded very similar results that largely agree with independent mapping data. The assemblies effectively cover the euchromatic regions of the human chromosomes. More than 90% of the genome is in scaffold assemblies of 100,000 bp or more, and 25% of the genome is in scaffolds of 10 million bp or larger. Analysis of the genome sequence revealed 26,588 protein-encoding transcripts for which there was strong corroborating evidence and an additional ∼12,000 computationally derived genes with mouse matches or other weak supporting evidence. Although gene-dense clusters are obvious, almost half the genes are dispersed in low G+C sequence separated by large tracts of apparently noncoding sequence. Only 1.1% of the genome is spanned by exons, whereas 24% is in introns, with 75% of the genome being intergenic DNA. Duplications of segmental blocks, ranging in size up to chromosomal lengths, are abundant throughout the genome and reveal a complex evolutionary history. Comparative genomic analysis indicates vertebrate expansions of genes associated with neuronal function, with tissue-specific developmental regulation, and with the hemostasis and immune systems. DNA sequence comparisons between the consensus sequence and publicly funded genome data provided locations of 2.1 million single-nucleotide polymorphisms (SNPs). A random pair of human haploid genomes differed at a rate of 1 bp per 1250 on average, but there was marked heterogeneity in the level of polymorphism across the genome. Less than 1% of all SNPs resulted in variation in proteins, but the task of determining which SNPs have functional consequences remains an open challenge.',\n",
              "  'authors': ['J. Craig Venter ',\n",
              "   ' Mark D. Adams ',\n",
              "   ' Eugene W. Myers ',\n",
              "   ' Peter W. Li ',\n",
              "   ' Richard J. Mural ',\n",
              "   ' Granger G. Sutton ',\n",
              "   ' Hamilton O. Smith ',\n",
              "   ' Mark Yandell ',\n",
              "   ' Cheryl A. Evans ',\n",
              "   ' Robert A. Holt ',\n",
              "   ' Jeannine D. Gocayne ',\n",
              "   ' Peter Amanatides ',\n",
              "   ' Richard M. Ballew ',\n",
              "   ' Daniel H. Huson ',\n",
              "   ' Jennifer Russo Wortman ',\n",
              "   ' Qing Zhang ',\n",
              "   ' Chinnappa D. Kodira ',\n",
              "   ' Xiangqun H. Zheng ',\n",
              "   ' Lin Chen ',\n",
              "   ' Marian Skupski ',\n",
              "   ' Gangadharan Subramanian ',\n",
              "   ' Paul D. Thomas ',\n",
              "   ' Jinghui Zhang ',\n",
              "   ' George L. Gabor Miklos ',\n",
              "   ' Catherine Nelson ',\n",
              "   ' Samuel Broder ',\n",
              "   ' Andrew G. Clark ',\n",
              "   ' Joe Nadeau ',\n",
              "   ' Victor A. McKusick ',\n",
              "   ' Norton Zinder ',\n",
              "   ' Arnold J. Levine ',\n",
              "   ' Richard J. Roberts ',\n",
              "   ' Mel Simon ',\n",
              "   ' Carolyn Slayman ',\n",
              "   ' Michael Hunkapiller ',\n",
              "   ' Randall Bolanos ',\n",
              "   ' Arthur Delcher ',\n",
              "   ' Ian Dew ',\n",
              "   ' Daniel Fasulo ',\n",
              "   ' Michael Flanigan ',\n",
              "   ' Liliana Florea ',\n",
              "   ' Aaron Halpern ',\n",
              "   ' Sridhar Hannenhalli ',\n",
              "   ' Saul Kravitz ',\n",
              "   ' Samuel Levy ',\n",
              "   ' Clark Mobarry ',\n",
              "   ' Knut Reinert ',\n",
              "   ' Karin Remington ',\n",
              "   ' Jane Abu-Threideh ',\n",
              "   ' Ellen Beasley +223'],\n",
              "  'date': '2015',\n",
              "  'identifier': '2165460636',\n",
              "  'references': ['2144634347',\n",
              "   '2165460636',\n",
              "   '2141652419',\n",
              "   '1971403296',\n",
              "   '1984248485',\n",
              "   '2094448442',\n",
              "   '2062594085',\n",
              "   '1487324552',\n",
              "   '2044405977'],\n",
              "  'title': 'The Sequence of the Human Genome'},\n",
              " {'abstract': \"This study is a part of a research effort to develop the Questionnaire for User Interface Satisfaction (QUIS). Participants, 150 PC user group members, rated familiar software products. Two pairs of software categories were compared: 1) software that was liked and disliked, and 2) a standard command line system (CLS) and a menu driven application (MDA). The reliability of the questionnaire was high, Cronbach's alpha=.94. The overall reaction ratings yielded significantly higher ratings for liked software and MDA over disliked software and a CLS, respectively. Frequent and sophisticated PC users rated MDA more satisfying, powerful and flexible than CLS. Future applications of the QUIS on computers are discussed.\",\n",
              "  'authors': ['John P. Chin ', ' Virginia A. Diehl ', ' Kent L. Norman'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2037057633',\n",
              "  'references': ['2158685692',\n",
              "   '3124865537',\n",
              "   '2096878712',\n",
              "   '2011976980',\n",
              "   '1978794113',\n",
              "   '2049968466',\n",
              "   '2080039484',\n",
              "   '2145173373'],\n",
              "  'title': 'Development of an instrument measuring user satisfaction of the human-computer interface'},\n",
              " {'abstract': '',\n",
              "  'authors': ['A. Asuncion'],\n",
              "  'date': '2007',\n",
              "  'identifier': '3120740533',\n",
              "  'references': ['2146502635',\n",
              "   '2963399829',\n",
              "   '3100515187',\n",
              "   '2963977107',\n",
              "   '2106525823',\n",
              "   '2786672974',\n",
              "   '2099419573',\n",
              "   '2170505850',\n",
              "   '2962790689'],\n",
              "  'title': 'UCI Machine Learning Repository'},\n",
              " {'abstract': \"The slant of a stereoscopically defined surface cannot be determined solely from horizontal disparities or from derived quantities such as horizontal size ratio (HSR). There are four other signals that, in combination with horizontal disparity, could in principle allow an unambiguous estimate of slant: the vergence and version of the eyes, the vertical size ratio (VSR), and the horizontal gradient of VSR. Another useful signal is provided by perspective slant cues. The determination of perceived slant can be modeled as a weighted combination of three estimates based on those signals: a perspective estimate, a stereoscopic estimate based on HSR and VSR, and a stereoscopic estimate based on HSR and sensed eye position. In a series of experiments, we examined human observers' use of the two stereoscopic means of estimation. Perspective cues were rendered uninformative. We found that VSR and sensed eye position are both used to interpret the measured horizontal disparities. When the two are placed in conflict, the visual system usually gives more weight to VSR. However, when VSR is made difficult to measure by using short stimuli or stimuli composed of vertical lines, the visual system relies on sensed eye position. A model in which the observer's slant estimate is a weighted average of the slant estimate based on HSR and VSR and the one based on HSR and eye position accounted well for the data. The weights varied across viewing conditions because the informativeness of the signals they employ vary from one situation to another.\",\n",
              "  'authors': ['Benjamin T. Backus 1',\n",
              "   ' Martin S. Banks 1',\n",
              "   ' Raymond van Ee 1',\n",
              "   ' James A. Crowell 2'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2156387357',\n",
              "  'references': ['1571144263',\n",
              "   '1540682689',\n",
              "   '2164182318',\n",
              "   '1989701469',\n",
              "   '1979525364',\n",
              "   '2000735908',\n",
              "   '3080590132',\n",
              "   '2035571299',\n",
              "   '2041528325',\n",
              "   '2034423008'],\n",
              "  'title': 'Horizontal and vertical disparity, eye position, and stereoscopic slant perception'},\n",
              " {'abstract': 'We present a simple, but surprisingly effective, method of self-training a two-phase parser-reranker system using readily available unlabeled data. We show that this type of bootstrapping is possible for parsing when the bootstrapped parses are processed by a discriminative reranker. Our improved model achieves an f-score of 92.1%, an absolute 1.1% improvement (12% error reduction) over the previous best result for Wall Street Journal parsing. Finally, we provide some analysis to better understand the phenomenon.',\n",
              "  'authors': ['David McClosky ', ' Eugene Charniak ', ' Mark Johnson'],\n",
              "  'date': '2006',\n",
              "  'identifier': '2163568299',\n",
              "  'references': ['1632114991',\n",
              "   '2048679005',\n",
              "   '1535015163',\n",
              "   '2158195707',\n",
              "   '3021452258',\n",
              "   '1567570606',\n",
              "   '2125712079',\n",
              "   '2729906263',\n",
              "   '2098379588',\n",
              "   '1859173823'],\n",
              "  'title': 'Effective Self-Training for Parsing'},\n",
              " {'abstract': 'Time-series, cross-sectional, and prospective cohort studies have observed associations between mortality and particulate air pollution but have been limited by ecologic design or small number of subjects or study areas. The present study evaluates effects of particulate air pollution on mortality using data from a large cohort drawn from many study areas. We linked ambient air pollution data from 151 U.S. metropolitan areas in 1980 with individual risk factor on 552,138 adults who resided in these areas when enrolled in a prospective study in 1982. Deaths were ascertained through December, 1989. Exposure to sulfate and fine particulate air pollution, which is primarily from fossil fuel combustion, was estimated from national data bases. The relationships of air pollution to all-cause, lung cancer, and cardiopulmonary mortality was examined using multivariate analysis which controlled for smoking, education, and other risk factors. Although small compared with cigarette smoking, an association between mor...',\n",
              "  'authors': ['C A Pope ',\n",
              "   ' M J Thun ',\n",
              "   ' M M Namboodiri ',\n",
              "   ' D W Dockery ',\n",
              "   ' J S Evans ',\n",
              "   ' F E Speizer ',\n",
              "   ' C W Heath'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2146137933',\n",
              "  'references': ['2318698569',\n",
              "   '2113912428',\n",
              "   '2045258300',\n",
              "   '2330709704',\n",
              "   '1977426512',\n",
              "   '2031451281',\n",
              "   '1976557884',\n",
              "   '1925921352',\n",
              "   '2022179128',\n",
              "   '2093161332'],\n",
              "  'title': 'Particulate air pollution as a predictor of mortality in a prospective study of U.S. adults.'},\n",
              " {'abstract': 'In a number of applications of image processing, much information about objects or textures in the image can be obtained by sequential analysis of individual scan lines.',\n",
              "  'authors': ['Ehrich ', ' Foith'],\n",
              "  'date': '1976',\n",
              "  'identifier': '2117900366',\n",
              "  'references': ['2044465660',\n",
              "   '2043735243',\n",
              "   '2031435600',\n",
              "   '1970144710',\n",
              "   '2056918046',\n",
              "   '1498289939',\n",
              "   '2141794434',\n",
              "   '2004350592',\n",
              "   '129965471',\n",
              "   '1507502112'],\n",
              "  'title': 'Representation of Random Waveforms by Relational Trees'},\n",
              " {'abstract': 'We present an automatic subpixel registration algorithm that minimizes the mean square intensity difference between a reference and a test data set, which can be either images (two-dimensional) or volumes (three-dimensional). It uses an explicit spline representation of the images in conjunction with spline processing, and is based on a coarse-to-fine iterative strategy (pyramid approach). The minimization is performed according to a new variation (ML*) of the Marquardt-Levenberg algorithm for nonlinear least-square optimization. The geometric deformation model is a global three-dimensional (3-D) affine transformation that can be optionally restricted to rigid-body motion (rotation and translation), combined with isometric scaling. It also includes an optional adjustment of image contrast differences. We obtain excellent results for the registration of intramodality positron emission tomography (PET) and functional magnetic resonance imaging (fMRI) data. We conclude that the multiresolution refinement strategy is more robust than a comparable single-stage method, being less likely to be trapped into a false local optimum. In addition, our improved version of the Marquardt-Levenberg algorithm is faster.',\n",
              "  'authors': ['P. Thevenaz ', ' U.E. Ruttimann ', ' M. Unser'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2131938193',\n",
              "  'references': ['2341283081',\n",
              "   '2049981393',\n",
              "   '1874027545',\n",
              "   '1963623641',\n",
              "   '2063549868',\n",
              "   '1990005524',\n",
              "   '2087380704',\n",
              "   '2986444355',\n",
              "   '1883517952',\n",
              "   '2138943050'],\n",
              "  'title': 'A pyramid approach to subpixel registration based on intensity'},\n",
              " {'abstract': 'Massachusetts Institute of Technology. Dept. of Electrical Engineering. Thesis. 1970. Ph.D.',\n",
              "  'authors': ['Patrick H. Winston'],\n",
              "  'date': '1970',\n",
              "  'identifier': '1488252886',\n",
              "  'references': ['2116064496',\n",
              "   '2149706766',\n",
              "   '2885825670',\n",
              "   '2040884411',\n",
              "   '2156406284',\n",
              "   '1526441817',\n",
              "   '2073308541',\n",
              "   '1999138184',\n",
              "   '2141312052'],\n",
              "  'title': 'Learning Structural Descriptions From Examples'},\n",
              " {'abstract': 'Methods are described for the isolation, complementation and mapping of mutants of Caenorhabditis elegans, a small free-living nematode worm. About 300 EMS-induced mutants affecting behavior and morphology have been characterized and about one hundred genes have been defined. Mutations in 77 of these alter the movement of the animal. Estimates of the induced mutation frequency of both the visible mutants and X chromosome lethals suggests that, just as in Drosophila, the genetic units in C. elegans are large.',\n",
              "  'authors': ['S Brenner'],\n",
              "  'date': '1974',\n",
              "  'identifier': '1944127002',\n",
              "  'references': ['2115708583', '314047257', '2018868264'],\n",
              "  'title': 'THE GENETICS OF CAENORHABDITIS ELEGANS'},\n",
              " {'abstract': \"This book is based on the author's experience with calculations involving polynomial splines. It presents those parts of the theory which are especially useful in calculations and stresses the representation of splines as linear combinations of B-splines. After two chapters summarizing polynomial approximation, a rigorous discussion of elementary spline theory is given involving linear, cubic and parabolic splines. The computational handling of piecewise polynomial functions (of one variable) of arbitrary order is the subject of chapters VII and VIII, while chapters IX, X, and XI are devoted to B-splines. The distances from splines with fixed and with variable knots is discussed in chapter XII. The remaining five chapters concern specific approximation methods, interpolation, smoothing and least-squares approximation, the solution of an ordinary differential equation by collocation, curve fitting, and surface fitting. The present text version differs from the original in several respects. The book is now typeset (in plain TeX), the Fortran programs now make use of Fortran 77 features. The figures have been redrawn with the aid of Matlab, various errors have been corrected, and many more formal statements have been provided with proofs. Further, all formal statements and equations have been numbered by the same numbering system, to make it easier to find any particular item. A major change has occured in Chapters IX-XI where the B-spline theory is now developed directly from the recurrence relations without recourse to divided differences. This has brought in knot insertion as a powerful tool for providing simple proofs concerning the shape-preserving properties of the B-spline series.\",\n",
              "  'authors': ['Carl R. de Boor'],\n",
              "  'date': '1978',\n",
              "  'identifier': '2162870748',\n",
              "  'references': ['2049981393',\n",
              "   '2102201073',\n",
              "   '2006262236',\n",
              "   '2964010366',\n",
              "   '2080922987',\n",
              "   '2003410902',\n",
              "   '2162218551',\n",
              "   '2154065358',\n",
              "   '1990420052',\n",
              "   '2032377318'],\n",
              "  'title': 'A practical guide to splines'},\n",
              " {'abstract': 'We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by: (1) solving for correspondences between points on the two shapes; (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. The dissimilarity between the two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework as the problem of finding the stored prototype shape that is maximally similar to that in the image. Results are presented for silhouettes, trademarks, handwritten digits, and the COIL data set.',\n",
              "  'authors': ['S. Belongie 1', ' J. Malik 2', ' J. Puzicha 3'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2057175746',\n",
              "  'references': ['2310919327',\n",
              "   '2124386111',\n",
              "   '2119821739',\n",
              "   '2138451337',\n",
              "   '2117812871',\n",
              "   '2038952578',\n",
              "   '2124087378',\n",
              "   '2123977795',\n",
              "   '2101522199',\n",
              "   '2146766088'],\n",
              "  'title': 'Shape matching and object recognition using shape contexts'},\n",
              " {'abstract': \"“Pure” SETL is a language of very high level allowing algorithms to be programmed rapidly and succintly. SETL's representation sublanguage adds a system of declarations which allow the user of the language to control the data structures that will be used to implement an algorithm which has already been written in pure SETL, so as to improve its efficiency. Ideally no rewriting of the algorithm should be necessary. The facilities provided by the representation sublanguage and the run-time data structures that it can generate are described; based on this a heuristic which uses some of the methods of global program analysis and which should be capable of selecting an acceptably efficient representation automatically is given.\",\n",
              "  'authors': ['Robert B. K. Dewar 1',\n",
              "   ' Arthur Grand 1',\n",
              "   ' Ssu-Cheng Liu 1',\n",
              "   ' Jacob T. Schwartz 1',\n",
              "   ' Edmond Schonberg 2'],\n",
              "  'date': '1979',\n",
              "  'identifier': '2040073555',\n",
              "  'references': ['1655990431',\n",
              "   '110734221',\n",
              "   '2109647823',\n",
              "   '1606724894',\n",
              "   '1559460776',\n",
              "   '2330123543',\n",
              "   '2012413264',\n",
              "   '2089901765',\n",
              "   '1554731703',\n",
              "   '2022941785'],\n",
              "  'title': 'Programming by Refinement, as Exemplified by the SETL Representation Sublanguage'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Alexey Kurakin ', ' Ian J. Goodfellow ', ' Samy Bengio'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2963542245',\n",
              "  'references': ['2964308564'],\n",
              "  'title': 'Adversarial examples in the physical world'},\n",
              " {'abstract': 'Support vector machines (SVMs) with the gaussian (RBF) kernel have been popular for practical use. Model selection in this class of SVMs involves two hyperparameters: the penalty parameter C and the kernel width σ. This letter analyzes the behavior of the SVM classifier when these hyperparameters take very small or very large values. Our results help in understanding the hyperparameter space that leads to an efficient heuristic method of searching for hyperparameter values with small generalization errors. The analysis also indicates that if complete model selection using the gaussian kernel has been conducted, there is no need to consider linear SVM.',\n",
              "  'authors': ['S. Sathiya Keerthi 1', ' Chih-Jen Lin 2'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2118286367',\n",
              "  'references': ['2153635508',\n",
              "   '2148603752',\n",
              "   '1512098439',\n",
              "   '1604938182',\n",
              "   '2982720039',\n",
              "   '2036350498',\n",
              "   '1539150806',\n",
              "   '2113584252',\n",
              "   '2039402388',\n",
              "   '2099129687'],\n",
              "  'title': 'Asymptotic behaviors of support vector machines with Gaussian kernel'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Waloddi Weibull'],\n",
              "  'date': '1951',\n",
              "  'identifier': '2727420541',\n",
              "  'references': ['592060461'],\n",
              "  'title': 'A Statistical Distribution Function of Wide Applicability'},\n",
              " {'abstract': 'Clustering is the division of data into groups of similar objects. In clustering, some details are disregarded in exchange for data simplification. Clustering can be viewed as a data modeling technique that provides for concise summaries of the data. Clustering is therefore related to many disciplines and plays an important role in a broad range of applications. The applications of clustering usually deal with large datasets and data with many attributes. Exploration of such data is a subject of data mining. This survey concentrates on clustering algorithms from a data mining perspective.',\n",
              "  'authors': ['Pavel Berkhin'],\n",
              "  'date': '2006',\n",
              "  'identifier': '1501500081',\n",
              "  'references': ['2140190241',\n",
              "   '2148694408',\n",
              "   '1639032689',\n",
              "   '2099111195',\n",
              "   '1679913846',\n",
              "   '1992419399',\n",
              "   '1673310716',\n",
              "   '2165874743',\n",
              "   '2156718197',\n",
              "   '2049633694'],\n",
              "  'title': 'A Survey of Clustering Data Mining Techniques'},\n",
              " {'abstract': \"Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.\",\n",
              "  'authors': ['William L. Hamilton ', ' Rex Ying ', ' Jure Leskovec'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2624431344',\n",
              "  'references': ['2964121744',\n",
              "   '2153579005',\n",
              "   '2101234009',\n",
              "   '2112090702',\n",
              "   '2064675550',\n",
              "   '2130410032',\n",
              "   '2302255633',\n",
              "   '2271840356',\n",
              "   '2962756421',\n",
              "   '2560609797'],\n",
              "  'title': 'Inductive Representation Learning on Large Graphs'},\n",
              " {'abstract': 'An efficient node-deletion algorithm is introduced to find submatrices in expression data that have low mean squared residue scores and it is shown to perform well in finding co-regulation patterns in yeast and human. This introduces \"biclustering’, or simultaneous clustering of both genes and conditions, to knowledge discovery from expression data. This approach overcomes some problems associated with traditional clustering methods, by allowing automatic discovery of similarity based on a subset of attributes, simultaneous clustering of genes and conditions, and overlapped grouping that provides a better representation for genes with multiple functions or regulated by many factors.',\n",
              "  'authors': ['Yizong Cheng ', ' George M. Church'],\n",
              "  'date': '2000',\n",
              "  'identifier': '1493217831',\n",
              "  'references': ['2147246240',\n",
              "   '2135000328',\n",
              "   '2142460132',\n",
              "   '2002252750',\n",
              "   '2148602507',\n",
              "   '2037744768',\n",
              "   '2148043549',\n",
              "   '2054774141',\n",
              "   '2065183358',\n",
              "   '2036328877'],\n",
              "  'title': 'Biclustering of Expression Data'},\n",
              " {'abstract': 'Full genome sequences are increasingly used to track the geographic spread and transmission dynamics of viral pathogens. Here, with a focus on Israel, we sequence 212 SARS-CoV-2 sequences and use them to perform a comprehensive analysis to trace the origins and spread of the virus. We find that travelers returning from the United States of America significantly contributed to viral spread in Israel, more than their proportion in incoming infected travelers. Using phylodynamic analysis, we estimate that the basic reproduction number of the virus was initially around 2.5, dropping by more than two-thirds following the implementation of social distancing measures. We further report high levels of transmission heterogeneity in SARS-CoV-2 spread, with between 2-10% of infected individuals resulting in 80% of secondary infections. Overall, our findings demonstrate the effectiveness of social distancing measures for reducing viral spread.',\n",
              "  'authors': ['Danielle Miller 1',\n",
              "   ' Michael A Martin 2',\n",
              "   ' Noam Harel 1',\n",
              "   ' Omer Tirosh 1',\n",
              "   ' Talia Kustin 1',\n",
              "   ' Moran Meir 1',\n",
              "   ' Nadav Sorek 3',\n",
              "   ' Shiraz Gefen-Halevi 4',\n",
              "   ' Sharon Amit 4',\n",
              "   ' Olesya Vorontsov 5',\n",
              "   ' Avraham Shaag 5',\n",
              "   ' Dana Wolf 5',\n",
              "   ' Avi Peretz 6',\n",
              "   ' Yonat Shemer-Avni 7',\n",
              "   ' Diana Roif-Kaminsky 8',\n",
              "   ' Naama M Kopelman 9',\n",
              "   ' Amit Huppert 4',\n",
              "   ' Katia Koelle 2',\n",
              "   ' Adi Stern 1'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3096084589',\n",
              "  'references': ['3001118548',\n",
              "   '3001897055',\n",
              "   '3004280078',\n",
              "   '2158714788',\n",
              "   '2011301426',\n",
              "   '3015571324',\n",
              "   '3015988827',\n",
              "   '3003257820',\n",
              "   '3020184843',\n",
              "   '3013188135'],\n",
              "  'title': 'Full genome viral sequences inform patterns of SARS-CoV-2 spread into and within Israel.'},\n",
              " {'abstract': 'An algorithm for matching images of real world scenes is presented. The matching is a specification of the geometrical disparity between the images and may be used to partially reconstruct the three-dimensional structure of the scene. Sets of candidate matching points are selected independently in each image. These points are the locations of small, distinct features which are likely to be detectable in both images. An initial network of possible matches between the two sets of candidates is constructed. Each possible match specifies a possible disparity of a candidate point in a selected reference image. An initial estimate of the probability of each possible disparity is made, based on the similarity of subimages surrounding the points. These estimates are iteratively improved by a relaxation labeling technique making use of the local continuity property of disparity that is a consequence of the continuity of real world surfaces. The algorithm is effective for binocular parallax, motion parallax, and object motion. It quickly converges to good estimates of disparity, which reflect the spatial organization of the scene.',\n",
              "  'authors': ['Stephen T. Barnard ', ' William B. Thompson'],\n",
              "  'date': '1980',\n",
              "  'identifier': '2136113379',\n",
              "  'references': ['2164934677',\n",
              "   '1979622972',\n",
              "   '2048330959',\n",
              "   '2163009106',\n",
              "   '2115084764',\n",
              "   '1997494543',\n",
              "   '2103584248',\n",
              "   '2090638869',\n",
              "   '204039786',\n",
              "   '2093033724'],\n",
              "  'title': 'Disparity Analysis of Images'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Caroline Buckee'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3012538234',\n",
              "  'references': ['3027518954',\n",
              "   '2068163455',\n",
              "   '2747968860',\n",
              "   '2905179958',\n",
              "   '2061848003',\n",
              "   '2604976044',\n",
              "   '2971924659',\n",
              "   '1986321739',\n",
              "   '2970434820',\n",
              "   '2794252651'],\n",
              "  'title': 'Improving epidemic surveillance and response: big data is dead, long live big data'},\n",
              " {'abstract': 'This paper presents a general trainable framework for object detection in static images of cluttered scenes. The detection technique we develop is based on a wavelet representation of an object class derived from a statistical analysis of the class instances. By learning an object class in terms of a subset of an overcomplete dictionary of wavelet basis functions, we derive a compact representation of an object class which is used as an input to a support vector machine classifier. This representation overcomes both the problem of in-class variability and provides a low false detection rate in unconstrained environments. We demonstrate the capabilities of the technique in two domains whose inherent information content differs significantly. The first system is face detection and the second is the domain of people which, in contrast to faces, vary greatly in color, texture, and patterns. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or motion-based segmentation. The paper also presents a motion-based extension to enhance the performance of the detection algorithm over video sequences. The results presented here suggest that this architecture may well be quite general.',\n",
              "  'authors': ['C.P. Papageorgiou ', ' M. Oren ', ' T. Poggio'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2115763357',\n",
              "  'references': ['2132984323',\n",
              "   '2087347434',\n",
              "   '2124351082',\n",
              "   '2125848778',\n",
              "   '2104671481',\n",
              "   '2159173611',\n",
              "   '2137346077',\n",
              "   '2056695679',\n",
              "   '1676612073',\n",
              "   '2030989822'],\n",
              "  'title': 'A general framework for object detection'},\n",
              " {'abstract': \"This year, the field of neuroscience celebrates the 50th anniversary of Mountcastle's discovery of the cortical column. In this review, we summarize half a century of research and come to the disappointing realization that the column may have no function. Originally, it was described as a discrete structure, spanning the layers of the somatosensory cortex, which contains cells responsive to only a single modality, such as deep joint receptors or cutaneous receptors. Subsequently, examples of columns have been uncovered in numerous cortical areas, expanding the original concept to embrace a variety of different structures and principles. A ‘column’ now refers to cells in any vertical cluster that share the same tuning for any given receptive field attribute. In striate cortex, for example, cells with the same eye preference are grouped into ocular dominance columns. Unaccountably, ocular dominance columns are present in some species, but not others. In principle, it should be possible to determine their function by searching for species differences in visual performance that correlate with their presence or absence. Unfortunately, this approach has been to no avail; no visual faculty has emerged that appears to require ocular dominance columns. Moreover, recent evidence has shown that the expression of ocular dominance columns can be highly variable among members of the same species, or even in different portions of the visual cortex in the same individual. These observations deal a fatal blow to the idea that ocular dominance columns serve a purpose. More broadly, the term ‘column’ also denotes the periodic termination of anatomical projections within or between cortical areas. In many instances, periodic projections have a consistent relationship with some architectural feature, such as the cytochrome oxidase patches in V1 or the stripes in V2. These tissue compartments appear to divide cells with different receptive field properties into distinct processing streams. However, it is unclear what advantage, if any, is conveyed by this form of columnar segregation. Although the column is an attractive concept, it has failed as a unifying principle for understanding cortical function. Unravelling the organization of the cerebral cortex will require a painstaking description of the circuits, projections and response properties peculiar to cells in each of its various areas.\",\n",
              "  'authors': ['Jonathan C Horton 1', ' Daniel L Adams 2'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2038995818',\n",
              "  'references': ['2117940227',\n",
              "   '1963806203',\n",
              "   '2046031057',\n",
              "   '1503727145',\n",
              "   '2151718948',\n",
              "   '2103934527',\n",
              "   '2134711325',\n",
              "   '2130793535',\n",
              "   '1515334663',\n",
              "   '2132164731'],\n",
              "  'title': 'The cortical column: a structure without a function'},\n",
              " {'abstract': 'The medial temporal lobe includes a system of anatomically related structures that are essential for declarative memory (conscious memory for facts and events). The system consists of the hippocampal region (CA fields, dentate gyrus, and subicular complex) and the adjacent perirhinal, entorhinal, and parahippocampal cortices. Here, we review findings from humans, monkeys, and rodents that illuminate the function of these structures. Our analysis draws on studies of human memory impairment and animal models of memory impairment, as well as neurophysiological and neuroimaging data, to show that this system (a) is principally concerned with memory, (b) operates with neocortex to establish and maintain long-term memory, and (c) ultimately, through a process of consolidation, becomes independent of long-term memory, though questions remain about the role of perirhinal and parahippocampal cortices in this process and about spatial memory in rodents. Data from neurophysiology, neuroimaging, and neuroanatomy point to a division of labor within the medial temporal lobe. However, the available data do not support simple dichotomies between the functions of the hippocampus and the adjacent medial temporal cortex, such as associative versus nonassociative memory, episodic versus semantic memory, and recollection versus familiarity.',\n",
              "  'authors': ['Larry R. Squire 1',\n",
              "   ' Craig E. L. Stark 2',\n",
              "   ' Robert E. Clark 3'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2129789527',\n",
              "  'references': ['2319937903',\n",
              "   '2056081184',\n",
              "   '2144225695',\n",
              "   '1984214648',\n",
              "   '2047057213',\n",
              "   '1608785134',\n",
              "   '2103692957',\n",
              "   '2076425653',\n",
              "   '2064864838',\n",
              "   '2154457867'],\n",
              "  'title': 'THE MEDIAL TEMPORAL LOBE'},\n",
              " {'abstract': 'We describe a method for classifying news stories using Memory Based Reasoning (MBR) a k -nearest neighbor method), that does not require manual topic definitions. Using an already coded training database of about 50,000 stories from the Dow Jones Press Release News Wire, and SEEKER [Stanfill] (a text retrieval system that supports relevance feedback) as the underlying match engine, codes are assigned to new, unseen stories with a recall of about 80% and precision of about 70%. There are about 350 different codes to be assigned. Using a massively parallel supercomputer, we leverage the information already contained in the thousands of coded stories and are able to code a story in about 2 seconds. Given SEEKER, the text retrieval system, we achieved these results in about two person-months. We believe this approach is effective in reducing the development time to implement classification systems involving large number of topics for the purpose of classification, message routing etc.',\n",
              "  'authors': ['Brij Masand 1', ' Gordon Linoff 1', ' David Waltz 2'],\n",
              "  'date': '1992',\n",
              "  'identifier': '1993934121',\n",
              "  'references': ['1610836425',\n",
              "   '2004131797',\n",
              "   '2079690930',\n",
              "   '2019087979',\n",
              "   '2061310592',\n",
              "   '2088658068',\n",
              "   '2127994451',\n",
              "   '2004871537',\n",
              "   '2140956226',\n",
              "   '2077777431'],\n",
              "  'title': 'Classifying news stories using memory based reasoning'},\n",
              " {'abstract': 'Abstract In digital image processing, thresholding is a well-known technique for image segmentation. Because of its wide applicability to other areas of the digital image processing, quite a number of thresholding methods have been proposed over the years. In this paper, we present a survey of thresholding techniques and update the earlier survey work by Weszka (Comput. Vision Graphics & Image Process 7, 1978 , 259–265) and Fu and Mu (Pattern Recognit. 13, 1981 , 3–16). We attempt to evaluate the performance of some automatic global thresholding methods using the criterion functions such as uniformity and shape measures. The evaluation is based on some real world images.',\n",
              "  'authors': ['P. K. Sahoo ', ' S. Soltani ', ' A. K.C. Wong ', ' Y. C. Chen'],\n",
              "  'date': '1988',\n",
              "  'identifier': '1970800786',\n",
              "  'references': ['2133059825',\n",
              "   '2044465660',\n",
              "   '2083970667',\n",
              "   '2027091505',\n",
              "   '1978818813',\n",
              "   '2042342673',\n",
              "   '1530383550',\n",
              "   '2063751786',\n",
              "   '2021511865',\n",
              "   '1984153831'],\n",
              "  'title': 'A survey of thresholding techniques'},\n",
              " {'abstract': 'Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.',\n",
              "  'authors': ['Warren S. McCulloch ', ' Walter Pitts'],\n",
              "  'date': '1988',\n",
              "  'identifier': '1554576613',\n",
              "  'references': ['2582187633',\n",
              "   '616993223',\n",
              "   '2785184350',\n",
              "   '2748669035',\n",
              "   '2090556347',\n",
              "   '2402395425',\n",
              "   '2091354315',\n",
              "   '2048282940',\n",
              "   '2750384459',\n",
              "   '2944090748'],\n",
              "  'title': 'A logical calculus of the ideas immanent in nervous activity'},\n",
              " {'abstract': \"This important text and reference for researchers and students in machine learning, game theory, statistics and information theory offers a comprehensive treatment of the problem of predicting individual sequences. Unlike standard statistical approaches to forecasting, prediction of individual sequences does not impose any probabilistic assumption on the data-generating mechanism. Yet, prediction algorithms can be constructed that work well for all possible sequences, in the sense that their performance is always nearly as good as the best forecasting strategy in a given reference class. The central theme is the model of prediction using expert advice, a general framework within which many related problems can be cast and discussed. Repeated game playing, adaptive data compression, sequential investment in the stock market, sequential pattern analysis, and several other problems are viewed as instances of the experts' framework and analyzed from a common nonstochastic standpoint that often reveals new and intriguing connections.\",\n",
              "  'authors': ['Nicolo Cesa-Bianchi 1', ' Gabor Lugosi 2'],\n",
              "  'date': '2006',\n",
              "  'identifier': '1570963478',\n",
              "  'references': ['2148603752',\n",
              "   '2099111195',\n",
              "   '2119821739',\n",
              "   '1988790447',\n",
              "   '3023786531',\n",
              "   '2137813581',\n",
              "   '1510073064',\n",
              "   '2168405694',\n",
              "   '1601740268',\n",
              "   '2087347434'],\n",
              "  'title': 'Prediction, learning, and games'},\n",
              " {'abstract': 'Peer observation of classroom and clinical teaching has received increased attention over the past decade in schools of nursing to augment student ratings of teaching effectiveness. One essential ingredient is the scale used to evaluate performance. A five-step systematic procedure for adapting, writing, and building any peer observation scale is described. The differences between the development of a classroom observation scale and an appraisal scale to observe clinical instructors are examined. Psychometric issues peculiar to observation scales are discussed in terms of content validity, eight types of response bias, and interobserver reliability. The applications of the scales in one school of nursing as part of the triangulation of methods with student ratings and the teaching portfolio are illustrated. Copies of the scales are also provided.',\n",
              "  'authors': ['Ronald A Berk ', ' Phyllis L Naumann ', ' Susan E Appling'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2110228222',\n",
              "  'references': ['2019398887',\n",
              "   '2977419074',\n",
              "   '2317546447',\n",
              "   '3022468393',\n",
              "   '579060270',\n",
              "   '2015092539',\n",
              "   '2010149969',\n",
              "   '2022607151',\n",
              "   '2614971049',\n",
              "   '2097929748'],\n",
              "  'title': 'Beyond Student Ratings: Peer Observation of Classroom and Clinical Teaching'},\n",
              " {'abstract': 'This paper presents the current status of a new initiative aimed at developing a versatile framework and image database for empirical evaluation of texture analysis algorithms. The proposed Outex framework contains a large collection of surface textures captured under different conditions, which facilitates construction of a wide range of texture analysis problems. The problems are encapsulated into test suites, for which baseline results obtained with algorithms from literature are provided. The rich functionality of the framework is demonstrated with examples in texture classification, segmentation and retrieval. The framework has a web site for public dissemination of the database and comparative results obtained by research groups world wide.',\n",
              "  'authors': ['T. Ojala ',\n",
              "   ' T. Maenpaa ',\n",
              "   ' M. Pietikainen ',\n",
              "   ' J. Viertola ',\n",
              "   ' J. Kyllonen ',\n",
              "   ' S. Huovinen'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2159988601',\n",
              "  'references': ['2163352848',\n",
              "   '2125148312',\n",
              "   '2039051707',\n",
              "   '2098347925',\n",
              "   '2000123870',\n",
              "   '2106798282',\n",
              "   '2132047332',\n",
              "   '1993655741',\n",
              "   '2028652181',\n",
              "   '2056472112'],\n",
              "  'title': 'Outex - new framework for empirical evaluation of texture analysis algorithms'},\n",
              " {'abstract': 'We present a model for asynchronous distributed computation and then proceed to analyze the convergence of natural asynchronous distributed versions of a large class of deterministic and stochastic gradient-like algorithms. We show that such algorithms retain the desirable convergence properties of their centralized counterparts, provided that the time between consecutive interprocessor communications and the communication delays are not too large.',\n",
              "  'authors': ['J. Tsitsiklis ', ' D. Bertsekas ', ' M. Athans'],\n",
              "  'date': '1986',\n",
              "  'identifier': '2154834860',\n",
              "  'references': ['1540723801',\n",
              "   '1547358136',\n",
              "   '2125812768',\n",
              "   '2002501531',\n",
              "   '1997996213',\n",
              "   '2235056388',\n",
              "   '1978564754',\n",
              "   '2111749847',\n",
              "   '2155143729',\n",
              "   '2026154367'],\n",
              "  'title': 'Distributed asynchronous deterministic and stochastic gradient optimization algorithms'},\n",
              " {'abstract': 'The author reviews recent multichannel models developed in psychophysiology, computer vision, and image processing. In psychophysiology, multichannel models have been particularly successful in explaining some low-level processing in the visual cortex. The expansion of a function into several frequency channels provides a representation which is intermediate between a spatial and a Fourier representation. The author describes the mathematical properties of such decompositions and introduces the wavelet transform. He reviews the classical multiresolution pyramidal transforms developed in computer vision and shows how they relate to the decomposition of an image into a wavelet orthonormal basis. He discusses the properties of the zero crossings of multifrequency channels. Zero-crossing representations are particularly well adapted for pattern recognition in computer vision. >',\n",
              "  'authors': ['S.G. Mallat'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2166982406',\n",
              "  'references': ['2132984323',\n",
              "   '2098914003',\n",
              "   '2103504761',\n",
              "   '2109863423',\n",
              "   '2003370853',\n",
              "   '1980149518',\n",
              "   '2096684483',\n",
              "   '2022735534',\n",
              "   '1995756857',\n",
              "   '2139797453'],\n",
              "  'title': 'Multifrequency channel decompositions of images and wavelet models'},\n",
              " {'abstract': 'A new recurrent neural network based language model (RNN LM) with applications to speech recognition is presented. Results indicate that it is possible to obtain around 50% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model. Speech recognition experiments show around 18% reduction of word error rate on the Wall Street Journal task when comparing models trained on the same amount of data, and around 5% on the much harder NIST RT05 task, even when the backoff model is trained on much more data than the RNN LM. We provide ample empirical evidence to suggest that connectionist language models are superior to standard n-gram techniques, except their high computational (training) complexity. Index Terms: language modeling, recurrent neural networks, speech recognition',\n",
              "  'authors': ['Tomas Mikolov 1',\n",
              "   ' Martin Karafiát 1',\n",
              "   ' Lukás Burget 1',\n",
              "   ' Jan Cernocký ',\n",
              "   ' Sanjeev Khudanpur 2'],\n",
              "  'date': '2010',\n",
              "  'identifier': '179875071',\n",
              "  'references': ['2132339004',\n",
              "   '2110485445',\n",
              "   '2107878631',\n",
              "   '36903255',\n",
              "   '2096072088',\n",
              "   '2468573742',\n",
              "   '2152808281',\n",
              "   '2027499299',\n",
              "   '2292896937',\n",
              "   '2437096199'],\n",
              "  'title': 'Recurrent neural network based language model'},\n",
              " {'abstract': 'An approach for genome analysis based on sequencing and assembly of unselected pieces of DNA from the whole chromosome has been applied to obtain the complete nucleotide sequence (1,830,137 base pairs) of the genome from the bacterium Haemophilus influenzae Rd. This approach eliminates the need for initial mapping efforts and is therefore applicable to the vast array of microbial species for which genome maps are unavailable. The H. influenzae Rd genome sequence (Genome Sequence DataBase accession number L42023) represents the only complete genome sequence from a free-living organism.',\n",
              "  'authors': ['Fleischmann Rd 1',\n",
              "   ' Adams 2',\n",
              "   ' White O 2',\n",
              "   ' Clayton Ra 2',\n",
              "   ' Kirkness Ef 2',\n",
              "   ' Kerlavage Ar 2',\n",
              "   ' Bult Cj 2',\n",
              "   ' Tomb Jf 3',\n",
              "   ' Dougherty Ba 3',\n",
              "   ' Merrick Jm 4'],\n",
              "  'date': '1995',\n",
              "  'identifier': '1971403296',\n",
              "  'references': ['2055043387',\n",
              "   '2015292449',\n",
              "   '1975304761',\n",
              "   '2143210482',\n",
              "   '2094448442',\n",
              "   '2081702874',\n",
              "   '2784619191',\n",
              "   '1992194142',\n",
              "   '2108141139',\n",
              "   '1966711026'],\n",
              "  'title': 'Whole-genome random sequencing and assembly of Haemophilus influenzae Rd.'},\n",
              " {'abstract': '',\n",
              "  'authors': ['David J. C. MacKay'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2911546748',\n",
              "  'references': ['1988520084',\n",
              "   '2168175751',\n",
              "   '2111051539',\n",
              "   '1531060698',\n",
              "   '2054658115',\n",
              "   '161994183',\n",
              "   '2798264002',\n",
              "   '2088538739',\n",
              "   '1965770722',\n",
              "   '2025130480'],\n",
              "  'title': 'Bayesian interpolation'},\n",
              " {'abstract': 'We analyze microblog posts generated during two recent, concurrent emergency events in North America via Twitter, a popular microblogging service. We focus on communications broadcast by people who were \"on the ground\" during the Oklahoma Grassfires of April 2009 and the Red River Floods that occurred in March and April 2009, and identify information that may contribute to enhancing situational awareness (SA). This work aims to inform next steps for extracting useful, relevant information during emergencies using information extraction (IE) techniques.',\n",
              "  'authors': ['Sarah Vieweg ',\n",
              "   ' Amanda L. Hughes ',\n",
              "   ' Kate Starbird ',\n",
              "   ' Leysia Palen'],\n",
              "  'date': '2010',\n",
              "  'identifier': '2081212507',\n",
              "  'references': ['2099556653',\n",
              "   '2046804949',\n",
              "   '2146948159',\n",
              "   '3122139608',\n",
              "   '2000200507',\n",
              "   '1997879853',\n",
              "   '2139398774',\n",
              "   '1973921702',\n",
              "   '2050237388',\n",
              "   '67050709'],\n",
              "  'title': 'Microblogging during two natural hazards events: what twitter may contribute to situational awareness'},\n",
              " {'abstract': \"1. Spatial summation within cat retinal receptive fields was studied by recording from optic-tract fibres the responses of ganglion cells to grating patterns whose luminance perpendicular to the bars varied sinusoidally about the mean level. 2. Summation over the receptive fields of some cells (X-cells) was found to be approximately linear, while for other cells (Y-cells) summation was very non-linear. 3. The mean discharge frequency of Y-cells (unlike that of X-cells) was greatly increased when grating patterns drifted across their receptive fields. 4. In twenty-one X-cells the relation between the contrast and spatial frequency of drifting sinusoidal gratings which evoked the same small response was measured. In every case it was found that the reciprocal of this relation, the contrast sensitivity function, could be satisfactorily described by the difference of two Gaussian functions. 5. This finding supports the hypothesis that the sensitivities of the antagonistic centre and surround summating regions of ganglion cell receptive fields fall off as Gaussian functions of the distance from the field centre. 6. The way in which the sensitivity of an X-cell for a contrast-edge pattern varied with the distance of the edge from the receptive field centre was determined and found to be consistent with the cell's measured contrast sensitivity function. 7. Reducing the retinal illumination produced changes in the contrast sensitivity function of an X-cell which suggested that the diameters of the summating regions of the receptive field increased while the surround region became relatively ineffective.\",\n",
              "  'authors': ['Christina Enroth-Cugell ', ' J. G. Robson'],\n",
              "  'date': '1966',\n",
              "  'identifier': '1988849438',\n",
              "  'references': ['2003370853',\n",
              "   '2131329059',\n",
              "   '1583953270',\n",
              "   '2108992228',\n",
              "   '2028470175',\n",
              "   '2046297486',\n",
              "   '2099616257',\n",
              "   '1993197592',\n",
              "   '2127137933',\n",
              "   '2044456223'],\n",
              "  'title': 'The contrast sensitivity of retinal ganglion cells of the cat.'},\n",
              " {'abstract': 'We propose a new probabilistic approach to information retrieval based upon the ideas and methods of statistical machine translation. The central ingredient in this approach is a statistical model of how a user might distill or \"translate\" a given document into a query. To assess the relevance of a document to a user\\'s query, we estimate the probability that the query would have been generated as a translation of the document, and factor in the user\\'s general preferences in the form of a prior distribution over documents. We propose a simple, well motivated model of the document-to-query translation process, and describe an algorithm for learning the parameters of this model in an unsupervised manner from a collection of documents. As we show, one can view this approach as a generalization and justification of the \"language modeling\" strategy recently proposed by Ponte and Croft. In a series of experiments on TREC data, a simple translation-based retrieval system performs well in comparison to conventional retrieval techniques. This prototype system only begins to tap the full potential of translation-based retrieval.',\n",
              "  'authors': ['Adam Berger ', ' John Lafferty'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2062270497',\n",
              "  'references': ['2049633694',\n",
              "   '2006969979',\n",
              "   '1978394996',\n",
              "   '2093390569',\n",
              "   '1482214997',\n",
              "   '2097333193',\n",
              "   '2154384676',\n",
              "   '2043909051',\n",
              "   '36244633',\n",
              "   '2030750105'],\n",
              "  'title': 'Information retrieval as statistical translation'},\n",
              " {'abstract': 'In December, 2019, a pneumonia associated with the 2019 novel coronavirus (2019-nCoV) emerged in Wuhan, China. We aimed to further clarify the epidemiological and clinical characteristics of 2019-nCoV pneumonia. In this retrospective, single-centre study, we included all confirmed cases of 2019-nCoV in Wuhan Jinyintan Hospital from Jan 1 to Jan 20, 2020. Cases were confirmed by real-time RT-PCR and were analysed for epidemiological, demographic, clinical, and radiological features and laboratory data. Outcomes were followed up until Jan 25, 2020.',\n",
              "  'authors': ['Nanshan Chen 1',\n",
              "   ' Min Zhou 2',\n",
              "   ' Xuan Dong 1',\n",
              "   ' Jieming Qu 2',\n",
              "   ' Fengyun Gong 1',\n",
              "   ' Yang Han 1',\n",
              "   ' Yang Qiu 3',\n",
              "   ' Jingli Wang 1',\n",
              "   ' Ying Liu 1',\n",
              "   ' Yuan Wei 1',\n",
              "   \" Jia'an Xia 1\",\n",
              "   ' Ting Yu 1',\n",
              "   ' Xinxin Zhang 2',\n",
              "   ' Li Zhang 1'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3002108456',\n",
              "  'references': ['3001118548',\n",
              "   '2903899730',\n",
              "   '2166867592',\n",
              "   '2999409984',\n",
              "   '2999318660',\n",
              "   '2132260239',\n",
              "   '2999364275',\n",
              "   '2991899552',\n",
              "   '2909194930',\n",
              "   '2775086803'],\n",
              "  'title': 'Epidemiological and clinical characteristics of 99 cases of 2019 novel coronavirus pneumonia in Wuhan, China: a descriptive study'},\n",
              " {'abstract': 'QUANTUM ESPRESSO is an integrated suite of computer codes for electronic-structure calculations and materials modeling, based on density-functional theory, plane waves, and pseudopotentials (norm-conserving, ultrasoft, and projector-augmented wave). The acronym ESPRESSO stands for opEn Source Package for Research in Electronic Structure, Simulation, and Optimization. It is freely available to researchers around the world under the terms of the GNU General Public License. QUANTUM ESPRESSO builds upon newly-restructured electronic-structure codes that have been developed and tested by some of the original authors of novel electronic-structure algorithms and applied in the last twenty years by some of the leading materials modeling groups worldwide. Innovation and efficiency are still its main focus, with special attention paid to massively parallel architectures, and a great effort being devoted to user friendliness. QUANTUM ESPRESSO is evolving towards a distribution of independent and interoperable codes in the spirit of an open-source project, where researchers active in the field of electronic-structure calculations are encouraged to participate in the project by contributing their own codes or by implementing their own ideas into existing codes.',\n",
              "  'authors': ['Paolo Giannozzi 1',\n",
              "   ' Stefano Baroni 2',\n",
              "   ' Nicola Bonini 3',\n",
              "   ' Matteo Calandra 4',\n",
              "   ' Roberto Car 5',\n",
              "   ' Carlo Cavazzoni 6',\n",
              "   ' Davide Ceresoli 3',\n",
              "   ' Guido L Chiarotti 7',\n",
              "   ' Matteo Cococcioni 8',\n",
              "   ' Ismaila Dabo 9',\n",
              "   ' Andrea Dal Corso 2',\n",
              "   ' Stefano de Gironcoli 2',\n",
              "   ' Stefano Fabris 2',\n",
              "   ' Guido Fratesi 10',\n",
              "   ' Ralph Gebauer 11',\n",
              "   ' Uwe Gerstmann 12',\n",
              "   ' Christos Gougoussis 4',\n",
              "   ' Anton Kokalj 13',\n",
              "   ' Michele Lazzeri 4',\n",
              "   ' Layla Martin-Samos 14',\n",
              "   ' Nicola Marzari 3',\n",
              "   ' Francesco Mauri 4',\n",
              "   ' Riccardo Mazzarello 15',\n",
              "   ' Stefano Paolini 2',\n",
              "   ' Alfredo Pasquarello 16',\n",
              "   ' Lorenzo Paulatto 2',\n",
              "   ' Carlo Sbraccia 13',\n",
              "   ' Sandro Scandolo 11',\n",
              "   ' Gabriele Sclauzero 2',\n",
              "   ' Ari P Seitsonen 4',\n",
              "   ' Alexander Smogunov 11',\n",
              "   ' Paolo Umari 14',\n",
              "   ' Renata M Wentzcovitch 17'],\n",
              "  'date': '2009',\n",
              "  'identifier': '2120145199',\n",
              "  'references': ['1979544533',\n",
              "   '2007395042',\n",
              "   '1970127494',\n",
              "   '1550061415',\n",
              "   '2029667189',\n",
              "   '2102182691',\n",
              "   '1523142422',\n",
              "   '2022950330',\n",
              "   '1998866028',\n",
              "   '2077658674'],\n",
              "  'title': 'QUANTUM ESPRESSO: a modular and open-source software project for quantum simulations of materials'},\n",
              " {'abstract': '',\n",
              "  'authors': ['D. V. Gokhale ', ' G. E. P. Box ', ' G. C. Tiao'],\n",
              "  'date': '1973',\n",
              "  'identifier': '2798264002',\n",
              "  'references': ['2038840577',\n",
              "   '2125001590',\n",
              "   '2113945798',\n",
              "   '2083875149',\n",
              "   '1582484699',\n",
              "   '1999814123',\n",
              "   '2911546748',\n",
              "   '195465510',\n",
              "   '2787827073',\n",
              "   '941378780'],\n",
              "  'title': 'Bayesian inference in statistical analysis'},\n",
              " {'abstract': '',\n",
              "  'authors': ['F W Campbell ', ' D G Green'],\n",
              "  'date': '1965',\n",
              "  'identifier': '2153782322',\n",
              "  'references': ['2035989480', '1996518889', '2444652752', '1964857244'],\n",
              "  'title': 'Optical and retinal factors affecting visual resolution.'},\n",
              " {'abstract': \"One of the surprising recurring phenomena observed in experiments with boosting is that the test error of the generated classifier usually does not increase as its size becomes very large, and often is observed to decrease even after the training error reaches zero. In this paper, we show that this phenomenon is related to the distribution of margins of the training examples with respect to the generated voting classification rule, where the margin of an example is simply the difference between the number of correct votes and the maximum number of votes received by any incorrect label. We show that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error. We also show theoretically and experimentally that boosting is especially effective at increasing the margins of the training examples. Finally, we compare our explanation to those based on the bias-variance decomposition.\",\n",
              "  'authors': ['Robert E. Schapire ',\n",
              "   ' Yoav Freund 1',\n",
              "   ' Peter Bartlett 2',\n",
              "   ' Wee Sun Lee 3'],\n",
              "  'date': '1998',\n",
              "  'identifier': '1975846642',\n",
              "  'references': ['2156909104',\n",
              "   '2119821739',\n",
              "   '1988790447',\n",
              "   '2912934387',\n",
              "   '2112076978',\n",
              "   '2087347434',\n",
              "   '1594031697',\n",
              "   '1605688901',\n",
              "   '2982720039',\n",
              "   '2032210760'],\n",
              "  'title': 'Boosting the margin: a new explanation for the effectiveness of voting methods'},\n",
              " {'abstract': 'Centra underscores the importance of active methods of teaching and the need to evaluate those methods in less traditional ways. He discusses the value and proper use of self-reports and portfolios, and examines better ways to involve colleagues in evaluating and improving teaching.',\n",
              "  'authors': ['John A. Centra'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2022607151',\n",
              "  'references': ['2125827881',\n",
              "   '2131464571',\n",
              "   '2002451608',\n",
              "   '2326479160',\n",
              "   '1573940606',\n",
              "   '1993719478',\n",
              "   '138344760',\n",
              "   '2008266299',\n",
              "   '1633607198',\n",
              "   '2253593819'],\n",
              "  'title': 'Reflective Faculty Evaluation: Enhancing Teaching and Determining Faculty Effectiveness'},\n",
              " {'abstract': 'With the increasing advances in hardware technology for data collection, and advances in software technology (databases) for data organization, computer scientists have increasingly participated in the latest advancements of the outlier analysis field. Computer scientists, specifically, approach this field based on their practical experiences in managing large amounts of data, and with far fewer assumptions the data can be of any type, structured or unstructured, and may be extremely large. Outlier Analysisis a comprehensive exposition, as understood by data mining experts, statisticians and computer scientists. The book has been organized carefully, and emphasis was placed on simplifying the content, so that students and practitioners can also benefit. Chapters will typically cover one of three areas: methods and techniques commonly used in outlier analysis, such as linear methods, proximity-based methods, subspace methods, and supervised methods; data domains, such as, text, categorical, mixed-attribute, time-series, streaming, discrete sequence, spatial and network data; and key applications of these methods as applied to diverse domains such as credit card fraud detection, intrusion detection, medical diagnosis, earth science, web log analytics, and social network analysis are covered.',\n",
              "  'authors': ['Charu C. Aggarwal'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2338990760',\n",
              "  'references': ['3120740533',\n",
              "   '2912934387',\n",
              "   '2148143831',\n",
              "   '2295428206',\n",
              "   '1647729745',\n",
              "   '2129249398',\n",
              "   '3003716168',\n",
              "   '2108556791',\n",
              "   '2296719434',\n",
              "   '2057712948'],\n",
              "  'title': 'Outlier Analysis'},\n",
              " {'abstract': 'We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals).',\n",
              "  'authors': ['R. Fergus 1', ' P. Perona 2', ' A. Zisserman 1'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2154422044',\n",
              "  'references': ['2164598857',\n",
              "   '2217896605',\n",
              "   '2049633694',\n",
              "   '2119747362',\n",
              "   '2109200236',\n",
              "   '2159686933',\n",
              "   '2155511848',\n",
              "   '1949116567',\n",
              "   '2160225842',\n",
              "   '1699734612'],\n",
              "  'title': 'Object class recognition by unsupervised scale-invariant learning'},\n",
              " {'abstract': '',\n",
              "  'authors': ['T N Wiesel ', ' D H Hubel'],\n",
              "  'date': '1966',\n",
              "  'identifier': '1829900417',\n",
              "  'references': ['1979741733',\n",
              "   '2295233784',\n",
              "   '2063640158',\n",
              "   '2153017955',\n",
              "   '1964180894',\n",
              "   '1993644779',\n",
              "   '2008605035',\n",
              "   '2097462803',\n",
              "   '2142768220',\n",
              "   '2090060263'],\n",
              "  'title': 'Spatial and chromatic interactions in the lateral geniculate body of the rhesus monkey.'},\n",
              " {'abstract': 'Two identical top halves of a face are perceived as being different when their bottom halves belong to different faces, showing that the parts of a face cannot be perceived independently from the whole face. When this visual illusion is inserted in a matching task, observers make more mistakes and/or are slower at matching identical top face halves aligned with different bottom halves than when the bottom halves are spatially offset: The composite face effect. This composite face paradigm has been used in more than 60 studies that have provided information about the specificity and nature of perceptual integration between facial parts (“holistic face perception”), the impairment of this process in acquired prosopagnosia, its developmental course, temporal dynamics, and neural basis. Following a review of the main contributions made with the paradigm, I explain its rationale and strengths, and discuss its methodological parameters, making a number of proposals for its optimal use and refinement in order to improve our understanding of holistic face perception. Finally, I explain how this standard composite face paradigm is fundamentally different than the application to facial parts of a congruency/interference paradigm that has a long tradition in experimental psychology since Stroop (1935), and which was originally developed to measure attentional and response interference between different representations rather than perceptual integration. Moreover, a version of this congruency/interference paradigm used extensively over the past years with composite faces lacks a baseline measure and has decisional, attentional, and stimulus confounds, making the findings of these studies impossible to interpret in terms of holistic perception. I conclude by encouraging researchers in this field to concentrate fully on the standard composite face paradigm, gaze contingency, and other behavioural measures that can help us take one of the most important challenges of visual perception research: Understanding the neural mechanisms of holistic face perception.',\n",
              "  'authors': ['Bruno Rossion'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2151152593',\n",
              "  'references': ['2138451337',\n",
              "   '2013112874',\n",
              "   '2120357670',\n",
              "   '2123341385',\n",
              "   '1536620489',\n",
              "   '2054802006',\n",
              "   '2101790396',\n",
              "   '2156406284',\n",
              "   '2113820953',\n",
              "   '2054530400'],\n",
              "  'title': 'The composite face illusion: A whole window into our understanding of holistic face perception'},\n",
              " {'abstract': '',\n",
              "  'authors': ['M. G. Kendall ', ' A. Stuart'],\n",
              "  'date': '1963',\n",
              "  'identifier': '2777019853',\n",
              "  'references': ['2082928585',\n",
              "   '1528905581',\n",
              "   '2161163382',\n",
              "   '2064978316',\n",
              "   '2067174909',\n",
              "   '2101846955',\n",
              "   '3125696988',\n",
              "   '2146871184',\n",
              "   '1986528915'],\n",
              "  'title': 'The Advanced Theory of Statistics'},\n",
              " {'abstract': 'Abstract This paper presents an edge-based smoothed finite element method (ES-FEM) to significantly improve the accuracy of the finite element method (FEM) without much changing to the standard FEM settings. The ES-FEM can use different shape of elements but prefers triangular elements that can be much easily generated automatically for complicated domains. In the ES-FEM, the system stiffness matrix is computed using strains smoothed over the smoothing domains associated with the edges of the triangles. Intensive numerical results demonstrated that the ES-FEM possesses the following excellent properties: (1) the ES-FEM model possesses a close-to-exact stiffness: it is much softer than the “overly-stiff” FEM and much stiffer than the “overly-soft” NS-FEM model; (2) the results are often found superconvergence and ultra-accurate: much more accurate than the linear triangular elements of FEM and even more accurate than those of the FEM using quadrilateral elements with the same sets of nodes; (3) there are no spurious non-zeros energy modes found and hence the method is also temporally stable and works well for vibration analysis and (4) the implementation of the method is straightforward and no penalty parameter is used, and the computational efficiency is better than the FEM using the same sets of nodes. In addition, a novel domain-based selective scheme is proposed leading to a combined ES/NS-FEM model that is immune from volumetric locking and hence works very well for nearly incompressible materials. These properties of the ES-FEM are confirmed using examples of static, free and forced vibration analyses of solids.',\n",
              "  'authors': ['G.R. Liu 1', ' 2', ' T. Nguyen-Thoi 2', ' K.Y. Lam 3'],\n",
              "  'date': '2009',\n",
              "  'identifier': '1966753479',\n",
              "  'references': ['2109911863',\n",
              "   '1573186872',\n",
              "   '1591608973',\n",
              "   '1517038794',\n",
              "   '2490615762',\n",
              "   '2074134204',\n",
              "   '2139933850',\n",
              "   '2017805808',\n",
              "   '2111521743',\n",
              "   '2114605149'],\n",
              "  'title': 'An edge-based smoothed finite element method (ES-FEM) for static, free and forced vibration analyses of solids'},\n",
              " {'abstract': 'The primate retina contains three classes of cones, the L, M and S cones, which respond preferentially to long-, middle- and short-wavelength visible light, respectively. Colour appearance results from neural processing of these cone signals within the retina and the brain. Perceptual experiments have identified three types of neural pathways that represent colour: a red–green pathway that signals differences between L- and M-cone responses; a blue–yellow pathway that signals differences between S-cone responses and a sum of L- and M-cone responses; and a luminance pathway that signals a sum of L- and M-cone responses1,2,3. It might be expected that there are neurons in the primary visual cortex with response properties that resemble these three perceptual pathways, but attempts to find them have led to inconsistent results4,5,6,7. We have therefore used functional magnetic resonance imaging (fMRI) to examine responses in the human brain to a large number of colours. In visual cortical areas V1 and V2, the strongest response is to red–green stimuli, and much of this activity is from neurons receiving opposing inputs from L and M cones. A strong response is also seen with blue–yellow stimuli, and this response declines rapidly as the temporal frequency of the stimulus is increased. These responses resemble psychophysical measurements, suggesting that colour signals relevant for perception are encoded in a large population of neurons in areas V1 and V2.',\n",
              "  'authors': ['Stephen A Engel 1',\n",
              "   ' 2',\n",
              "   ' Xuemei Zhang 1',\n",
              "   ' Brian Wandell 1'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2142768220',\n",
              "  'references': ['2093793583',\n",
              "   '2141964005',\n",
              "   '2142245130',\n",
              "   '2037926997',\n",
              "   '2132873551',\n",
              "   '1982447763',\n",
              "   '2166278041',\n",
              "   '2044558395',\n",
              "   '2123390288',\n",
              "   '2112709532'],\n",
              "  'title': 'Colour tuning in human visual cortex measured with functional magnetic resonance imaging.'},\n",
              " {'abstract': 'How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched.',\n",
              "  'authors': ['Thomas K. Landauer ', ' Susan T. Dumais'],\n",
              "  'date': '1997',\n",
              "  'identifier': '1983578042',\n",
              "  'references': ['2147152072',\n",
              "   '2293063825',\n",
              "   '1898014694',\n",
              "   '1593045043',\n",
              "   '2001467963',\n",
              "   '1540136915',\n",
              "   '2059975159',\n",
              "   '2152632951',\n",
              "   '2163953154',\n",
              "   '1594369375'],\n",
              "  'title': \"A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.\"},\n",
              " {'abstract': 'This article develops methods for determining visually appealing motion transitions using linear blending. Motion transitions are segues between two sequences of animation, and are important components for generating compelling animation streams in virtual environments and computer games. Methods involving linear blending are studied because of their efficiency, computational speed, and widespread use. Two methods of transition specification are detailed, center-aligned and start-end transitions. First, we compute a set of optimal weights for an underlying cost metric used to determine the transition points. We then evaluate the optimally weighted cost metric for generalizability, appeal, and robustness through a cross-validation and user study. Next, we develop methods for computing visually appealing blend lengths for two broad categories of motion. We empirically evaluate these results through user studies. Finally, we assess the importance of these techniques by determining the minimum sensitivity of viewers to transition durations, the just noticeable difference, for both center-aligned and start-end specifications.',\n",
              "  'authors': ['Jing Wang 1', ' Bobby Bodenheimer 2'],\n",
              "  'date': '2008',\n",
              "  'identifier': '2090267299',\n",
              "  'references': ['1506281249',\n",
              "   '2954064014',\n",
              "   '2336236730',\n",
              "   '2799061466',\n",
              "   '2249800031',\n",
              "   '2295660824',\n",
              "   '2243558602',\n",
              "   '2276504555',\n",
              "   '2151857564',\n",
              "   '2083382040'],\n",
              "  'title': 'Synthesis and evaluation of linear motion transitions'},\n",
              " {'abstract': \"Abstract : Cells were recorded with tungsten electrodes in the dorsal lateral geniculate body of the cat. Receptive fields of these units were mapped out, in the light-adapted state, with small sports of light. In their general arrangement geniculate receptive fields resembled those of retinal ganglion cells, having an excitatory ('on') centre and inhibitory ('off') preriphery, or reverse. The two portions of a receptive field were mutually antagonistic; the decrease in centre responses cauded by inclusion of peripheral portions of receptive fields was termed peripheral suppression. Cells recorded in layers A and B of the lateral geniculate body were driven from the contralateral eye; cells in layer A1 from the ipsilateral eye. In penetrations normal to the layers receptive fields of cells in a single layer were close together or superimposed, and from one layer to the next occupied exactly homologous positions in the two retinas. Binocular interaction was not observed in any of the cells studied. All three layers of the lateral geniculate contained both 'on'-centre and 'off'-centre units. Cells in layers A and A1 were similar both in their firing patterns and in average receptive field size. Cells in layer B were more sluggish in their responses to light stimuli, and tended to have larger receptive field centres. Cells with receptive fields within or near the area centralis tended to have smaller field centres and stronger suppression by the receptive field periphery than cells with their fields situated in more peripheral regions of the retina.\",\n",
              "  'authors': ['D. H. Hubel ', ' T. N. Wiesel'],\n",
              "  'date': '1961',\n",
              "  'identifier': '2136325353',\n",
              "  'references': ['2212384750', '2117254374', '2064348522'],\n",
              "  'title': \"Integrative action in the cat's lateral geniculate body.\"},\n",
              " {'abstract': 'In this paper, we describe a statistical method for 3D object detection. We represent the statistics of both object appearance and \"non-object\" appearance using a product of histograms. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Our approach is to use many such histograms representing a wide variety of visual attributes. Using this method, we have developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithm that can reliably detect passenger cars over a wide range of viewpoints.',\n",
              "  'authors': ['H. Schneiderman ', ' T. Kanade'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2155511848',\n",
              "  'references': ['2156909104',\n",
              "   '1988790447',\n",
              "   '2217896605',\n",
              "   '2117812871',\n",
              "   '1658679052',\n",
              "   '2159686933',\n",
              "   '2140785063',\n",
              "   '3003716168',\n",
              "   '2166713160',\n",
              "   '2138560582'],\n",
              "  'title': 'A statistical method for 3D object detection applied to faces and cars'},\n",
              " {'abstract': \"A key concern in Information Systems (IS) research has been to better understand the linkage between information systems and individual performance. The research reported in this study has two primary objectives: (1) to propose a comprehensive theoretical model that incorporates valuable insights from two complementary streams of research, and (2) to empirically test the core of the model. At the heart of the new model is the assertion that for an information technology to have a positive impact on individual performance, the technology: (1) must be utilized and (2) must be a good fit with the tasks it supports. This new model is moderately supported by an analysis of data from over 600 individuals in two companies. This research highlights the importance of the fit between technologies and users' tasks in achieving individual performance impacts from information technology. It also suggests that task-technology fit when decomposed into its more detailed components, could be the basis for a strong diagnostic tool to evaluate whether information systems and services in a given organization are meeting user needs.\",\n",
              "  'authors': ['Dale L. Goodhue 1', ' Ronald L. Thompson 2'],\n",
              "  'date': '1995',\n",
              "  'identifier': '1587451402',\n",
              "  'references': ['1791587663',\n",
              "   '2033943395',\n",
              "   '3008948231',\n",
              "   '2057012437',\n",
              "   '2036389121',\n",
              "   '2008441192',\n",
              "   '1515402129',\n",
              "   '1497226654',\n",
              "   '2108617106',\n",
              "   '2123438112'],\n",
              "  'title': 'Task-technology fit and individual performance'},\n",
              " {'abstract': 'Computational modelling of probability has become a major part of automated decision support systems. In this book, the principal ideas of probabilistic reasoning - known as Bayesian networks - are outlined and their practical implications illustrated. The book is intended for MSc students in knowledge-based systems, artificial intelligence and statistics, and for professionals in decision support systems applications and research.',\n",
              "  'authors': ['Finn V. Jensen'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2171265988',\n",
              "  'references': ['2117812871',\n",
              "   '1817561967',\n",
              "   '2170112109',\n",
              "   '2397866408',\n",
              "   '1698663318',\n",
              "   '2119394710',\n",
              "   '2019963883',\n",
              "   '2006258746',\n",
              "   '2024332750',\n",
              "   '2128299927'],\n",
              "  'title': 'An introduction to Bayesian networks'},\n",
              " {'abstract': 'Summary Background Since Dec 31, 2019, the Chinese city of Wuhan has reported an outbreak of atypical pneumonia caused by the 2019 novel coronavirus (2019-nCoV). Cases have been exported to other Chinese cities, as well as internationally, threatening to trigger a global outbreak. Here, we provide an estimate of the size of the epidemic in Wuhan on the basis of the number of cases exported from Wuhan to cities outside mainland China and forecast the extent of the domestic and global public health risks of epidemics, accounting for social and non-pharmaceutical prevention interventions. Methods We used data from Dec 31, 2019, to Jan 28, 2020, on the number of cases exported from Wuhan internationally (known days of symptom onset from Dec 25, 2019, to Jan 19, 2020) to infer the number of infections in Wuhan from Dec 1, 2019, to Jan 25, 2020. Cases exported domestically were then estimated. We forecasted the national and global spread of 2019-nCoV, accounting for the effect of the metropolitan-wide quarantine of Wuhan and surrounding cities, which began Jan 23–24, 2020. We used data on monthly flight bookings from the Official Aviation Guide and data on human mobility across more than 300 prefecture-level cities in mainland China from the Tencent database. Data on confirmed cases were obtained from the reports published by the Chinese Center for Disease Control and Prevention. Serial interval estimates were based on previous studies of severe acute respiratory syndrome coronavirus (SARS-CoV). A susceptible-exposed-infectious-recovered metapopulation model was used to simulate the epidemics across all major cities in China. The basic reproductive number was estimated using Markov Chain Monte Carlo methods and presented using the resulting posterior mean and 95% credibile interval (CrI). Findings In our baseline scenario, we estimated that the basic reproductive number for 2019-nCoV was 2·68 (95% CrI 2·47–2·86) and that 75\\u2008815 individuals (95% CrI 37\\u2008304–130\\u2008330) have been infected in Wuhan as of Jan 25, 2020. The epidemic doubling time was 6·4 days (95% CrI 5·8–7·1). We estimated that in the baseline scenario, Chongqing, Beijing, Shanghai, Guangzhou, and Shenzhen had imported 461 (95% CrI 227–805), 113 (57–193), 98 (49–168), 111 (56–191), and 80 (40–139) infections from Wuhan, respectively. If the transmissibility of 2019-nCoV were similar everywhere domestically and over time, we inferred that epidemics are already growing exponentially in multiple major cities of China with a lag time behind the Wuhan outbreak of about 1–2 weeks. Interpretation Given that 2019-nCoV is no longer contained within Wuhan, other major Chinese cities are probably sustaining localised outbreaks. Large cities overseas with close transport links to China could also become outbreak epicentres, unless substantial public health interventions at both the population and personal levels are implemented immediately. Independent self-sustaining outbreaks in major cities globally could become inevitable because of substantial exportation of presymptomatic cases and in the absence of large-scale public health interventions. Preparedness plans and mitigation interventions should be readied for quick deployment globally. Funding Health and Medical Research Fund (Hong Kong, China).',\n",
              "  'authors': ['Joseph T Wu ', ' Kathy Leung ', ' Gabriel M Leung'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3003573988',\n",
              "  'references': ['3003668884',\n",
              "   '3004397688',\n",
              "   '3002764620',\n",
              "   '2147166346',\n",
              "   '3002533591',\n",
              "   '2069251911',\n",
              "   '2096145431',\n",
              "   '1815575713',\n",
              "   '2104595316',\n",
              "   '1998725525'],\n",
              "  'title': 'Nowcasting and forecasting the potential domestic and international spread of the 2019-nCoV outbreak originating in Wuhan, China: a modelling study.'},\n",
              " {'abstract': 'We describe an algorithm, SSAHA (Sequence Search and Alignment by Hashing Algorithm), for performing fast searches on databases containing multiple gigabases of DNA. Sequences in the database are preprocessed by breaking them into consecutive k-tuples of k contiguous bases and then using a hash table to store the position of each occurrence of each k-tuple. Searching for a query sequence in the database is done by obtaining from the hash table the \"hits\" for each k-tuple in the query sequence and then performing a sort on the results. We discuss the effect of the tuple length k on the search speed, memory usage, and sensitivity of the algorithm and present the results of computational experiments which show that SSAHA can be three to four orders of magnitude faster than BLAST or FASTA, while requiring less memory than suffix tree methods. The SSAHA algorithm is used for high-throughput single nucleotide polymorphism (SNP) detection and very large scale sequence assembly. Also, it provides Web-based sequence search facilities for Ensembl projects.',\n",
              "  'authors': ['Zemin Ning ', ' Anthony J. Cox ', ' James C. Mullikin'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2142619120',\n",
              "  'references': ['2158714788',\n",
              "   '2055043387',\n",
              "   '2168909179',\n",
              "   '2015292449',\n",
              "   '2061008984',\n",
              "   '1990061958',\n",
              "   '2112814753',\n",
              "   '2055666215',\n",
              "   '2752853835',\n",
              "   '2087064593'],\n",
              "  'title': 'SSAHA: A Fast Search Method for Large DNA Databases'},\n",
              " {'abstract': 'Our eyes see so much in such varied conditions that one might consider the question posed in the title to be meaningless, but we show here that, within the range that we have been able to test, there is a particular spatiotemporal pattern of light that is detected better than any other. At least two plausible theories of visual detection predict that a stimulus will be seen best (will have greatest quantum efficiency) when it matches the weighting function of the most efficient detector. We have measured quantum efficiency for detecting a wide variety of spatiotemporal patterns using foveal vision in bright light. The best stimulus found so far is a small, briefly exposed circular patch of sinusoidal grating having a spatial frequency of approximately 7 c deg-1, drifting at approximately 4 Hz. We propose that this is the weighting function of the most efficient human contrast detector. We believe this answer to the question is unexpected and may have fundamental implications with regard to the mechanisms of visual perception.',\n",
              "  'authors': ['Andrew B. Watson 1',\n",
              "   ' 2',\n",
              "   ' H. B. Barlow 3',\n",
              "   ' John G. Robson 3'],\n",
              "  'date': '1983',\n",
              "  'identifier': '2079721233',\n",
              "  'references': ['2138100172',\n",
              "   '2022491393',\n",
              "   '1976692340',\n",
              "   '1988849438',\n",
              "   '2090948255',\n",
              "   '2089325630',\n",
              "   '2040730002',\n",
              "   '2060258698',\n",
              "   '2065170391',\n",
              "   '2001301726'],\n",
              "  'title': 'What does the eye see best'},\n",
              " {'abstract': 'This paper investigates the maximal channel coding rate achievable at a given blocklength and error probability. For general classes of channels new achievability and converse bounds are given, which are tighter than existing bounds for wide ranges of parameters of interest, and lead to tight approximations of the maximal achievable rate for blocklengths n as short as 100. It is also shown analytically that the maximal rate achievable with error probability ? isclosely approximated by C - ?(V/n) Q-1(?) where C is the capacity, V is a characteristic of the channel referred to as channel dispersion , and Q is the complementary Gaussian cumulative distribution function.',\n",
              "  'authors': ['Yury Polyanskiy ', ' H Vincent Poor ', ' Sergio Verdu'],\n",
              "  'date': '2010',\n",
              "  'identifier': '2106864314',\n",
              "  'references': ['2095882513',\n",
              "   '2801179766',\n",
              "   '2142901448',\n",
              "   '1590772317',\n",
              "   '2090841176',\n",
              "   '2020347709',\n",
              "   '2109035510',\n",
              "   '2753908209',\n",
              "   '2104340231',\n",
              "   '2751862591'],\n",
              "  'title': 'Channel Coding Rate in the Finite Blocklength Regime'},\n",
              " {'abstract': 'Abstract In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest. To achieve the best possible performance with a particular learning algorithm on a particular training set, a feature subset selection method should consider how the algorithm and the training set interact. We explore the relation between optimal feature subset selection and relevance. Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain. We study the strengths and weaknesses of the wrapper approach and show a series of improved designs. We compare the wrapper approach to induction without feature subset selection and to Relief, a filter approach to feature subset selection. Significant improvement in accuracy is achieved for some datasets for the two families of induction algorithms used: decision trees and Naive-Bayes.',\n",
              "  'authors': ['Ron Kohavi 1', ' George H. John 2'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2017337590',\n",
              "  'references': ['1639032689',\n",
              "   '1988790447',\n",
              "   '2912934387',\n",
              "   '2122410182',\n",
              "   '2084812512',\n",
              "   '2125055259',\n",
              "   '2340020088',\n",
              "   '3085162807',\n",
              "   '2149706766',\n",
              "   '1680392829'],\n",
              "  'title': 'Wrappers for feature subset selection'},\n",
              " {'abstract': 'The relationship between brain structure and complex behavior is governed by large-scale neurocognitive networks. The availability of a noninvasive technique that can visualize the neuronal projections connecting the functional centers should therefore provide new keys to the understanding of brain function. By using high-resolution three-dimensional diffusion magnetic resonance imaging and a newly designed tracking approach, we show that neuronal pathways in the rat brain can be probed in situ. The results are validated through comparison with known anatomical locations of such fibers.',\n",
              "  'authors': ['Susumu Mori ',\n",
              "   ' Barbara J. Crain ',\n",
              "   ' V. P. Chacko ',\n",
              "   ' Peter C. M. Van Zijl'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2145132952',\n",
              "  'references': ['2163815564',\n",
              "   '1964802316',\n",
              "   '1542836032',\n",
              "   '2022530159',\n",
              "   '2110431535',\n",
              "   '2154108863',\n",
              "   '2009039636',\n",
              "   '2058986306',\n",
              "   '1988276998',\n",
              "   '2063819516'],\n",
              "  'title': 'Three-dimensional tracking of axonal projections in the brain by magnetic resonance imaging.'},\n",
              " {'abstract': 'Preface. 0. The Applied Setting. 1. The Counting Process and Martingale Framework. 2. Local Square Integrable Martingales. 3. Finite Sample Moments and Large Sample Consistency of Tests and Estimators. 4. Censored Data Regression Models and Their Application. 5. Martingale Central Limit Theorem. 6. Large Sample results of the Kaplan-Meier Estimator. 7. Weighted Logrank Statistics. 8. Distribution Theory for Proportional Hazards Regression. Appendix A: Some Results from stieltjes Integration and Probability Theory. Appendix B: An Introduction to Weak convergence. Appendix C: The Martingale Central Limit Theorem: Some Preliminaries. Appendix D: Data. Appendix E: Exercises. Bibliography. Notation. Author Index. Subject Index.',\n",
              "  'authors': ['Thomas R. Fleming ', ' David P. Harrington'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2057968703',\n",
              "  'references': ['2166604768',\n",
              "   '2038981426',\n",
              "   '2318698569',\n",
              "   '2160842550',\n",
              "   '2023690749',\n",
              "   '1966714873',\n",
              "   '2289748525',\n",
              "   '2096673955',\n",
              "   '2214802907',\n",
              "   '2052825782'],\n",
              "  'title': 'Counting Processes and Survival Analysis'},\n",
              " {'abstract': 'A natural generalization of the ARCH (Autoregressive Conditional Heteroskedastic) process introduced in Engle (1982) to allow for past conditional variances in the current conditional variance equation is proposed. Stationarity conditions and autocorrelation structure for this new class of parametric models are derived. Maximum likelihood estimation and testing are also considered. Finally an empirical example relating to the uncertainty of the inflation rate is presented.',\n",
              "  'authors': ['Tim Bollerslev'],\n",
              "  'date': '1986',\n",
              "  'identifier': '1999996900',\n",
              "  'references': ['1979575715',\n",
              "   '2114001875',\n",
              "   '2313953460',\n",
              "   '2017137572',\n",
              "   '2616344413',\n",
              "   '2060806362',\n",
              "   '3121818550',\n",
              "   '2021760340',\n",
              "   '1975502490',\n",
              "   '2030704696'],\n",
              "  'title': 'Generalized autoregressive conditional heteroskedasticity'},\n",
              " {'abstract': 'This paper describes an approach for tracking rigid and articulated objects using a view-based representation. The approach builds on and extends work on eigenspace representations, robust estimation techniques, and parameterized optical flow estimation. First, we note that the least-squares image reconstruction of standard eigenspace techniques has a number of problems and we reformulate the reconstruction problem as one of robust estimation. Second we define a “subspace constancy assumption” that allows us to exploit techniques for parameterized optical flow estimation to simultaneously solve for the view of an object and the affine transformation between the eigenspace and the image. To account for large affine transformations between the eigenspace and the image we define a multi-scale eigenspace representation and a coarse-to-fine matching strategy. Finally, we use these techniques to track objects over long image sequences in which the objects simultaneously undergo both affine image motions and changes of view. In particular we use this “EigenTracking” technique to track and recognize the gestures of a moving hand.',\n",
              "  'authors': ['Michael J. Black 1', ' Allan D. Jepson 2'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2753461371',\n",
              "  'references': ['2098693229',\n",
              "   '2123977795',\n",
              "   '1874027545',\n",
              "   '2098947662',\n",
              "   '2129249398',\n",
              "   '1938714998',\n",
              "   '2159173611',\n",
              "   '2012712694',\n",
              "   '2100315781',\n",
              "   '1992402718'],\n",
              "  'title': 'EigenTracking: Robust Matching and Tracking of Articulated Objects Using a View-Based Representation'},\n",
              " {'abstract': \"The source of the severe acute respiratory syndrome (SARS) epidemic was traced to wildlife market civets and ultimately to bats. Subsequent hunting for novel coronaviruses (CoVs) led to the discovery of two additional human and over 40 animal CoVs, including the prototype lineage C betacoronaviruses, Tylonycteris bat CoV HKU4 and Pipistrellus bat CoV HKU5; these are phylogenetically closely related to the Middle East respiratory syndrome (MERS) CoV, which has affected more than 1,000 patients with over 35% fatality since its emergence in 2012. All primary cases of MERS are epidemiologically linked to the Middle East. Some of these patients had contacted camels which shed virus and/or had positive serology. Most secondary cases are related to health care-associated clusters. The disease is especially severe in elderly men with comorbidities. Clinical severity may be related to MERS-CoV's ability to infect a broad range of cells with DPP4 expression, evade the host innate immune response, and induce cytokine dysregulation. Reverse transcription-PCR on respiratory and/or extrapulmonary specimens rapidly establishes diagnosis. Supportive treatment with extracorporeal membrane oxygenation and dialysis is often required in patients with organ failure. Antivirals with potent in vitro activities include neutralizing monoclonal antibodies, antiviral peptides, interferons, mycophenolic acid, and lopinavir. They should be evaluated in suitable animal models before clinical trials. Developing an effective camel MERS-CoV vaccine and implementing appropriate infection control measures may control the continuing epidemic.\",\n",
              "  'authors': ['Jasper F. W. Chan ',\n",
              "   ' Susanna K. P. Lau ',\n",
              "   ' Kelvin K. W. To ',\n",
              "   ' Vincent C. C. Cheng ',\n",
              "   ' Patrick C. Y. Woo ',\n",
              "   ' Kwok-Yung Yuen'],\n",
              "  'date': '2015',\n",
              "  'identifier': '2115555188',\n",
              "  'references': ['2166867592',\n",
              "   '2107053896',\n",
              "   '2025170735',\n",
              "   '2006434809',\n",
              "   '2129542667',\n",
              "   '1993577573',\n",
              "   '1703839189',\n",
              "   '2119111857',\n",
              "   '2565805236',\n",
              "   '2149508011'],\n",
              "  'title': 'Middle East Respiratory Syndrome Coronavirus: Another Zoonotic Betacoronavirus Causing SARS-Like Disease'},\n",
              " {'abstract': 'A number of procedures are described for finding delta E/ delta W/sub ij/ where E is an error functional of the temporal trajectory of the states of a continuous recurrent network and w/sub ij/ are the weights of that network. Computing these quantities allows one to perform gradient descent in the weights to minimize E, so these procedures form the kernels of connectionist learning algorithms. Simulations in which networks are taught to move through limit cycles are shown, along with some empirical perturbation sensitivity tests. The author describes a number of elaborations of the basic idea, including mutable time delays and teacher forcing. He includes a complexity analysis of the various learning procedures discussed and analyzed. Temporally continuous recurrent networks seems particularly suited for temporally continuous domains, such as signal processing, control, and speech. >',\n",
              "  'authors': ['Pearlmutter'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2028629011',\n",
              "  'references': ['2581275558',\n",
              "   '2154642048',\n",
              "   '1597286183',\n",
              "   '2173629880',\n",
              "   '2016589492',\n",
              "   '1507849272',\n",
              "   '2007431958',\n",
              "   '1959983357',\n",
              "   '1971129545',\n",
              "   '3121926921'],\n",
              "  'title': 'Learning state space trajectories in recurrent neural networks'},\n",
              " {'abstract': 'This paper presents the findings of two studies that replicate previous work by Fred Davis on the subject of perceived usefulness, ease of use, and usage of information technology. The two studies focus on evaluating the psychometric properties of the ease of use and usefulness scales, while examining the relationship between ease of use, usefulness, and system usage. Study 1 provides a strong assessment of the convergent validity of the two scales by examining heterogeneous user groups dealing with heterogeneous implementations of messaging technology. In addition, because one might expect users to share similar perspectives about voice and electronic mail, the study also represents a strong test of discriminant validity. In this study a total of 118 respondents from 10 different organizations were surveyed for their attitudes toward two messaging technologies: voice and electronic mail.',\n",
              "  'authors': ['Dennis A. Adams ', ' R. Ryan Nelson ', ' Peter A. Todd'],\n",
              "  'date': '1992',\n",
              "  'identifier': '1515402129',\n",
              "  'references': ['1791587663',\n",
              "   '2033943395',\n",
              "   '2100408980',\n",
              "   '2149608872',\n",
              "   '2036389121',\n",
              "   '1990513740',\n",
              "   '1595575146',\n",
              "   '1595891490',\n",
              "   '196041357',\n",
              "   '2917388694'],\n",
              "  'title': 'Perceived usefulness, ease of use, and usage of information technology: a replication'},\n",
              " {'abstract': 'In this article, we attempt to distinguish between the properties of moderator and mediator variables at a number of levels. First, we seek to make theorists and researchers aware of the importance of not using the terms moderator and mediator interchangeably by carefully elaborating, both conceptually and strategically, the many ways in which moderators and mediators differ. We then go beyond this largely pedagogical function and delineate the conceptual and strategic implications of making use of such distinctions with regard to a wide range of phenomena, including control and stress, attitudes, and personality traits. We also provide a specific compendium of analytic procedures appropriate for making the most effective use of the moderator and mediator distinction, both separately and in terms of a broader causal system that includes both moderators and mediators.',\n",
              "  'authors': ['Reuben M. Baron ', ' David A. Kenny'],\n",
              "  'date': '1986',\n",
              "  'identifier': '1971440513',\n",
              "  'references': ['1491644571',\n",
              "   '2159401492',\n",
              "   '1989314580',\n",
              "   '1976876708',\n",
              "   '2004168348',\n",
              "   '2024509488',\n",
              "   '2133177370',\n",
              "   '2019758655',\n",
              "   '2051882866',\n",
              "   '2012073895'],\n",
              "  'title': 'The moderator–mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations.'},\n",
              " {'abstract': 'Principal component analysis (PCA) is a commonly applied technique for dimensionality reduction. PCA implicitly minimizes a squared loss function, which may be inappropriate for data that is not real-valued, such as binary-valued data. This paper draws on ideas from the Exponential family, Generalized linear models, and Bregman distances, to give a generalization of PCA to loss functions that we argue are better suited to other data types. We describe algorithms for minimizing the loss functions, and give examples on simulated data.',\n",
              "  'authors': ['Michael Collins ', ' S. Dasgupta ', ' Robert E Schapire'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2135001774',\n",
              "  'references': ['2148694408',\n",
              "   '1902027874',\n",
              "   '2135029798',\n",
              "   '2107743791',\n",
              "   '3015463134',\n",
              "   '1528905581',\n",
              "   '2125027820',\n",
              "   '1506313179',\n",
              "   '2043800867',\n",
              "   '2135561481'],\n",
              "  'title': 'A Generalization of Principal Components Analysis to the Exponential Family'},\n",
              " {'abstract': 'This cross-sectional emergency department study of 70 wheezing children and 59 control subjects (2 mo to 16 yr of age) examined the prevalence of respiratory viruses and their relationship to age, atopic status, and eosinophil markers. Nasal washes were cultured for respiratory viruses, assayed for respiratory syncytial virus (RSV) antigen, and tested for coronavirus and rhinovirus RNA using reverse transcription-PCR (RT-PCR). Also evaluated were eosinophil numbers and eosinophil cationic protein (ECP) in both nasal washes and serum, along with total IgE and specific IgE antibody in serum. Respiratory viruses were detected in 82% (18 of 22) of wheezing infants younger than 2 yr of age and in 83% (40 of 48) of older wheezing children. The predominant pathogens were RSV in infants (detected in 68% of wheezing subjects) and rhinovirus in older wheezing children (71%), and both were strongly associated with wheezing (p < 0.005). RSV was largely limited to wheezing children younger than 24 mo of age, but rhinovirus was detected by RT-PCR in 41% of all infants and in 35% of nonwheezing control subjects older than 2 yr of age. After 2 yr of age the strongest odds for wheezing were observed among those who had a positive RT-PCR test for rhinovirus together with a positive serum radioallergosorbent testing (RAST), nasal eosinophilia, or elevated nasal ECP (odds ratios = 17, 21, and 25, respectively). Results from this study demonstrate that a large majority of emergent wheezing illnesses during childhood (2 to 16 yr of age) can be linked to infection with rhinovirus, and that these wheezing attacks are most likely in those who have rhinovirus together with evidence of atopy or eosinophilic airway inflammation.',\n",
              "  'authors': ['Gary P. Rakes ',\n",
              "   ' Eurico Arruda ',\n",
              "   ' Jim M. Ingram ',\n",
              "   ' Gates E. Hoover ',\n",
              "   ' Juan C. Zambrano ',\n",
              "   ' Frederick G. Hayden ',\n",
              "   ' Thomas A. E. Platts-Mills ',\n",
              "   ' Peter W. Heymann'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2148710849',\n",
              "  'references': ['1964779747',\n",
              "   '2080575389',\n",
              "   '1980185618',\n",
              "   '2091249799',\n",
              "   '2023239553',\n",
              "   '2082696402',\n",
              "   '1915722592',\n",
              "   '2054090763',\n",
              "   '2146082572',\n",
              "   '2108308695'],\n",
              "  'title': 'Rhinovirus and Respiratory Syncytial Virus in Wheezing Children Requiring Emergency Care IgE and Eosinophil Analyses'},\n",
              " {'abstract': 'A Support Vector Machine SVM is a uni versal learning machine whose decision sur face is parameterized by a set of support vec tors and by a set of corresponding weights An SVM is also characterized by a kernel function Choice of the kernel determines whether the resulting SVM is a polynomial classi er a two layer neural network a ra dial basis function machine or some other learning machine SVMs are currently considerably slower in test phase than other approaches with sim ilar generalization performance To address this we present a general method to signif icantly decrease the complexity of the deci sion rule obtained using an SVM The pro posed method computes an approximation to the decision rule in terms of a reduced set of vectors These reduced set vectors are not support vectors and can in some cases be computed analytically We give ex perimental results for three pattern recogni tion problems The results show that the method can decrease the computational com plexity of the decision rule by a factor of ten with no loss in generalization perfor mance making the SVM test speed com petitive with that of other methods Fur ther the method allows the generalization performance complexity trade o to be di rectly controlled The proposed method is not speci c to pattern recognition and can be applied to any problem where the Sup port Vector algorithm is used for example regression INTRODUCTION SUPPORT VECTOR MACHINES Consider a two class classi er for which the decision rule takes the form',\n",
              "  'authors': ['Christopher J. C. Burges'],\n",
              "  'date': '1996',\n",
              "  'identifier': '26816478',\n",
              "  'references': ['2139212933',\n",
              "   '1964357740',\n",
              "   '2140095548',\n",
              "   '1648445109',\n",
              "   '2124351082',\n",
              "   '2108995755',\n",
              "   '2143331230',\n",
              "   '2149298154',\n",
              "   '1608462934',\n",
              "   '2125027820'],\n",
              "  'title': 'Simplified support vector decision rules'},\n",
              " {'abstract': 'This paper describes a hierarchical estimation framework for the computation of diverse representations of motion information. The key features of the resulting framework (or family of algorithms) are a global model that constrains the overall structure of the motion estimated, a local model that is used in the estimation process, and a coarse-fine refinement strategy. Four specific motion models: affine flow, planar surface flow, rigid body motion, and general optical flow, are described along with their application to specific examples.',\n",
              "  'authors': ['James R. Bergen ',\n",
              "   ' P. Anandan ',\n",
              "   ' Keith J. Hanna ',\n",
              "   ' Rajesh Hingorani'],\n",
              "  'date': '1992',\n",
              "  'identifier': '1938714998',\n",
              "  'references': ['2911709767',\n",
              "   '2103504761',\n",
              "   '2620619910',\n",
              "   '2118877769',\n",
              "   '2130657708',\n",
              "   '2168564612',\n",
              "   '2043003144',\n",
              "   '2179278902',\n",
              "   '2168262846',\n",
              "   '1991518198'],\n",
              "  'title': 'Hierarchical Model-Based Motion Estimation'},\n",
              " {'abstract': 'Drawing on the correspondence between the graph Laplacian, the Laplace-Beltrami operator on a manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for constructing a representation for data sampled from a low dimensional manifold embedded in a higher dimensional space. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality preserving properties and a natural connection to clustering. Several applications are considered.',\n",
              "  'authors': ['Mikhail Belkin ', ' Partha Niyogi'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2156718197',\n",
              "  'references': ['2053186076',\n",
              "   '2121947440',\n",
              "   '2001141328',\n",
              "   '1578099820',\n",
              "   '108654854'],\n",
              "  'title': 'Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering'},\n",
              " {'abstract': 'To better understand the duration of immunity against respiratory syncytial virus (RSV) and the role of serum antibodies to the surface glycoproteins, F and G, in susceptibility to reinfection, 15 adults with previous natural RSV infection were challenged with RSV of the same strain group (A) at 2, 4, 8, 14, 20, and 26 months after natural infection. By 2 months about one-half and by 8 months two-thirds of the subjects became reinfected. Each challenge resulted in infection in at least one-fourth of the subjects. Within 26 months 73% had two or more and 47% had three or more infections. The duration of immunity tended to increase after two closely spaced infections. Higher neutralizing, F and GA antibody levels before challenge correlated significantly with protection against infection. However, even in subjects with the highest antibody levels, the risk of reinfection was 25%. Specific nasal IgA antibody titers did not correlate significantly with protection. This suggests that humoral neutralizing, F, and G antibodies correlate with resistance to reinfection, but protection is far from complete and is of short duration.',\n",
              "  'authors': ['Caroline Breese Hall ',\n",
              "   ' Edward E. Walsh ',\n",
              "   ' Christine E. Long ',\n",
              "   ' Kenneth C. Schnabel'],\n",
              "  'date': '1991',\n",
              "  'identifier': '1974542809',\n",
              "  'references': ['2145445974',\n",
              "   '2119627949',\n",
              "   '2081114699',\n",
              "   '2025391611',\n",
              "   '1968605303',\n",
              "   '2010568322',\n",
              "   '2123704395',\n",
              "   '2029246207',\n",
              "   '1502226011',\n",
              "   '2131354424'],\n",
              "  'title': 'Immunity to and Frequency of Reinfection with Respiratory Syncytial Virus'},\n",
              " {'abstract': 'We propose a novel approach to learn and recognize natural scene categories. Unlike previous work, it does not require experts to annotate the training set. We represent the image of a scene by a collection of local regions, denoted as codewords obtained by unsupervised learning. Each region is represented as part of a \"theme\". In previous work, such themes were learnt from hand-annotations of experts, while our method learns the theme distributions as well as the codewords distribution over the themes without supervision. We report satisfactory categorization performances on a large set of 13 categories of complex scenes.',\n",
              "  'authors': ['L. Fei-Fei ', ' P. Perona'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2107034620',\n",
              "  'references': ['1880262756',\n",
              "   '2124386111',\n",
              "   '2045656233',\n",
              "   '1566135517',\n",
              "   '1484228140',\n",
              "   '2127006916',\n",
              "   '2171188998',\n",
              "   '1699734612',\n",
              "   '2104924585',\n",
              "   '2094414211'],\n",
              "  'title': 'A Bayesian hierarchical model for learning natural scene categories'},\n",
              " {'abstract': 'The use of contextual constraints in speech recognition has been contemplated by many authors. This paper describes a system under development which will perform correction of errors made in a phonemic recognizer by comparison of the received phoneme sequence with the syntax and dictionary of \"the language being spoken. The language syntax is stored in a relatively efficient manner, being essentially in Backus-Naur Form. The error correction procedure can best be described as a sequential decoding on the tree of syntax generated by the tables, as traversed by a syntactical parser. The system is currently being implemented in a form such that it will recognize a \"spoken FORTRAN\" language. Some initial results of its application to certain error-containing inputs are described.',\n",
              "  'authors': ['R. Alter'],\n",
              "  'date': '1968',\n",
              "  'identifier': '2074460300',\n",
              "  'references': ['2104416102',\n",
              "   '2087362480',\n",
              "   '2079145130',\n",
              "   '1989932830',\n",
              "   '2165490943',\n",
              "   '2093784773',\n",
              "   '2028528924'],\n",
              "  'title': 'Utilization of contextual constraints in automatic speech recognition'},\n",
              " {'abstract': 'We examine learning in all experiments we could locate involving 100 periods or more of games with a unique equilibrium in mixed strategies, and in a new experiment. We study both the ex post ( \"best fit\") descriptive power of learning models, and their ex ante predictive power, by simulating each experiment using parameters estimated from the other experiments. Even a one-parameter reinforcement learning model robustly outperforms the equilibrium predictions. Predictive power is improved by adding \"forgetting\" and \"experimentation, \" or by allowing greater rationality as in probabilistic fictitious play. Implications for developing a low-rationality, cognitive game theory are discussed. (JEL C72, C92)',\n",
              "  'authors': ['Ido Erev ', ' Alvin E. Roth'],\n",
              "  'date': '1998',\n",
              "  'identifier': '1564229172',\n",
              "  'references': ['1708874574',\n",
              "   '2138863509',\n",
              "   '1960351623',\n",
              "   '1993325457',\n",
              "   '2163569945',\n",
              "   '5086244',\n",
              "   '2264897026',\n",
              "   '2096348520',\n",
              "   '2044754442',\n",
              "   '3121358103'],\n",
              "  'title': 'Predicting How People Play Games: Reinforcement Learning in Experimental Games with Unique, Mixed Strategy Equilibria'},\n",
              " {'abstract': 'Three multiplex hemi-nested RT-PCR assays were developed to detect simultaneously 12 RNA respiratory viruses: influenza viruses A, B and C, human respiratory syncytial virus (hRSV), human metapneumovirus (hMPV), parainfluenza virus types 1-4 (PIV-1, -2, -3 and -4), human coronavirus OC43 and 229E (HCoV) and rhinovirus (hRV). An internal amplification control was included in one of the RT-PCR assays. The RT-PCR multiplex 1 and the hemi-nested multiplex 1 detected 1 and 0.1 TCID50 of RSV A, respectively, and 0.01 and 0.001 TCID50 of influenza virus A/H3N2, respectively. Two hundred and three nasal aspirates from hospitalised children were retrospectively tested in comparison with two conventional methods: direct immunofluorescence assay and viral isolation technique. Almost all samples (89/91) that were positive by immunofluorescence assay and/or viral isolation technique were detected by the multiplex assay. This method also detected an additional 85 viruses and 33 co-infections. The overall sensitivity (98%), rapidity and enhanced efficiency of these multiplex hemi-nested RT-PCR assays suggest that they would be a significant improvement over conventional methods for the detection of a broad spectrum of respiratory viruses.',\n",
              "  'authors': ['S. Bellau-Pujol 1',\n",
              "   ' A. Vabret 1',\n",
              "   ' L. Legrand 1',\n",
              "   ' J. Dina 1',\n",
              "   ' S. Gouarin 1',\n",
              "   ' J. Petitjean-Lecherbonnier 1',\n",
              "   ' B. Pozzetto 2',\n",
              "   ' C. Ginevra 2',\n",
              "   ' F. Freymuth 1'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2063850263',\n",
              "  'references': ['2133680517',\n",
              "   '2137089963',\n",
              "   '2053048205',\n",
              "   '2318915316',\n",
              "   '2082669336',\n",
              "   '2083060892',\n",
              "   '1981656628',\n",
              "   '1907972820',\n",
              "   '2089170816',\n",
              "   '2043370923'],\n",
              "  'title': 'Development of three multiplex RT-PCR assays for the detection of 12 respiratory RNA viruses'},\n",
              " {'abstract': '',\n",
              "  'authors': ['William Feller'],\n",
              "  'date': '1950',\n",
              "  'identifier': '2751862591',\n",
              "  'references': ['1660562555',\n",
              "   '2099040451',\n",
              "   '1527262418',\n",
              "   '2106864314',\n",
              "   '2149959815',\n",
              "   '2180060173',\n",
              "   '2117756735',\n",
              "   '2147717514',\n",
              "   '2161160262'],\n",
              "  'title': 'An introduction to probability theory and its applications'},\n",
              " {'abstract': \"Publisher Summary This chapter presents a general theoretical framework of human memory and describes the results of a number of experiments designed to test specific models that can be derived from the overall theory. This general theoretical framework categorizes the memory system along two major dimensions. The first categorization distinguishes permanent, structural features of the system from control processes that can be readily modified or reprogrammed at the will of the subject. The second categorization divides memory into three structural components: the sensory register, the short-term store, and the long-term store. Incoming sensory information first enters the sensory register, where it resides for a very brief period of time, then decays and is lost. The short-term store is the subject's working memory; it receives selected inputs from the sensory register and also from long-term store. The chapter also discusses the control processes associated with the sensory register. The term control process refers to those processes that are not permanent features of memory, but are instead transient phenomena under the control of the subject; their appearance depends on several factors such as instructional set, the experimental task, and the past history of the subject.\",\n",
              "  'authors': ['Richard C. Atkinson ', ' Richard M. Shiffrin'],\n",
              "  'date': '1968',\n",
              "  'identifier': '1878893887',\n",
              "  'references': ['2947000318',\n",
              "   '1984314602',\n",
              "   '2106654511',\n",
              "   '2053566542',\n",
              "   '2073588290',\n",
              "   '2088974767',\n",
              "   '2107033637',\n",
              "   '2170931964',\n",
              "   '2008615354',\n",
              "   '2046260226'],\n",
              "  'title': 'Human memory ; A proposed system and its control processes'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Takeru Miyato 1',\n",
              "   ' Toshiki Kataoka ',\n",
              "   ' Masanori Koyama 2',\n",
              "   ' Yuichi Yoshida 3'],\n",
              "  'date': '2018',\n",
              "  'identifier': '2963836885',\n",
              "  'references': ['3003301247',\n",
              "   '2893749619',\n",
              "   '2962974533',\n",
              "   '2804078698',\n",
              "   '3035574324',\n",
              "   '2982763192',\n",
              "   '2962754210',\n",
              "   '2963841322',\n",
              "   '2933374552'],\n",
              "  'title': 'Spectral Normalization for Generative Adversarial Networks'},\n",
              " {'abstract': 'The study of networks pervades all of science, from neurobiology to statistical physics. The most basic issues are structural: how does one characterize the wiring diagram of a food web or the Internet or the metabolic network of the bacterium Escherichia coli? Are there any unifying principles underlying their topology? From the perspective of nonlinear dynamics, we would also like to understand how an enormous network of interacting dynamical systems — be they neurons, power stations or lasers — will behave collectively, given their individual dynamics and coupling architecture. Researchers are only now beginning to unravel the structure and dynamics of complex networks.',\n",
              "  'authors': ['Steven H. Strogatz'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2164727176',\n",
              "  'references': ['2112090702',\n",
              "   '2008620264',\n",
              "   '2061901927',\n",
              "   '2065769502',\n",
              "   '1976969221',\n",
              "   '2905110430',\n",
              "   '2144885342',\n",
              "   '2175110005',\n",
              "   '2125315567',\n",
              "   '2104085672'],\n",
              "  'title': 'Exploring complex networks'},\n",
              " {'abstract': 'Given a dictionary D = {dk} of vectors dk, we seek to represent a signal S as a linear combination S = ∑k γ(k)dk, with scalar coefficients γ(k). In particular, we aim for the sparsest representation possible. In general, this requires a combinatorial optimization process. Previous work considered the special case where D is an overcomplete system consisting of exactly two orthobases and has shown that, under a condition of mutual incoherence of the two bases, and assuming that S has a sufficiently sparse representation, this representation is unique and can be found by solving a convex optimization problem: specifically, minimizing the l1 norm of the coefficients γ. In this article, we obtain parallel results in a more general setting, where the dictionary D can arise from two or several bases, frames, or even less structured systems. We sketch three applications: separating linear features from planar ones in 3D data, noncooperative multiuser encoding, and identification of over-complete independent component models.',\n",
              "  'authors': ['David L. Donoho ', ' Michael Elad'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2154332973',\n",
              "  'references': ['2115755118',\n",
              "   '2078204800',\n",
              "   '2610857016',\n",
              "   '2099641086',\n",
              "   '2151693816',\n",
              "   '2136235822',\n",
              "   '2167839759',\n",
              "   '1604810369',\n",
              "   '2125455772',\n",
              "   '1995963238'],\n",
              "  'title': 'Optimally sparse representation in general (nonorthogonal) dictionaries via 1 minimization'},\n",
              " {'abstract': 'Multiresolution representations are effective for analyzing the information content of images. The properties of the operator which approximates a signal at a given resolution were studied. It is shown that the difference of information between the approximation of a signal at the resolutions 2/sup j+1/ and 2/sup j/ (where j is an integer) can be extracted by decomposing this signal on a wavelet orthonormal basis of L/sup 2/(R/sup n/), the vector space of measurable, square-integrable n-dimensional functions. In L/sup 2/(R), a wavelet orthonormal basis is a family of functions which is built by dilating and translating a unique function psi (x). This decomposition defines an orthogonal multiresolution representation called a wavelet representation. It is computed with a pyramidal algorithm based on convolutions with quadrature mirror filters. Wavelet representation lies between the spatial and Fourier domains. For images, the wavelet representation differentiates several spatial orientations. The application of this representation to data compression in image coding, texture discrimination and fractal analysis is discussed. >',\n",
              "  'authors': ['S.G. Mallat'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2132984323',\n",
              "  'references': ['2078206416',\n",
              "   '2098914003',\n",
              "   '2103504761',\n",
              "   '2109863423',\n",
              "   '1980149518',\n",
              "   '2096684483',\n",
              "   '2022735534',\n",
              "   '1995756857',\n",
              "   '2139797453',\n",
              "   '2978983090'],\n",
              "  'title': 'A theory for multiresolution signal decomposition: the wavelet representation'},\n",
              " {'abstract': 'Despite many empirical successes of spectral clustering methods— algorithms that cluster points using eigenvectors of matrices derived from the data—there are several unresolved issues. First. there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.',\n",
              "  'authors': ['Andrew Y. Ng 1', ' Michael I. Jordan 1', ' Yair Weiss 2'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2165874743',\n",
              "  'references': [],\n",
              "  'title': 'On Spectral Clustering: Analysis and an algorithm'},\n",
              " {'abstract': \"ObjectiveTo develop consensus-based recommendations for measures to be taken by medical and public health professionals if hemorrhagic fever viruses (HFVs) are used as biological weapons against a civilian population.ParticipantsThe Working Group on Civilian Biodefense included 26 representatives from academic medical centers, public health, military services, governmental agencies, and other emergency management institutions.EvidenceMEDLINE was searched from January 1966 to January 2002. Retrieved references, relevant material published prior to 1966, and additional sources identified by participants were reviewed.Consensus ProcessThree formal drafts of the statement that synthesized information obtained in the evidence-gathering process were reviewed by the working group. Each draft incorporated comments and judgments of the members. All members approved the final draft.ConclusionsWeapons disseminating a number of HFVs could cause an outbreak of an undifferentiated febrile illness 2 to 21 days later, associated with clinical manifestations that could include rash, hemorrhagic diathesis, and shock. The mode of transmission and clinical course would vary depending on the specific pathogen. Diagnosis may be delayed given clinicians' unfamiliarity with these diseases, heterogeneous clinical presentation within an infected cohort, and lack of widely available diagnostic tests. Initiation of ribavirin therapy in the early phases of illness may be useful in treatment of some of these viruses, although extensive experience is lacking. There are no licensed vaccines to treat the diseases caused by HFVs.\",\n",
              "  'authors': ['Luciana Borio 1',\n",
              "   ' Thomas Inglesby 1',\n",
              "   ' C. J. Peters 2',\n",
              "   ' Alan L. Schmaljohn 3',\n",
              "   ' James M. Hughes 4',\n",
              "   ' Peter B. Jahrling 3',\n",
              "   ' Thomas Ksiazek 4',\n",
              "   ' Karl M. Johnson 5',\n",
              "   ' Andrea Meyerhoff 6',\n",
              "   \" Tara O'Toole 1\",\n",
              "   ' Michael S. Ascher 7',\n",
              "   ' John Bartlett 1',\n",
              "   ' Joel G. Breman 8',\n",
              "   ' Edward M. Eitzen 3',\n",
              "   ' Margaret Hamburg 9',\n",
              "   ' Jerry Hauer 7',\n",
              "   ' D. A. Henderson 1',\n",
              "   ' Richard T. Johnson 1',\n",
              "   ' Gigi Kwik 1',\n",
              "   ' Marci Layton 10',\n",
              "   ' Scott Lillibridge 7',\n",
              "   ' Gary J. Nabel 8',\n",
              "   ' Michael T. Osterholm 11',\n",
              "   ' Trish M. Perl 1',\n",
              "   ' Philip Russell 7',\n",
              "   ' Kevin Tonat 7'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2136166622',\n",
              "  'references': ['1833207062',\n",
              "   '2109779439',\n",
              "   '2103828083',\n",
              "   '2137889830',\n",
              "   '2558766452',\n",
              "   '2100511744',\n",
              "   '2167960824',\n",
              "   '1545248704',\n",
              "   '2118488619',\n",
              "   '2145710422'],\n",
              "  'title': 'Hemorrhagic Fever Viruses as Biological Weapons: Medical and Public Health Management'},\n",
              " {'abstract': 'The source of human infection with Middle East respiratory syndrome coronavirus remains unknown. Molecular investigation indicated that bats in Saudi Arabia are infected with several alphacoronaviruses and betacoronaviruses. Virus from 1 bat showed 100% nucleotide identity to virus from the human index case-patient. Bats might play a role in human infection.',\n",
              "  'authors': ['Ziad A. Memish ',\n",
              "   ' Nischay Mishra ',\n",
              "   ' Kevin J. Olival ',\n",
              "   ' Shamsudeen F. Fagbo ',\n",
              "   ' Vishal Kapoor ',\n",
              "   ' Jonathan H. Epstein ',\n",
              "   ' Rafat AlHakeem ',\n",
              "   ' Abdulkareem Durosinloun ',\n",
              "   ' Mushabab Al Asmari ',\n",
              "   ' Ariful Islam ',\n",
              "   ' Amit Kapoor ',\n",
              "   ' Thomas Briese ',\n",
              "   ' Peter Daszak ',\n",
              "   ' Abdullah A. Al Rabeeah ',\n",
              "   ' W. Ian Lipkin'],\n",
              "  'date': '2013',\n",
              "  'identifier': '2049975503',\n",
              "  'references': ['2166867592',\n",
              "   '2107053896',\n",
              "   '1703839189',\n",
              "   '2103503670',\n",
              "   '1852588318',\n",
              "   '2140338292',\n",
              "   '2066347985',\n",
              "   '2131369206',\n",
              "   '2122576818',\n",
              "   '1997655974'],\n",
              "  'title': 'Middle East Respiratory Syndrome Coronavirus in Bats, Saudi Arabia'},\n",
              " {'abstract': 'In this paper, we discuss consensus problems for networks of dynamic agents with fixed and switching topologies. We analyze three cases: 1) directed networks with fixed topology; 2) directed networks with switching topology; and 3) undirected networks with communication time-delays and fixed topology. We introduce two consensus protocols for networks with and without time-delays and provide a convergence analysis in all three cases. We establish a direct connection between the algebraic connectivity (or Fiedler eigenvalue) of the network and the performance (or negotiation speed) of a linear consensus protocol. This required the generalization of the notion of algebraic connectivity of undirected graphs to digraphs. It turns out that balanced digraphs play a key role in addressing average-consensus problems. We introduce disagreement functions for convergence analysis of consensus protocols. A disagreement function is a Lyapunov function for the disagreement network dynamics. We proposed a simple disagreement function that is a common Lyapunov function for the disagreement dynamics of a directed network with switching topology. A distinctive feature of this work is to address consensus problems for networks with directed information flow. We provide analytical tools that rely on algebraic graph theory, matrix theory, and control theory. Simulations are provided that demonstrate the effectiveness of our theoretical results.',\n",
              "  'authors': ['R. Olfati-Saber ', ' R.M. Murray'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2107396783',\n",
              "  'references': ['2165744313',\n",
              "   '2146890818',\n",
              "   '2610857016',\n",
              "   '2164727176',\n",
              "   '247697463',\n",
              "   '2798588639',\n",
              "   '1888172398',\n",
              "   '2074796812',\n",
              "   '2611515161',\n",
              "   '1864806140'],\n",
              "  'title': 'Consensus problems in networks of agents with switching topology and time-delays'},\n",
              " {'abstract': \"Computer vision is moving into a new era in which the aim is to develop visual skills for robots that allow them to interact with a dynamic, unconstrained environment. To achieve this aim, new kinds of vision algorithms need to be developed which run in real time and subserve the robot's goals. Two fundamental goals are determining the identity of an object with a known location, and determining the location of a known object. Color can be successfully used for both tasks. This dissertation demonstrates that color histograms of multicolored objects provide a robust, efficient cue for indexing into a large database of models. It shows that color histograms are stable object representations in the presence of occlusion and over change in view, and that they can differentiate among a large number of objects. For solving the identification problem, it introduces a technique called Histogram Intersection, which matches model and image histograms and a fast incremental version of Histogram Intersection which allows real-time indexing into a large database of stored models. It demonstrates techniques for dealing with crowded scenes and with models with similar color signatures. For solving the location problem it introduces an algorithm called Histogram Backprojection which performs this task efficiently in crowded scenes.\",\n",
              "  'authors': ['Michael James Swain ', ' Dana H. Ballard'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2914885528',\n",
              "  'references': ['2740373864',\n",
              "   '2115738369',\n",
              "   '2913703059',\n",
              "   '3021212382',\n",
              "   '2296039540',\n",
              "   '2415527960',\n",
              "   '2119204143',\n",
              "   '2125756925',\n",
              "   '2172373809',\n",
              "   '2489504689'],\n",
              "  'title': 'Color indexing'},\n",
              " {'abstract': 'Neurons in the cerebral cortex are organized into anatomical columns, with ensembles of cells arranged from the surface to the whitematter.Withinacolumn,neuronsoftensharefunctionalproperties,suchasselectivityforstimulusorientation;columnswith distinctproperties,suchasdifferentpreferredorientations,tilethecorticalsurfaceinorderlypatterns.Thisfunctionalarchitecture was discovered with the relatively sparse sampling of microelectrode recordings. Optical imaging of membrane voltage or metabolic activity elucidated the overall geometry of functional maps, but is averaged over many cells (resolution >100mm). Consequently, the purity of functional domains and the precision of the borders between them could not be resolved. Here, we labelled thousands of neurons of the visual cortex with a calcium-sensitive indicator in vivo. We then imaged the activity of neuronal populations at single-cell resolution with two-photon microscopy up to a depth of 400mm. In rat primary visual cortex, neurons had robust orientation selectivity but there was no discernible local structure; neighbouring neurons often responded to different orientations. In area 18 of cat visual cortex, functional maps were organized at a fine scale. Neurons with opposite preferences for stimulus direction were segregated with extraordinary spatial precision in three dimensions, with columnar borders one to two cells wide. These results indicate that cortical maps can be built with single-cell precision.',\n",
              "  'authors': ['Kenichi Ohki ',\n",
              "   ' Sooyoung Chung ',\n",
              "   \" Yeang H. Ch'ng \",\n",
              "   ' Prakash Kara ',\n",
              "   ' R. Clay Reid'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2117940227',\n",
              "  'references': ['2469177269',\n",
              "   '2167460696',\n",
              "   '2046031057',\n",
              "   '2121071682',\n",
              "   '2163755116',\n",
              "   '2054797412',\n",
              "   '2007494471',\n",
              "   '2116360511',\n",
              "   '1481189295',\n",
              "   '2167670991'],\n",
              "  'title': 'Functional imaging with cellular resolution reveals precise micro-architecture in visual cortex'},\n",
              " {'abstract': 'Conceptual clustering is an important way of summarizing and explaining data. However, the recent formulation of this paradigm has allowed little exploration of conceptual clustering as a means of improving performance. Furthermore, previous work in conceptual clustering has not explicitly dealt with constraints imposed by real world environments. This article presents COBWEB, a conceptual clustering system that organizes data so as to maximize inference ability. Additionally, COBWEB is incremental and computationally economical, and thus can be flexibly applied in a variety of domains.',\n",
              "  'authors': ['Douglas H. Fisher'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2073308541',\n",
              "  'references': ['1596324102',\n",
              "   '2612166593',\n",
              "   '2159047538',\n",
              "   '2091579301',\n",
              "   '1978304080',\n",
              "   '2009207944',\n",
              "   '2273972223',\n",
              "   '2056613695',\n",
              "   '2070429602',\n",
              "   '1527883571'],\n",
              "  'title': 'Knowledge acquisition via incremental conceptual clustering'},\n",
              " {'abstract': 'We describe the current state of a system that recognizes printed text of various fonts and sizes for the Roman alphabet. The system combines several techniques in order to improve the overall recognition rate. Thinning and shape extraction are performed directly on a graph of the run-length encoding of a binary image. The resulting strokes and other shapes are mapped, using a shape-clustering approach, into binary features which are then fed into a statistical Bayesian classifier. Large-scale trials have shown better than 97 percent top choice correct performance on mixtures of six dissimilar fonts, and over 99 percent on most single fonts, over a range of point sizes. Certain remaining confusion classes are disambiguated through contour analysis, and characters suspected of being merged are broken and reclassified. Finally, layout and linguistic context are applied. The results are illustrated by sample pages.',\n",
              "  'authors': ['Simon Kahan 1', ' Theo Pavlidis 2', ' Henry S. Baird 3'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2155818555',\n",
              "  'references': ['22745672',\n",
              "   '2095905764',\n",
              "   '2092276439',\n",
              "   '2062361515',\n",
              "   '1963892690',\n",
              "   '2073775066',\n",
              "   '2143635578',\n",
              "   '2000821228',\n",
              "   '2058918737',\n",
              "   '1519534430'],\n",
              "  'title': 'On the Recognition of Printed Characters of Any Font and Size'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Wolf Singer'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2159353177',\n",
              "  'references': ['1554576613',\n",
              "   '2095757522',\n",
              "   '2149194912',\n",
              "   '22297218',\n",
              "   '1898014694',\n",
              "   '2118615399',\n",
              "   '1972544340',\n",
              "   '2098580305',\n",
              "   '1986246844',\n",
              "   '2093353037'],\n",
              "  'title': 'Neuronal Synchrony: A Versatile Code for the Definition of Relations?'},\n",
              " {'abstract': 'The forebrain comprises an intricate set of structures that are required for some of the most complex and evolved functions of the mammalian brain. As a reflection of its complexity, cell migration in the forebrain is extremely elaborated, with widespread dispersion of cells across multiple functionally distinct areas. Two general modes of migration are distinguished in the forebrain: radial migration, which establishes the general cytoarchitectonical framework of the different forebrain subdivisions; and tangential migration, which increases the cellular complexity of forebrain circuits by allowing the dispersion of multiple neuronal types. Here, we review the cellular and molecular mechanisms underlying each of these types of migrations and discuss how emerging concepts in neuronal migration are reshaping our understanding of forebrain development in normal and pathological situations.',\n",
              "  'authors': ['Oscar Marín 1', ' John L.R. Rubenstein 2'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2134711325',\n",
              "  'references': ['2124248841',\n",
              "   '1503727145',\n",
              "   '2007242343',\n",
              "   '1859730138',\n",
              "   '2067376187',\n",
              "   '2035250926',\n",
              "   '1979890518',\n",
              "   '2043204105',\n",
              "   '1967450020',\n",
              "   '2079396188'],\n",
              "  'title': 'Cell migration in the forebrain.'},\n",
              " {'abstract': 'An approach for performing multiple alignments of large numbers of amino acid or nucleotide sequences is described. The method is based on first deriving a phylogenetic tree from a matrix of all pairwise sequence similarity scores, obtained using a fast pairwise alignment algorithm. Then the multiple alignment is achieved from a series of pairwise alignments of clusters of sequences, following the order of branching in the tree. The method is sufficiently fast and economical with memory to be easily implemented on a microcomputer, and yet the results obtained are comparable to those from packages requiring mainframe computer facilities.',\n",
              "  'authors': ['Desmond G. Higgins ', ' Paul M. Sharp'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2094031081',\n",
              "  'references': ['93588716',\n",
              "   '1969153299',\n",
              "   '2601913882',\n",
              "   '2074231493',\n",
              "   '1969051510',\n",
              "   '1527979595',\n",
              "   '1994414218',\n",
              "   '2086438703',\n",
              "   '2000164358',\n",
              "   '1967904359'],\n",
              "  'title': 'CLUSTAL: A package for performing multiple sequence alignment on a microcomputer'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Vittorio Basevi'],\n",
              "  'date': '2011',\n",
              "  'identifier': '2520432709',\n",
              "  'references': ['2777968081',\n",
              "   '1592674309',\n",
              "   '2616235706',\n",
              "   '2616009730',\n",
              "   '2185461071',\n",
              "   '2571593881',\n",
              "   '2319495438',\n",
              "   '2013253830',\n",
              "   '2077464591',\n",
              "   '2037910887'],\n",
              "  'title': 'Diagnosis and Classification of Diabetes Mellitus'},\n",
              " {'abstract': 'The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion. This results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix, without increasing the complexity of the calculation. The resulting approximation of faces projected from outside of the data set onto this optimal basis is improved on average. >',\n",
              "  'authors': ['M. Kirby ', ' L. Sirovich'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2135463994',\n",
              "  'references': ['1770825568',\n",
              "   '2130259898',\n",
              "   '1633869374',\n",
              "   '147723833',\n",
              "   '2798461040',\n",
              "   '1507699566',\n",
              "   '1535031115',\n",
              "   '1509349128',\n",
              "   '2051366222',\n",
              "   '2565264375'],\n",
              "  'title': 'Application of the Karhunen-Loeve procedure for the characterization of human faces'},\n",
              " {'abstract': 'We propose a model for the first stage of the cortical transformation of the visual image based on the principle that the cortex encodes the information with the minimum number of channels mathematically needed. We restrict our model to be consistent with the data on size adaptations, the known relationships of acuity and the inverse of magnification factor with eccentricity, and the electrophysiological findings on the physiological uniformity of the striate cortex. Assuming that each hypercolumn analyzes a limited spatial domain, we apply the sampling theorem to show that only 16 channels, composed of 4 sizes, are needed for dimension. The extension to 2 dimensions leads to a possible scheme for the number, spacing, and orientational disposition of the elements, together with predictions about the number of inputs from the eyes and the total number of hypercolumns. Since all these predictions are consistent with physical and neural estimates, we conclude that the cortex may analyze the image along the lines we suggest.',\n",
              "  'authors': ['Barbara Sakitt 1', ' H. B. Barlow 2'],\n",
              "  'date': '1982',\n",
              "  'identifier': '2040730002',\n",
              "  'references': ['2105672294',\n",
              "   '2130355536',\n",
              "   '1999908130',\n",
              "   '1964415410',\n",
              "   '2167553001',\n",
              "   '2022491393',\n",
              "   '1976692340',\n",
              "   '1680579736',\n",
              "   '1988849438',\n",
              "   '2047496335'],\n",
              "  'title': 'A model for the economical encoding of the visual image in cerebral cortex'},\n",
              " {'abstract': 'Abstract The picture segmentation problem is formulated within the framework of numerical analysis as an optimization problem of functional approximation. A suboptimal solution is presented together with examples of its application on the segmentation of maps and pictures from a scanning electron microscope.',\n",
              "  'authors': ['Theodosios Pavlidis'],\n",
              "  'date': '1972',\n",
              "  'identifier': '1970144710',\n",
              "  'references': ['2133246412',\n",
              "   '1972885239',\n",
              "   '2019831869',\n",
              "   '2031435600',\n",
              "   '2168893189',\n",
              "   '1498289939',\n",
              "   '1995259821',\n",
              "   '2038453652',\n",
              "   '1984297154',\n",
              "   '2142764459'],\n",
              "  'title': 'Segmentation of pictures and maps through functional approximation'},\n",
              " {'abstract': 'Despite the apparent randomness of the Internet, we discover some surprisingly simple power-laws of the Internet topology. These power-laws hold for three snapshots of the Internet, between November 1997 and December 1998, despite a 45% growth of its size during that period. We show that our power-laws fit the real data very well resulting in correlation coefficients of 96% or higher.Our observations provide a novel perspective of the structure of the Internet. The power-laws describe concisely skewed distributions of graph properties such as the node outdegree. In addition, these power-laws can be used to estimate important parameters such as the average neighborhood size, and facilitate the design and the performance analysis of protocols. Furthermore, we can use them to generate and select realistic topologies for simulation purposes.',\n",
              "  'authors': ['Michalis Faloutsos ',\n",
              "   ' Petros Faloutsos ',\n",
              "   ' Christos Faloutsos'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1976969221',\n",
              "  'references': ['2170120409',\n",
              "   '2078206416',\n",
              "   '2105818147',\n",
              "   '2148275477',\n",
              "   '2138543759',\n",
              "   '2408227189',\n",
              "   '2145721479',\n",
              "   '2171873915',\n",
              "   '2175892715',\n",
              "   '2128796442'],\n",
              "  'title': 'On power-law relationships of the Internet topology'},\n",
              " {'abstract': \"This paper describes a technique for making personalized recommendations from any type of database to a user based on similarities between the interest profile of that user and those of other users. In particular, we discuss the implementation of a networked system called Ringo, which makes personalized recommendations for music albums and artists. Ringo's database of users and artists grows dynamically as more people use the system and enter more information. Four different algorithms for making recommendations by using social information filtering were tested and compared. We present quantitative and qualitative results obtained from the use of Ringo by more than 2000 people.\",\n",
              "  'authors': ['Upendra Shardanand ', ' Pattie Maes'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2124591829',\n",
              "  'references': ['2147152072',\n",
              "   '2155106456',\n",
              "   '1966553486',\n",
              "   '2147859400',\n",
              "   '1589728983',\n",
              "   '1608058569'],\n",
              "  'title': 'Social information filtering: algorithms for automating “word of mouth”'},\n",
              " {'abstract': 'Memory-based classification algorithms such as radial basis functions or K-nearest neighbors typically rely on simple distances (Euclidean, dot product...), which are not particularly meaningful on pattern vectors. More complex, better suited distance measures are often expensive and rather ad-hoc (elastic matching, deformable templates). We propose a new distance measure which (a) can be made locally invariant to any set of transformations of the input and (b) can be computed efficiently. We tested the method on large handwritten character databases provided by the Post Office and the NIST. Using invariances with respect to translation, rotation, scaling, shearing and line thickness, the method consistently outperformed all other systems tested on the same databases.',\n",
              "  'authors': ['Patrice Simard 1',\n",
              "   ' 2',\n",
              "   ' Yann LeCun 3',\n",
              "   ' John S. Denker 1',\n",
              "   ' 4'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2137291015',\n",
              "  'references': ['1991848143',\n",
              "   '2154579312',\n",
              "   '23758216',\n",
              "   '2111494971',\n",
              "   '60275550'],\n",
              "  'title': 'Efficient Pattern Recognition Using a New Transformation Distance'},\n",
              " {'abstract': 'Abstract A digital watermark is an invisible mark embedded in a digital image which may be used for a number of different purposes including image captioning and copyright protection. This paper describes how a combination of spread spectrum encoding of the embedded message and transform-based invariants can be used for digital image watermarking. In particular, it is described how a Fourier–Mellin-based approach can be used to construct watermarks which are designed to be unaffected by any combination of rotation and scale transformations. In addition, a novel method of CDMA spread spectrum encoding is introduced which allows one to embed watermark messages of arbitrary length and which need only a secret key for decoding. The paper also describes the usefulness of Reed Solomon error-correcting codes in this scheme.',\n",
              "  'authors': ['Joseph J.K. ÓRuanaidh ', ' Thierry Pun'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2113183384',\n",
              "  'references': ['2408227189',\n",
              "   '2158518777',\n",
              "   '2139289040',\n",
              "   '1788382226',\n",
              "   '2160438444',\n",
              "   '1593683169',\n",
              "   '1571441458',\n",
              "   '1522884824',\n",
              "   '2138445005',\n",
              "   '2506763343'],\n",
              "  'title': 'Rotation, scale and translation invariant spread spectrum digital image watermarking'},\n",
              " {'abstract': \"Most current linguistic theories give lexical accounts of several phenomena that used to be considered purely syntactic. The information put in the lexicon is thereby increased both in amount and complexity. We explore the view that syntactic rules are not separated from lexical items. In this approach, each elementary structure is associated with a lexical item called the anchor. These structures specify extended domains of locality (as compared to context-free grammars) over which constraints can be stated. The 'grammar' consists of a lexicon where each lexical item is associated with a finite number of structures for which that item is the anchor. There are 'rules' which tell us how these structures are composed. A grammar of this form will be said to be lexicalized. The process of lexicalization of context-free grammars (CFGs) constrained by linguistic requirements forces us to use operations for combining structures that make the formalism fall in the class of mildly context sensitive languages. We show that substitution, the combining operation corresponding to CFGs, does not allow one to lexicalize CFGs but the combination of substitution and adjunction does. We show how tree-adjoining grammar (TAG) is derived from the lexicalization process of CFGs. Then we show that TAGs are closed under lexicalization and we illustrate the main structures found in a lexicalized TAG for English. The properties of TAGs permit us to encapsulate diverse syntactic phenomena in a very natural way. TAG's extended domain of locality and its factoring of recursion from local dependencies enable us to localize many syntactic dependencies (such as filler-gap) as well as semantic dependencies (such as predicate-arguments). We investigate the processing of lexicalized TAGs. We first present two general practical parsers that follow Earley-style parsing. They are practical parsers for TAGs because, as for CFGs, the average behavior of Earley-type parsers is superior to its worst case complexity. They are both left to right bottom-up parsers that use top-down predictions but they differ in the way the top down prediction is used. Then we explain the building of a set of deterministic bottom-up left to right parsers which analyze a subset of tree-adjoining languages. The LR parsing strategy for CFGs is extended to TAG by using a machine, called Bottom-up Embedded Push Down Automaton (BEPDA), that recognizes in a bottom-up fashion the set of tree-adjoining languages (and exactly this set). Finally we show how lexicalized grammars suggest a natural two-step parsing strategy. We consider lexicalized TAGs as an instance of lexicalized grammar and we examine the effect of the two-step parsing strategy on main types of parsing algorithms.\",\n",
              "  'authors': ['Yves Schabes ', ' Aravind K. Joshi'],\n",
              "  'date': '1990',\n",
              "  'identifier': '1526927911',\n",
              "  'references': ['2151149636',\n",
              "   '1608050331',\n",
              "   '1479758177',\n",
              "   '86295895',\n",
              "   '1528941926',\n",
              "   '2305592425',\n",
              "   '2126410802',\n",
              "   '2146053064',\n",
              "   '1479669738',\n",
              "   '1982944197'],\n",
              "  'title': 'Mathematical and computational aspects of lexicalized grammars'},\n",
              " {'abstract': 'When subjects view stimulation of a rubber hand while feeling congruent stimulation of their own hand, they may come to feel that the rubber hand is part of their own body. This illusion of body ownership is termed ‘Rubber Hand Illusion’ (RHI). We investigated sensitivity of RHI to spatial mismatches between visual and somatic experience. We compared the effects of spatial mismatch between the stimulation of the two hands, and equivalent mismatches between the postures of the two hands. We created the mismatch either by adjusting stimulation or posture of the subject’s hand, or, in a separate group of subjects, by adjusting stimulation or posture of the rubber hand. The matching processes underlying body ownership were asymmetrical. The illusion survived small changes in the subject’s hand posture, but disappeared when the same posture transformations were applied to the rubber hand. Mismatch between the stimulation delivered to the subject’s hand and the rubber hand abolished the illusion. The combination of these two situations is of particular interest. When the subject’s hand posture was slightly different from the rubber hand posture, the RHI remained as long as stimulation of the two hands was congruent in a hand-centred spatial reference frame, even though the altered posture of the subject’s hand meant that stimulation was incongruent in external space. Conversely, the RHI was reduced when the stimulation was incongruent in hand-centred space but congruent in external space. We conclude that the visual–tactile correlation that causes the RHI is computed within a hand-centred frame of reference, which is updated with changes in body posture. Current sensory evidence about what is ‘me’ is interpreted with respect to a prior mental body representation.',\n",
              "  'authors': ['Marcello Costantini 1', ' Patrick Haggard 2'],\n",
              "  'date': '2007',\n",
              "  'identifier': '1972961786',\n",
              "  'references': [],\n",
              "  'title': 'The rubber hand illusion: sensitivity and reference frame for body ownership.'},\n",
              " {'abstract': 'Part I: Toeplitz Forms: Preliminaries Orthogonal polynomials. Algebraic properties Orthogonal polynomials. Limit properties The trigonometric moment problem Eigenvalues of Toeplitz forms Generalizations and analogs of Toeplitz forms Further generalizations Certain matrices and integral equations of the Toeplitz type Part II: Applications of Toeplitz Forms: Applications to analytic functions Applications to probability theory Applications to statistics Appendix: Notes and references Bibliography Index.',\n",
              "  'authors': ['Ulf Grenander ', ' Gabor Szegö ', ' Mark Kac'],\n",
              "  'date': '1984',\n",
              "  'identifier': '2045463928',\n",
              "  'references': [],\n",
              "  'title': 'Toeplitz forms and their applications'},\n",
              " {'abstract': 'Although the study of visual perception has made more progress in the past 40 years than any other area of cognitive science, there remain major disagreements as to how closely vision is tied to cognition. This target article sets out some of the arguments for both sides (arguments from computer vision, neuroscience, psychophysics, perceptual learning, and other areas of vision science) and defends the position that an important part of visual perception, corresponding to what some people have called early vision, is prohibited from accessing relevant expectations, knowledge, and utilities in determining the function it computes - in other words, it is cognitively im- penetrable. That part of vision is complex and involves top-down interactions that are internal to the early vision system. Its function is to provide a structured representation of the 3-D surfaces of objects sufficient to serve as an index into memory, with somewhat differ- ent outputs being made available to other systems such as those dealing with motor control. The paper also addresses certain concep- tual and methodological issues raised by this claim, such as whether signal detection theory and event-related potentials can be used to assess cognitive penetration of vision. A distinction is made among several stages in visual processing, including, in addition to the inflexible early-vision stage, a pre-per- ceptual attention-allocation stage and a post-perceptual evaluation, selection, and inference stage, which accesses long-term memory. These two stages provide the primary ways in which cognition can affect the outcome of visual perception. The paper discusses argu- ments from computer vision and psychology showing that vision is \"intelligent\" and involves elements of \"problem solving.\" The cases of apparently intelligent interpretation sometimes cited in support of this claim do not show cognitive penetration; rather, they show that certain natural constraints on interpretation, concerned primarily with optical and geometrical properties of the world, have been com- piled into the visual system. The paper also examines a number of examples where instructions and \"hints\" are alleged to affect what is seen. In each case it is concluded that the evidence is more readily assimilated to the view that when cognitive effects are found, they have a locus outside early vision, in such processes as the allocation of focal attention and the identification of the stimulus.',\n",
              "  'authors': ['Zenon Pylyshyn'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2105096388',\n",
              "  'references': ['2120357670',\n",
              "   '1536929369',\n",
              "   '2123341385',\n",
              "   '1898014694',\n",
              "   '1933657216',\n",
              "   '2133735566',\n",
              "   '2098580305',\n",
              "   '2088563966',\n",
              "   '2029740044',\n",
              "   '2152871995'],\n",
              "  'title': 'Is vision continuous with cognition? The case for cognitive impenetrability of visual perception'},\n",
              " {'abstract': 'The literature contains indications of a bias in student evaluations of teaching (SET) against online instruction compared to face-to-face instruction. The present case study consists of content analysis of anonymous student responses to open-ended SET questions submitted by 534 students enrolled in 82 class sections taught by 41 instructors, one online and one face-to-face class section for each instructor. There was no significant difference in the proportion of appraisal text segments by delivery method, suggesting no delivery method bias existed. However, there were significant differences in the proportion of text segments for topical themes and topical categories by delivery method. Implications of the findings for research and practice are presented.',\n",
              "  'authors': ['Henry F. Kelly 1',\n",
              "   ' Michael K. Ponton 2',\n",
              "   ' Alfred P. Rovai 2'],\n",
              "  'date': '2007',\n",
              "  'identifier': '2008266299',\n",
              "  'references': ['1539265701',\n",
              "   '115394847',\n",
              "   '265171692',\n",
              "   '32261593',\n",
              "   '2056203448',\n",
              "   '1555686332',\n",
              "   '1983610490',\n",
              "   '2015092539',\n",
              "   '2041379578',\n",
              "   '1885973872'],\n",
              "  'title': 'A comparison of student evaluations of teaching between online and face-to-face courses'},\n",
              " {'abstract': 'It is shown that training a neural network using a mean-square-error criterion gives network outputs that approximate posterior class probabilities. Based on this probabilistic interpretation of the network operation, information-theoretic training criteria such as maximum mutual information and the Kullback-Liebler measure are investigated. It is shown that both of these criteria are equivalent to the maximum-likelihood estimation (MLE) of the network parameters. MLE of a network allows for the comparison of network models using the Akaike information criterion and the minimum-description length criterion. >',\n",
              "  'authors': ['H. Gish'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2124229187',\n",
              "  'references': ['2054658115', '1877570817', '2140539590', '2140766383'],\n",
              "  'title': 'A probabilistic approach to the understanding and training of neural network classifiers'},\n",
              " {'abstract': 'Because of their occasional need to return to shallow points in a search tree, existing backtracking methods can sometimes erase meaningful progress toward solving a search problem. In this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty. The technique developed is a variant of dependency-directed backtracking that uses only polynomial space while still providing useful control information and retaining the completeness guarantees provided by earlier approaches.',\n",
              "  'authors': ['Matthew L. Ginsberg'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2913258176',\n",
              "  'references': ['1667614912',\n",
              "   '2147096558',\n",
              "   '4326551',\n",
              "   '2038118137',\n",
              "   '2911929719',\n",
              "   '2096138715',\n",
              "   '2170826919',\n",
              "   '1554957931',\n",
              "   '164549',\n",
              "   '2091327243'],\n",
              "  'title': 'Dynamic backtracking'},\n",
              " {'abstract': 'Current studies in density functional theory and density matrix functional theory are reviewed, with special attention to the possible applications within chemistry. Topics discussed include the concept of electronegativity, the concept of an atom in a molecule, calculation of electronegativities from the Xα method, the concept of pressure, Gibbs-Duhem equation, Maxwell relations, stability conditions, and local density functional theory.',\n",
              "  'authors': ['Robert G. Parr'],\n",
              "  'date': '1989',\n",
              "  'identifier': '1550061415',\n",
              "  'references': ['2030976617',\n",
              "   '2044202126',\n",
              "   '2001795256',\n",
              "   '2058762328',\n",
              "   '2082903059',\n",
              "   '1995801559',\n",
              "   '2063518908',\n",
              "   '2050714532',\n",
              "   '2018541907',\n",
              "   '2039524817'],\n",
              "  'title': 'Density-functional theory of atoms and molecules'},\n",
              " {'abstract': 'The responses of parietal visual neurons are markedly increased during attentive fixation, as compared to those evoked in relaxed wakefulness, an effect specific for directed attention and unrelated to putative differences in the general level of arousal. Those responses are also strongly influenced by the angle of gaze, an effect observed only during directed visual attention. The change in response is smoothly graded along a meridian for about one-half the neuron population; the average spatial gradient from maximum to minimum is 78% response for a 20 degrees shift in eye position. No lateral preference was observed. For the remaining half, responses were either maximal or minimal for fixations dead ahead, and changes occurred with deviations in any direction. Angle of gaze effects were observed for neurons with foveal as well as eccentrically located receptive fields, all of which were organized in retinotopic not spatial coordinates. Control experiments showed that the effect was not produced by changes in visual background with changes in the angle of gaze, nor to changes in fixation distance, nor to variations in the intensity of stimuli viewed from different angles. The effect depends upon the position of the eye in the orbit, but is unlikely due to a direct central action of changes in nonretinal orbital afferent activity at different angles of gaze, for the effect was rarely observed with changes in the angle of gaze during relaxed wakefulness without directed visual attention. The evidence supports the interpretation that the effect is produced by a central influence of the systems controlling directed visual attention and the angle of gaze upon those linking the retinae to the parietal lobe.',\n",
              "  'authors': ['RA Andersen ', ' VB Mountcastle'],\n",
              "  'date': '1983',\n",
              "  'identifier': '2098933766',\n",
              "  'references': ['1997953085',\n",
              "   '2123086804',\n",
              "   '2019377328',\n",
              "   '2125733184',\n",
              "   '2098011981',\n",
              "   '1585013154',\n",
              "   '2181613865',\n",
              "   '2118015362',\n",
              "   '1793175812',\n",
              "   '2088744610'],\n",
              "  'title': 'The influence of the angle of gaze upon the excitability of the light- sensitive neurons of the posterior parietal cortex'},\n",
              " {'abstract': 'Abstract An historical discussion is provided of the intellectual trends that caused nineteenth century interdisciplinary studies of physics and psychobiology by leading scientists such as Helmholtz, Maxwell, and Mach to splinter into separate twentieth-century scientific movements. The nonlinear, nonstationary, and nonlocal nature of behavioral and brain data are emphasized. Three sources of contemporary neural network research—the binary, linear, and continuous-nonlinear models—are noted. The remainder of the article describes results about continuous-nonlinear models: Many models of content-addressable memory are shown to be special cases of the Cohen-Grossberg model and global Liapunov function, including the additive, brain-state-in-a-box, McCulloch-Pitts, Boltzmann machine, Hartline-Ratliff-Miller, shunting, masking field, bidirectional associative memory, Volterra-Lotka, Gilpin-Ayala, and Eigen-Schuster models. A Liapunov functional method is described for proving global limit or oscillation theorems for nonlinear competitive systems when their decision schemes are globally consistent or inconsistent, respectively. The former case is illustrated by a model of a globally stable economic market, and the latter case is illustrated by a model of the voting paradox. Key properties of shunting competitive feedback networks are summarized, including the role of sigmoid signalling, automatic gain control, competitive choice and quantization, tunable filtering, total activity normalization, and noise suppression in pattern transformation and memory storage applications. Connections to models of competitive learning, vector quantization, and categorical perception are noted. Adaptive resonance theory (ART) models for self-stabilizing adaptive pattern recognition in response to complex real-time nonstationary input environments are compared with off-line models such as autoassociators, the Boltzmann machine, and back propagation. Special attention is paid to the stability and capacity of these models, and to the role of top-down expectations and attentional processing in the active regulation of both learning and fast information processing. Models whose performance and learning are regulated by internal gating and matching signals, or by external environmentally generated error signals, are contrasted with models whose learning is regulated by external teacher signals that have no analog in natural real-time environments. Examples from sensory-motor control of adaptive vector encoders, adaptive coordinate transformations, adaptive gain control by visual error signals, and automatic generation of synchronous multijoint movement trajectories illustrate the former model types. Internal matching processes are shown capable of discovering several different types of invariant environmental properties. These include ART mechanisms which discover recognition invariants, adaptive vector encoder mechanisms which discover movement invariants, and autoreceptive associative mechanisms which discover invariants of self-regulating target position maps.',\n",
              "  'authors': ['Stephen Grossberg'],\n",
              "  'date': '1988',\n",
              "  'identifier': '1996773027',\n",
              "  'references': ['2581275558',\n",
              "   '2154642048',\n",
              "   '1997063559',\n",
              "   '2293063825',\n",
              "   '1991848143',\n",
              "   '3017143921',\n",
              "   '1554576613',\n",
              "   '1597286183',\n",
              "   '2177721432',\n",
              "   '22297218'],\n",
              "  'title': 'Nonlinear neural networks: Principles, mechanisms, and architectures'},\n",
              " {'abstract': 'Numerical Optimization presents a comprehensive and up-to-date description of the most effective methods in continuous optimization. It responds to the growing interest in optimization in engineering, science, and business by focusing on the methods that are best suited to practical problems. For this new edition the book has been thoroughly updated throughout. There are new chapters on nonlinear interior methods and derivative-free methods for optimization, both of which are used widely in practice and the focus of much current research. Because of the emphasis on practical methods, as well as the extensive illustrations and exercises, the book is accessible to a wide audience. It can be used as a graduate text in engineering, operations research, mathematics, computer science, and business. It also serves as a handbook for researchers and practitioners in the field. The authors have strived to produce a text that is pleasant to read, informative, and rigorous - one that reveals both the beautiful nature of the discipline and its practical side.',\n",
              "  'authors': ['Jorge Nocedal 1', ' Stephen J. Wright 2'],\n",
              "  'date': '2006',\n",
              "  'identifier': '3029645440',\n",
              "  'references': ['2152195021',\n",
              "   '2798766386',\n",
              "   '2109364787',\n",
              "   '2610857016',\n",
              "   '2151554678',\n",
              "   '2124541940',\n",
              "   '2077658674',\n",
              "   '391578156',\n",
              "   '1576347883',\n",
              "   '3124770806'],\n",
              "  'title': 'Numerical Optimization'},\n",
              " {'abstract': 'Most approaches for estimating optical flow assume that, within a finite image region, only a single motion is present. Thissingle motion assumptionis violated in common situations involving transparency, depth discontinuities, independently moving objects, shadows, and specular reflections. To robustly estimate optical flow, the single motion assumption must be relaxed. This paper presents a framework based onrobust estimationthat addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions. We show how therobust estimation frameworkcan be applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions. The approach has been applied to three standard techniques for recovering optical flow: area-based regression, correlation, and regularization with motion discontinuities. This paper focuses on the recovery of multiple parametric motion models within a region, as well as the recovery of piecewise-smooth flow fields, and provides examples with natural and synthetic image sequences.',\n",
              "  'authors': ['Michael J. Black 1', ' P. Anandan 2'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2100315781',\n",
              "  'references': ['1997063559',\n",
              "   '2150134853',\n",
              "   '3003662786',\n",
              "   '2432517183',\n",
              "   '2620619910',\n",
              "   '2129249398',\n",
              "   '2118877769',\n",
              "   '1938714998',\n",
              "   '2796837256',\n",
              "   '2913192828'],\n",
              "  'title': 'The Robust Estimation of Multiple Motions'},\n",
              " {'abstract': 'SUMMARY The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses -the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.',\n",
              "  'authors': ['Yoav Benjamini ', ' Yosef Hochberg'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2110065044',\n",
              "  'references': ['2115012618',\n",
              "   '2121044470',\n",
              "   '2796586415',\n",
              "   '1997917263',\n",
              "   '2036714085',\n",
              "   '2099107563',\n",
              "   '1976018371',\n",
              "   '2123830992',\n",
              "   '2063093012',\n",
              "   '2003972391'],\n",
              "  'title': 'Controlling the false discovery rate: a practical and powerful approach to multiple testing'},\n",
              " {'abstract': 'An adaptive neural network with asymmetric connections is introduced. This network is related to the Hopfield network with graded neurons and uses a recurrent generalization of the \\\\ensuremath{\\\\delta} rule of Rumelhart, Hinton, and Williams to modify adaptively the synaptic weights. The new network bears a resemblance to the master/slave network of Lapedes and Farber but it is architecturally simpler.',\n",
              "  'authors': ['Fernando J. Pineda'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2007431958',\n",
              "  'references': ['1652505363', '2177721432', '2075510082'],\n",
              "  'title': 'Generalization of back-propagation to recurrent neural networks.'},\n",
              " {'abstract': 'Factor analysis in several populations, covariance structure models, three-mode factor analysis, structural equation systems with measurement model, and analysis of covariance with measurement model are all shown to be specializations of a general moment structure model published previously in this journal. Some new structured linear models are also described; they may be considered either generalizations or special cases of existing models. Simple representations are developed for complex linear models, and some applications to behavioral data are cited.',\n",
              "  'authors': ['Peter M. Bentler ', ' David G. Weeks'],\n",
              "  'date': '1979',\n",
              "  'identifier': '1990967863',\n",
              "  'references': ['1987258130',\n",
              "   '2149608872',\n",
              "   '2084062768',\n",
              "   '1972999672',\n",
              "   '2168659786',\n",
              "   '2061214267',\n",
              "   '2057237814',\n",
              "   '2131217004',\n",
              "   '2056877099',\n",
              "   '2605943844'],\n",
              "  'title': 'Interrelations Among Models For The Analysis Of Moment Structures'},\n",
              " {'abstract': \"The authors present random early detection (RED) gateways for congestion avoidance in packet-switched networks. The gateway detects incipient congestion by computing the average queue size. The gateway could notify connections of congestion either by dropping packets arriving at the gateway or by setting a bit in packet headers. When the average queue size exceeds a present threshold, the gateway drops or marks each arriving packet with a certain probability, where the exact probability is a function of the average queue size. RED gateways keep the average queue size low while allowing occasional bursts of packets in the queue. During congestion, the probability that the gateway notifies a particular connection to reduce its window is roughly proportional to that connection's share of the bandwidth through the gateway. RED gateways are designed to accompany a transport-layer congestion control protocol such as TCP. The RED gateway has no bias against bursty traffic and avoids the global synchronization of many connections decreasing their window at the same time. Simulations of a TCP/IP network are used to illustrate the performance of RED gateways. >\",\n",
              "  'authors': ['Sally Floyd ', ' Van Jacobson'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2158733823',\n",
              "  'references': ['2753542457',\n",
              "   '2571446175',\n",
              "   '2104820473',\n",
              "   '2050353731',\n",
              "   '2098289156',\n",
              "   '2011730388',\n",
              "   '1993549051',\n",
              "   '2096597645',\n",
              "   '2096812769',\n",
              "   '1556522047'],\n",
              "  'title': 'Random early detection gateways for congestion avoidance'},\n",
              " {'abstract': 'The successive refinement of information consists of first approximating data using a few bits of information, then iteratively improving the approximation as more and more information is supplied. The goal is to achieve an optimal description at each stage. In general, an ongoing description which is rate-distortion optimal whenever it is interrupted is sought. It is shown that in order to achieve optimal successive refinement the necessary and sufficient conditions are that the solutions of the rate distortion problem can be written as a Markov chain. In particular, all finite alphabet signals with Hamming distortion satisfy these requirements. It is also shown that the same is true for Gaussian signals with squared error distortion and for Laplacian signals with absolute error distortion. A simple counterexample with absolute error distortion and a symmetric source distribution which shows that successive refinement is not always achievable is presented. >',\n",
              "  'authors': ['W.H.R. Equitz 1', ' T.M. Cover 2'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2151252184',\n",
              "  'references': ['2130305844',\n",
              "   '2123095296',\n",
              "   '2011564903',\n",
              "   '2138571053',\n",
              "   '2109808436',\n",
              "   '1990531224',\n",
              "   '2113331866',\n",
              "   '2156117528',\n",
              "   '2062540956',\n",
              "   '1966065707'],\n",
              "  'title': 'Successive refinement of information'},\n",
              " {'abstract': 'We describe the results of extensive experiments using optimized rule-based induction methods on large document collections. The goal of these methods is to discover automatically classification patterns that can be used for general document categorization or personalized filtering of free text. Previous reports indicate that human-engineered rule-based systems, requiring many man-years of developmental efforts, have been successfully built to “read” documents and assign topics to them. We show that machine-generated decision rules appear comparable to human performance, while using the identical rule-based representation. In comparison with other machine-learning techniques, results on a key benchmark from the Reuters collection show a large gain in performance, from a previously reported 67% recall/precision breakeven point to 80.5%. In the context of a very high-dimensional feature space, several methodological alternatives are examined, including universal versus local dictionaries, and binary versus frequency-related features.',\n",
              "  'authors': ['Chidanand Apté 1', ' Fred Damerau 1', ' Sholom M. Weiss 2'],\n",
              "  'date': '1994',\n",
              "  'identifier': '2094934653',\n",
              "  'references': ['1593045043',\n",
              "   '2136000097',\n",
              "   '2128420091',\n",
              "   '2137719099',\n",
              "   '1527532036',\n",
              "   '2042986967',\n",
              "   '2126502509',\n",
              "   '1570286060',\n",
              "   '1993934121',\n",
              "   '2043772506'],\n",
              "  'title': 'Automated learning of decision rules for text categorization'},\n",
              " {'abstract': \"The relative efficiency of any particular image-coding scheme should be defined only in relation to the class of images that the code is likely to encounter. To understand the representation of images by the mammalian visual system, it might therefore be useful to consider the statistics of images from the natural environment (i.e., images with trees, rocks, bushes, etc). In this study, various coding schemes are compared in relation to how they represent the information in such natural images. The coefficients of such codes are represented by arrays of mechanisms that respond to local regions of space, spatial frequency, and orientation (Gabor-like transforms). For many classes of image, such codes will not be an efficient means of representing information. However, the results obtained with six natural images suggest that the orientation and the spatial-frequency tuning of mammalian simple cells are well suited for coding the information in such images if the goal of the code is to convert higher-order redundancy (e.g., correlation between the intensities of neighboring pixels) into first-order redundancy (i.e., the response distribution of the coefficients). Such coding produces a relatively high signal-to-noise ratio and permits information to be transmitted with only a subset of the total number of cells. These results support Barlow's theory that the goal of natural vision is to represent the information in the natural environment with minimal redundancy.\",\n",
              "  'authors': ['David J. Field'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2167034998',\n",
              "  'references': ['2003370853',\n",
              "   '2006500012',\n",
              "   '1995875735',\n",
              "   '2078498116',\n",
              "   '1499486838',\n",
              "   '2116360511',\n",
              "   '2135587681',\n",
              "   '2138100172',\n",
              "   '1999908130',\n",
              "   '1964415410'],\n",
              "  'title': 'Relations between the statistics of natural images and the response properties of cortical cells.'},\n",
              " {'abstract': 'We introduce a new distance between two distributions that we call the Earth Mover\\'s Distance (EMD), which reflects the minimal amount of work that must be performed to transform one distribution into the other by moving \"distribution mass\" around. This is a special case of the transportation problem from linear optimization, for which efficient algorithms are available. The EMD also allows for partial matching. When used to compare distributions that have the same overall mass, the EMD is a true metric, and has easy-to-compute lower bounds. In this paper we focus on applications to image databases, especially color and texture. We use the EMD to exhibit the structure of color-distribution and texture spaces by means of Multi-Dimensional Scaling displays. We also propose a novel approach to the problem of navigating through a collection of color images, which leads to a new paradigm for image database search.',\n",
              "  'authors': ['Y. Rubner ', ' C. Tomasi ', ' L.J. Guibas'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2125101937',\n",
              "  'references': ['2914885528',\n",
              "   '2125148312',\n",
              "   '2093191240',\n",
              "   '1969294188',\n",
              "   '2138584058',\n",
              "   '2059975159',\n",
              "   '2152825437',\n",
              "   '1988445395',\n",
              "   '1526351017',\n",
              "   '1608339372'],\n",
              "  'title': 'A metric for distributions with applications to image databases'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Geoffrey E. Hinton'],\n",
              "  'date': '1989',\n",
              "  'identifier': '145476170',\n",
              "  'references': ['1652505363', '2073257493', '1539686131', '2013239224'],\n",
              "  'title': 'Learning distributed representations of concepts.'},\n",
              " {'abstract': '',\n",
              "  'authors': ['J. R. Stroop'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2120357670',\n",
              "  'references': ['2970689268',\n",
              "   '2327714462',\n",
              "   '2054923368',\n",
              "   '2075013666',\n",
              "   '1995460504',\n",
              "   '2065385668',\n",
              "   '1982142465',\n",
              "   '1978262670',\n",
              "   '2498811023',\n",
              "   '2030826745'],\n",
              "  'title': 'Studies of interference in serial verbal reactions.'},\n",
              " {'abstract': 'This article considers the role of the hippocampus in memory function. A central thesis is that work with rats, monkeys, and humans--which has sometimes seemed to proceed independently in 3 separate literatures--is now largely in agreement about the function of the hippocampus and related structures. A biological perspective is presented, which proposes multiple memory systems with different functions and distinct anatomical organizations. The hippocampus (together with anatomically related structures) is essential for a specific kind of memory, here termed declarative memory (similar terms include explicit and relational). Declarative memory is contrasted with a heterogeneous collection of nondeclarative (implicit) memory abilities that do not require the hippocampus (skills and habits, simple conditioning, and the phenomenon of priming). The hippocampus is needed temporarily to bind together distributed sites in neocortex that together represent a whole memory.',\n",
              "  'authors': ['Larry R. Squire'],\n",
              "  'date': '1992',\n",
              "  'identifier': '1984214648',\n",
              "  'references': ['2098580305',\n",
              "   '1601242444',\n",
              "   '2103692957',\n",
              "   '2076425653',\n",
              "   '1519522181',\n",
              "   '2381723125',\n",
              "   '2166869510',\n",
              "   '2047431989',\n",
              "   '1681844354',\n",
              "   '1523723941'],\n",
              "  'title': 'Memory and the hippocampus: A synthesis from findings with rats, monkeys, and humans.'},\n",
              " {'abstract': 'Topology optimization of structures and composite continua has two main subfields: Layout Optimization (LO) deals with grid-like structures having very low volume fractions and Generalized Shape Optimization (GSO) is concerned with higher volume fractions, optimizing simultaneously the topology and shape of internal boundaries of porous or composite continua. The solutions for both problem classes can be exact/analytical or discretized/FE-based. This review article discusses FE-based generalized shape optimization, which can be classified with respect to the types of topologies involved, namely Isotropic-Solid/Empty (ISE), Anisotropic-Solid/Empty (ASE), and Isotropic-Solid/Empty/Porous (ISEP) topologies. Considering in detail the most important class of (i.e. ISE) topologies, the computational efficiency of various solution strategies, such as SIMP (Solid Isotropic Microstructure with Penalization), OMP (Optimal Microstructure with Penalization) and NOM (NonOptimal Microstructures) are compared. The SIMP method was proposed under the terms \"direct approach\" or \"artificial density approach\" by Bendsoe over a decade ago; it was derived independently, used extensively and promoted by the author\\'s research group since 1990. The term \"SIMP\" was introducted by the author in 1992. After being out of favour with most other research schools until recently, SIMP is becoming generally accepted in topology optimization as a technique of considerable advantages. It seems, therefore, useful to review in greater detail the origins, theoretical background, history, range of validity and major advantages of this method.',\n",
              "  'authors': ['G. I. N. Rozvany'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2118555989',\n",
              "  'references': ['2069697210',\n",
              "   '2137726847',\n",
              "   '2122397978',\n",
              "   '2092801729',\n",
              "   '2158862486',\n",
              "   '2062523101',\n",
              "   '2086620292',\n",
              "   '2071910487',\n",
              "   '2004945242',\n",
              "   '2024978924'],\n",
              "  'title': 'Aims, scope, methods, history and unified terminology of computer-aided topology optimization in structural mechanics'},\n",
              " {'abstract': 'Abstract This paper presents an unsupervised texture segmentation method, which uses distributions of local binary patterns and pattern contrasts for measuring the similarity of adjacent image regions during the segmentation process. Nonparametric log-likelihood test, the G statistic, is engaged as a pseudo-metric for comparing feature distributions. A region-based algorithm is developed for coarse image segmentation and a pixelwise classification scheme for improving localization of region boundaries. The performance of the method is evaluated with various types of test images.',\n",
              "  'authors': ['Timo Ojala ', ' Matti Pietikäinen'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2028652181',\n",
              "  'references': ['1984792953',\n",
              "   '2115313253',\n",
              "   '2100503224',\n",
              "   '2159988601',\n",
              "   '2158061095',\n",
              "   '1993655741',\n",
              "   '2024212834',\n",
              "   '2056052642',\n",
              "   '2122524329',\n",
              "   '2438939487'],\n",
              "  'title': 'Unsupervised texture segmentation using feature distributions'},\n",
              " {'abstract': 'What determines what we see? In contrast to the traditional \"modular\" understanding of perception, according to which visual processing is encapsulated from higher-level cognition, a tidal wave of recent research alleges that states such as beliefs, desires, emotions, motivations, intentions, and linguistic representations exert direct top-down influences on what we see. There is a growing consensus that such effects are ubiquitous, and that the distinction between perception and cognition may itself be unsustainable. We argue otherwise: none of these hundreds of studies - either individually or collectively - provide compelling evidence for true top-down effects on perception, or \"cognitive penetrability\". In particular, and despite their variety, we suggest that these studies all fall prey to only a handful of pitfalls. And whereas abstract theoretical challenges have failed to resolve this debate in the past, our presentation of these pitfalls is empirically anchored: in each case, we show not only how certain studies could be susceptible to the pitfall (in principle), but how several alleged top-down effects actually are explained by the pitfall (in practice). Moreover, these pitfalls are perfectly general, with each applying to dozens of other top-down effects. We conclude by extracting the lessons provided by these pitfalls into a checklist that future work could use to convincingly demonstrate top-down effects on visual perception. The discovery of substantive top-down effects of cognition on perception would revolutionize our understanding of how the mind is organized; but without addressing these pitfalls, no such empirical report will license such exciting conclusions. Language: en',\n",
              "  'authors': ['Chaz Firestone ', ' Brian J. Scholl'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2129245434',\n",
              "  'references': ['2153791616',\n",
              "   '2056046632',\n",
              "   '1641311894',\n",
              "   '2118125647',\n",
              "   '1620203002',\n",
              "   '1996938738',\n",
              "   '1998151455',\n",
              "   '2170214771',\n",
              "   '2010055427',\n",
              "   '2008372697'],\n",
              "  'title': 'Cognition does not affect perception: Evaluating the evidence for \"top-down\" effects.'},\n",
              " {'abstract': 'Cluster ensemble has proved to be a good alternative when facing cluster analysis problems. It consists of generating a set of clusterings from the same dataset and combining them into a final clustering. The goal of this combination process is to improve the quality of individual data clusterings. Due to the increasing appearance of new methods, their promising results and the great number of applications, we consider that it is necessary to make a critical analysis of the existing techniques and future projections. This paper presents an overview of clustering ensemble methods that can be very useful for the community of clustering practitioners. The characteristics of several methods are discussed, which may help in the selection of the most appropriate one to solve a problem at hand. We also present a taxonomy of these techniques and illustrate some important applications.',\n",
              "  'authors': ['Sandro Vega-Pons ', ' José Ruiz-Shulcloper'],\n",
              "  'date': '2011',\n",
              "  'identifier': '2002767255',\n",
              "  'references': ['1992419399',\n",
              "   '2581275558',\n",
              "   '2165874743',\n",
              "   '1560724230',\n",
              "   '2153233077',\n",
              "   '1579271636',\n",
              "   '2125637308',\n",
              "   '2097645701',\n",
              "   '2488678869',\n",
              "   '2070232376'],\n",
              "  'title': 'A SURVEY OF CLUSTERING ENSEMBLE ALGORITHMS'},\n",
              " {'abstract': 'This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.',\n",
              "  'authors': ['John Canny'],\n",
              "  'date': '1986',\n",
              "  'identifier': '2145023731',\n",
              "  'references': ['2003370853',\n",
              "   '1995756857',\n",
              "   '1968245656',\n",
              "   '2130355536',\n",
              "   '2002882922',\n",
              "   '2007057443',\n",
              "   '1533832053',\n",
              "   '1555351000',\n",
              "   '128364430',\n",
              "   '2016396776'],\n",
              "  'title': 'A Computational Approach to Edge Detection'},\n",
              " {'abstract': 'It is highly desirable that the security and stability of electric power systems after exposure to large disturbances be assessable. In this connection, the critical clearing time (CCT) is an attribute which provides significant information about the quality of the post-fault system behavior. It may be regarded as a complex mapping of the prefault, fault-on, and post-fault system conditions in the time domain. Y.-H. Pao and D.J. Solajic (1989) showed that a feedforward neural network can be used to learn this mapping and successfully perform under variable system operating conditions and topologies. In that work the system was described in terms of some conventionally used parameters. In contrast to using those pragmatic features selected on the basis of the engineering understanding of the problem, the possibility of using unsupervised and supervised learning paradigms to discover what combination of raw measurements are significant in determining CCT is considered. Correlation analysis and Euclidean metric are used to specify interfeature dependencies. An example of a 4-machine power system is used to illustrate the suggested approach. >',\n",
              "  'authors': ['Y.-H. Pao ', ' D.J. Sobajic'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2113229797',\n",
              "  'references': ['2154642048',\n",
              "   '2042264548',\n",
              "   '2293063825',\n",
              "   '2177721432',\n",
              "   '65738273',\n",
              "   '1541274513',\n",
              "   '2152477898',\n",
              "   '2158053363',\n",
              "   '2077662993',\n",
              "   '186975152'],\n",
              "  'title': 'Combined use of unsupervised and supervised learning for dynamic security assessment'},\n",
              " {'abstract': '',\n",
              "  'authors': ['John C. Platt'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1618905105',\n",
              "  'references': ['2153635508',\n",
              "   '2122646361',\n",
              "   '1648445109',\n",
              "   '2964212410',\n",
              "   '1825604117',\n",
              "   '2115150266',\n",
              "   '1999954155',\n",
              "   '1510526001',\n",
              "   '2115252128'],\n",
              "  'title': 'Probabilistic Outputs for Support vector Machines and Comparisons to Regularized Likelihood Methods'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Ulf Grenander'],\n",
              "  'date': '1978',\n",
              "  'identifier': '94647076',\n",
              "  'references': ['1997063559',\n",
              "   '1993845689',\n",
              "   '1992192543',\n",
              "   '3022628558',\n",
              "   '2093976044',\n",
              "   '1558012644',\n",
              "   '1998563636',\n",
              "   '85976583',\n",
              "   '1983649039',\n",
              "   '2962701695'],\n",
              "  'title': 'Lectures in pattern theory'},\n",
              " {'abstract': 'The proliferation of topic hierarchies for text documents has resulted in a need for tools that automatically classify new documents within such hierarchies. One can use existing classifiers by ignoring the hierarchical structure, treating the topics as separate classes. Unfortunately, in the context of text categorization, we are faced with a large number of classes and a huge number of relevant features needed to distinguish between them. Consequently, we are restricted to using only very simple classifiers, both because of computational cost and the tendency of complex models to overfit. We propose an approach that utilizes the hierarchical topic structure to decompose the classification task into a set of simpler problems, one at each node in the classification tree. As we show, each of these smaller problems can be solved accurately by focusing only on a very small set of features, those relevant to the task at hand. This set of relevant features varies widely throughout the hierarchy, so that, while the overall relevant feature set may be large, each classifier only examines a small subset. The use of reduced feature sets allows us to utilize more complex (probabilistic) models, without encountering the computational and robustness difficulties described above.',\n",
              "  'authors': ['Daphne Koller ', ' Mehran Sahami'],\n",
              "  'date': '1997',\n",
              "  'identifier': '1620204465',\n",
              "  'references': ['2118020653',\n",
              "   '2150102617',\n",
              "   '2097089247',\n",
              "   '2053463056',\n",
              "   '2005422315',\n",
              "   '1550206324',\n",
              "   '2108991785',\n",
              "   '1651093245',\n",
              "   '1648885110'],\n",
              "  'title': 'Hierarchically Classifying Documents Using Very Few Words'},\n",
              " {'abstract': 'A simple, nonrigorous, synthetic view of wavelet theory is presented for both review and tutorial purposes. The discussion includes nonstationary signal analysis, scale versus frequency, wavelet analysis and synthesis, scalograms, wavelet frames and orthonormal bases, the discrete-time case, and applications of wavelets in signal processing. The main definitions and properties of wavelet transforms are covered, and connections among the various fields where results have been developed are shown. >',\n",
              "  'authors': ['O. Rioul ', ' M. Vetterli'],\n",
              "  'date': '1991',\n",
              "  'identifier': '1970352604',\n",
              "  'references': ['2132984323',\n",
              "   '2098914003',\n",
              "   '1996021349',\n",
              "   '2103504761',\n",
              "   '2165878107',\n",
              "   '3005363104',\n",
              "   '1980149518',\n",
              "   '2166982406',\n",
              "   '2149072817',\n",
              "   '2094585768'],\n",
              "  'title': 'Wavelets and signal processing'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Ronald J. Williams ', ' David Zipser'],\n",
              "  'date': '1995',\n",
              "  'identifier': '1674799117',\n",
              "  'references': ['2064675550',\n",
              "   '1810943226',\n",
              "   '2144499799',\n",
              "   '2136848157',\n",
              "   '1828163288',\n",
              "   '1735317348',\n",
              "   '2079735306',\n",
              "   '3099873379',\n",
              "   '2147568880'],\n",
              "  'title': 'Gradient-based learning algorithms for recurrent networks and their computational complexity'},\n",
              " {'abstract': 'Using the analytical logic underlying the classical adopter categorization approach proposed by Rogers, the authors suggest that adopter categories for a product innovation can also be developed by...',\n",
              "  'authors': ['Vijay Mahajan 1',\n",
              "   ' Eitan Muller 2',\n",
              "   ' Rajendra Kumar Srivastava 3'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2090254306',\n",
              "  'references': ['1991567646',\n",
              "   '2265720734',\n",
              "   '2316166305',\n",
              "   '2074661292',\n",
              "   '1505037116',\n",
              "   '2016535321',\n",
              "   '2045988471',\n",
              "   '1982329432',\n",
              "   '2106616952',\n",
              "   '2325808677'],\n",
              "  'title': 'Determination of Adopter Categories by Using Innovation Diffusion Models'},\n",
              " {'abstract': 'We consider image transformation problems, where an input image is transformed into an output image. Recent methods for such problems typically train feed-forward convolutional neural networks using a per-pixel loss between the output and ground-truth images. Parallel work has shown that high-quality images can be generated by defining and optimizing perceptual loss functions based on high-level features extracted from pretrained networks. We combine the benefits of both approaches, and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks. We show results on image style transfer, where a feed-forward network is trained to solve the optimization problem proposed by Gatys et al. in real-time. Compared to the optimization-based method, our network gives similar qualitative results but is three orders of magnitude faster. We also experiment with single-image super-resolution, where replacing a per-pixel loss with a perceptual loss gives visually pleasing results.',\n",
              "  'authors': ['Justin Johnson ', ' Alexandre Alahi ', ' Li Fei-Fei'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2331128040',\n",
              "  'references': ['2194775991',\n",
              "   '2962835968',\n",
              "   '2964121744',\n",
              "   '1836465849',\n",
              "   '2117539524',\n",
              "   '1903029394',\n",
              "   '2133665775',\n",
              "   '1861492603',\n",
              "   '2963684088',\n",
              "   '2964153729'],\n",
              "  'title': 'Perceptual Losses for Real-Time Style Transfer and Super-Resolution'},\n",
              " {'abstract': '',\n",
              "  'authors': ['David Gevaux'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2044405977',\n",
              "  'references': ['2165460636',\n",
              "   '2211842592',\n",
              "   '1984630246',\n",
              "   '2049910414',\n",
              "   '2036409383',\n",
              "   '3007995327',\n",
              "   '1940974336',\n",
              "   '1993109166',\n",
              "   '2161502586',\n",
              "   '2053656764'],\n",
              "  'title': 'Exhibition: A life decoded'},\n",
              " {'abstract': 'A new information-theoretic approach is presented for finding the pose of an object in an image. The technique does not require information about the surface properties of the object, besides its shape, and is robust with respect to variations of illumination. In our derivation few assumptions are made about the nature of the imaging process. As a result the algorithms are quite general and may foreseeably be used in a wide variety of imaging situations. Experiments are presented that demonstrate the approach registering magnetic resonance (MR) images, aligning a complex 3D object model to real scenes including clutter and occlusion, tracking a human head in a video sequence and aligning a view-based 2D object model to real images. The method is based on a formulation of the mutual information between the model and the image. As applied here the technique is intensity-based, rather than feature-based. It works well in domains where edge or gradient-magnitude based methods have difficulty, yet it is more robust than traditional correlation. Additionally, it has an efficient implementation that is based on stochastic approximation.',\n",
              "  'authors': ['Paul Viola ', ' William M. Wells'],\n",
              "  'date': '1997',\n",
              "  'identifier': '1874027545',\n",
              "  'references': ['2124776405',\n",
              "   '2099111195',\n",
              "   '2098693229',\n",
              "   '3017143921',\n",
              "   '2911709767',\n",
              "   '1535810436',\n",
              "   '1540723801',\n",
              "   '1996773532',\n",
              "   '1686754659',\n",
              "   '1771671527'],\n",
              "  'title': 'Alignment by Maximization of Mutual Information'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Lloyd R. Peterson ', ' Margaret Jean Peterson'],\n",
              "  'date': '1959',\n",
              "  'identifier': '2088974767',\n",
              "  'references': ['1999147675',\n",
              "   '2030096042',\n",
              "   '1998654733',\n",
              "   '2320642236',\n",
              "   '2153297147',\n",
              "   '2005653771',\n",
              "   '1976016228',\n",
              "   '2014071828',\n",
              "   '3028593536'],\n",
              "  'title': 'Short-term retention of individual verbal items.'},\n",
              " {'abstract': 'From the Publisher: The accessible presentation of this book gives both a general view of the entire computer vision enterprise and also offers sufficient detail to be able to build useful applications. Users learn techniques that have proven to be useful by first-hand experience and a wide range of mathematical methods. A CD-ROM with every copy of the text contains source code for programming practice, color images, and illustrative movies. Comprehensive and up-to-date, this book includes essential topics that either reflect practical significance or are of theoretical importance. Topics are discussed in substantial and increasing depth. Application surveys describe numerous important application areas such as image based rendering and digital libraries. Many important algorithms broken down and illustrated in pseudo code. Appropriate for use by engineers as a comprehensive reference to the computer vision enterprise.',\n",
              "  'authors': ['David A. Forsyth ', ' Jean Ponce'],\n",
              "  'date': '2002',\n",
              "  'identifier': '1508960934',\n",
              "  'references': ['1666447063',\n",
              "   '2132947399',\n",
              "   '2137471889',\n",
              "   '2170140722',\n",
              "   '2121193292',\n",
              "   '2082991751',\n",
              "   '2137918516',\n",
              "   '2149077040',\n",
              "   '2963488291'],\n",
              "  'title': 'Computer Vision: A Modern Approach'},\n",
              " {'abstract': 'Systems for inducing concept descriptions from examples are valuable tools for assisting in the task of knowledge acquisition for expert systems. This paper presents a description and empirical evaluation of a new induction system, CN2, designed for the efficient induction of simple, comprehensible production rules in domains where problems of poor description language and/or noise may be present. Implementations of the CN2, ID3, and AQ algorithms are compared on three medical classification tasks.',\n",
              "  'authors': ['Peter Clark ', ' Tim Niblett'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2136000097',\n",
              "  'references': ['2128420091',\n",
              "   '1596324102',\n",
              "   '2159047538',\n",
              "   '2428981601',\n",
              "   '1570286060',\n",
              "   '128754594',\n",
              "   '1567276288',\n",
              "   '177590838',\n",
              "   '3021257214',\n",
              "   '2796339269'],\n",
              "  'title': 'The CN2 Induction Algorithm'},\n",
              " {'abstract': 'Abstract A unifying approach is proposed to studying the distributions of eigenvalues and singular values of Toeplitz matrices associated with a Fourier series, and multilevel Toeplitz matrices associated with a multidimensional Fourier series. Obtained are the extensions of the Szego and Avram-Parter theorems, where the generating function is now required to belong to L 2 , and not necessarily to L ∞ . Analogous extensions are given for multilevel Toeplitz matrices. In particular, it is proved that if f ( x 1 , …, x p )∈ L 2 , then the p -level (complex) Toeplitz matrices allied with f have their singular values distributed as | f ( x 1 , …, x p )|. The distribution results for the Cesaro (optimal) circulants hold even if f ∈ L 1 . Also suggested are new theorems on clustering that have to do with the preconditioning of multilevel Toeplitz matrices by multilevel circulants.',\n",
              "  'authors': ['Evgenij E. Tyrtyshnikov'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2089598668',\n",
              "  'references': ['2798909945',\n",
              "   '2045463928',\n",
              "   '2080097309',\n",
              "   '1533471646',\n",
              "   '2138152282',\n",
              "   '1975696503',\n",
              "   '2009501332',\n",
              "   '1991469062',\n",
              "   '2025799417',\n",
              "   '2003887018'],\n",
              "  'title': 'A unifying approach to some old and new theorems on distribution and clustering'},\n",
              " {'abstract': 'The speech recognition problem hidden Markov models the acoustic model basic language modelling the Viterbi search hypothesis search on a tree and the fast match elements of information theory the complexity of tasks - the quality of language models the expectation - maximization algorithm and its consequences decision trees and tree language models phonetics from orthography - spelling-to-base from mappings triphones and allophones maximum entropy probability estimation and language models three applications of maximum entropy estimation to language modelling estimation of probabilities from counts and the Back-Off method.',\n",
              "  'authors': ['Frederick Jelinek'],\n",
              "  'date': '1997',\n",
              "  'identifier': '1508165687',\n",
              "  'references': ['1560013842', '1980862600'],\n",
              "  'title': 'Statistical methods for speech recognition'},\n",
              " {'abstract': 'There are many papers that present the problems of educational videos: need of a high number of resources to create them, excess of information in the majority of videos, gaps of information between videos and the rest of materials of the courses, etc. This paper introduces the concept ‘low-cost educational video’, which attempts to solve to a large extent the problems that have been identified in the educational videos. To this end, an empirical research is conducted with 487 students and various lecturers and professors in three undergraduate degrees: Mechanical Engineering, Industrial Engineering and Management (in face-to-face as well as semi-distance modalities), and Aeronautical Engineering at the Universitat Politecnica de Catalunya (Spain). In order to achieve this goal, we introduce the process and the required resources for the creation and the diffusion of these low-cost educational videos. The results are analysed taking a literature-based questionnaire as a starting point and within the principles of good practice in higher education framework. The main research findings revealed an improved student motivation and an increase of the perceived efficiency in the learning and teaching processes, without substantially raising costs.',\n",
              "  'authors': ['Federico Garriga Garzón ',\n",
              "   ' Manuel Rajadell Carreras ',\n",
              "   ' Daniel García-Almiñana ',\n",
              "   ' Albert Sunyer Torrents ',\n",
              "   ' Vicenç Fernández Alarcón ',\n",
              "   ' Pep Simó Guzmán ',\n",
              "   ' Inés María Algaba Joaquín ',\n",
              "   ' Maria Albareda Sambola ',\n",
              "   ' Maria Núria Salán Ballesteros ',\n",
              "   ' Beatriz Amante García ',\n",
              "   ' Cristina Mihaela Enache ',\n",
              "   ' Edna Rocío Bravo Ibarra'],\n",
              "  'date': '2011',\n",
              "  'identifier': '3125126645',\n",
              "  'references': ['3022468393',\n",
              "   '1481340920',\n",
              "   '2120873112',\n",
              "   '2086655119',\n",
              "   '2014790997',\n",
              "   '2053067298',\n",
              "   '1512735724',\n",
              "   '2040748992',\n",
              "   '2026552288',\n",
              "   '2050751587'],\n",
              "  'title': \"Low-Cost educational videos' for engineering students: a new concept based on video streaming and Youtube channels\"},\n",
              " {'abstract': 'This paper presents a critique of expected utility theory as a descriptive model of decision making under risk, and develops an alternative model, called prospect theory. Choices among risky prospects exhibit several pervasive effects that are inconsistent with the basic tenets of utility theory. In particular, people underweight outcomes that are merely probable in comparison with outcomes that are obtained with certainty. This tendency, called the certainty effect, contributes to risk aversion in choices involving sure gains and to risk seeking in choices involving sure losses. In addition, people generally discard components that are shared by all prospects under consideration. This tendency, called the isolation effect, leads to inconsistent preferences when the same choice is presented in different forms. An alternative theory of choice is developed, in which value is assigned to gains and losses rather than to final assets and in which probabilities are replaced by decision weights. The value function is normally concave for gains, commonly convex for losses, and is generally steeper for losses than for gains. Decision weights are generally lower than the corresponding probabilities, except in the range of low prob- abilities. Overweighting of low probabilities may contribute to the attractiveness of both insurance and gambling. EXPECTED UTILITY THEORY has dominated the analysis of decision making under risk. It has been generally accepted as a normative model of rational choice (24), and widely applied as a descriptive model of economic behavior, e.g. (15, 4). Thus, it is assumed that all reasonable people would wish to obey the axioms of the theory (47, 36), and that most people actually do, most of the time. The present paper describes several classes of choice problems in which preferences systematically violate the axioms of expected utility theory. In the light of these observations we argue that utility theory, as it is commonly interpreted and applied, is not an adequate descriptive model and we propose an alternative account of choice under risk. 2. CRITIQUE',\n",
              "  'authors': ['Daniel Kahneman ', ' Amos Tversky'],\n",
              "  'date': '1979',\n",
              "  'identifier': '2133469585',\n",
              "  'references': ['1989959848',\n",
              "   '158727920',\n",
              "   '1986808060',\n",
              "   '2991769409',\n",
              "   '2580645530',\n",
              "   '2808650095',\n",
              "   '1566309000',\n",
              "   '2145170747',\n",
              "   '1604526811',\n",
              "   '1965761421'],\n",
              "  'title': 'PROSPECT THEORY: AN ANALYSIS OF DECISION UNDER RISK'},\n",
              " {'abstract': 'We consider the problem of discovering association rules between items in a large database of sales transactions. We present two new algorithms for solving thii problem that are fundamentally different from the known algorithms. Empirical evaluation shows that these algorithms outperform the known algorithms by factors ranging from three for small problems to more than an order of magnitude for large problems. We also show how the best features of the two proposed algorithms can be combined into a hybrid algorithm, called AprioriHybrid. Scale-up experiments show that AprioriHybrid scales linearly with the number of transactions. AprioriHybrid also has excellent scale-up properties with respect to the transaction size and the number of items in the database.',\n",
              "  'authors': ['Rakesh Agrawal ', ' Ramakrishnan Srikant'],\n",
              "  'date': '1998',\n",
              "  'identifier': '1484413656',\n",
              "  'references': ['2166559705',\n",
              "   '2125055259',\n",
              "   '3085162807',\n",
              "   '1506285740',\n",
              "   '2159080219',\n",
              "   '1594031697',\n",
              "   '1504694836',\n",
              "   '2008906462',\n",
              "   '2100406636',\n",
              "   '1499049447'],\n",
              "  'title': 'Fast algorithms for mining association rules'},\n",
              " {'abstract': \"Accurate and reliable predictions of infectious disease dynamics can be valuable to public health organizations that plan interventions to decrease or prevent disease transmission. A great variety of models have been developed for this task, using different model structures, covariates, and targets for prediction. Experience has shown that the performance of these models varies; some tend to do better or worse in different seasons or at different points within a season. Ensemble methods combine multiple models to obtain a single prediction that leverages the strengths of each model. We considered a range of ensemble methods that each form a predictive density for a target of interest as a weighted sum of the predictive densities from component models. In the simplest case, equal weight is assigned to each component model; in the most complex case, the weights vary with the region, prediction target, week of the season when the predictions are made, a measure of component model uncertainty, and recent observations of disease incidence. We applied these methods to predict measures of influenza season timing and severity in the United States, both at the national and regional levels, using three component models. We trained the models on retrospective predictions from 14 seasons (1997/1998-2010/2011) and evaluated each model's prospective, out-of-sample performance in the five subsequent influenza seasons. In this test phase, the ensemble methods showed average performance that was similar to the best of the component models, but offered more consistent performance across seasons than the component models. Ensemble methods offer the potential to deliver more reliable predictions to public health decision makers.\",\n",
              "  'authors': ['Evan L. Ray 1', ' 2', ' Nicholas G. Reich 1'],\n",
              "  'date': '2018',\n",
              "  'identifier': '2604976044',\n",
              "  'references': ['2582743722',\n",
              "   '1554944419',\n",
              "   '1678356000',\n",
              "   '2129905273',\n",
              "   '2025720061',\n",
              "   '2167917621',\n",
              "   '2116512828',\n",
              "   '28412257',\n",
              "   '2148330046',\n",
              "   '2143469080'],\n",
              "  'title': 'Prediction of infectious disease epidemics via weighted density ensembles.'},\n",
              " {'abstract': 'Speech research has made tremendous progress in the past using the following paradigm:• define the research problem,• collect a corpus to objectively measure progress, and• solve the research problem.Natural language research, on the other hand, has typically progressed without the benefit of any corpus of data with which to test research hypotheses. We describe the Air Travel Information System (ATIS) pilot corpus, a corpus designed to measure progress in Spoken Language Systems that include both a speech and natural language component. This pilot marks the first full-scale attempt to collect such a corpus and provides guidelines for future efforts.',\n",
              "  'authors': ['Charles T. Hemphill ',\n",
              "   ' John J. Godfrey ',\n",
              "   ' George R. Doddington'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2077302143',\n",
              "  'references': ['1643320849', '2039265849'],\n",
              "  'title': 'The ATIS spoken language systems pilot corpus'},\n",
              " {'abstract': 'In this tutorial we give an overview of the basic ideas underlying Support Vector (SV) machines for function estimation. Furthermore, we include a summary of currently used algorithms for training SV machines, covering both the quadratic (or convex) programming part and advanced methods for dealing with large datasets. Finally, we mention some modifications and extensions that have been applied to the standard SV algorithm, and discuss the aspect of regularization from a SV perspective.',\n",
              "  'authors': ['Alex J. Smola 1', ' Bernhard Schölkopf 2'],\n",
              "  'date': '2004',\n",
              "  'identifier': '1964357740',\n",
              "  'references': ['2153635508',\n",
              "   '2156909104',\n",
              "   '2148603752',\n",
              "   '2124776405',\n",
              "   '2102865756',\n",
              "   '1554663460',\n",
              "   '2139212933',\n",
              "   '2119821739',\n",
              "   '1563088657',\n",
              "   '2078204800'],\n",
              "  'title': 'A tutorial on support vector regression'},\n",
              " {'abstract': \"Abstract : This reprint will introduce and study the most basic properties of three new variational problems which are suggested by applications to computer vision. In computer vision, a fundamental problem is to appropriately decompose the domain R of a function g (x,y) of two variables. This problem starts by describing the physical situation which produces images: assume that a three-dimensional world is observed by an eye or camera from some point P and that g1(rho) represents the intensity of the light in this world approaching the point sub 1 from a direction rho. If one has a lens at P focusing this light on a retina or a film-in both cases a plane domain R in which we may introduce coordinates x, y then let g(x,y) be the strength of the light signal striking R at a point with coordinates (x,y); g(x,y) is essentially the same as sub 1 (rho) -possibly after a simple transformation given by the geometry of the imaging syste. The function g(x,y) defined on the plane domain R will be called an image. What sort of function is g? The light reflected off the surfaces Si of various solid objects O sub i visible from P will strike the domain R in various open subsets R sub i. When one object O1 is partially in front of another object O2 as seen from P, but some of object O2 appears as the background to the sides of O1, then the open sets R1 and R2 will have a common boundary (the 'edge' of object O1 in the image defined on R) and one usually expects the image g(x,y) to be discontinuous along this boundary. (JHD)\",\n",
              "  'authors': ['David Bryant Mumford 1', ' Jayant Shah 2'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2114487471',\n",
              "  'references': ['1997063559',\n",
              "   '2120062331',\n",
              "   '1586623601',\n",
              "   '2147035016',\n",
              "   '2564031986',\n",
              "   '1601420106',\n",
              "   '2130711343',\n",
              "   '2033954961',\n",
              "   '2042352549',\n",
              "   '2039343706'],\n",
              "  'title': 'Optimal approximations by piecewise smooth functions and associated variational problems'},\n",
              " {'abstract': 'A motion sequence may be represented as a single pattern in x–y–t space; a velocity of motion corresponds to a three-dimensional orientation in this space. Motion sinformation can be extracted by a system that responds to the oriented spatiotemporal energy. We discuss a class of models for human motion mechanisms in which the first stage consists of linear filters that are oriented in space-time and tuned in spatial frequency. The outputs of quadrature pairs of such filters are squared and summed to give a measure of motion energy. These responses are then fed into an opponent stage. Energy models can be built from elements that are consistent with known physiology and psychophysics, and they permit a qualitative understanding of a variety of motion phenomena.',\n",
              "  'authors': ['Edward H. Adelson ', ' James R. Bergen'],\n",
              "  'date': '1985',\n",
              "  'identifier': '2108992228',\n",
              "  'references': ['2164934677',\n",
              "   '2035108601',\n",
              "   '1999908130',\n",
              "   '1964415410',\n",
              "   '2074798463',\n",
              "   '2129181505',\n",
              "   '2022491393',\n",
              "   '2157392891',\n",
              "   '1988849438',\n",
              "   '2053895730'],\n",
              "  'title': 'Spatiotemporal energy models for the perception of motion'},\n",
              " {'abstract': 'Positron emission tomography with 18-fluorodeoxyglucose is more accurate than computed tomography for mediastinal staging. However, it is more sensitive but less specific when computed tomography s...',\n",
              "  'authors': ['Michael K. Gould ',\n",
              "   ' Ware G. Kuschner ',\n",
              "   ' Chara E. Rydzak ',\n",
              "   ' Courtney C. Maclean ',\n",
              "   ' Anita N. Demas ',\n",
              "   ' Hidenobu Shigemitsu ',\n",
              "   ' Jo Kay Chan ',\n",
              "   ' Douglas K. Owens'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2058839291',\n",
              "  'references': ['2107328434',\n",
              "   '2313581450',\n",
              "   '1973870205',\n",
              "   '2339934527',\n",
              "   '1982228885',\n",
              "   '2094129713',\n",
              "   '2133971354',\n",
              "   '2057631921',\n",
              "   '2113009004',\n",
              "   '2069752504'],\n",
              "  'title': 'Test performance of positron emission tomography and computed tomography for mediastinal staging in patients with non-small-cell lung cancer: a meta-analysis.'},\n",
              " {'abstract': 'Since the outbreak of severe acute respiratory syndrome (SARS) 18 years ago, a large number of SARS-related coronaviruses (SARSr-CoVs) have been discovered in their natural reservoir host, bats1-4. Previous studies have shown that some bat SARSr-CoVs have the potential to infect humans5-7. Here we report the identification and characterization of a new coronavirus (2019-nCoV), which caused an epidemic of acute respiratory syndrome in humans in Wuhan, China. The epidemic, which started on 12 December 2019, had caused 2,794 laboratory-confirmed infections including 80 deaths by 26 January 2020. Full-length genome sequences were obtained from five patients at an early stage of the outbreak. The sequences are almost identical and share 79.6% sequence identity to SARS-CoV. Furthermore, we show that 2019-nCoV is 96% identical at the whole-genome level to a bat coronavirus. Pairwise protein sequence analysis of seven conserved non-structural proteins domains show that this virus belongs to the species of SARSr-CoV. In addition, 2019-nCoV virus isolated from the bronchoalveolar lavage fluid of a critically ill patient could be neutralized by sera from several patients. Notably, we confirmed that 2019-nCoV uses the same cell entry receptor-angiotensin converting enzyme II (ACE2)-as SARS-CoV.',\n",
              "  'authors': ['Peng Zhou 1',\n",
              "   ' Xing Lou Yang 1',\n",
              "   ' Xian Guang Wang 2',\n",
              "   ' Ben Hu 1',\n",
              "   ' Lei Zhang 1',\n",
              "   ' Wei Zhang 1',\n",
              "   ' Hao Rui Si 1',\n",
              "   ' Yan Zhu 1',\n",
              "   ' Bei Li 1',\n",
              "   ' Chao Lin Huang 2',\n",
              "   ' Hui Dong Chen 2',\n",
              "   ' Jing Chen 1',\n",
              "   ' Yun Luo 1',\n",
              "   ' Hua Guo 1',\n",
              "   ' Ren Di Jiang 1',\n",
              "   ' Mei Qin Liu 1',\n",
              "   ' Ying Chen 1',\n",
              "   ' Xu Rui Shen 1',\n",
              "   ' Xi Wang 1',\n",
              "   ' Xiao Shuang Zheng 1',\n",
              "   ' Kai Zhao 1',\n",
              "   ' Quan Jiao Chen 1',\n",
              "   ' Fei Deng 1',\n",
              "   ' Lin Lin Liu 3',\n",
              "   ' Bing Yan 1',\n",
              "   ' Fa Xian Zhan 3',\n",
              "   ' Yan Yi Wang 1',\n",
              "   ' Geng Fu Xiao 1',\n",
              "   ' Zheng Li Shi 1'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3004280078',\n",
              "  'references': ['2903899730',\n",
              "   '2166867592',\n",
              "   '2132260239',\n",
              "   '1993577573',\n",
              "   '2775086803',\n",
              "   '1966238900',\n",
              "   '2195009776',\n",
              "   '2103503670',\n",
              "   '2918873120',\n",
              "   '2298153446'],\n",
              "  'title': 'A pneumonia outbreak associated with a new coronavirus of probable bat origin'},\n",
              " {'abstract': 'A method for detecting and describing the features of faces using deformable templates is described. The feature of interest, an eye for example, is described by a parameterized template. An energy function is defined which links edges, peaks, and valleys in the image intensity to corresponding properties of the template. The template then interacts dynamically with the image, by altering its parameter values to minimize the energy function, thereby deforming itself to find the best fit. The final parameter values can be used as descriptors for the features. This method is demonstrated by showing deformable templates detecting eyes and mouths in real images. >',\n",
              "  'authors': ['A.L. Yuille ', ' D.S. Cohen ', ' P.W. Hallinan'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2125848778',\n",
              "  'references': ['2104095591',\n",
              "   '2164741953',\n",
              "   '2740373864',\n",
              "   '2082206048',\n",
              "   '2051719061',\n",
              "   '1574225613',\n",
              "   '2107198582',\n",
              "   '2045798786',\n",
              "   '1977699267',\n",
              "   '1758984152'],\n",
              "  'title': 'Feature extraction from faces using deformable templates'},\n",
              " {'abstract': 'OBJECTIVE. The purpose of this study was to describe the chest CT findings in seven patients with Middle East respiratory syndrome coronavirus (MERS-CoV) infection. CONCLUSION. The most common CT finding in hospitalized patients with MERS-CoV infection is that of bilateral predominantly subpleural and basilar airspace changes, with more extensive ground-glass opacities than consolidation. The subpleural and peribronchovascular predilection of the abnormalities is suggestive of an organizing pneumonia pattern.',\n",
              "  'authors': ['Amr M. Ajlan ',\n",
              "   ' Rayan A. Ahyad ',\n",
              "   ' Lamia Ghazi Jamjoom ',\n",
              "   ' Ahmed Alharthy ',\n",
              "   ' Tariq A. Madani'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2112136274',\n",
              "  'references': ['2166867592',\n",
              "   '2107053896',\n",
              "   '2006434809',\n",
              "   '2149661971',\n",
              "   '1703839189',\n",
              "   '2045002682',\n",
              "   '1852588318',\n",
              "   '2109520345',\n",
              "   '2119837294',\n",
              "   '2049975503'],\n",
              "  'title': 'Middle East Respiratory Syndrome Coronavirus (MERS-CoV) Infection: Chest CT Findings'},\n",
              " {'abstract': 'Planar, underactuated, biped walkers form an important domain of applications for hybrid dynamical systems. This paper presents the design of exponentially stable walking controllers for general planar bipedal systems that have one degree-of-freedom greater than the number of available actuators. The within-step control action creates an attracting invariant set - a two-dimensional zero dynamics submanifold of the full hybrid model $whose restriction dynamics admits a scalar linear time-invariant return map. Exponentially stable periodic orbits of the zero dynamics correspond to exponentially stabilizable orbits of the full model. A convenient parameterization of the hybrid zero dynamics is imposed through the choice of a class of output functions. Parameter optimization is used to tune the hybrid zero dynamics in order to achieve closed-loop, exponentially stable walking with low energy consumption, while meeting natural kinematic and dynamic constraints. The general theory developed in the paper is illustrated on a five link walker, consisting of a torso and two legs with knees.',\n",
              "  'authors': ['E.R. Westervelt ', ' J.W. Grizzle ', ' D.E. Koditschek'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2128131727',\n",
              "  'references': ['1564897360',\n",
              "   '2142992961',\n",
              "   '1988837728',\n",
              "   '2062691475',\n",
              "   '1496777766',\n",
              "   '1964373008',\n",
              "   '2137547873',\n",
              "   '2114414717',\n",
              "   '2136605942',\n",
              "   '2013232999'],\n",
              "  'title': 'Hybrid zero dynamics of planar biped walkers'},\n",
              " {'abstract': 'Introduction -- Part I Linear Programming -- Basic Properties of Linear Programs -- The Simplex Method -- Duality and Complementarity -- Interior-Point Methods -- Conic Linear Programming -- Part II Unconstrained Problems -- Basic Properties of Solutions and Algorithms -- Basic Descent Methods -- Conjugate Direction Methods -- Quasi-Newton Methods -- Part III Constrained Minimization -- Constrained Minimization Conditions -- Primal Methods -- Penalty and Barrier Methods -- Duality and Dual Methods -- Primal-Dual Methods -- Appendix A: Mathematical Review -- Appendix B: Convex Sets -- Appendix C: Gaussian Elimination -- Appendix D: Basic Network Concepts.',\n",
              "  'authors': ['David G Luenberger ', ' Yinyu Ye'],\n",
              "  'date': '2016',\n",
              "  'identifier': '3124770806',\n",
              "  'references': ['2014414177',\n",
              "   '2963430899',\n",
              "   '2919546652',\n",
              "   '2994798986',\n",
              "   '2980086582',\n",
              "   '2905128989',\n",
              "   '3016798895'],\n",
              "  'title': 'Linear and Nonlinear Programming'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Shayle R. Searle'],\n",
              "  'date': '1971',\n",
              "  'identifier': '2798510847',\n",
              "  'references': ['1951724000',\n",
              "   '2159267296',\n",
              "   '1528905581',\n",
              "   '2164777277',\n",
              "   '2108169091',\n",
              "   '2126693856',\n",
              "   '2324175318',\n",
              "   '2168029744',\n",
              "   '2234310114',\n",
              "   '2039991270'],\n",
              "  'title': 'Linear Models'},\n",
              " {'abstract': 'A model is proposed which expresses consumer satisfaction as a function of expectation and expectancy disconfirmation. Satisfaction, in turn, is believed to influence attitude change and purchase i...',\n",
              "  'authors': ['Richard L. Oliver'],\n",
              "  'date': '1980',\n",
              "  'identifier': '2028184439',\n",
              "  'references': ['37476018',\n",
              "   '2004168348',\n",
              "   '2052156595',\n",
              "   '1972557675',\n",
              "   '1979928421',\n",
              "   '2084715591',\n",
              "   '2024311825',\n",
              "   '1979756272',\n",
              "   '1983225075',\n",
              "   '2008373070'],\n",
              "  'title': 'A Cognitive Model of the Antecedents and Consequences of Satisfaction Decisions'},\n",
              " {'abstract': '1. The sensitivity to temporally modulated sinusoidal gratings was determined. Two thresholds could be distinguished for the modulated gratings: the contrast at which flicker could be perceived and the contrast at which the spatial structure became distinct. 2. The flicker detection thresholds and pattern recognition threshold varied independently as functions of the spatial and temporal frequencies, suggesting that the two thresholds represent the activity of two independent systems of channels. 3. The channels detecting flicker prefer low and medium spatial frequencies. They have a pronounced decline in sensitivity at low temporal frequencies of sinusoidal modulation. They respond twice as well to gratings whose phase is alternated repetitively as to gratings turned on and off at the same rate. 4. The channels responsible for the discrimination of spatial structure are most responsive at high and medium spatial frequencies. There is no decline in sensitivity at low temporal frequencies. These channels respond equally well to alternating and on/off gratings up to about 8 Hz. 5. The temporal properties as revealed with sinusoidal modulation, suggest that the flicker-detecting channels would give transient responses to prolonged presentation of stimuli: the channels responsible for analysing the spatial structure would give sustained responses. The responses of the two types of channel to alternating and on/off gratings confirm this suggestion.',\n",
              "  'authors': ['J. J. Kulikowski ', ' D. J. Tolhurst'],\n",
              "  'date': '1973',\n",
              "  'identifier': '2163875444',\n",
              "  'references': ['2165222134',\n",
              "   '2008605035',\n",
              "   '2133033884',\n",
              "   '2950188464',\n",
              "   '2036543705',\n",
              "   '2023563670',\n",
              "   '2059214109',\n",
              "   '2001590643',\n",
              "   '2110934090'],\n",
              "  'title': 'Psychophysical evidence for sustained and transient detectors in human vision'},\n",
              " {'abstract': 'A versatile method, quartet puzzling, is introduced to reconstruct the topology (branching pattern) of a phylogenetic tree based on DNA or amino acid sequence data. This method applies maximum-likelihood tree reconstruction to all possible quartets that can be formed from n sequences. The quartet trees serve as starting points to reconstruct a set of optimal n-taxon trees. The majority rule consensus of these trees defines the quartet puzzling tree and shows groupings that are well supported. Computer simulations show that the performance of quartet puzzling to reconstruct the true tree is always equal to or better than that of neighbor joining. For some cases with high transition/transversion bias quartet puzzling outperforms neighbor joining by a factor of 10. The application of quartet puzzling to mitochondrial RNA and tRNAVd’ sequences from amniotes demonstrates the power of the approach. A PHYLIP-compatible ANSI C program, PUZZLE, for analyzing nucleotide or amino acid sequence data is available.',\n",
              "  'authors': ['K Strimmer ', ' A von Haeseler'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2164997158',\n",
              "  'references': ['2106882534',\n",
              "   '2097706568',\n",
              "   '2065461553',\n",
              "   '2102424972',\n",
              "   '2009596137',\n",
              "   '1525734744',\n",
              "   '2148860997',\n",
              "   '2005471817',\n",
              "   '2078650268',\n",
              "   '2041513000'],\n",
              "  'title': 'Quartet Puzzling: A Quartet Maximum-Likelihood Method for Reconstructing Tree Topologies'},\n",
              " {'abstract': 'This paper describes a project in which an analysis was undertaken of user queries addressed to seven libraries which manage archives of widely varying still and moving image material. The sampling procedure is described, in which queries obtained from each library were broadly categorised by image content, identification and accessibility. Attention is focused on the image content requests, for which a categorisation based on facet analysis is developed. The analytical tool which is used for this purpose is based on a schema already well established for the analysis of levels of meaning in images.The project demonstrates the possibility of formulating a general categorisation of requests which seek widely different still and moving image material. The paper concludes with observations on the potential value of embedding such a schema within the user interface of unmediated-query visual information retrieval systems.',\n",
              "  'authors': ['Linda H. Armitage ', ' Peter G.B. Enser'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2166447979',\n",
              "  'references': ['2004690028',\n",
              "   '2026842155',\n",
              "   '2142468277',\n",
              "   '1994609618',\n",
              "   '2047772672',\n",
              "   '2063319376',\n",
              "   '2154045501',\n",
              "   '584416852',\n",
              "   '1556535778',\n",
              "   '1767743992'],\n",
              "  'title': 'Analysis of user need in image archives'},\n",
              " {'abstract': 'Abstract An explicit three-dimensional (3D) representation is constructed from feature points extracted from a sequence of images taken by a moving camera. The points are tracked through the sequence, and their 3D locations are accurately determined by use of Kalman filters. The egomotion of the camera is also determined.',\n",
              "  'authors': ['C. G. Harris ', ' J. M. Pike'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2063599328',\n",
              "  'references': ['2020554914', '1988027882'],\n",
              "  'title': '3D positional integration from image sequences'},\n",
              " {'abstract': 'The Middle East respiratory syndrome (MERS) coronavirus has caused recurrent outbreaks in the Arabian Peninsula since 2012. Although MERS has low overall human-to-human transmission potential, there is occasional amplification in the healthcare setting, a pattern reminiscent of the dynamics of the severe acute respiratory syndrome (SARS) outbreaks in 2003. Here we provide a head-to-head comparison of exposure patterns and transmission dynamics of large hospital clusters of MERS and SARS, including the most recent South Korean outbreak of MERS in 2015.',\n",
              "  'authors': ['Gerardo Chowell 1',\n",
              "   ' 2',\n",
              "   ' Fatima Abdirizak 1',\n",
              "   ' Sunmi Lee 3',\n",
              "   ' Jonggul Lee 4',\n",
              "   ' Eunok Jung 4',\n",
              "   ' Hiroshi Nishiura 5',\n",
              "   ' Cécile Viboud 2'],\n",
              "  'date': '2015',\n",
              "  'identifier': '1815575713',\n",
              "  'references': ['2166867592',\n",
              "   '2107053896',\n",
              "   '2006434809',\n",
              "   '2138324310',\n",
              "   '2147166346',\n",
              "   '1990049863',\n",
              "   '2069251911',\n",
              "   '2096145431',\n",
              "   '1968393246',\n",
              "   '2130227690'],\n",
              "  'title': 'Transmission characteristics of MERS and SARS in the healthcare setting: a comparative study'},\n",
              " {'abstract': 'Summary. This paper describes how data from a multinomial distribution, and in particular data in the form of a contingency table, may be studied by using a prior distribution of the parameters and expressing the results in the form of a posterior distribution, or some aspects thereof, of the parameters. The analysis used must depend on the prior distribution and the form described here only applies to a certain type of prior knowledge but, for reasons given below, it is believed that this type is of frequent occurrence. The binomial situation is first considered and the results obtained there suggest a general result for the multinomial distribution, which is then established. A few remarks on Bayesian analysis in general enable the result to be applied, first to certain multinomial problems and then, with the aid of another general result, to contingency tables. The method used there has close connections with the Analysis of Variance and these connections are examined, particularly with a view to simplifying the analysis of contingency tables involving three or more factors. 1. Binomial distributions. Although it will appear as a special case of results to be established for the general multinomial situation, it is instructive to begin with the binomial distribution which suggested the generalizations. Let N independent trials with constant probability 0 of success result in n successes and (N - n) failures. The likelihood is',\n",
              "  'authors': ['Dennis V. Lindley'],\n",
              "  'date': '1964',\n",
              "  'identifier': '1968269771',\n",
              "  'references': ['2123838014',\n",
              "   '2977327674',\n",
              "   '2035064373',\n",
              "   '1495984520',\n",
              "   '2089611415',\n",
              "   '2904073991',\n",
              "   '2126163471',\n",
              "   '2905260248',\n",
              "   '2905472553',\n",
              "   '2091383824'],\n",
              "  'title': 'The Bayesian Analysis of Contingency Tables'},\n",
              " {'abstract': 'Computational intelligence techniques have been used in wide applications. Out of numerous computational intelligence techniques, neural networks and support vector machines (SVMs) have been playing the dominant roles. However, it is known that both neural networks and SVMs face some challenging issues such as: (1) slow learning speed, (2) trivial human intervene, and/or (3) poor computational scalability. Extreme learning machine (ELM) as emergent technology which overcomes some challenges faced by other techniques has recently attracted the attention from more and more researchers. ELM works for generalized single-hidden layer feedforward networks (SLFNs). The essence of ELM is that the hidden layer of SLFNs need not be tuned. Compared with those traditional computational intelligence techniques, ELM provides better generalization performance at a much faster learning speed and with least human intervene. This paper gives a survey on ELM and its variants, especially on (1) batch learning mode of ELM, (2) fully complex ELM, (3) online sequential ELM, (4) incremental ELM, and (5) ensemble of ELM.',\n",
              "  'authors': ['Guang-Bin Huang 1', ' Dian Hui Wang 2', ' Yuan Lan 1'],\n",
              "  'date': '2011',\n",
              "  'identifier': '1993717606',\n",
              "  'references': ['2148603752',\n",
              "   '2119821739',\n",
              "   '1988790447',\n",
              "   '2912934387',\n",
              "   '2111072639',\n",
              "   '1964357740',\n",
              "   '2172000360',\n",
              "   '2137983211',\n",
              "   '1498436455',\n",
              "   '1596717185'],\n",
              "  'title': 'Extreme learning machines: a survey'},\n",
              " {'abstract': 'In this paper we introduce a stroke based lexicon reduction technique in order to reduce the search space for recognition of handwritten words. The principle of this technique involves mainly two aspects of a word image to constitute a feature vector: one is word-length and the other is shape of the word. The length of the word image is represented by the number of specific vertical strokes present in the word image and, on the other hand, the shape of a word image is realized with the combination of both horizontal and vertical strokes. The experiment has been carried out with a database of 35,700 off-line handwritten Bangla word images. Though our proposed lexicon reduction technique is developed for recognition of Bangla handwritten words, its generalization property can easily be exploited for recognition of handwriting in other scripts also.',\n",
              "  'authors': ['Tapan Kumar Bhowmik 1', ' Utpal Roy 2', ' Swapan K. Parui 3'],\n",
              "  'date': '2012',\n",
              "  'identifier': '2158078830',\n",
              "  'references': ['2163374925',\n",
              "   '2155793192',\n",
              "   '2149319679',\n",
              "   '2170275199',\n",
              "   '2137027750',\n",
              "   '1570317704',\n",
              "   '2163943059',\n",
              "   '101240229',\n",
              "   '2143060414',\n",
              "   '1960827080'],\n",
              "  'title': 'Lexicon Reduction Technique for Bangla Handwritten Word Recognition'},\n",
              " {'abstract': 'Gaussian mixture models are currently the dominant technique for modeling the emission distribution of hidden Markov models for speech recognition. We show that better phone recognition on the TIMIT dataset can be achieved by replacing Gaussian mixture models by deep neural networks that contain many layers of features and a very large number of parameters. These networks are first pre-trained as a multi-layer generative model of a window of spectral feature vectors without making use of any discriminative information. Once the generative pre-training has designed the features, we perform discriminative fine-tuning using backpropagation to adjust the features slightly to make them better at predicting a probability distribution over the states of monophone hidden Markov models.',\n",
              "  'authors': ['A. Mohamed ', ' G. E. Dahl ', ' G. Hinton'],\n",
              "  'date': '2012',\n",
              "  'identifier': '1993882792',\n",
              "  'references': ['2136922672',\n",
              "   '3118608800',\n",
              "   '2100495367',\n",
              "   '2116064496',\n",
              "   '2147768505',\n",
              "   '2159080219',\n",
              "   '44815768',\n",
              "   '1994197834',\n",
              "   '2913932916',\n",
              "   '2103359087'],\n",
              "  'title': 'Acoustic Modeling Using Deep Belief Networks'},\n",
              " {'abstract': '',\n",
              "  'authors': ['David G. Hays'],\n",
              "  'date': '1964',\n",
              "  'identifier': '2089505529',\n",
              "  'references': ['2027979924',\n",
              "   '73274768',\n",
              "   '81000870',\n",
              "   '2126034021',\n",
              "   '1965605789',\n",
              "   '2914096745',\n",
              "   '2114719613',\n",
              "   '2145211186',\n",
              "   '140467209',\n",
              "   '3001497429'],\n",
              "  'title': 'Dependency Theory: A Formalism and Some Observations'},\n",
              " {'abstract': 'We present a neural network-based upright frontal face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We present a straightforward procedure for aligning positive face examples for training. To collect negative examples, we use a bootstrap algorithm, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting nonface training examples, which must be chosen to span the entire space of nonface images. Simple heuristics, such as using the fact that faces rarely overlap in images, can further improve the accuracy. Comparisons with several other state-of-the-art face detection systems are presented, showing that our system has comparable performance in terms of detection and false-positive rates.',\n",
              "  'authors': ['H.A. Rowley 1', ' S. Baluja 2', ' T. Kanade 1'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2217896605',\n",
              "  'references': ['2139212933',\n",
              "   '2313307644',\n",
              "   '2133671888',\n",
              "   '2124351082',\n",
              "   '2147800946',\n",
              "   '2098947662',\n",
              "   '1997011019',\n",
              "   '2173629880',\n",
              "   '2042371054',\n",
              "   '2159173611'],\n",
              "  'title': 'Neural network-based face detection'},\n",
              " {'abstract': 'A method for computer-aided cleaning of undesirable patterns in large training databases has been developed. The method uses the trainable classifier itself, to point out patterns that are suspicious, and should be checked by the human supervisor. While suspicious patterns that are meaningless or mislabeled are considered garbage, and removed from the database, the remaining patterns, like ambiguous or atypical, represent valid patterns that are hard to learn and should be kept in the database. By using the method of pattern cleaning, combined with an emphasizing scheme applied on the patterns that are hard to learn, the error rate on the test set has been reduced by half, in the case of the database of handwritten lowercase characters entered on a touch terminal. The classifier is based on a time delay neural network (TDNN). >',\n",
              "  'authors': ['N. Matic ',\n",
              "   ' I. Guyon ',\n",
              "   ' L. Bottou ',\n",
              "   ' J. Denker ',\n",
              "   ' V. Vapnik'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2159901481',\n",
              "  'references': ['1530699444',\n",
              "   '2055075080',\n",
              "   '2057619148',\n",
              "   '2165217207',\n",
              "   '2145513251',\n",
              "   '2054882585',\n",
              "   '2607313294'],\n",
              "  'title': 'Computer aided cleaning of large databases for character recognition'},\n",
              " {'abstract': '',\n",
              "  'authors': ['I. S. Gradshteyn ', ' I. M. Ryzhik ', ' Robert H. Romer'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2299769372',\n",
              "  'references': ['1999814123',\n",
              "   '2075295072',\n",
              "   '2149171456',\n",
              "   '1994703549',\n",
              "   '2101493165',\n",
              "   '1965967625',\n",
              "   '2170561782',\n",
              "   '2139727241',\n",
              "   '2073427212',\n",
              "   '1983211478'],\n",
              "  'title': 'Tables of Integrals, Series, and Products'},\n",
              " {'abstract': 'There are many excellent toolkits which provide support for developing machine learning software in Python, R, Matlab, and similar environments. Dlib-ml is an open source library, targeted at both engineers and research scientists, which aims to provide a similarly rich environment for developing machine learning software in the C++ language. Towards this end, dlib-ml contains an extensible linear algebra toolkit with built in BLAS support. It also houses implementations of algorithms for performing inference in Bayesian networks and kernel-based methods for classification, regression, clustering, anomaly detection, and feature ranking. To enable easy use of these tools, the entire library has been developed with contract programming, which provides complete and precise documentation as well as powerful debugging tools.',\n",
              "  'authors': ['Davis E. King'],\n",
              "  'date': '2009',\n",
              "  'identifier': '2115252128',\n",
              "  'references': ['2153635508',\n",
              "   '1618905105',\n",
              "   '2142623206',\n",
              "   '2125993116',\n",
              "   '2154462399',\n",
              "   '1486089539',\n",
              "   '2153290280',\n",
              "   '1633751774',\n",
              "   '1494068061'],\n",
              "  'title': 'Dlib-ml: A Machine Learning Toolkit'},\n",
              " {'abstract': 'Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character ngram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English!German and English!Russian by up to 1.1 and 1.3 BLEU, respectively.',\n",
              "  'authors': ['Rico Sennrich ', ' Barry Haddow ', ' Alexandra Birch'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2962784628',\n",
              "  'references': ['2964308564',\n",
              "   '2130942839',\n",
              "   '2157331557',\n",
              "   '1902237438',\n",
              "   '6908809',\n",
              "   '1753482797',\n",
              "   '2124807415',\n",
              "   '2251012068',\n",
              "   '1815076433',\n",
              "   '2100664567'],\n",
              "  'title': 'Neural Machine Translation of Rare Words with Subword Units'},\n",
              " {'abstract': \"We define organizational improvisation as the degree to which the composition and execution of an action converge in time, and we examine the theoretical potential of this definition. We then propose that both organizational procedural memory (skill knowledge) and declarative memory (fact knowledge) moderate improvisation's impact on organizational outcomes in distinct ways. We also suggest that improvisation influences organizational memory by (1) generating experiments and (2) permitting the development of higher-level competency in improvisation. Contemporary technological changes related to the nature of organizational memory intensify the salience of these issues.\",\n",
              "  'authors': ['Christine Moorman ', ' Anne S. Miner'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2068899020',\n",
              "  'references': ['2108795964',\n",
              "   '2568476927',\n",
              "   '2027320617',\n",
              "   '1659842140',\n",
              "   '1708874574',\n",
              "   '2137358449',\n",
              "   '2168341514',\n",
              "   '2106919063',\n",
              "   '2392998718',\n",
              "   '2025579080'],\n",
              "  'title': 'Organizational Improvisation and Organizational Memory'},\n",
              " {'abstract': 'We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We applied this approach to segmenting static images, as well as motion sequences, and found the results to be very encouraging.',\n",
              "  'authors': ['Jianbo Shi 1', ' J. Malik 2'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2121947440',\n",
              "  'references': ['2121947440',\n",
              "   '2798909945',\n",
              "   '1578099820',\n",
              "   '1997063559',\n",
              "   '1971784203',\n",
              "   '2114487471',\n",
              "   '2913192828',\n",
              "   '2114030927',\n",
              "   '2132603077',\n",
              "   '100944330'],\n",
              "  'title': 'Normalized cuts and image segmentation'},\n",
              " {'abstract': 'It is urgent to understand the future of severe acute respiratory syndrome-coronavirus 2 (SARS-CoV-2) transmission. We used estimates of seasonality, immunity, and cross-immunity for human coronavirus OC43 (HCoV-OC43) and HCoV-HKU1 using time-series data from the United States to inform a model of SARS-CoV-2 transmission. We projected that recurrent wintertime outbreaks of SARS-CoV-2 will probably occur after the initial, most severe pandemic wave. Absent other interventions, a key metric for the success of social distancing is whether critical care capacities are exceeded. To avoid this, prolonged or intermittent social distancing may be necessary into 2022. Additional interventions, including expanded critical care capacity and an effective therapeutic, would improve the success of intermittent distancing and hasten the acquisition of herd immunity. Longitudinal serological studies are urgently needed to determine the extent and duration of immunity to SARS-CoV-2. Even in the event of apparent elimination, SARS-CoV-2 surveillance should be maintained because a resurgence in contagion could be possible as late as 2024.',\n",
              "  'authors': ['Stephen M. Kissler ',\n",
              "   ' Christine Tedijanto ',\n",
              "   ' Edward Goldstein ',\n",
              "   ' Yonatan H. Grad ',\n",
              "   ' Marc Lipsitch'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3015988827',\n",
              "  'references': ['3003668884',\n",
              "   '3008028633',\n",
              "   '2097360283',\n",
              "   '3010233963',\n",
              "   '3012284084',\n",
              "   '2122825543',\n",
              "   '3023441241',\n",
              "   '3009155494',\n",
              "   '3013215798',\n",
              "   '3002764620'],\n",
              "  'title': 'Projecting the transmission dynamics of SARS-CoV-2 through the postpandemic period.'},\n",
              " {'abstract': 'Analysis in terms of the relative operating characteristic (ROC) has recently been applied to several studies of medical decision-making, primarily to decisions based on imaging techniques. This paper presents a brief description of the ROC, and shows how it provides a measure of diagnostic accuracy that is free of judgmental bias. The results of medical studies are reviewed, and the main questions of theory and method that have arisen in the medical context are identified. Certain of these questions are basic to any psychophysical test, in which case an attempt has been made to present the best available answers. Other questions are of special medical importance and relevant reports are reviewed along with a description of current efforts to provide answers.',\n",
              "  'authors': ['John A. Swets'],\n",
              "  'date': '1979',\n",
              "  'identifier': '2060136512',\n",
              "  'references': ['2157825442',\n",
              "   '2155653793',\n",
              "   '2104960492',\n",
              "   '1990748933',\n",
              "   '1494052777',\n",
              "   '2102150307',\n",
              "   '2093265755',\n",
              "   '1511622053',\n",
              "   '2098154993',\n",
              "   '2109597745'],\n",
              "  'title': 'ROC analysis applied to the evaluation of medical imaging techniques.'},\n",
              " {'abstract': 'This paper attempts to present a comprehensive tutorial survey of the development of efficient modulation techniques for bandlimited channels, such as telephone channels. After a history of advances in commercial high-speed modems and a discussion of theoretical limits, it reviews efforts to optimize two-dimensional signal constellations and presents further elaborations of uncoded modulation. Its principal emphasis, however, is on coded modulation techniques, in which there is an explosion of current interest, both for research and for practical application. Both block-coded and trellis-coded modulation are covered, in a common framework. A few new techniques are presented.',\n",
              "  'authors': ['G. Forney 1',\n",
              "   ' R. Gallager 2',\n",
              "   ' G. Lang 1',\n",
              "   ' F. Longstaff 1',\n",
              "   ' S. Qureshi 3'],\n",
              "  'date': '1984',\n",
              "  'identifier': '2112544308',\n",
              "  'references': ['2165205968',\n",
              "   '2142384583',\n",
              "   '2119352491',\n",
              "   '2029495080',\n",
              "   '2112063104',\n",
              "   '2086362140',\n",
              "   '2036845965',\n",
              "   '1998972406',\n",
              "   '2120788459',\n",
              "   '2071238091'],\n",
              "  'title': 'Efficient Modulation for Band-Limited Channels'},\n",
              " {'abstract': 'This paper is concerned with Chebyshev approximation by spline functions with free knots. Necessary and sufficient conditions for the best approximations are derived. It is shown by examples that the gap between these conditions cannot be bridged. The situation is less complicated, if the given function satisfies a generalized convexity condition. In dieser Arbeit wird die Tschebyscheff-Approximation mit Splines bei freien Knoten behandelt. Notwendige und hinreichende Alternantenkriterien werden hergeleitet. Anhand von Beispielen zeigt sich, daβ diese nicht ohne weiteres verscharft werden konnen. Dies hat erhebliche Konsequenzen fur die Konstruktion bester Approximationen. Fur Funktionen, die in einem bestimmten Sinne konvex sind, ist die Lage wesentlich ubersichtlicher. An verschiedenen Stellen ergeben sich Parallelen zur Approximation mit ?-Polynomen, die in einer fruheren Arbeit untersucht wurden.',\n",
              "  'authors': ['Dietrich Braess'],\n",
              "  'date': '1971',\n",
              "  'identifier': '1995259821',\n",
              "  'references': ['2018639632',\n",
              "   '1981674498',\n",
              "   '1984297154',\n",
              "   '2142764459',\n",
              "   '2091978911',\n",
              "   '2326524952',\n",
              "   '2049590995',\n",
              "   '2036968702',\n",
              "   '2042142840',\n",
              "   '2313797667'],\n",
              "  'title': 'Chebyshev approximation by spline functions with free knots'},\n",
              " {'abstract': 'Forecasting is beginning to be integrated into decision-making processes for infectious disease outbreak response. We discuss how technologies could accelerate the adoption of forecasting among public health practitioners, improve epidemic management, save lives, and reduce the economic impact of outbreaks.',\n",
              "  'authors': ['Dylan B. George 1',\n",
              "   ' Wendy Taylor 2',\n",
              "   ' Jeffrey Shaman 3',\n",
              "   ' Caitlin Rivers 4',\n",
              "   ' Brooke Paul 5',\n",
              "   ' Tara O’Toole 6',\n",
              "   ' Michael A. Johansson 7',\n",
              "   ' Lynette Hirschman 8',\n",
              "   ' Matthew Biggerstaff 7',\n",
              "   ' Jason Asher 9',\n",
              "   ' Nicholas G. Reich 10'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2970434820',\n",
              "  'references': ['2897257410',\n",
              "   '2946778829',\n",
              "   '2486241280',\n",
              "   '2789327676',\n",
              "   '2799902886',\n",
              "   '2807251817',\n",
              "   '2961367025',\n",
              "   '2190947059',\n",
              "   '2789543280',\n",
              "   '2978600916'],\n",
              "  'title': 'Technology to advance infectious disease forecasting for outbreak management.'},\n",
              " {'abstract': '',\n",
              "  'authors': ['John S. Denker ',\n",
              "   ' Daniel B. Schwartz ',\n",
              "   ' Ben S. Wittner ',\n",
              "   ' Sara A. Solla ',\n",
              "   ' Richard E. Howard ',\n",
              "   ' Lawrence D. Jackel ',\n",
              "   ' John J. Hopfield'],\n",
              "  'date': '1987',\n",
              "  'identifier': '56903235',\n",
              "  'references': ['2581275558',\n",
              "   '2154642048',\n",
              "   '2011039300',\n",
              "   '1991848143',\n",
              "   '2895674046',\n",
              "   '1666015432',\n",
              "   '1505652865',\n",
              "   '2137224975',\n",
              "   '1964849666',\n",
              "   '1978909760'],\n",
              "  'title': 'Large Automatic Learning, Rule Extraction, and Generalization.'},\n",
              " {'abstract': 'In this study, excess rates of pneumonia and influenza (P&I) associated hospitalization during influenza A epidemics which occurred in the United States between 1970-78 were computed utilizing unpublished data from the National Hospital Discharge Survey (NHDS). Excesses occurred at rates of 35, 93, and 370 per 100,000 persons per epidemic for age groups 15-44, 45-64, and 65+ years. There was no evidence of a persisting excess or a compensatory decline in P&I hospitalization during post-epidemic months. An average excess of about 172,000 hospitalizations per epidemic at a cost in excess of $300 million was computed. The study quantifies a major impact of epidemic influenza upon health and health services, much of which may be preventable, and illustrates an important use of unpublished data contained in the NHDS.',\n",
              "  'authors': ['William H. Barker'],\n",
              "  'date': '1986',\n",
              "  'identifier': '1974047133',\n",
              "  'references': ['1905652260',\n",
              "   '2040296952',\n",
              "   '1582506212',\n",
              "   '2035672404',\n",
              "   '2137780431',\n",
              "   '2066848313',\n",
              "   '2151805197',\n",
              "   '1892590924',\n",
              "   '2469390252',\n",
              "   '1974074644'],\n",
              "  'title': 'Excess pneumonia and influenza associated hospitalization during influenza epidemics in the United States, 1970-78.'},\n",
              " {'abstract': 'Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent boosting paradigm is developed for additive expansions based on any fitting criterion. Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such TreeBoost models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.',\n",
              "  'authors': ['Jerome H. Friedman'],\n",
              "  'date': '2001',\n",
              "  'identifier': '1678356000',\n",
              "  'references': ['2156909104',\n",
              "   '2117812871',\n",
              "   '3085162807',\n",
              "   '2112076978',\n",
              "   '2024046085',\n",
              "   '2151693816',\n",
              "   '1498436455',\n",
              "   '740415',\n",
              "   '2797583072',\n",
              "   '2102201073'],\n",
              "  'title': 'Greedy function approximation: A gradient boosting machine.'},\n",
              " {'abstract': 'We present a unifying framework for studying the solution of multiclass categorization problems by reducing them to multiple binary problems that are then solved using a margin-based binary learning algorithm. The proposed framework unifies some of the most popular approaches in which each class is compared against all others, or in which all pairs of classes are compared to each other, or in which output codes with error-correcting properties are used. We propose a general method for combining the classifiers generated on the binary problems, and we prove a general empirical multiclass loss bound given the empirical loss of the individual binary learning algorithms. The scheme and the corresponding bounds apply to many popular classification learning algorithms including support-vector machines, AdaBoost, regression, logistic regression and decision-tree algorithms. We also give a multiclass generalization error analysis for general output codes with AdaBoost as the binary learner. Experimental results with SVM and AdaBoost show that our scheme provides a viable alternative to the most commonly used multiclass algorithms.',\n",
              "  'authors': ['Erin L. Allwein 1', ' Robert E. Schapire 2', ' Yoram Singer 3'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2101276256',\n",
              "  'references': ['2156909104',\n",
              "   '2119821739',\n",
              "   '1988790447',\n",
              "   '2125055259',\n",
              "   '2154642048',\n",
              "   '3085162807',\n",
              "   '2024046085',\n",
              "   '1975846642',\n",
              "   '1594031697',\n",
              "   '2161920802'],\n",
              "  'title': 'Reducing multiclass to binary: a unifying approach for margin classifiers'},\n",
              " {'abstract': 'In this chapter, we discuss a statistical generative model called independent component analysis. It is basically a proper probabilistic formulation of the ideas underpinning sparse coding. It shows how sparse coding can be interpreted as providing a Bayesian prior, and answers some questions which were not properly answered in the sparse coding framework.',\n",
              "  'authors': ['Aapo Hyvarinen ', ' Juha Karhunen ', ' Erkki Oja'],\n",
              "  'date': '2001',\n",
              "  'identifier': '1548802052',\n",
              "  'references': ['2076063813',\n",
              "   '2163922914',\n",
              "   '2072128103',\n",
              "   '2154053567',\n",
              "   '2132549764',\n",
              "   '2123649031',\n",
              "   '2115706991',\n",
              "   '2098535678',\n",
              "   '1976709621'],\n",
              "  'title': 'Independent Component Analysis'},\n",
              " {'abstract': 'This article described three heuristics that are employed in making judgements under uncertainty: (i) representativeness, which is usually employed when people are asked to judge the probability that an object or event A belongs to class or process B; (ii) availability of instances or scenarios, which is often employed when people are asked to assess the frequency of a class or the plausibility of a particular development; and (iii) adjustment from an anchor, which is usually employed in numerical prediction when a relevant value is available. These heuristics are highly economical and usually effective, but they lead to systematic and predictable errors. A better understanding of these heuristics and of the biases to which they lead could improve judgements and decisions in situations of uncertainty.',\n",
              "  'authors': ['A. Tversky ', ' D. Kahneman'],\n",
              "  'date': '1974',\n",
              "  'identifier': '158727920',\n",
              "  'references': ['2035782089',\n",
              "   '1980054641',\n",
              "   '2016377072',\n",
              "   '2079199322',\n",
              "   '1976624377',\n",
              "   '1965761421',\n",
              "   '2018507693',\n",
              "   '1972320590',\n",
              "   '1965740984',\n",
              "   '2035863199'],\n",
              "  'title': 'Judgment Under Uncertainty: Heuristics and Biases'},\n",
              " {'abstract': 'We propose a watermarking scheme to hide copyright information in an image. The scheme employs visual masking to guarantee that the embedded watermark is invisible and to maximize the robustness of the hidden data. The watermark is constructed for arbitrary image blocks by filtering a pseudo-noise sequence (author id) with a filter that approximates the frequency masking characteristics of the visual system. The noise-like watermark is statistically invisible to deter unauthorized removal. Experimental results show that the watermark is robust to several distortions including white and colored noises, JPEG coding at different qualities, and cropping.',\n",
              "  'authors': ['M.D. Swanson ', ' Bin Zhu ', ' A.H. Tewfik'],\n",
              "  'date': '1996',\n",
              "  'identifier': '1788382226',\n",
              "  'references': ['2116467012',\n",
              "   '2159390040',\n",
              "   '2158518777',\n",
              "   '2307756920',\n",
              "   '2144520790',\n",
              "   '1522884824',\n",
              "   '2612977707',\n",
              "   '2016372521',\n",
              "   '1991221331'],\n",
              "  'title': 'Transparent robust image watermarking'},\n",
              " {'abstract': 'Summary Background Rapid spread of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) in Wuhan, China, prompted heightened surveillance in Shenzhen, China. The resulting data provide a rare opportunity to measure key metrics of disease course, transmission, and the impact of control measures. Methods From Jan 14 to Feb 12, 2020, the Shenzhen Center for Disease Control and Prevention identified 391 SARS-CoV-2 cases and 1286 close contacts. We compared cases identified through symptomatic surveillance and contact tracing, and estimated the time from symptom onset to confirmation, isolation, and admission to hospital. We estimated metrics of disease transmission and analysed factors influencing transmission risk. Findings Cases were older than the general population (mean age 45 years) and balanced between males (n=187) and females (n=204). 356 (91%) of 391 cases had mild or moderate clinical severity at initial assessment. As of Feb 22, 2020, three cases had died and 225 had recovered (median time to recovery 21 days; 95% CI 20–22). Cases were isolated on average 4·6 days (95% CI 4·1–5·0) after developing symptoms; contact tracing reduced this by 1·9 days (95% CI 1·1–2·7). Household contacts and those travelling with a case were at higher risk of infection (odds ratio 6·27 [95% CI 1·49–26·33] for household contacts and 7·06 [1·43–34·91] for those travelling with a case) than other close contacts. The household secondary attack rate was 11·2% (95% CI 9·1–13·8), and children were as likely to be infected as adults (infection rate 7·4% in children Interpretation Our data on cases as well as their infected and uninfected close contacts provide key insights into the epidemiology of SARS-CoV-2. This analysis shows that isolation and contact tracing reduce the time during which cases are infectious in the community, thereby reducing the R. The overall impact of isolation and contact tracing, however, is uncertain and highly dependent on the number of asymptomatic cases. Moreover, children are at a similar risk of infection to the general population, although less likely to have severe symptoms; hence they should be considered in analyses of transmission and control. Funding Emergency Response Program of Harbin Institute of Technology, Emergency Response Program of Peng Cheng Laboratory, US Centers for Disease Control and Prevention.',\n",
              "  'authors': ['Qifang Bi 1',\n",
              "   ' Yongsheng Wu 2',\n",
              "   ' Shujiang Mei 3',\n",
              "   ' Chenfei Ye 4',\n",
              "   ' Xuan Zou 5',\n",
              "   ' Zhen Zhang 2',\n",
              "   ' Xiaojian Liu 2',\n",
              "   ' Lan Wei 2',\n",
              "   ' Shaun A Truelove 1',\n",
              "   ' Tong Zhang 6',\n",
              "   ' Wei Gao 3',\n",
              "   ' Cong Cheng 3',\n",
              "   ' Xiujuan Tang 3',\n",
              "   ' Xiaoliang Wu 3',\n",
              "   ' Yu Wu 7',\n",
              "   ' Binbin Sun 4',\n",
              "   ' Suli Huang 8',\n",
              "   ' Yu Sun 6',\n",
              "   ' Juncen Zhang 6',\n",
              "   ' Ting Ma 4',\n",
              "   ' Justin Lessler 1',\n",
              "   ' Tiejian Feng 5'],\n",
              "  'date': '2020',\n",
              "  'identifier': '3020184843',\n",
              "  'references': ['3005079553',\n",
              "   '3003668884',\n",
              "   '3002108456',\n",
              "   '3002539152',\n",
              "   '3006961006',\n",
              "   '3010233963',\n",
              "   '3008985036',\n",
              "   '3006643024',\n",
              "   '3004912618',\n",
              "   '2129542667'],\n",
              "  'title': 'Epidemiology and transmission of COVID-19 in 391 cases and 1286 of their close contacts in Shenzhen, China: a retrospective cohort study.'},\n",
              " {'abstract': 'Automatic information retrieval systems have to deal with documents of varying lengths in a text collection. Document length normalization is used to fairly retrieve documents of all lengths. In this study, we ohserve that a normalization scheme that retrieves documents of all lengths with similar chances as their likelihood of relevance will outperform another scheme which retrieves documents with chances very different from their likelihood of relevance. We show that the retrievaf probabilities for a particular normalization method deviate systematically from the relevance probabilities across different collections. We present pivoted normalization, a technique that can be used to modify any normalization function thereby reducing the gap between the relevance and the retrieval probabilities. Training pivoted normalization on one collection, we can successfully use it on other (new) text collections, yielding a robust, collectzorz independent normalization technique. We use the idea of pivoting with the well known cosine normalization function. We point out some shortcomings of the cosine function andpresent two new normalization functions--pivoted unique normalization and piuotert byte size normalization.',\n",
              "  'authors': ['Amit Singhal ', ' Chris Buckley ', ' Manclar Mitra'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2000569744',\n",
              "  'references': ['1956559956',\n",
              "   '1978394996',\n",
              "   '1833785989',\n",
              "   '1482214997',\n",
              "   '2014415866',\n",
              "   '2887107689',\n",
              "   '2165612380',\n",
              "   '1525341925',\n",
              "   '2019976352',\n",
              "   '1518529582'],\n",
              "  'title': 'Pivoted document length normalization'},\n",
              " {'abstract': 'The history of non-ABC hepatitis is a kaleidoscope of intriguing, but often conflicting and confounding data. Studies of transfusion-associated non-ABC hepatitis are less convincing than they originally seemed. Chimpanzee cross-challenge studies, once the bastion for the theory of multiple NANB hepatitis agents, now have an alternative explanation in the impaired immune response associated with HCV infection and the ability of this agent to reinfect individuals previously assumed to be immune. Nonetheless, there are so many cases of acute and chronic NANB hepatitis that cannot currently be attributed to HCV that it is hard to avoid the implication of at least one, and possibly more, non-ABC hepatitis agents. There are now some transmission studies in small primates to support this contention, though recent chimpanzee transmission studies have been disappointingly negative. As with the hepatitis C virus, the breakthrough in this disease will not come from classic serology or virology, but from molecular biology. Similar molecular approaches to those that elucidated HCV are in progress and are promising in preliminary experiments. It is anticipated that the pace of molecular biology is such that a great deal more will be known about non-ABC in a relatively brief time, and perhaps one or more non-ABC agents will prove to be real and clinically relevant.',\n",
              "  'authors': ['Harvey J. Alter ', ' Daniel W. Bradley'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2089463925',\n",
              "  'references': ['2038264706',\n",
              "   '2089551619',\n",
              "   '2336905550',\n",
              "   '2156404972',\n",
              "   '208665126',\n",
              "   '2123520809',\n",
              "   '2010203103',\n",
              "   '2038066870',\n",
              "   '2108938529',\n",
              "   '2069607004'],\n",
              "  'title': 'Non-A, non-B hepatitis unrelated to the hepatitis C virus (non-ABC).'},\n",
              " {'abstract': 'This paper presents algorithms for computing constraints on the position of an object due to the presence of ther objects. This problem arises in applications that require choosing how to arrange or how to move objects without collisions. The approach presented here is based on characterizing the position and orientation of an object as a single point in a configuration space, in which each coordinate represents a degree of freedom in the position or orientation of the object. The configurations forbidden to this object, due to the presence of other objects, can then be characterized as regions in the configuration space, called configuration space obstacles. The paper presents algorithms for computing these configuration space obstacles when the objects are polygons or polyhedra.',\n",
              "  'authors': ['Lozano-Perez'],\n",
              "  'date': '1983',\n",
              "  'identifier': '2150500908',\n",
              "  'references': ['2163178194',\n",
              "   '2141825555',\n",
              "   '2033013465',\n",
              "   '1604766291',\n",
              "   '2077091230',\n",
              "   '2005814556',\n",
              "   '2007610503',\n",
              "   '1874694348',\n",
              "   '1991461030',\n",
              "   '2041775009'],\n",
              "  'title': 'Spatial Planning: A Configuration Space Approach'},\n",
              " {'abstract': \"In this paper, a framework for maximum a posteriori (MAP) estimation of hidden Markov models (HMM) is presented. Three key issues of MAP estimation, namely, the choice of prior distribution family, the specification of the parameters of prior densities, and the evaluation of the MAP estimates, are addressed. Using HMM's with Gaussian mixture state observation densities as an example, it is assumed that the prior densities for the HMM parameters can be adequately represented as a product of Dirichlet and normal-Wishart densities. The classical maximum likelihood estimation algorithms, namely, the forward-backward algorithm and the segmental k-means algorithm, are expanded, and MAP estimation formulas are developed. Prior density estimation issues are discussed for two classes of applications/spl minus/parameter smoothing and model adaptation/spl minus/and some experimental results are given illustrating the practical interest of this approach. Because of its adaptive nature, Bayesian learning is shown to serve as a unified approach for a wide range of speech recognition applications. >\",\n",
              "  'authors': ['J.-L. Gauvain 1', ' Chin-Hui Lee 2'],\n",
              "  'date': '1994',\n",
              "  'identifier': '2100969003',\n",
              "  'references': ['2049633694',\n",
              "   '3017143921',\n",
              "   '2142384583',\n",
              "   '1981367467',\n",
              "   '2403035479',\n",
              "   '1643320849',\n",
              "   '1575431606',\n",
              "   '2006258746',\n",
              "   '2086699924',\n",
              "   '2142775654'],\n",
              "  'title': 'Maximum a posteriori estimation for multivariate Gaussian mixture observations of Markov chains'},\n",
              " {'abstract': 'Abstract: We propose a novel deep network structure called \"Network In Network\" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.',\n",
              "  'authors': ['Min Lin ', ' Qiang Chen ', ' Shuicheng Yan'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2963911037',\n",
              "  'references': ['2962835968',\n",
              "   '2097117768',\n",
              "   '2117539524',\n",
              "   '1536680647',\n",
              "   '2963446712',\n",
              "   '2963037989',\n",
              "   '2109255472',\n",
              "   '2096733369',\n",
              "   '2302255633'],\n",
              "  'title': 'Network In Network'},\n",
              " {'abstract': 'In the post-fault dynamic analysis of interconnected power systems, the critical fault clearing time (CCT) is one of the parameters of paramount importance. Critical clearing time is a complex function of pre-fault system conditions (operating point, topology, system parameters), fault structure (type and location) and post-fault conditions that are in part dependent on the protective relaying policy. To define analytically such a relationship would be highly desirable but diversity of variable involved makes this task extremely complicated. Our efforts focus on examination of that complex mapping and investigation of the influence of the various parameters on CCT. The evaluation of CCT involves elaborate computations that often include time-consuming solutions of nonlinear on-fault system equations. Existing conventional pattern recognition techniques are incapable of synthesizing such complex and transparent mappings. Thus, when a human operator tells the machine learning unit (that is the pattern recognizer) that system state belongs to a certain class, say \"emergency\", the pattern recognizer merely records that classification mindlessly and is not able to look at the pattern with insight and discover what underlies the \"emergency\" nature of pattern. It is, therefore, highly desirable to have a mechanism which when presented with a sequence of class labeled patterns not only learns an internal structure which allows it to generalize and to classify other and to classify other patterns correctly, but also is able to shed some light on what combination of features give rise to the particular class membership.',\n",
              "  'authors': ['Dejan J. Sobajic ', ' Yoh-Han Pao'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2158053363',\n",
              "  'references': ['2293063825',\n",
              "   '1597286183',\n",
              "   '2177721432',\n",
              "   '2177040213',\n",
              "   '2152477898',\n",
              "   '2030851210',\n",
              "   '1980573901',\n",
              "   '1993628045',\n",
              "   '2060694473',\n",
              "   '1977125457'],\n",
              "  'title': 'Artificial neural-net based dynamic security assessment for electric power systems'},\n",
              " {'abstract': 'The previous decade witnessed significant advancements in the scholarship of teaching at the levels of both theory building and program development. Notwithstanding these achievements, there remains considerable ambiguity regarding the meaning of the concept. This ambiguity has implications for faculty evaluation. Excellence in teaching, expertise in teaching, and the scholarship of teaching are analyzed according to the nature and sources of knowledge construction underlying each. Practical examples are included to illustrate differences. It is argued that excellence in teaching and the scholarship of teaching are both important but should be recognized and rewarded in their own right.',\n",
              "  'authors': ['Carolin Kreber'],\n",
              "  'date': '2002',\n",
              "  'identifier': '1573940606',\n",
              "  'references': ['2140205964',\n",
              "   '2153000380',\n",
              "   '1518638857',\n",
              "   '31045409',\n",
              "   '1548317321',\n",
              "   '2018255452',\n",
              "   '2005492506',\n",
              "   '2151251644',\n",
              "   '62042437',\n",
              "   '2012940279'],\n",
              "  'title': 'Teaching Excellence, Teaching Expertise, and the Scholarship of Teaching'},\n",
              " {'abstract': \"The proposal of G. Cottrell et al. (1987) that their image compression network might be used to extract image features for pattern recognition automatically, is tested by training a neural network to compress 64 face images, spanning 11 subjects, and 13 nonface images. Features extracted in this manner (the output of the hidden units) are given as input to a one-layer network trained to distinguish faces from nonfaces and to attach a name and sex to the face images. The network successfully recognizes new images of familiar faces, categorizes novel images as to their `faceness' and, to a great extent, gender, and exhibits continued accuracy over a considerable range of partial or shifted input\",\n",
              "  'authors': ['M.K. Fleming ', ' G.W. Cottrell'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2125999363',\n",
              "  'references': ['1498436455',\n",
              "   '3121926921',\n",
              "   '2006852055',\n",
              "   '2565808444',\n",
              "   '2169718527',\n",
              "   '2045817341'],\n",
              "  'title': 'Categorization of faces using unsupervised feature extraction'},\n",
              " {'abstract': 'We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.',\n",
              "  'authors': ['Tim Salimans 1',\n",
              "   ' Ian Goodfellow 2',\n",
              "   ' Wojciech Zaremba 3',\n",
              "   ' Vicki Cheung ',\n",
              "   ' Alec Radford 1',\n",
              "   ' Xi Chen 4'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2963373786',\n",
              "  'references': ['1836465849',\n",
              "   '2183341477',\n",
              "   '2963684088',\n",
              "   '2964153729',\n",
              "   '2271840356',\n",
              "   '648143168',\n",
              "   '830076066',\n",
              "   '2949416428',\n",
              "   '2963685250',\n",
              "   '1487641199'],\n",
              "  'title': 'Improved techniques for training GANs'},\n",
              " {'abstract': 'Introduction. Generalized Least Squares and the Analysis of Heteroscedasticity. Estimation and Inference for Variance Functions. The Transform-Both-Sides Methodology. Combining Transformations and Weighting. Influence and Robustness. Technical Complements. Some Open Problems. References. Index.',\n",
              "  'authors': ['R. J. Carroll ', ' D. Ruppert'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2102000606',\n",
              "  'references': ['2118812883',\n",
              "   '2052176508',\n",
              "   '350025413',\n",
              "   '3123574146',\n",
              "   '2047142410',\n",
              "   '2102118103',\n",
              "   '2126052291',\n",
              "   '2032167823',\n",
              "   '2068302187',\n",
              "   '2312643126'],\n",
              "  'title': 'Transformation and Weighting in Regression'},\n",
              " {'abstract': 'In this paper, 3D voxel-similarity-based (VB) registration algorithms that optimize a feature-space clustering measure are proposed to combine the segmentation and registration process. We present a unifying definition and a classification scheme for existing VB matching criteria and propose a new matching criterion: the entropy of the grey-level scatter-plot. This criterion requires no segmentation or feature extraction and no a priori knowledge of photometric model parameters. The effects of practical implementation issues concerning grey-level resampling, scatter-plot binning, parzen-windowing and resampling frequencies are discussed in detail and evaluated using real world data (CT and MRI).',\n",
              "  'authors': ['André Collignon ',\n",
              "   ' Dirk Vandermeulen ',\n",
              "   ' Paul Suetens ',\n",
              "   ' Guy Marchal'],\n",
              "  'date': '1995',\n",
              "  'identifier': '1771671527',\n",
              "  'references': ['1963623641',\n",
              "   '3017143921',\n",
              "   '2051809205',\n",
              "   '2138943050',\n",
              "   '2049928737',\n",
              "   '2151297710',\n",
              "   '2079743144',\n",
              "   '1988978899',\n",
              "   '1974824465',\n",
              "   '2065406597'],\n",
              "  'title': '3D Multi-Modality Medical Image Registration Using Feature Space Clustering'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Masaru Tomita'],\n",
              "  'date': '1985',\n",
              "  'identifier': '2059000558',\n",
              "  'references': ['2139828164',\n",
              "   '1562942180',\n",
              "   '2106013472',\n",
              "   '2159400269',\n",
              "   '2467097043',\n",
              "   '1955233831',\n",
              "   '1850047186',\n",
              "   '1971135355',\n",
              "   '1990438144',\n",
              "   '1578472035'],\n",
              "  'title': 'Efficient parsing for natural language'},\n",
              " {'abstract': '',\n",
              "  'authors': ['N. Wang ', ' J.P. Butler ', ' D.E. Ingber'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2005929586',\n",
              "  'references': ['1960659342', '2589346240', '112704326', '3110233931'],\n",
              "  'title': 'Mechanotransduction across the cell surface and through the cytoskeleton'},\n",
              " {'abstract': 'In this paper, we review most major filtering approaches to texture feature extraction and perform a comparative study. Filtering approaches included are Laws masks (1980), ring/wedge filters, dyadic Gabor filter banks, wavelet transforms, wavelet packets and wavelet frames, quadrature mirror filters, discrete cosine transform, eigenfilters, optimized Gabor filters, linear predictors, and optimized finite impulse response filters. The features are computed as the local energy of the filter responses. The effect of the filtering is highlighted, keeping the local energy function and the classification algorithm identical for most approaches. For reference, comparisons with two classical nonfiltering approaches, co-occurrence (statistical) and autoregressive (model based) features, are given. We present a ranking of the tested approaches based on extensive experiments.',\n",
              "  'authors': ['T. Randen 1', ' J.H. Husoy 2'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2098347925',\n",
              "  'references': [],\n",
              "  'title': 'Filtering for texture classification: a comparative study'},\n",
              " {'abstract': 'As one of the most successful approaches to building recommender systems, collaborative filtering (CF) uses the known preferences of a group of users to make recommendations or predictions of the unknown preferences for other users. In this paper, we first introduce CF tasks and their main challenges, such as data sparsity, scalability, synonymy, gray sheep, shilling attacks, privacy protection, etc., and their possible solutions. We then present three main categories of CF techniques: memory-based, modelbased, and hybrid CF algorithms (that combine CF with other recommendation techniques), with examples for representative algorithms of each category, and analysis of their predictive performance and their ability to address the challenges. From basic techniques to the state-of-the-art, we attempt to present a comprehensive survey for CF techniques, which can be served as a roadmap for research and practice in this area.',\n",
              "  'authors': ['Xiaoyuan Su ', ' Taghi M. Khoshgoftaar'],\n",
              "  'date': '2009',\n",
              "  'identifier': '2100235918',\n",
              "  'references': ['1880262756',\n",
              "   '2140190241',\n",
              "   '2171960770',\n",
              "   '2042281163',\n",
              "   '1971040550',\n",
              "   '2110325612',\n",
              "   '1673310716',\n",
              "   '2121863487',\n",
              "   '1994389483',\n",
              "   '2159080219'],\n",
              "  'title': 'A survey of collaborative filtering techniques'},\n",
              " {'abstract': 'Abstract This paper explores differences between Connectionist proposals for cognitive architecture and the sorts of models that have traditionally been assumed in cognitive science. We claim that the major distinction is that, while both Connectionist and Classical architectures postulate representational mental states, the latter but not the former are committed to a symbol-level of representation, or to a ‘language of thought’: i.e., to representational states that have combinatorial syntactic and semantic structure. Several arguments for combinatorial structure in mental representations are then reviewed. These include arguments based on the ‘systematicity’ of mental representation: i.e., on the fact that cognitive capacities always exhibit certain symmetries, so that the ability to entertain a given thought implies the ability to entertain thoughts with semantically related contents. We claim that such arguments make a powerful case that mind/brain architecture is not Connectionist at the cognitive level. We then consider the possibility that Connectionism may provide an account of the neural (or ‘abstract neurological’) structures in which Classical cognitive architecture is implemented. We survey a number of the standard arguments that have been offered in favor of Connectionism, and conclude that they are coherent only on this interpretation.',\n",
              "  'authors': ['Jerry A. Fodor 1', ' Zenon W. Pylyshyn 2'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2118373646',\n",
              "  'references': ['1652505363',\n",
              "   '2158365276',\n",
              "   '2083137466',\n",
              "   '2112325651',\n",
              "   '2122988375',\n",
              "   '2170716495',\n",
              "   '2094249282',\n",
              "   '2912225506',\n",
              "   '2144862731',\n",
              "   '1529681538'],\n",
              "  'title': 'Connectionism and cognitive architecture: a critical analysis'},\n",
              " {'abstract': 'In this thesis, we apply as well as develop techniques and methodologies for the examination of the complex systems that are lexicalized statistical parsing models. The primary idea is that of treating the “model as data”, which is not a particular method, but a paradigm and a research methodology. Our argument is that lexicalized statistical parsing models have become increasingly complex, and therefore require thorough scrutiny, both to achieve the scientific aim of understanding what has been built thus far, and to achieve both the scientific and engineering goal of using that understanding for progress. In this thesis, we take a particular, dominant type of parsing model and perform a macro analysis, to reveal its core (and design a software engine that modularizes the periphery), and we also crucially perform a detailed analysis, which provides for the first time a window onto the efficacy of specific parameters. These analyses have not only yielded insight into the core model, but they have also enabled the identification of “inefficiencies” in our baseline model, such that those inefficiencies can be reduced to form a more compact model, or exploited for finding a better-estimated model with higher accuracy, or both.',\n",
              "  'authors': ['Daniel M. Bikel ', ' Mitchell P. Marcus'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2305592425',\n",
              "  'references': ['2099111195',\n",
              "   '2147880316',\n",
              "   '2125055259',\n",
              "   '2049633694',\n",
              "   '1632114991',\n",
              "   '1535015163',\n",
              "   '1508165687',\n",
              "   '2092654472',\n",
              "   '2151170651',\n",
              "   '1773803948'],\n",
              "  'title': 'On the parameter space of generative lexicalized statistical parsing models'},\n",
              " {'abstract': \"INTRODUCTION: Brief History. Multifingered Hands and Dextrous Manipulation. Outline of the Book. Bibliography. RIGID BODY MOTION: Rigid Body Transformations. Rotational Motion in R3. Rigid Motion in R3. Velocity of a Rigid Body. Wrenches and Reciprocal Screws. MANIPULATOR KINEMATICS: Introduction. Forward Kinematics. Inverse Kinematics. The Manipulator Jacobian. Redundant and Parallel Manipulators. ROBOT DYNAMICS AND CONTROL: Introduction. Lagrange's Equations. Dynamics of Open-Chain Manipulators. Lyapunov Stability Theory. Position Control and Trajectory Tracking. Control of Constrained Manipulators. MULTIFINGERED HAND KINEMATICS: Introduction to Grasping. Grasp Statics. Force-Closure. Grasp Planning. Grasp Constraints. Rolling Contact Kinematics. HAND DYNAMICS AND CONTROL: Lagrange's Equations with Constraints. Robot Hand Dynamics. Redundant and Nonmanipulable Robot Systems. Kinematics and Statics of Tendon Actuation. Control of Robot Hands. NONHOLONOMIC BEHAVIOR IN ROBOTIC SYSTEMS: Introduction. Controllability and Frobenius' Theorem. Examples of Nonholonomic Systems. Structure of Nonholonomic Systems. NONHOLONOMIC MOTION PLANNING: Introduction. Steering Model Control Systems Using Sinusoids. General Methods for Steering. Dynamic Finger Repositioning. FUTURE PROSPECTS: Robots in Hazardous Environments. Medical Applications for Multifingered Hands. Robots on a Small Scale: Microrobotics. APPENDICES: Lie Groups and Robot Kinematics. A Mathematica Package for Screw Calculus. Bibliography. Index Each chapter also includes a Summary, Bibliography, and Exercises\",\n",
              "  'authors': ['Richard M. Murray ', ' S. Shankar Sastry ', ' Li Zexiang'],\n",
              "  'date': '1994',\n",
              "  'identifier': '1564897360',\n",
              "  'references': ['1887006513',\n",
              "   '2062691475',\n",
              "   '1612551514',\n",
              "   '1555601014',\n",
              "   '3094663703',\n",
              "   '2133361850',\n",
              "   '1964373008',\n",
              "   '3013971696',\n",
              "   '2112474089',\n",
              "   '1582353822'],\n",
              "  'title': 'A Mathematical Introduction to Robotic Manipulation'},\n",
              " {'abstract': 'In this paper we introduce a novel representation of the significant changes in curvature along the bounding contour of planar shape. We call the representation the Curvature Primal Sketch because of the close analogy to the primal sketch representation advocated by Marr for describing significant intensity changes. We define a set of primitive parameterized curvature discontinuities, and derive expressions for their convolutions with the first and second derivatives of a Gaussian. We describe an implemented algorithm that computes the Curvature Primal Sketch by matching the multiscale convolutions of a shape, and illustrate its performance on a set of tool shapes. Several applications of the representation are sketched.',\n",
              "  'authors': ['Haruo Asada 1', ' Michael Brady 2'],\n",
              "  'date': '1986',\n",
              "  'identifier': '2163775665',\n",
              "  'references': ['2109863423',\n",
              "   '2003370853',\n",
              "   '2133155955',\n",
              "   '1968245656',\n",
              "   '1530383550',\n",
              "   '2130355536',\n",
              "   '2052277674',\n",
              "   '2913090860',\n",
              "   '1992779461',\n",
              "   '2077246452'],\n",
              "  'title': 'The Curvature Primal Sketch'},\n",
              " {'abstract': 'Linear Support Vector Machines (SVMs) have become one of the most prominent machine learning techniques for high-dimensional sparse data commonly encountered in applications like text classification, word-sense disambiguation, and drug design. These applications involve a large number of examples n as well as a large number of features N, while each example has only s << N non-zero features. This paper presents a Cutting Plane Algorithm for training linear SVMs that provably has training time 0(s,n) for classification problems and o(sn log (n))for ordinal regression problems. The algorithm is based on an alternative, but equivalent formulation of the SVM optimization problem. Empirically, the Cutting-Plane Algorithm is several orders of magnitude faster than decomposition methods like svm light for large datasets.',\n",
              "  'authors': ['Thorsten Joachims'],\n",
              "  'date': '2006',\n",
              "  'identifier': '2035720976',\n",
              "  'references': ['2153635508',\n",
              "   '3023786531',\n",
              "   '2149684865',\n",
              "   '1512098439',\n",
              "   '2047221353',\n",
              "   '1576520375',\n",
              "   '2150102617',\n",
              "   '2105842272',\n",
              "   '2161920802',\n",
              "   '2170654002'],\n",
              "  'title': 'Training linear SVMs in linear time'},\n",
              " {'abstract': \"Mandell, Douglas, and Bennett's principles and practice of infectious diseases / , Mandell, Douglas, and Bennett's principles and practice of infectious diseases / , کتابخانه دیجیتال جندی شاپور اهواز\",\n",
              "  'authors': ['[edited by] Gerald L. Mandell 1',\n",
              "   ' John E. Bennett 2',\n",
              "   ' Raphael Dolin 2'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2109779439',\n",
              "  'references': ['2108693332',\n",
              "   '2130141864',\n",
              "   '2118546214',\n",
              "   '2125675160',\n",
              "   '2139894595',\n",
              "   '2098716491',\n",
              "   '2053058114',\n",
              "   '2103338644',\n",
              "   '3031436746',\n",
              "   '2032866129'],\n",
              "  'title': \"Mandell, Douglas, and Bennett's Principles and Practice of Infectious Diseases\"},\n",
              " {'abstract': 'Probabilistic Latent Semantic Indexing is a novel approach to automated document indexing which is based on a statistical latent class model for factor analysis of count data. Fitted from a training corpus of text documents by a generalization of the Expectation Maximization algorithm, the utilized model is able to deal with domain{specific synonymy as well as with polysemous words. In contrast to standard Latent Semantic Indexing (LSI) by Singular Value Decomposition, the probabilistic variant has a solid statistical foundation and defines a proper generative data model. Retrieval experiments on a number of test collections indicate substantial performance gains over direct term matching methods as well as over LSI. In particular, the combination of models with different dimensionalities has proven to be advantageous.',\n",
              "  'authors': ['Thomas Hofmann'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2107743791',\n",
              "  'references': ['2147152072',\n",
              "   '2049633694',\n",
              "   '1956559956',\n",
              "   '1612003148',\n",
              "   '2567948266',\n",
              "   '2127314673',\n",
              "   '1718512272',\n",
              "   '2140842551',\n",
              "   '2143144851',\n",
              "   '2063089147'],\n",
              "  'title': 'Probabilistic latent semantic indexing'},\n",
              " {'abstract': 'We present an application of back-propagation networks to handwritten digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service.',\n",
              "  'authors': ['Yann LeCun 1',\n",
              "   ' Bernhard E. Boser 2',\n",
              "   ' John S. Denker 2',\n",
              "   ' 3',\n",
              "   ' Donnie Henderson 1',\n",
              "   ' R. E. Howard 2',\n",
              "   ' Wayne E. Hubbard 2',\n",
              "   ' Lawrence D. Jackel 1'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2154579312',\n",
              "  'references': ['2154642048',\n",
              "   '2147800946',\n",
              "   '2114766824',\n",
              "   '169539560',\n",
              "   '2157475639',\n",
              "   '1965770722',\n",
              "   '56903235',\n",
              "   '2091987367',\n",
              "   '2058841211',\n",
              "   '2153988646'],\n",
              "  'title': 'Handwritten Digit Recognition with a Back-Propagation Network'},\n",
              " {'abstract': 'The probability of error in decoding an optimal convolutional code transmitted over a memoryless channel is bounded from above and below as a function of the constraint length of the code. For all but pathological channels the bounds are asymptotically (exponentially) tight for rates above R_{0} , the computational cutoff rate of sequential decoding. As a function of constraint length the performance of optimal convolutional codes is shown to be superior to that of block codes of the same length, the relative improvement increasing with rate. The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms.',\n",
              "  'authors': ['A. Viterbi'],\n",
              "  'date': '1967',\n",
              "  'identifier': '1991133427',\n",
              "  'references': ['2034274945',\n",
              "   '1993944611',\n",
              "   '2087362480',\n",
              "   '2005530146',\n",
              "   '1976797517',\n",
              "   '1527268325',\n",
              "   '1527096151'],\n",
              "  'title': 'Error bounds for convolutional codes and an asymptotically optimum decoding algorithm'},\n",
              " {'abstract': 'Abstract Many existing rule learning systems are computationally expensive on large noisy datasets. In this paper we evaluate the recently-proposed rule learning algorithm IREP on a large and diverse collection of benchmark problems. We show that while IREP is extremely efficient, it frequently gives error rates higher than those of C4.5 and C4.5rules. We then propose a number of modifications resulting in an algorithm RIPPERk that is very competitive with C4.5rules with respect to error rates, but much more efficient on large samples. RIPPERk obtains error rates lower than or equivalent to C4.5rules on 22 of 37 benchmark problems, scales nearly linearly with the number of training examples, and can efficiently process noisy datasets containing hundreds of thousands of examples.',\n",
              "  'authors': ['William W. Cohen'],\n",
              "  'date': '1995',\n",
              "  'identifier': '1670263352',\n",
              "  'references': ['2128420091',\n",
              "   '1999138184',\n",
              "   '1604329830',\n",
              "   '1531743498',\n",
              "   '2111746072',\n",
              "   '2089967664',\n",
              "   '146100937',\n",
              "   '2037689320',\n",
              "   '1510806966',\n",
              "   '165133269'],\n",
              "  'title': 'Fast effective rule induction'},\n",
              " {'abstract': 'The Viterbi algorithm (VA) is a recursive optimal solution to the problem of estimating the state sequence of a discrete-time finite-state Markov process observed in memoryless noise. Many problems in areas such as digital communications can be cast in this form. This paper gives a tutorial exposition of the algorithm and of how it is implemented and analyzed. Applications to date are reviewed. Increasing use of the algorithm in a widening variety of areas is foreseen.',\n",
              "  'authors': ['Jr. G.D. Forney'],\n",
              "  'date': '1973',\n",
              "  'identifier': '2142384583',\n",
              "  'references': ['1562979145',\n",
              "   '2045407304',\n",
              "   '2131086249',\n",
              "   '1991133427',\n",
              "   '2122683098',\n",
              "   '2106185713',\n",
              "   '2153810958',\n",
              "   '2035227369',\n",
              "   '2161457263',\n",
              "   '2134360027'],\n",
              "  'title': 'The viterbi algorithm'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Leo Breiman'],\n",
              "  'date': '1996',\n",
              "  'identifier': '2912934387',\n",
              "  'references': ['2102865756',\n",
              "   '3085162807',\n",
              "   '2102201073',\n",
              "   '2111814036',\n",
              "   '1969557815',\n",
              "   '2030748132',\n",
              "   '1482451543',\n",
              "   '1531648066',\n",
              "   '1541145887',\n",
              "   '3112073073'],\n",
              "  'title': 'Bagging predictors'},\n",
              " {'abstract': 'Some individuals infected with hepatitis C virus (HCV) experience multiple episodes of acute hepatitis. It is unclear whether these episodes are due to reinfection with HCV or to reactivation of the original virus infection. Markers of viral replication and host immunity were studied in five chimpanzees sequentially inoculated over a period of 3 years with different HCV strains of proven infectivity. Each rechallenge of a convalescent chimpanzee with the same or a different HCV strain resulted in the reappearance of viremia, which was due to infection with the subsequent challenge virus. The evidence indicates that HCV infection does not elicit protective immunity against reinfection with homologous or heterologous strains, which raises concerns for the development of effective vaccines against HCV.',\n",
              "  'authors': ['P Farci ',\n",
              "   ' HJ Alter ',\n",
              "   ' S Govindarajan ',\n",
              "   ' DC Wong ',\n",
              "   ' R Engle ',\n",
              "   ' RR Lesniewski ',\n",
              "   ' IK Mushahwar ',\n",
              "   ' SM Desai ',\n",
              "   ' RH Miller ',\n",
              "   ' N Ogata'],\n",
              "  'date': '1992',\n",
              "  'identifier': '1993023565',\n",
              "  'references': ['2006309458',\n",
              "   '2066124462',\n",
              "   '1974879228',\n",
              "   '2124528668',\n",
              "   '2163131045',\n",
              "   '1971792395',\n",
              "   '1581048386',\n",
              "   '2000229624',\n",
              "   '1999334158',\n",
              "   '2092200952'],\n",
              "  'title': 'Lack of protective immunity against reinfection with hepatitis C virus'},\n",
              " {'abstract': 'Metagenomic next-generation sequencing (mNGS), the shotgun sequencing of RNA and DNA from clinical samples, has proved useful for broad-spectrum pathogen detection and the genomic surveillance of viral outbreaks. An additional target enrichment step is generally needed for high-sensitivity pathogen identification in low-titre infections, yet available methods using PCR or capture probes can be limited by high cost, narrow scope of detection, lengthy protocols and/or cross-contamination. Here, we developed metagenomic sequencing with spiked primer enrichment (MSSPE), a method for enriching targeted RNA viral sequences while simultaneously retaining metagenomic sensitivity for other pathogens. We evaluated MSSPE for 14 different viruses, yielding a median tenfold enrichment and mean 47% (±16%) increase in the breadth of genome coverage over mNGS alone. Virus detection using MSSPE arboviral or haemorrhagic fever viral panels was comparable in sensitivity to specific PCR, demonstrating 95% accuracy for the detection of Zika, Ebola, dengue, chikungunya and yellow fever viruses in plasma samples from infected patients. Notably, sequences from re-emerging and/or co-infecting viruses that have not been specifically targeted a priori, including Powassan and Usutu, were successfully enriched using MSSPE. MSSPE is simple, low cost, fast and deployable on either benchtop or portable nanopore sequencers, making this method directly applicable for diagnostic laboratory and field use.',\n",
              "  'authors': ['Xianding Deng 1',\n",
              "   ' Asmeeta Achari 1',\n",
              "   ' Scot Federman 1',\n",
              "   ' Guixia Yu 1',\n",
              "   ' Sneha Somasekar 1',\n",
              "   ' Inês Bártolo 2',\n",
              "   ' Shigeo Yagi 3',\n",
              "   ' Placide Mbala-Kingebeni 4',\n",
              "   ' Jimmy Kapetshi 4',\n",
              "   ' Steve Ahuka-Mundeke 4',\n",
              "   ' Jean-Jacques Muyembe-Tamfum 4',\n",
              "   ' Asim A. Ahmed 5',\n",
              "   ' 6',\n",
              "   ' Vijay Ganesh 7',\n",
              "   ' Manasi Tamhankar 8',\n",
              "   ' Jean L. Patterson 8',\n",
              "   ' Nicaise Ndembi 9',\n",
              "   ' Dora Mbanya 10',\n",
              "   ' 11',\n",
              "   ' Lazare Kaptue 12',\n",
              "   ' Carole McArthur 13',\n",
              "   ' José E. Muñoz-Medina 14',\n",
              "   ' Cesar R. Gonzalez-Bonilla 14',\n",
              "   ' Susana López 15',\n",
              "   ' Carlos F. Arias 15',\n",
              "   ' Shaun Arevalo 1',\n",
              "   ' Steve Miller 1',\n",
              "   ' Mars Stone 16',\n",
              "   ' Michael Busch 16',\n",
              "   ' Kristina Hsieh 3',\n",
              "   ' Sharon Messenger 3',\n",
              "   ' Debra A. Wadford 3',\n",
              "   ' Mary Rodgers 17',\n",
              "   ' Gavin Cloherty 17',\n",
              "   ' Nuno R. Faria 18',\n",
              "   ' Julien Thézé 18',\n",
              "   ' Oliver G. Pybus 18',\n",
              "   ' Zoraima Neto 19',\n",
              "   ' Joana Morais 19',\n",
              "   ' Nuno Taveira 2',\n",
              "   ' John R. Hackett 17',\n",
              "   ' Charles Y. Chiu 1'],\n",
              "  'date': '2020',\n",
              "  'identifier': '2999983020',\n",
              "  'references': ['2170551349',\n",
              "   '2128880918',\n",
              "   '1975375203',\n",
              "   '2122349387',\n",
              "   '2121180999',\n",
              "   '2259815689',\n",
              "   '2170486072',\n",
              "   '2616925143',\n",
              "   '2106780559',\n",
              "   '2618268848'],\n",
              "  'title': 'Metagenomic sequencing with spiked primer enrichment for viral diagnostics and genomic surveillance.'},\n",
              " {'abstract': 'Summary. We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together.The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the',\n",
              "  'authors': ['Hui Zou ', ' Trevor Hastie'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2122825543',\n",
              "  'references': ['1554944419',\n",
              "   '2135046866',\n",
              "   '2109363337',\n",
              "   '2063978378',\n",
              "   '2157795344',\n",
              "   '2798909945',\n",
              "   '2143426320',\n",
              "   '2074682976',\n",
              "   '1975900269',\n",
              "   '2138550913'],\n",
              "  'title': 'Regularization and variable selection via the elastic net'},\n",
              " {'abstract': 'This paper deals with the ground state of an interacting electron gas in an external potential $v(\\\\mathrm{r})$. It is proved that there exists a universal functional of the density, $F[n(\\\\mathrm{r})]$, independent of $v(\\\\mathrm{r})$, such that the expression $E\\\\ensuremath{\\\\equiv}\\\\ensuremath{\\\\int}v(\\\\mathrm{r})n(\\\\mathrm{r})d\\\\mathrm{r}+F[n(\\\\mathrm{r})]$ has as its minimum value the correct ground-state energy associated with $v(\\\\mathrm{r})$. The functional $F[n(\\\\mathrm{r})]$ is then discussed for two situations: (1) $n(\\\\mathrm{r})={n}_{0}+\\\\stackrel{\\\\ifmmode \\\\tilde{}\\\\else \\\\~{}\\\\fi{}}{n}(\\\\mathrm{r})$, $\\\\frac{\\\\stackrel{\\\\ifmmode \\\\tilde{}\\\\else \\\\~{}\\\\fi{}}{n}}{{n}_{0}}\\\\ensuremath{\\\\ll}1$, and (2) $n(\\\\mathrm{r})=\\\\ensuremath{\\\\phi}(\\\\frac{\\\\mathrm{r}}{{r}_{0}})$ with $\\\\ensuremath{\\\\phi}$ arbitrary and ${r}_{0}\\\\ensuremath{\\\\rightarrow}\\\\ensuremath{\\\\infty}$. In both cases $F$ can be expressed entirely in terms of the correlation energy and linear and higher order electronic polarizabilities of a uniform electron gas. This approach also sheds some light on generalized Thomas-Fermi methods and their limitations. Some new extensions of these methods are presented.',\n",
              "  'authors': ['P. C. Hohenberg 1', ' Walter Kohn 2'],\n",
              "  'date': '1964',\n",
              "  'identifier': '2030976617',\n",
              "  'references': ['1550061415',\n",
              "   '2166244948',\n",
              "   '2159752439',\n",
              "   '2112850441',\n",
              "   '1501145371',\n",
              "   '1992985800',\n",
              "   '1544171083',\n",
              "   '2057936436',\n",
              "   '2757803490',\n",
              "   '1964875359'],\n",
              "  'title': 'Inhomogeneous Electron Gas'},\n",
              " {'abstract': 'A nerve net model for the visual cortex of higher vertebrates is presented. A simple learning procedure is shown to be sufficient for the organization of some essential functional properties of single units. The rather special assumptions usually made in the literature regarding preorganization of the visual cortex are thereby avoided. The model consists of 338 neurones forming a sheet analogous to the cortex. The neurones are connected randomly to a “retina” of 19 cells. Nine different stimuli in the form of light bars were applied. The afferent connections were modified according to a mechanism of synaptic training. After twenty presentations of all the stimuli individual cortical neurones became sensitive to only one orientation. Neurones with the same or similar orientation sensitivity tended to appear in clusters, which are analogous to cortical columns. The system was shown to be insensitive to a background of disturbing input excitations during learning. After learning it was able to repair small defects introduced into the wiring and was relatively insensitive to stimuli not used during training.',\n",
              "  'authors': ['C. von der Malsburg'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2887242076',\n",
              "  'references': ['2116360511',\n",
              "   '2117731089',\n",
              "   '85058473',\n",
              "   '2119051448',\n",
              "   '2008353316',\n",
              "   '2008625057',\n",
              "   '148261105',\n",
              "   '1757333299',\n",
              "   '1969469807',\n",
              "   '2011203963'],\n",
              "  'title': 'Self-organization of orientation sensitive cells in the striata cortex'},\n",
              " {'abstract': 'We review techniques for sensor fusion in robot navigation, emphasizing algorithms for self-location. These find use when the sensor suite of a mobile robot comprises several different sensors, some complementary and some redundant. Integrating the sensor readings, the robot seeks to accomplish tasks such as constructing a map of its environment, locating itself in that map, and recognizing objects that should be avoided or sought. The review describes integration techniques in two categories: low-level fusion is used for direct integration of sensory data, resulting in parameter and state estimates; high-level fusion is used for indirect integration of sensory data in hierarchical architectures, through command arbitration and integration of control signals suggested by different modules. The review provides an arsenal of tools for addressing this (rather ill-posed) problem in machine intelligence, including Kalman filtering, rule-based techniques, behavior based algorithms, and approaches that borrow from information theory, Dempster-Shafer reasoning, fuzzy logic and neural networks.',\n",
              "  'authors': ['M. Kam ', ' Xiaoxun Zhu ', ' P. Kalata'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2159879829',\n",
              "  'references': ['2528268528',\n",
              "   '2028310195',\n",
              "   '2571050459',\n",
              "   '2177274602',\n",
              "   '2110144538',\n",
              "   '2057650923',\n",
              "   '2145060371',\n",
              "   '2122512809',\n",
              "   '1591763911',\n",
              "   '2113786136'],\n",
              "  'title': 'Sensor fusion for mobile robot navigation'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Thomas N. Kipf ', ' Max Welling'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2964015378',\n",
              "  'references': ['2962711740',\n",
              "   '2907492528',\n",
              "   '3100848837',\n",
              "   '2962883549',\n",
              "   '2963224980',\n",
              "   '2963184176',\n",
              "   '3100278010',\n",
              "   '2796426482',\n",
              "   '2786016794',\n",
              "   '2966149470'],\n",
              "  'title': 'Semi-Supervised Classification with Graph Convolutional Networks'},\n",
              " {'abstract': \"In this paper, a methodological educational proposal based on constructivism and collaborative learning theories is described. The suggested approach has been successfully applied to a subject entitled ''Computer Architecture and Engineering'' in a Computer Science degree in the University of La Laguna in Spain. This methodology is supported by two tools: the Moodle platform as a collaboration framework among students and teachers and a free Instruction Level Parallelism (ILP) processor simulator called SIMDE, developed by the authors to promote the experience and help the understanding of superscalar and VLIW processors. This work is described showing how the constructivist and collaborative approaches have been applied and how the activities have been structured temporarily in phases. This educational proposal has been validated and improved with the feedback of the students during two academic years. Furthermore, the methodological procedure is also suitable to be used not only in subjects with contents which require the understanding of dynamic situations but also in subjects with other requirements.\",\n",
              "  'authors': ['Lorenzo Moreno ',\n",
              "   ' Carina Gonzalez ',\n",
              "   ' Ivan Castilla ',\n",
              "   ' Evelio Gonzalez ',\n",
              "   ' Jose Sigut'],\n",
              "  'date': '2007',\n",
              "  'identifier': '1970496636',\n",
              "  'references': ['2149338788',\n",
              "   '2788962374',\n",
              "   '3022468393',\n",
              "   '1555915743',\n",
              "   '1583020840',\n",
              "   '200254236',\n",
              "   '2118172827',\n",
              "   '2047259106',\n",
              "   '2078446599',\n",
              "   '617486778'],\n",
              "  'title': 'Applying a constructivist and collaborative methodological approach in engineering education'},\n",
              " {'abstract': 'Background & Aims: Severe acute respiratory syndrome (SARS) is a recently emerged infection from a novel coronavirus (CoV). Apart from fever and respiratory complications, gastrointestinal symptoms are frequently observed in patients with SARS but the significance remains undetermined. Herein, we describe the clinical, pathologic, and virologic features of the intestinal involvement of this new viral infection. Methods: A retrospective analysis of the gastrointestinal symptoms and other clinical parameters of the first 138 patients with confirmed SARS admitted for a major outbreak in Hong Kong in March 2003 was performed. Intestinal specimens were obtained by colonoscopy or postmortem examination to detect the presence of coronavirus by electron microscopy, virus culture, and reverse-transcription polymerase chain reaction. Results: Among these 138 patients with SARS, 28 (20.3%) presented with watery diarrhea and up to 38.4% of patients had symptoms of diarrhea during the course of illness. Diarrhea was more frequently observed during the first week of illness. The mean number of days with diarrhea was 3.7 ± 2.7, and most diarrhea was self-limiting. Intestinal biopsy specimens obtained by colonoscopy or autopsy showed minimal architectural disruption but the presence of active viral replication within both the small and large intestine. Coronavirus was also isolated by culture from these specimens, and SARS-CoV RNA can be detected in the stool of patients for more than 10 weeks after symptom onset. Conclusions: Diarrhea is a common presenting symptom of SARS. The intestinal tropism of the SARS-CoV has major implications on clinical presentation and viral transmission.',\n",
              "  'authors': ['Wai K Leung 1',\n",
              "   ' Ka-fai To 1',\n",
              "   ' Paul K.S Chan 1',\n",
              "   ' Henry L.Y Chan 1',\n",
              "   ' Alan K.L Wu 1',\n",
              "   ' Nelson Lee 1',\n",
              "   ' Kwok Y Yuen 2',\n",
              "   ' Joseph J.Y Sung 1'],\n",
              "  'date': '2003',\n",
              "  'identifier': '1757215199',\n",
              "  'references': ['2132260239',\n",
              "   '2104548316',\n",
              "   '2131262274',\n",
              "   '2129542667',\n",
              "   '2163627712',\n",
              "   '1990049863',\n",
              "   '1971054351',\n",
              "   '1976741900',\n",
              "   '2122296975',\n",
              "   '2022066607'],\n",
              "  'title': 'Enteric involvement of severe acute respiratory syndrome-associated coronavirus infection.'},\n",
              " {'abstract': 'This paper describes FOIL, a system that learns Horn clauses from data expressed as relations. FOIL is based on ideas that have proved effective in attribute-value learning systems, but extends them to a first-order formalism. This new system has been applied successfully to several tasks taken from the machine learning literature.',\n",
              "  'authors': ['J. R. Quinlan'],\n",
              "  'date': '1990',\n",
              "  'identifier': '1999138184',\n",
              "  'references': ['3085162807',\n",
              "   '2149706766',\n",
              "   '1594031697',\n",
              "   '2136000097',\n",
              "   '2128420091',\n",
              "   '2180885055',\n",
              "   '1983661866',\n",
              "   '145476170',\n",
              "   '2428981601',\n",
              "   '2106596127'],\n",
              "  'title': 'Learning Logical Definitions from Relations'},\n",
              " {'abstract': \"An efficient method for the calculation of the interactions of a 2' factorial ex- periment was introduced by Yates and is widely known by his name. The generaliza- tion to 3' was given by Box et al. (1). Good (2) generalized these methods and gave elegant algorithms for which one class of applications is the calculation of Fourier series. In their full generality, Good's methods are applicable to certain problems in which one must multiply an N-vector by an N X N matrix which can be factored into m sparse matrices, where m is proportional to log N. This results inma procedure requiring a number of operations proportional to N log N rather than N2. These methods are applied here to the calculation of complex Fourier series. They are useful in situations where the number of data points is, or can be chosen to be, a highly composite number. The algorithm is here derived and presented in a rather different form. Attention is given to the choice of N. It is also shown how special advantage can be obtained in the use of a binary computer with N = 2' and how the entire calculation can be performed within the array of N data storage locations used for the given Fourier coefficients. Consider the problem of calculating the complex Fourier series N-1 (1) X(j) = EA(k)-Wjk, j = 0 1, * ,N- 1, k=0\",\n",
              "  'authors': ['James W. Cooley ', ' John W. Tukey'],\n",
              "  'date': '1965',\n",
              "  'identifier': '2061171222',\n",
              "  'references': ['2795474086'],\n",
              "  'title': 'An algorithm for the machine calculation of complex Fourier series'},\n",
              " {'abstract': 'This paper examines the idea that ordered patterns of nerve connections are set up by means of markers carried by the individual cells. The case of the ordered retinotectal projection in amphibia and fishes is discussed in great detail. It is suggested that retinotectal mappings are the result of two mechanisms acting in concert. One mechanism induces a set of retinal markers into the tectum. By this means, an initially haphazard pattern of synapses is transformed into a continuous or piece-wise continuous projection. The other mechanism places the individual pieces of the map in the correct orientation. The machinery necessary for this inductive scheme has been expressed in terms of a set of differential equations, which have been solved numerically for a number of cases. Straightforward assumptions are made as to how markers are distributed in the retina; how they are induced into the tectum; and how the induced markers bring about alterations in the pattern of synaptic contacts. A detailed physiological interpretation of the model is given. The inductive mechanism has been formulated at the level of the individual synaptic interactions. Therefore, it is possible to specify, in a given situation, not only the nature of the end state of the mapping but also how the mapping develops over time. The role of the modes of growth of retina and tectum in shaping the developing projection becomes clear. Since, on this model, the tectum is initially devoid of markers, there is an important difference between the development and the regeneration of ordered mappings. In the development of duplicate maps from various types of compound-eyes, it is suggested that the tectum, rather than the retina, contains an abnormal distribution of markers. An important parameter in these experiments, and also in the regeneration experiments where part-duplication has been found, is the range of interaction amongst the retinal cells. It is suggested that the results of many of the regeneration experiments (including apparently contradictory ones) are manifestations of a conflict between the two alternative ways of specifying the orientation of the map: through the information carried by the markers previously induced into the tectum and through the orientation mechanism itself.',\n",
              "  'authors': ['D. J. Willshaw ', ' C. Von Der Malsburg'],\n",
              "  'date': '1979',\n",
              "  'identifier': '2017811812',\n",
              "  'references': ['1972536405',\n",
              "   '1980878261',\n",
              "   '2102993821',\n",
              "   '1949328498',\n",
              "   '1625407287',\n",
              "   '348476259',\n",
              "   '1980094138',\n",
              "   '2126941372',\n",
              "   '1967624605',\n",
              "   '2092157896'],\n",
              "  'title': 'A marker induction mechanism for the establishment of ordered neural mappings: its application to the retinotectal problem'},\n",
              " {'abstract': 'The popularity of the Web and Internet commerce provides many extremely large datasets from which information can be gleaned by data mining. This book focuses on practical algorithms that have been used to solve key problems in data mining and which can be used on even the largest datasets. It begins with a discussion of the map-reduce framework, an important tool for parallelizing algorithms automatically. The authors explain the tricks of locality-sensitive hashing and stream processing algorithms for mining data that arrives too fast for exhaustive processing. The PageRank idea and related tricks for organizing the Web are covered next. Other chapters cover the problems of finding frequent itemsets and clustering. The final chapters cover two applications: recommendation systems and Web advertising, each vital in e-commerce. Written by two authorities in database and Web technologies, this book is essential reading for students and practitioners alike.',\n",
              "  'authors': ['Anand Rajaraman 1', ' Jeffrey David Ullman 2'],\n",
              "  'date': '2011',\n",
              "  'identifier': '1736726159',\n",
              "  'references': ['2173213060',\n",
              "   '1532325895',\n",
              "   '1565377632',\n",
              "   '3013264884',\n",
              "   '2171960770',\n",
              "   '2139212933',\n",
              "   '2119821739',\n",
              "   '1981420413',\n",
              "   '2121947440',\n",
              "   '2119565742'],\n",
              "  'title': 'Mining of Massive Datasets'},\n",
              " {'abstract': 'Chemical analysis and a study of renaturation kinetics show that the nematode, Caenorhabditis elegans, has a haploid DNA content of 8 x 10(7) base pairs (20 times the genome of E. coli). Eighty-three percent of the DNA sequences are unique. The mean base composition is 36% GC; a small component, containing the rRNA cistrons, has a base composition of 51% GC. The haploid genome contains about 300 genes for 4S RNA, 110 for 5S RNA, and 55 for (18 + 28)S RNA.',\n",
              "  'authors': ['J E Sulston ', ' S Brenner'],\n",
              "  'date': '1974',\n",
              "  'identifier': '2115708583',\n",
              "  'references': ['2005389848', '1966071664', '2091544943'],\n",
              "  'title': 'THE DNA OF CAENORHABDITIS ELEGANS'},\n",
              " {'abstract': 'Suppose a discrete-time signal S(t), 0/spl les/t<N, is a superposition of atoms taken from a combined time-frequency dictionary made of spike sequences 1/sub {t=/spl tau/}/ and sinusoids exp{2/spl pi/iwt/N}//spl radic/N. Can one recover, from knowledge of S alone, the precise collection of atoms going to make up S? Because every discrete-time signal can be represented as a superposition of spikes alone, or as a superposition of sinusoids alone, there is no unique way of writing S as a sum of spikes and sinusoids in general. We prove that if S is representable as a highly sparse superposition of atoms from this time-frequency dictionary, then there is only one such highly sparse representation of S, and it can be obtained by solving the convex optimization problem of minimizing the l/sup 1/ norm of the coefficients among all decompositions. Here \"highly sparse\" means that N/sub t/+N/sub w/</spl radic/N/2 where N/sub t/ is the number of time atoms, N/sub w/ is the number of frequency atoms, and N is the length of the discrete-time signal. Underlying this result is a general l/sup 1/ uncertainty principle which says that if two bases are mutually incoherent, no nonzero signal can have a sparse representation in both bases simultaneously. For the above setting, the bases are sinusoids and spikes, and mutual incoherence is measured in terms of the largest inner product between different basis elements. The uncertainty principle holds for a variety of interesting basis pairs, not just sinusoids and spikes. The results have idealized applications to band-limited approximation with gross errors, to error-correcting encryption, and to separation of uncoordinated sources. Related phenomena hold for functions of a real variable, with basis pairs such as sinusoids and wavelets, and for functions of two variables, with basis pairs such as wavelets and ridgelets. In these settings, if a function f is representable by a sufficiently sparse superposition of terms taken from both bases, then there is only one such sparse representation; it may be obtained by minimum l/sup 1/ norm atomic decomposition. The condition \"sufficiently sparse\" becomes a multiscale condition; for example, that the number of wavelets at level j plus the number of sinusoids in the jth dyadic frequency band are together less than a constant times 2/sup j/2/.',\n",
              "  'authors': ['D.L. Donoho 1', ' X. Huo 2'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2099641086',\n",
              "  'references': ['2115755118',\n",
              "   '2062024414',\n",
              "   '2078204800',\n",
              "   '2151693816',\n",
              "   '1916685473',\n",
              "   '1604810369',\n",
              "   '2066462711',\n",
              "   '2125455772',\n",
              "   '2033367330',\n",
              "   '1997149618'],\n",
              "  'title': 'Uncertainty principles and ideal atomic decomposition'},\n",
              " {'abstract': 'Severe acute respiratory syndrome (SARS) is a recently described illness of humans that has spread widely over the past 6 months. With the use of detailed epidemiologic data from Singapore and epidemic curves from other settings, we estimated the reproductive number for SARS in the absence of interventions and in the presence of control efforts. We estimate that a single infectious case of SARS will infect about three secondary cases in a population that has not yet instituted control measures. Public-health efforts to reduce transmission are expected to have a substantial impact on reducing the size of the epidemic.',\n",
              "  'authors': ['Marc Lipsitch 1',\n",
              "   ' Ted Cohen 1',\n",
              "   ' Ben Cooper 1',\n",
              "   ' James M. Robins 1',\n",
              "   ' Stefan Ma 2',\n",
              "   ' Lyn James 2',\n",
              "   ' Gowri Gopalakrishna 2',\n",
              "   ' Suok Kai Chew 2',\n",
              "   ' Chorh Chuan Tan 2',\n",
              "   ' Matthew H. Samore 3',\n",
              "   ' David Fisman 4',\n",
              "   ' Megan Murray 1'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2147166346',\n",
              "  'references': ['2132260239',\n",
              "   '2104548316',\n",
              "   '1606697907',\n",
              "   '2011756067',\n",
              "   '2318510691',\n",
              "   '1965399019',\n",
              "   '1979065938'],\n",
              "  'title': 'Transmission Dynamics and Control of Severe Acute Respiratory Syndrome'},\n",
              " {'abstract': 'This is the revision of the classic text in the field, adding two new chapters and thoroughly updating all others. The original structure is retained, and the book continues to serve as a combined text/reference.',\n",
              "  'authors': ['Sidney Siegel'],\n",
              "  'date': '1956',\n",
              "  'identifier': '2002664886',\n",
              "  'references': ['2624431344',\n",
              "   '2158847908',\n",
              "   '2155243985',\n",
              "   '2112422413',\n",
              "   '1531237901',\n",
              "   '2061504941',\n",
              "   '2148540129',\n",
              "   '2151170651',\n",
              "   '2090650059'],\n",
              "  'title': 'Nonparametric statistics for the behavioral sciences'},\n",
              " {'abstract': 'Abstract Viruses in the genus Coronavirus are currently placed in three groups based on antigenic cross-reactivity and sequence analysis of structural protein genes. Consensus polymerase chain reaction (PCR) primers were used to obtain cDNA, then cloned and sequenced a highly conserved 922 nucleotide region in open reading frame (ORF) 1b of the polymerase (pol) gene from eight coronaviruses. These sequences were compared with published sequences for three additional coronaviruses. In this comparison, it was found that nucleotide substitution frequencies (per 100 nucleotides) varied from 46.40 to 50.13 when viruses were compared among the traditional coronavirus groups and, with one exception (the human coronavirus (HCV) 229E), varied from 2.54 to 15.89 when compared within these groups. (The substitution frequency for 229E, as compared to other members of the same group, varied from 35.37 to 35.72.) Phylogenetic analysis of these pol gene sequences resulted in groupings which correspond closely with the previously described groupings, including recent data which places the two avian coronaviruses—infectious bronchitis virus (IBV) of chickens and turkey coronavirus (TCV)—in the same group [Guy, J.S., Barnes, H.J., Smith L.G., Breslin, J., 1997. Avian Dis. 41:583–590]. A single pair of degenerate primers was identified which amplify a 251 bp region from coronaviruses of all three groups using the same reaction conditions. This consensus PCR assay for the genus Coronavirus may be useful in identifying as yet unknown coronaviruses.',\n",
              "  'authors': ['Charles B. Stephensen ',\n",
              "   ' Donald B. Casebolt ',\n",
              "   ' Nupur N. Gangopadhyay'],\n",
              "  'date': '1999',\n",
              "  'identifier': '2084994773',\n",
              "  'references': ['2134812217',\n",
              "   '2009310436',\n",
              "   '132455992',\n",
              "   '2156596665',\n",
              "   '1582561043',\n",
              "   '2087363345',\n",
              "   '2149495938',\n",
              "   '2329318335',\n",
              "   '1994193749',\n",
              "   '3011200155'],\n",
              "  'title': 'Phylogenetic analysis of a highly conserved region of the polymerase gene from 11 coronaviruses and development of a consensus polymerase chain reaction assay.'},\n",
              " {'abstract': 'Suppose we are given a vector f in a class FsubeRopfN , e.g., a class of digital signals or digital images. How many linear measurements do we need to make about f to be able to recover f to within precision epsi in the Euclidean (lscr2) metric? This paper shows that if the objects of interest are sparse in a fixed basis or compressible, then it is possible to reconstruct f to within very high accuracy from a small number of random measurements by solving a simple linear program. More precisely, suppose that the nth largest entry of the vector |f| (or of its coefficients in a fixed basis) obeys |f|(n)lesRmiddotn-1p/, where R>0 and p>0. Suppose that we take measurements yk=langf# ,Xkrang,k=1,...,K, where the Xk are N-dimensional Gaussian vectors with independent standard normal entries. Then for each f obeying the decay estimate above for some 0<p<1 and with overwhelming probability, our reconstruction ft, defined as the solution to the constraints yk=langf# ,Xkrang with minimal lscr1 norm, obeys parf-f#parlscr2lesCp middotRmiddot(K/logN)-r, r=1/p-1/2. There is a sense in which this result is optimal; it is generally impossible to obtain a higher accuracy from any set of K measurements whatsoever. The methodology extends to various other random measurement ensembles; for example, we show that similar results hold if one observes a few randomly sampled Fourier coefficients of f. In fact, the results are quite general and require only two hypotheses on the measurement ensemble which are detailed',\n",
              "  'authors': ['E.J. Candes 1', ' T. Tao 2'],\n",
              "  'date': '2006',\n",
              "  'identifier': '2129638195',\n",
              "  'references': ['2296616510',\n",
              "   '2145096794',\n",
              "   '2115755118',\n",
              "   '2129131372',\n",
              "   '2078204800',\n",
              "   '2099641086',\n",
              "   '2103559027',\n",
              "   '2050834445',\n",
              "   '2154332973',\n",
              "   '1573820523'],\n",
              "  'title': 'Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?'},\n",
              " {'abstract': \"The Pascal Visual Object Classes (VOC) challenge consists of two components: (i) a publicly available dataset of images together with ground truth annotation and standardised evaluation software; and (ii) an annual competition and workshop. There are five challenges: classification, detection, segmentation, action classification, and person layout. In this paper we provide a review of the challenge from 2008---2012. The paper is intended for two audiences: algorithm designers, researchers who want to see what the state of the art is, as measured by performance on the VOC datasets, along with the limitations and weak points of the current generation of algorithms; and, challenge designers, who want to see what we as organisers have learnt from the process and our recommendations for the organisation of future challenges. To analyse the performance of submitted algorithms on the VOC datasets we introduce a number of novel evaluation methods: a bootstrapping method for determining whether differences in the performance of two algorithms are significant or not; a normalised average precision so that performance can be compared across classes with different proportions of positive instances; a clustering method for visualising the performance across multiple algorithms so that the hard and easy images can be identified; and the use of a joint classifier over the submitted algorithms in order to measure their complementarity and combined performance. We also analyse the community's progress through time using the methods of Hoiem et al. (Proceedings of European Conference on Computer Vision, 2012) to identify the types of occurring errors. We conclude the paper with an appraisal of the aspects of the challenge that worked well, and those that could be improved in future challenges.\",\n",
              "  'authors': ['Mark Everingham 1',\n",
              "   ' S. M. Eslami 2',\n",
              "   ' Luc Gool 3',\n",
              "   ' Christopher K. Williams 4',\n",
              "   ' John Winn 2',\n",
              "   ' Andrew Zisserman 5'],\n",
              "  'date': '2015',\n",
              "  'identifier': '2037227137',\n",
              "  'references': ['2618530766',\n",
              "   '2151103935',\n",
              "   '2153635508',\n",
              "   '2102605133',\n",
              "   '2161969291',\n",
              "   '2168356304',\n",
              "   '1849277567',\n",
              "   '2031489346',\n",
              "   '2088049833',\n",
              "   '3097096317'],\n",
              "  'title': 'The Pascal Visual Object Classes Challenge: A Retrospective'},\n",
              " {'abstract': '',\n",
              "  'authors': ['John Ziebuhr 1',\n",
              "   ' Eric J. Snijder 2',\n",
              "   ' Alexander E. Gorbalenya 3'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2103854602',\n",
              "  'references': ['2097382368',\n",
              "   '1567730256',\n",
              "   '1975001431',\n",
              "   '3026032990',\n",
              "   '2041877620',\n",
              "   '1855484651',\n",
              "   '132455992',\n",
              "   '1811783050',\n",
              "   '202001057',\n",
              "   '2041381307'],\n",
              "  'title': 'Virus-encoded proteinases and proteolytic processing in the Nidovirales.'},\n",
              " {'abstract': 'The hypothesis of decay of the memory trace as a cause of forgetting has been unpopular. The reasons for this unpopularity are criticized and a theory of the memory span, based on this hypothesis, ...',\n",
              "  'authors': ['John Brown'],\n",
              "  'date': '1958',\n",
              "  'identifier': '1998654733',\n",
              "  'references': ['2153297147',\n",
              "   '2049497517',\n",
              "   '2001554093',\n",
              "   '2060565253',\n",
              "   '2082565755',\n",
              "   '2005468759',\n",
              "   '2091450584',\n",
              "   '2031562393',\n",
              "   '2318266373',\n",
              "   '1976016228'],\n",
              "  'title': 'Some tests of the decay theory of immediate memory'},\n",
              " {'abstract': 'Four psychological theories are considered in determining the effects of disconfirmed expectations on perceived product performance and consumer satisfaction. Results reveal that too great a gap be...',\n",
              "  'authors': ['Rolph Ely Anderson'],\n",
              "  'date': '1973',\n",
              "  'identifier': '1979756272',\n",
              "  'references': ['2092713296',\n",
              "   '1966114254',\n",
              "   '1934425758',\n",
              "   '2313818646',\n",
              "   '2050506113',\n",
              "   '2312795932',\n",
              "   '2049777813',\n",
              "   '2320357682',\n",
              "   '1608259091',\n",
              "   '2415643197'],\n",
              "  'title': 'Consumer Dissatisfaction: The Effect of Disconfirmed Expectancy on Perceived Product Performance'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Frances E. Allen'],\n",
              "  'date': '1974',\n",
              "  'identifier': '110734221',\n",
              "  'references': ['148396834',\n",
              "   '2755920271',\n",
              "   '2102890180',\n",
              "   '1524758670',\n",
              "   '2128832779',\n",
              "   '2135144788',\n",
              "   '2018449188',\n",
              "   '2162436812',\n",
              "   '2171955286',\n",
              "   '2119452943'],\n",
              "  'title': 'Interprocedural Data Flow Analysis.'},\n",
              " {'abstract': '',\n",
              "  'authors': ['H. Vincent Poor'],\n",
              "  'date': '1994',\n",
              "  'identifier': '1590772317',\n",
              "  'references': ['2106864314',\n",
              "   '2172139273',\n",
              "   '2012462772',\n",
              "   '2170140722',\n",
              "   '2124280970',\n",
              "   '2110567841',\n",
              "   '2107959360',\n",
              "   '2141431231',\n",
              "   '1540959017',\n",
              "   '2156668452'],\n",
              "  'title': 'An introduction to signal detection and estimation (2nd ed.)'},\n",
              " {'abstract': 'We consider the problem of partitioning the nodes of a graph with costs on its edges into subsets of given sizes so as to minimize the sum of the costs on all edges cut. This problem arises in several physical situations — for example, in assigning the components of electronic circuits to circuit boards to minimize the number of connections between boards. This paper presents a heuristic method for partitioning arbitrary graphs which is both effective in finding optimal partitions, and fast enough to be practical in solving large problems.',\n",
              "  'authors': ['B. W. Kernighan ', ' S. Lin'],\n",
              "  'date': '1970',\n",
              "  'identifier': '2161455936',\n",
              "  'references': ['2152825437', '2148673189'],\n",
              "  'title': 'An efficient heuristic procedure for partitioning graphs'},\n",
              " {'abstract': 'We introduce a general probabilistic model of the gene structure of human genomic sequences which incorporates descriptions of the basic transcriptional, translational and splicing signals, as well as length distributions and compositional features of exons, introns and intergenic regions. Distinct sets of model parameters are derived to account for the many substantial differences in gene density and structure observed in distinct Ca G compositional regions of the human genome. In addition, new models of the donor and acceptor splice signals are described which capture potentially important dependencies between signal positions. The model is applied to the problem of gene identification in a computer program, GENSCAN, which identifies complete exon/intron structures of genes in genomic DNA. Novel features of the program include the capacity to predict multiple genes in a sequence, to deal with partial as well as complete genes, and to predict consistent sets of genes occurring on either or both DNA strands. GENSCAN is shown to have substantially higher accuracy than existing methods when tested on standardized sets of human and vertebrate genes, with 75 to 80% of exons identified exactly. The program is also capable of indicating fairly accurately the reliability of each predicted exon. Consistently high levels of accuracy are observed for sequences of differing Ca G content and for distinct groups of vertebrates. # 1997 Academic Press Limited',\n",
              "  'authors': ['Chris Burge ', ' Samuel Karlin'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2166187656',\n",
              "  'references': ['2055043387',\n",
              "   '2125838338',\n",
              "   '2142384583',\n",
              "   '1993158258',\n",
              "   '1966833356',\n",
              "   '1511730061',\n",
              "   '2039680623',\n",
              "   '1991133427',\n",
              "   '1999966058',\n",
              "   '2116390865'],\n",
              "  'title': 'Prediction of Complete Gene Structures in Human Genomic DNA'},\n",
              " {'abstract': 'The research focus is individuals who have information about many kinds of products, places to shop, and other facets of the market, and initiate discussions with and respond to information request...',\n",
              "  'authors': ['Lawrence F. Feick ', ' Linda L. Price'],\n",
              "  'date': '1987',\n",
              "  'identifier': '2316166305',\n",
              "  'references': ['1990513740',\n",
              "   '2097609137',\n",
              "   '2009977118',\n",
              "   '2327470083',\n",
              "   '1968401483',\n",
              "   '2045988471',\n",
              "   '2068944241',\n",
              "   '2322418431',\n",
              "   '2065549341',\n",
              "   '2051202561'],\n",
              "  'title': 'The market maven: A diffuser of marketplace information.'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Kevin Patrick Murphy ', ' Stuart Russell'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2110575115',\n",
              "  'references': ['1554663460',\n",
              "   '2752885492',\n",
              "   '1480376833',\n",
              "   '2147880316',\n",
              "   '2160337655',\n",
              "   '2122410182',\n",
              "   '2125838338',\n",
              "   '2137813581',\n",
              "   '2581275558',\n",
              "   '2044503966'],\n",
              "  'title': 'Dynamic bayesian networks: representation, inference and learning'},\n",
              " {'abstract': 'Summary Background Chikungunya virus (CHIKV), which is transmitted by Aedes spp mosquitoes, has recently caused several outbreaks on islands in the Indian Ocean and on the Indian subcontinent. We report on an outbreak in Italy. Methods After reports of a large number of cases of febrile illness of unknown origin in two contiguous villages in northeastern Italy, an outbreak investigation was done to identify the primary source of infection and modes of transmission. An active surveillance system was also implemented. The clinical case definition was presentation with fever and joint pain. Blood samples were gathered and analysed by PCR and serological assays to identify the causal agent. Locally captured mosquitoes were also tested by PCR. Phylogenetic analysis of the CHIKV E1 region was done. Findings Analysis of samples from human beings and from mosquitoes showed that the outbreak was caused by CHIKV. We identified 205 cases of infection with CHIKV between July 4 and Sept 27, 2007. The presumed index case was a man from India who developed symptoms while visiting relatives in one of the villages. Phylogenetic analysis showed a high similarity between the strains found in Italy and those identified during an earlier outbreak on islands in the Indian Ocean. The disease was fairly mild in nearly all cases, with only one reported death. Interpretation This outbreak of CHIKV disease in a non-tropical area was to some extent unexpected and emphasises the need for preparedness and response to emerging infectious threats in the era of globalisation.',\n",
              "  'authors': ['G Rezza 1',\n",
              "   ' L Nicoletti 1',\n",
              "   ' R Angelini 2',\n",
              "   ' R Romi 1',\n",
              "   ' AC Finarelli 3',\n",
              "   ' M Panning 4',\n",
              "   ' P Cordioli 5',\n",
              "   ' C Fortuna 1',\n",
              "   ' S Boros 1',\n",
              "   ' F Magurano 1',\n",
              "   ' G Silvi 2',\n",
              "   ' P Angelini 3',\n",
              "   ' M Dottori 5',\n",
              "   ' MG Ciufolini 1',\n",
              "   ' GC Majori 1',\n",
              "   ' A Cassone 1'],\n",
              "  'date': '2007',\n",
              "  'identifier': '2141987735',\n",
              "  'references': ['2034377840',\n",
              "   '2010585539',\n",
              "   '2097446992',\n",
              "   '2042525870',\n",
              "   '2116208514',\n",
              "   '2129358311',\n",
              "   '2155342050',\n",
              "   '2067506266',\n",
              "   '2052129607',\n",
              "   '2071258824'],\n",
              "  'title': 'Infection with chikungunya virus in Italy: an outbreak in a temperate region'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Hisar Maruli Manurung'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2146053064',\n",
              "  'references': ['1639032689',\n",
              "   '2038721957',\n",
              "   '2122410182',\n",
              "   '1574901103',\n",
              "   '2142183404',\n",
              "   '2097571405',\n",
              "   '2126385963',\n",
              "   '1659842140',\n",
              "   '1562911371',\n",
              "   '1579838312'],\n",
              "  'title': 'An evolutionary algorithm approach to poetry generation'},\n",
              " {'abstract': 'Information filtering systems are designed for unstructured or semistructured data, as opposed to database applications, which use very structured data. The systems also deal primarily with textual information, but they may also entail images, voice, video or other data types that are part of multimedia information systems. Information filtering systems also involve a large amount of data and streams of incoming data, whether broadcast from a remote source or sent directly by other sources. Filtering is based on descriptions of individual or group information preferences, or profiles, that typically represent long-term interests. Filtering also implies removal of data from an incoming stream rather than finding data in the stream; users see only the data that is extracted. Models of information retrieval and filtering, and lessons for filtering from retrieval research are presented.',\n",
              "  'authors': ['Nicholas J. Belkin 1', ' W. Bruce Croft 2'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2106365165',\n",
              "  'references': ['2159080219',\n",
              "   '2147152072',\n",
              "   '1956559956',\n",
              "   '1978394996',\n",
              "   '1770825568',\n",
              "   '2000672666',\n",
              "   '2135346934',\n",
              "   '2048045485',\n",
              "   '2078875869',\n",
              "   '2126502509'],\n",
              "  'title': 'Information filtering and information retrieval: two sides of the same coin?'},\n",
              " {'abstract': 'By photoelectric scanning, the light distribution was determined in the aerial ophthalmoscopic image of a thin light filament viewed by an observer with an homatropinized eye. Light distributions were obtained for various pupil sizes and degrees of defocusing. Measurements were also obtained with bar and grating objects.To compute the line-spread function on the fundus, correction was made for the double passage of the light through the optical system of the eye on the assumption that the spread in angular measure is the same in both directions. The results may be considered to depict distributions which are possibly broader, but certainly not narrower, than the real distributions in the retinal image. The line-spread function on the fundus was determined to have a half-width at half-height of one minute of arc for an eye in best focus with a 3-mm pupil, and this suggests that the point-spread function has half-width 0.66 min of arc as an upper estimate.',\n",
              "  'authors': ['Gerald Westheimer ', ' Fergus W. Campbell'],\n",
              "  'date': '1962',\n",
              "  'identifier': '1996518889',\n",
              "  'references': ['2019160381'],\n",
              "  'title': 'Light distribution in the image formed by the living human eye.'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Peter Lennie'],\n",
              "  'date': '1980',\n",
              "  'identifier': '2089325630',\n",
              "  'references': ['2116360511',\n",
              "   '2117731089',\n",
              "   '2053120614',\n",
              "   '1594551768',\n",
              "   '2022491393',\n",
              "   '2046384002',\n",
              "   '1988849438',\n",
              "   '2146567096',\n",
              "   '3004021698',\n",
              "   '2017600612'],\n",
              "  'title': 'Parallel visual pathways: a review.'},\n",
              " {'abstract': 'The hippocampus has long been known to be involved in spatial navigational learning in rodents, and in memory for events in rodents, primates and humans. A unifying property of both navigation and event memory is a requirement for dealing with temporally sequenced information. Reactivation of temporally sequenced memories for previous behavioural experiences has been reported in sleep in rats. Here we report that sequential replay occurs in the rat hippocampus during awake periods immediately after spatial experience. This replay has a unique form, in which recent episodes of spatial experience are replayed in a temporally reversed order. This replay is suggestive of a role in the evaluation of event sequences in the manner of reinforcement learning models. We propose that such replay might constitute a general mechanism of learning and memory.',\n",
              "  'authors': ['David J. Foster ', ' Matthew A. Wilson'],\n",
              "  'date': '2006',\n",
              "  'identifier': '2115107366',\n",
              "  'references': ['2313307644',\n",
              "   '2107726111',\n",
              "   '2117726420',\n",
              "   '2100677568',\n",
              "   '2141559645',\n",
              "   '1969769253',\n",
              "   '2103692957',\n",
              "   '2017169966',\n",
              "   '2119624849',\n",
              "   '2076735150'],\n",
              "  'title': 'Reverse replay of behavioural sequences in hippocampal place cells during the awake state'},\n",
              " {'abstract': 'A 67-year-old woman with mild Alzheimer’s disease who has a 2-day history of productive cough, fever, and increased confusion is transferred from a nursing home to the emergency department. According to the transfer records, she has had no recent hospitalizations or recent use of antibiotic agents. Her temperature is 38.4°C (101°F), the blood pressure is 145/85 mm Hg, the respiratory rate is 30 breaths per minute, the heart rate is 120 beats per minute, and the oxygen saturation is 91% while she is breathing ambient air. Crackles are heard in both lower lung fields. She is oriented to person only. The white-cell count is 4000 per cubic millimeter, the serum sodium level is 130 mmol per liter, and the blood urea nitrogen is 25 mg per deciliter (9.0 mmol per liter). A radiograph of the chest shows infiltrates in both lower lobes. How and where should this patient be treated?',\n",
              "  'authors': ['Richard G. Wunderink 1', ' Grant W. Waterer 2'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2067476021',\n",
              "  'references': ['2027162482',\n",
              "   '2331102377',\n",
              "   '2318532494',\n",
              "   '2040919444',\n",
              "   '2091953741',\n",
              "   '2409950106',\n",
              "   '2005758646',\n",
              "   '2063582576',\n",
              "   '2086952795',\n",
              "   '2056402864'],\n",
              "  'title': 'Community Acquired Pneumonia'},\n",
              " {'abstract': 'Abstract The performance of two methods for recognition-based segmentation of strings of on-line handprinted capital Latin characters is reported. The input strings consist of a time-ordered sequence of X, Y coordinates, punctuated by pen-lifts. The methods are designed to work in “run-on mode” where there is no constraint on the spacing between characters. While both methods use a neural network recognition engine and a graph-algorithmic post-processor, their approaches to segmentation are quite different. The first method, which we call INSEG (for input segmentation), uses a combination of heuristics to identify particular pen-lifts as tentative segmentation points. The second method, which we call OUTSEG (for output segmentation), relies on the empirically trained recognition engine for both recognizing characters and identifying relevant segmentation points. The best results are obtained with the INSEG method: 11% error on handprinted words from an 80,000 word dictionary.',\n",
              "  'authors': ['H. Weissman 1',\n",
              "   ' Markus Schenkel 2',\n",
              "   ' Isabelle Guyon 1',\n",
              "   ' C. Nohl 1',\n",
              "   ' Donnie Henderson 1'],\n",
              "  'date': '1994',\n",
              "  'identifier': '2045249386',\n",
              "  'references': ['2125838338',\n",
              "   '2154642048',\n",
              "   '2173629880',\n",
              "   '2142384583',\n",
              "   '2128160875',\n",
              "   '2148099973',\n",
              "   '2057619148',\n",
              "   '53596869',\n",
              "   '2115240329',\n",
              "   '1647671624'],\n",
              "  'title': 'Recognition-based segmentation of on-line run-on handprinted words: Input vs. output segmentation'},\n",
              " {'abstract': 'A 5-h, user-friendly PCR assay for the diagnosis of enteroviral meningitis was developed. Reverse transcription and amplification were performed in a one-step reaction using rTth polymerase. Carryover contamination was prevented with dUTP and uracil N-glycosylate. Detection was performed colorimetrically on a microwell titer plate. Sensitivity, specificity, positive predictive value, and negative predictive value were 94.7, 97.4, 94.7, and 97.4%, respectively.',\n",
              "  'authors': ['H. A. Rotbart ',\n",
              "   ' M. H. Sawyer ',\n",
              "   ' S. Fast ',\n",
              "   ' C. Lewinski ',\n",
              "   ' N. Murphy ',\n",
              "   ' E. F. Keyser ',\n",
              "   ' J. Spadoro ',\n",
              "   ' Shaw-Yi Kao ',\n",
              "   ' M. Loeffelholz'],\n",
              "  'date': '1994',\n",
              "  'identifier': '1634669351',\n",
              "  'references': ['1987176207',\n",
              "   '2132537748',\n",
              "   '1907631841',\n",
              "   '1515242323',\n",
              "   '1735834838',\n",
              "   '2076862415',\n",
              "   '2156949167',\n",
              "   '1973127311',\n",
              "   '2022660154',\n",
              "   '2054118459'],\n",
              "  'title': 'Diagnosis of enteroviral meningitis by using PCR with a colorimetric microwell detection assay.'},\n",
              " {'abstract': 'A model for representing image contours in a form that allows interaction with higher level processes has been proposed by Kass et al. (in Proceedings of First International Conference on Computer Vision, London, 1987, pp. 259–269). This active contour model is defined by an energy functional, and a solution is found using techniques of variational calculus. Amini et al. (in Proceedings, Second International Conference on Computer Vision, 1988, pp. 95–99) have pointed out some of the problems with this approach, including numerical instability and a tendency for points to bunch up on strong portions of an edge contour. They proposed an algorithm for the active contour model using dynamic programming. This approach is more stable and allows the inclusion of hard constraints in addition to the soft constraints inherent in the formulation of the functional; however, it is slow, having complexity O(nm3), where n is the number of points in the contour and m is the size of the neighborhood in which a point can move during a single iteration. In this paper we summarize the strengths and weaknesses of the previous approaches and present a greedy algorithm which has performance comparable to the dynamic programming and variational calculus approaches. It retains the improvements of stability, flexibility, and inclusion of hard constraints introduced by dynamic programming but is more than an order of magnitude faster than that approach, being O(nm). A different formulation is used for the continuity term than that of the previous authors so that points in the contour are more evenly spaced. The even spacing also makes the estimation of curvature more accurate. Because the concept of curvature is basic to the formulation of the contour functional, several curvature approximation methods for discrete curves are presented and evaluated as to efficiency of computation, accuracy of the estimation, and presence of anomalies.',\n",
              "  'authors': ['Donna J. Williams ', ' Mubarak Shah'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2121009299',\n",
              "  'references': ['2145023731',\n",
              "   '2104095591',\n",
              "   '2109863423',\n",
              "   '2003370853',\n",
              "   '2125848778',\n",
              "   '2145193861',\n",
              "   '2112480284',\n",
              "   '2913432249'],\n",
              "  'title': 'A fast algorithm for active contours and curvature estimation'},\n",
              " {'abstract': \"This case study examines the application of Quinlan's C4.5 to the task of diagnosing a subsystem of NASA's Space Shuttle. Hundreds of thousands of training instances were available from simulator runs and real flight data. The trees produced are highly accurate, moderately small, and after being converted to production rules, were judged by the expert to be not only comprehensible and acceptable, but to contain new knowledge that might otherwise have remained undiscovered. The training set's huge size contributes to the high accuracy. The lack of noise turned out not to be so critical to accuracy, but learning time looks infeasible if extrapolated to a million examples. The complexity of the concept could also grow too large. We point to methods of removing these two stumbling blocks of current machine learning technology.\",\n",
              "  'authors': ['Jason Catlett'],\n",
              "  'date': '1991',\n",
              "  'identifier': '1510806966',\n",
              "  'references': ['2128420091',\n",
              "   '2159047538',\n",
              "   '1597910678',\n",
              "   '1985624473',\n",
              "   '1552785817',\n",
              "   '98436501',\n",
              "   '1515227130'],\n",
              "  'title': 'Megainduction: a test flight'},\n",
              " {'abstract': 'Introduction to the CSP CSP solving - an overview chapter fundamental concepts of the CSP chapter problem reduction chapter basic search strategies for solving CSPs search orders in searching in CSPs exploitation of problem specific features stochastic search methods for CSPs solution synthesis optimization in CSPs.',\n",
              "  'authors': ['Edward Tsang'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2043193943',\n",
              "  'references': ['2063727779',\n",
              "   '125178576',\n",
              "   '1498099185',\n",
              "   '2119456262',\n",
              "   '2608471403',\n",
              "   '2478402337'],\n",
              "  'title': 'Foundations of Constraint Satisfaction'},\n",
              " {'abstract': 'DNA microarrays containing virtually every gene of Saccharomyces cerevisiae were used to carry out a comprehensive investigation of the temporal program of gene expression accompanying the metabolic shift from fermentation to respiration. The expression profiles observed for genes with known metabolic functions pointed to features of the metabolic reprogramming that occur during the diauxic shift, and the expression patterns of many previously uncharacterized genes provided clues to their possible functions. The same DNA microarrays were also used to identify genes whose expression was affected by deletion of the transcriptional co-repressor TUP1 or overexpression of the transcriptional activator YAP1. These results demonstrate the feasibility and utility of this approach to genomewide exploration of gene expression patterns.',\n",
              "  'authors': ['Joseph L. DeRisi 1',\n",
              "   ' Vishwanath R. Iyer 2',\n",
              "   ' Patrick O. Brown 1'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2165011536',\n",
              "  'references': ['1970156673',\n",
              "   '238668910',\n",
              "   '2037509330',\n",
              "   '1539988911',\n",
              "   '2023933641',\n",
              "   '1975620486',\n",
              "   '2073414410',\n",
              "   '2135920982',\n",
              "   '2028110618',\n",
              "   '1829255219'],\n",
              "  'title': 'Exploring the Metabolic and Genetic Control of Gene Expression on a Genomic Scale'},\n",
              " {'abstract': 'In recent years, many new cortical areas have been identified in the macaque monkey. The number of identified connections between areas has increased even more dramatically. We report here on (1) a summary of the layout of cortical areas associated with vision and with other modalities, (2) a computerized database for storing and representing large amounts of information on connectivity patterns, and (3) the application of these data to the analysis of hierarchical organization of the cerebral cortex. Our analysis concentrates on the visual system, which includes 25 neocortical areas that are predominantly or exclusively visual in function, plus an additional 7 areas that we regard as visual-association areas on the basis of their extensive visual inputs. A total of 305 connections among these 32 visual and visual-association areas have been reported. This represents 31% of the possible number of pathways if each area were connected with all others. The actual degree of connectivity is likely to be closer to 40%. The great majority of pathways involve reciprocal connections between areas. There are also extensive connections with cortical areas outside the visual system proper, including the somatosensory cortex, as well as neocortical, transitional, and archicortical regions in the temporal and frontal lobes. In the somatosensory/motor system, there are 62 identified pathways linking 13 cortical areas, suggesting an overall connectivity of about 40%. Based on the laminar patterns of connections between areas, we propose a hierarchy of visual areas and of somatosensory/motor areas that is more comprehensive than those suggested in other recent studies. The current version of the visual hierarchy includes 10 levels of cortical processing. Altogether, it contains 14 levels if one includes the retina and lateral geniculate nucleus at the bottom as well as the entorhinal cortex and hippocampus at the top. Within this hierarchy, there are multiple, intertwined processing streams, which, at a low level, are related to the compartmental organization of areas V1 and V2 and, at a high level, are related to the distinction between processing centers in the temporal and parietal lobes. However, there are some pathways and relationships (about 10% of the total) whose descriptions do not fit cleanly into this hierarchical scheme for one reason or another. In most instances, though, it is unclear whether these represent genuine exceptions to a strict hierarchy rather than inaccuracies or uncertainities in the reported assignment.',\n",
              "  'authors': ['Daniel J. Felleman 1', ' David C. Van Essen 2'],\n",
              "  'date': '1991',\n",
              "  'identifier': '2098580305',\n",
              "  'references': ['1979741733',\n",
              "   '1526492552',\n",
              "   '1975201511',\n",
              "   '2116360511',\n",
              "   '1986450498',\n",
              "   '2172373809',\n",
              "   '2003812047',\n",
              "   '2117731089',\n",
              "   '2135587681',\n",
              "   '1975700187'],\n",
              "  'title': 'Distributed Hierarchical Processing in the Primate Cerebral Cortex'},\n",
              " {'abstract': 'This introduction to computational geometry focuses on algorithms. Motivation is provided from the application areas as all techniques are related to particular applications in robotics, graphics, CAD/CAM, and geographic information systems. Modern insights in computational geometry are used to provide solutions that are both efficient and easy to understand and implement.',\n",
              "  'authors': ['Mark de Berg ',\n",
              "   ' Otfried Cheong ',\n",
              "   ' Marc van Kreveld ',\n",
              "   ' Mark Overmars'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2149906774',\n",
              "  'references': ['1862751212',\n",
              "   '192919555',\n",
              "   '2427881153',\n",
              "   '2157855380',\n",
              "   '2167816765',\n",
              "   '2137642864',\n",
              "   '2088386938',\n",
              "   '2129848981',\n",
              "   '2035033474',\n",
              "   '2162785138'],\n",
              "  'title': 'Computational Geometry: Algorithms and Applications'},\n",
              " {'abstract': 'We address the problem of determining what size test set guarantees statistically significant results in a character recognition task, as a function of the expected error rate. We provide a statistical analysis showing that if, for example, the expected character error rate is around 1 percent, then, with a test set of at least 10,000 statistically independent handwritten characters (which could be obtained by taking 100 characters from each of 100 different writers), we guarantee, with 95 percent confidence, that: (1) the expected value of the character error rate is not worse than 1.25 E, where E is the empirical character error rate of the best recognizer, calculated on the test set; and (2) a difference of 0.3 E between the error rates of two recognizers is significant. We developed this framework with character recognition applications in mind, but it applies as well to speech recognition and to other pattern recognition problems.',\n",
              "  'authors': ['I. Guyon 1', ' J. Makhoul 2', ' R. Schwartz 2', ' V. Vapnik 3'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2166312020',\n",
              "  'references': ['2056763477',\n",
              "   '2147510700',\n",
              "   '26450609',\n",
              "   '2801840425',\n",
              "   '1932968309',\n",
              "   '2103012681',\n",
              "   '98859974',\n",
              "   '2892533349',\n",
              "   '2042587503',\n",
              "   '2607313294'],\n",
              "  'title': 'What size test set gives good error rate estimates'},\n",
              " {'abstract': 'Much recent effort has sought asymptotically minimax methods for recovering infinite dimensional objects-curves, densities, spectral densities, images-from noisy data. A now rich and complex body of work develops nearly or exactly minimax estimators for an array of interesting problems. Unfortunately, the results have rarely moved into practice, for a variety of reasons-among them being similarity to known methods, computational intractability and lack of spatial adaptivity. We discuss a method for curve estimation based on n noisy data: translate the empirical wavelet coefficients towards the origin by an amount √(2 log n) /√n. The proposal differs from those in current use, is computationally practical and is spatially adaptive; it thus avoids several of the previous objections. Further, the method is nearly minimax both for a wide variety of loss functions-pointwise error, global error measured in L p -norms, pointwise and global error in estimation of derivatives-and for a wide range of smoothness classes, including standard Holder and Sobolev classes, and bounded variation. This is a much broader near optimality than anything previously proposed: we draw loose parallels with near optimality in robustness and also with the broad near eigenfunction properties of wavelets themselves. Finally, the theory underlying the method is interesting, as it exploits a correspondence between statistical questions and questions of optimal recovery and information-based complexity',\n",
              "  'authors': ['David L. Donoho 1',\n",
              "   ' Iain M. Johnstone 1',\n",
              "   ' Gérard Kerkyacharian 2',\n",
              "   ' Dominique Picard 3'],\n",
              "  'date': '1995',\n",
              "  'identifier': '191129667',\n",
              "  'references': ['2132984323',\n",
              "   '2146842127',\n",
              "   '2158940042',\n",
              "   '2151693816',\n",
              "   '2102201073',\n",
              "   '2079724595',\n",
              "   '2033484654',\n",
              "   '654435104',\n",
              "   '2092543127',\n",
              "   '2050947749'],\n",
              "  'title': 'Wavelet Shrinkage: Asymptopia?'},\n",
              " {'abstract': 'Current practice in the normalization of microbiome count data is inefficient in the statistical sense. For apparently historical reasons, the common approach is either to use simple proportions (which does not address heteroscedasticity) or to use rarefying of counts, even though both of these approaches are inappropriate for detection of differentially abundant species. Well-established statistical theory is available that simultaneously accounts for library size differences and biological variability using an appropriate mixture model. Moreover, specific implementations for DNA sequencing read count data (based on a Negative Binomial model for instance) are already available in RNA-Seq focused R packages such as edgeR and DESeq. Here we summarize the supporting statistical theory and use simulations and empirical data to demonstrate substantial improvements provided by a relevant mixture model framework over simple proportions or rarefying. We show how both proportions and rarefied counts result in a high rate of false positives in tests for species that are differentially abundant across sample classes. Regarding microbiome sample-wise clustering, we also show that the rarefying procedure often discards samples that can be accurately clustered by alternative methods. We further compare different Negative Binomial methods with a recently-described zero-inflated Gaussian mixture, implemented in a package called metagenomeSeq. We find that metagenomeSeq performs well when there is an adequate number of biological replicates, but it nevertheless tends toward a higher false positive rate. Based on these results and well-established statistical theory, we advocate that investigators avoid rarefying altogether. We have provided microbiome-specific extensions to these tools in the R package, phyloseq.',\n",
              "  'authors': ['Paul J. McMurdie ', ' Susan P. Holmes'],\n",
              "  'date': '2014',\n",
              "  'identifier': '2004014148',\n",
              "  'references': ['2582743722',\n",
              "   '2072970694',\n",
              "   '2110065044',\n",
              "   '2114104545',\n",
              "   '2108718991',\n",
              "   '2154431984',\n",
              "   '1587026990',\n",
              "   '2152239989',\n",
              "   '2160697532',\n",
              "   '2121211805'],\n",
              "  'title': 'Waste not, want not: why rarefying microbiome data is inadmissible.'},\n",
              " {'abstract': 'Much medical research is observational. The reporting of observational studies is often of insufficient quality. Poor reporting hampers the assessment of the strengths and weaknesses of a study and the generalisability of its results. Taking into account empirical evidence and theoretical considerations, a group of methodologists, researchers, and editors developed the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) recommendations to improve the quality of reporting of observational studies. The STROBE Statement consists of a checklist of 22 items, which relate to the title, abstract, introduction, methods, results and discussion sections of articles. Eighteen items are common to cohort studies, case-control studies and cross-sectional studies and four are specific to each of the three study designs. The STROBE Statement provides guidance to authors about how to improve the reporting of observational studies and facilitates critical appraisal and interpretation of studies by reviewers, journal editors and readers. This explanatory and elaboration document is intended to enhance the use, understanding, and dissemination of the STROBE Statement. The meaning and rationale for each checklist item are presented. For each item, one or several published examples and, where possible, references to relevant empirical studies and methodological literature are provided. Examples of useful flow diagrams are also included. The STROBE Statement, this document, and the associated Web site (http://www.strobe-statement.org/) should be helpful resources to improve reporting of observational research.',\n",
              "  'authors': ['Jan P Vandenbroucke 1',\n",
              "   ' Erik Björn von Elm 2',\n",
              "   ' Douglas G Altman 3',\n",
              "   ' Peter C Gøtzsche 4',\n",
              "   ' Cynthia D Mulrow 5',\n",
              "   ' Stuart J Pocock 6',\n",
              "   ' Charles Poole 7',\n",
              "   ' James J Schlesselman 8',\n",
              "   ' Matthias Egger 9',\n",
              "   ' 10'],\n",
              "  'date': '2007',\n",
              "  'identifier': '2116810060',\n",
              "  'references': ['2105625949',\n",
              "   '1979423827',\n",
              "   '2142960568',\n",
              "   '2097387720',\n",
              "   '2147581820',\n",
              "   '2810227481',\n",
              "   '2478623089',\n",
              "   '2083475779',\n",
              "   '2008972159',\n",
              "   '2044758663'],\n",
              "  'title': 'Strengthening the Reporting of Observational Studies in Epidemiology (STROBE): Explanation and elaboration'},\n",
              " {'abstract': 'The outbreak of Ebola that started in West Africa in late 2013 has caused at least 28,000 illnesses and 11,000 deaths. As the outbreak progressed, global and local public health authorities scrambled to contain the spread of the disease by isolating those who were ill, putting in place infection control processes in health care settings, and encouraging the public to take steps to prevent the spread of the illness in the community. It took a massive investment of resources and personnel from many countries to eventually bring the outbreak under control. To determine where to allocate people and resources during the outbreak, public health authorities often turned to mathematical models created by scientists to predict the course of the outbreak and identify interventions that could be effective. Many groups of scientists created models of the epidemic using publically available data or data they obtained from government officials or field studies. In some instances, the models yielded valuable insights. But with various groups using different methods and data, the models didn’t always agree on what would happen next or how best to contain the epidemic. Now, Chretien et al. provide an overview of Ebola mathematical modeling during the epidemic and suggest how future efforts may be improved. The overview included 66 published studies about Ebola outbreak models. Although most forecasts predicted many more cases than actually occurred, some modeling approaches produced more accurate predictions, and several models yielded valuable insights. For example, one study found that focusing efforts on isolating patients with the most severe cases of Ebola would help end the epidemic by substantially reducing the number of new infections. Another study used real-time airline data to predict which traveler screening strategies would be most efficient at preventing international spread of Ebola. Furthermore, studies that obtained genomic data showed how specific virus strains were transmitted across geographic areas. Chretien et al. argue that mathematical modeling efforts could be more useful in future pubic health emergencies if modelers cooperated more, and suggest the collaborative approach of weather forecasters as a good example to follow. Greater data sharing and the creation of standards for epidemic modeling would aid better collaboration.',\n",
              "  'authors': ['Jean-Paul Chretien 1', ' Steven Riley 2', ' Dylan B George 3'],\n",
              "  'date': '2015',\n",
              "  'identifier': '2190947059',\n",
              "  'references': ['2007872832',\n",
              "   '2156098321',\n",
              "   '78967600',\n",
              "   '2115102869',\n",
              "   '1975375203',\n",
              "   '179329265',\n",
              "   '3103645382',\n",
              "   '2077281606',\n",
              "   '2063651055',\n",
              "   '1975132434'],\n",
              "  'title': 'Mathematical modeling of the West Africa Ebola epidemic.'},\n",
              " {'abstract': 'A method of using functional magnetic resonance imaging (fMRI) to measure retinotopic organization within human cortex is described. The method is based on a visual stimulus that creates a traveling wave of neural activity within retinotopically organized visual areas. We measured the fMRI signal caused by this stimulus in visual cortex and represented the results on images of the flattened cortical sheet. We used the method to locate visual areas and to evaluate the spatial precision of fMRI. Specifically, we: (i) identified the borders between several retinotopically organized visual areas in the posterior occipital lobe; (ii) measured the function relating cortical position to visual field eccentricity within area V1; (iii) localized activity to within 1.1 mm of visual cortex; and (iv) estimated the spatial resolution of the fMRI signal and found that signal amplitude falls to 60% at a spatial frequency of 1 cycle per 9 mm of visual cortex. This spatial resolution is consistent with a linespread whose full width at half maximum spreads across 3.5 mm of visual cortex. In a series of experiments, we measured the retinotopic organization of human cortical area V1 and identified the locations of other nearby retinotopically organized visual areas. We also used the retinotopic organization of human primary visual cortex to measure the spatial localization and spatial resolution that can be obtained from functional magnetic resonance imaging (fMRI) of human visual cortex. Human primary visual cortex (area V1) is located in the',\n",
              "  'authors': ['Stephen A. Engel ', ' Gary H. Glover ', ' Brian A. Wandell'],\n",
              "  'date': '1997',\n",
              "  'identifier': '2141964005',\n",
              "  'references': ['2002660165',\n",
              "   '2050717100',\n",
              "   '2093366270',\n",
              "   '2111609296',\n",
              "   '2025283285',\n",
              "   '1988874269',\n",
              "   '2031425398',\n",
              "   '1519349329',\n",
              "   '2105265911',\n",
              "   '2142245130'],\n",
              "  'title': 'Retinotopic organization in human visual cortex and the spatial precision of functional MRI.'},\n",
              " {'abstract': 'When computing descriptors of image data, the type of information that can be extracted may be strongly dependent on the scales at which the image operators are applied. This article presents a systematic methodology for addressing this problem. A mechanism is presented for automatic selection of scale levels when detecting one-dimensional image features, such as edges and ridges. A novel concept of a scale-space edge is introduced, defined as a connected set of points in scale-space at which: (i) the gradient magnitude assumes a local maximum in the gradient direction, and (ii) a normalized measure of the strength of the edge response is locally maximal over scales. An important consequence of this definition is that it allows the scale levels to vary along the edge. Two specific measures of edge strength are analyzed in detail, the gradient magnitude and a differential expression derived from the third-order derivative in the gradient direction. For a certain way of normalizing these differential descriptors, by expressing them in terms of so-called γ-normalized derivatives, an immediate consequence of this definition is that the edge detector will adapt its scale levels to the local image structure. Specifically, sharp edges will be detected at fine scales so as to reduce the shape distortions due to scale-space smoothing, whereas sufficiently coarse scales will be selected at diffuse edges, such that an edge model is a valid abstraction of the intensity profile across the edge. Since the scale-space edge is defined from the intersection of two zero-crossing surfaces in scale-space, the edges will by definition form closed curves. This simplifies selection of salient edges, and a novel significance measure is proposed, by integrating the edge strength along the edge. Moreover, the scale information associated with each edge provides useful clues to the physical nature of the edge. With just slight modifications, similar ideas can be used for formulating ridge detectors with automatic selection, having the characteristic property that the selected scales on a scale-space ridge instead reflect the width of the ridge. It is shown how the methodology can be implemented in terms of straightforward visual front-end operations, and the validity of the approach is supported by theoretical analysis as well as experiments on real-world and synthetic data.',\n",
              "  'authors': ['Tony Lindeberg'],\n",
              "  'date': '1998',\n",
              "  'identifier': '1495971627',\n",
              "  'references': ['2145023731',\n",
              "   '2150134853',\n",
              "   '2109200236',\n",
              "   '2004217976',\n",
              "   '2178629455',\n",
              "   '2109863423',\n",
              "   '2997638132',\n",
              "   '2003370853',\n",
              "   '2112328181',\n",
              "   '2022735534'],\n",
              "  'title': 'Edge Detection and Ridge Detection with Automatic Scale Selection'},\n",
              " {'abstract': 'The present article presents an integrative theoretical framework to explain and to predict psychological changes achieved by different modes of treatment. This theory states that psychological procedures, whatever their form, alter the level and strength of self-efficacy. It is hypothesized that expectations of personal efficacy determine whether coping behavior will be initiated, how much effort will be expended, and how long it will be sustained in the face of obstacles and aversive experiences. Persistence in activities that are subjectively threatening but in fact relatively safe produces, through experiences of mastery, further enhancement of self-efficacy and corresponding reductions in defensive behavior. In the proposed model, expectations of personal efficacy are derived from four principal sources of information: performance accomplishments, vicarious experience, verbal persuasion, and physiological states. The more dependable the experiential sources, the greater are the changes in perceived selfefficacy. A number of factors are identified as influencing the cognitive processing of efficacy information arising from enactive, vicarious, exhortative, and emotive sources. The differential power of diverse therapeutic procedures is analyzed in terms of the postulated cognitive mechanism of operation. Findings are reported from microanalyses of enactive, vicarious, and emotive modes of treatment that support the hypothesized relationship between perceived self-efficacy and behavioral changes. Possible directions for further research are discussed.',\n",
              "  'authors': ['Albert Bandura'],\n",
              "  'date': '1978',\n",
              "  'identifier': '2179683524',\n",
              "  'references': ['1550621568',\n",
              "   '2100826189',\n",
              "   '1748197048',\n",
              "   '1551283852',\n",
              "   '2098688395',\n",
              "   '1573135555',\n",
              "   '2022987442',\n",
              "   '2152336442',\n",
              "   '1969193295',\n",
              "   '1585013689'],\n",
              "  'title': 'Self-efficacy: Toward a unifying theory of behavioral change☆☆☆'},\n",
              " {'abstract': 'Abstract What is the smallest multilayer perceptron able to compute arbitrary and random functions? Previous results show that a net with one hidden layer containing N − 1 threshold units is capable of implementing an arbitrary dichotomy of N points. A construction is presented here for implementing an arbitrary dichotomy with one hidden layer containing [ N d ] units, for any set of N points in general position in d dimensions. This is in fact the smallest such net as dichotomies which cannot be implemented by any net with fewer units are described. Several constructions are presented of one-hidden-layer nets implementing arbitrary functions into the e-dimensional hypercube. One of these has only [ 4N d ][ e [ log 2 ( N d) ]] units in its hidden layer. Arguments based on a function counting theorem of Cover establish that any net implementing arbitrary functions must have at least Ne log 2 (N) weights, so that no net with one hidden layer containing less than Ne/(d log2(N)) units will suffice. Simple counts also show that if the weights are only allowed to assume one of ng possible values, no net with fewer than Ne log 2 (n g ) weights will suffice. Thus the gain coming from using real valued synapses appears to be only logarithmic. The circuit implementing functions into the e hypercube realizes such logarithmic gains. Since the counting arguments limit below only the number of weights, the possibility is suggested that, if suitable restrictions are imposed on the input vector set to avoid topological obstructions, two-hidden-layer nets with O(N) weights but only O(√N) threshold units might suffice for arbitrary dichotomies. Interesting and potentially sufficient restrictions include (a) if the vectors are binary, i.e., lie on the d hypercube or (b) if they are randomly and uniformly selected from a bounded region.',\n",
              "  'authors': ['Eric B. Baum'],\n",
              "  'date': '1988',\n",
              "  'identifier': '2012903341',\n",
              "  'references': ['2154642048',\n",
              "   '2293063825',\n",
              "   '3036751298',\n",
              "   '1507849272',\n",
              "   '2178806388',\n",
              "   '1547224907',\n",
              "   '2414319931',\n",
              "   '3121926921',\n",
              "   '1977827719',\n",
              "   '2110200678'],\n",
              "  'title': 'On the capabilities of multilayer perceptrons'},\n",
              " {'abstract': 'Since the first edition of this landmark book was published in 1962, Everett Rogers\\'s name has become \"virtually synonymous with the study of diffusion of innovations\", according to Choice. The second and third editions of Diffusion of Innovations became the standard textbook and reference on diffusion studies. Now, in the fourth edition, Rogers presents the culmination of more than thirty years of research that will set a new standard for analysis and inquiry. The fourth edition is (1) a revision of the theoretical framework and the research evidence supporting this model of diffusion, and (2) a new intellectual venture, in that new concepts and new theoretical viewpoints are introduced. This edition differs from its predecessors in that it takes a much more critical stance in its review and synthesis of 5,000 diffusion publications. During the past thirty years or so, diffusion research has grown to be widely recognized, applied and admired, but it has also been subjected to both constructive and destructive criticism. This criticism is due in large part to the stereotyped and limited ways in which many diffusion scholars have defined the scope and method of their field of study. Rogers analyzes the limitations of previous diffusion studies, showing, for example, that the convergence model, by which participants create and share information to reach a mutual understanding, more accurately describes diffusion in most cases than the linear model. Rogers provides an entirely new set of case examples, from the Balinese Water Temple to Nintendo videogames, that beautifully illustrate his expansive research, as well as a completely revised bibliography covering all relevant diffusion scholarship in the past decade. Most important, he discusses recent research and current topics, including social marketing, forecasting the rate of adoption, technology transfer, and more. This all-inclusive work will be essential reading for scholars and students in the fields of communications, marketing, geography, economic development, political science, sociology, and other related fields for generations to come.',\n",
              "  'authors': ['Everett M. Rogers'],\n",
              "  'date': '1962',\n",
              "  'identifier': '1990513740',\n",
              "  'references': ['1972922514',\n",
              "   '2318267034',\n",
              "   '1970198987',\n",
              "   '2004325245',\n",
              "   '2084200558'],\n",
              "  'title': 'Diffusion of Innovations'},\n",
              " {'abstract': \"Despite continued efforts to improve health systems worldwide, emerging pathogen epidemics remain a major public health concern. Effective response to such outbreaks relies on timely intervention, ideally informed by all available sources of data. The collection, visualization and analysis of outbreak data are becoming increasingly complex, owing to the diversity in types of data, questions and available methods to address them. Recent advances have led to the rise of outbreak analytics, an emerging data science focused on the technological and methodological aspects of the outbreak data pipeline, from collection to analysis, modelling and reporting to inform outbreak response. In this article, we assess the current state of the field. After laying out the context of outbreak response, we critically review the most common analytics components, their inter-dependencies, data requirements and the type of information they can provide to inform operations in real time. We discuss some challenges and opportunities and conclude on the potential role of outbreak analytics for improving our understanding of, and response to outbreaks of emerging pathogens. This article is part of the theme issue 'Modelling infectious disease outbreaks in humans, animals and plants: epidemic forecasting and control'. This theme issue is linked with the earlier issue 'Modelling infectious disease outbreaks in humans, animals and plants: approaches and important themes'.\",\n",
              "  'authors': ['Jonathan Aaron Polonsky 1',\n",
              "   ' 2',\n",
              "   ' Amrish Baidjoe 3',\n",
              "   ' Zhian N Kamvar 3',\n",
              "   ' Anne Cori 3',\n",
              "   ' Kara Durski 2',\n",
              "   ' W John Edmunds 4',\n",
              "   ' Rosalind M Eggo 4',\n",
              "   ' Sebastian Funk 4',\n",
              "   ' Laurent Kaiser 1',\n",
              "   ' Patrick Keating 4',\n",
              "   ' Olivier le Polain de Waroux 4',\n",
              "   ' 5',\n",
              "   ' Michael Marks 4',\n",
              "   ' Paula Moraga 6',\n",
              "   ' Oliver Morgan 2',\n",
              "   ' Pierre Nouvellet 3',\n",
              "   ' 7',\n",
              "   ' Ruwan Ratnayake 4',\n",
              "   ' Chrissy H Roberts 4',\n",
              "   ' Jimmy Whitworth 4',\n",
              "   ' Thibaut Jombart 3',\n",
              "   ' 4'],\n",
              "  'date': '2019',\n",
              "  'identifier': '2946778829',\n",
              "  'references': ['2582743722',\n",
              "   '3003573988',\n",
              "   '2146058063',\n",
              "   '1587026990',\n",
              "   '2108344016',\n",
              "   '2098082628',\n",
              "   '2107053896',\n",
              "   '78967600',\n",
              "   '2157725602',\n",
              "   '1581993271'],\n",
              "  'title': 'Outbreak analytics: a developing data science for informing the response to emerging pathogens'},\n",
              " {'abstract': \"Abstract A variety of models have been proposed for the study of synchronous parallel computation. These models are reviewed and some prototype problems are studied further. Two classes of models are recognized, fixed connection networks and models based on a shared memory. Routing and sorting are prototype problems for the networks; in particular, they provide the basis for simulating the more powerful shared memory models. It is shown that a simple but important class of deterministic strategies (oblivious routing) is necessarily inefficient with respect to worst case analysis. Routing can be viewed as a special case of sorting, and the existence of an O (log n ) sorting algorithm for some n processor fixed connection network has only recently been established by Ajtai, Komlos, and Szemeredi (“15th ACM Sympos. on Theory of Comput.,” Boston, Mass., 1983, pp. 1–9). If the more powerful class of shared memory models is considered then it is possible to simply achieve an O (log n loglog n ) sort via Valiant's parallel merging algorithm, which it is shown can be implemented on certain models. Within a spectrum of shared memory models, it is shown that loglog n is asymptotically optimal for n processors to merge two sorted lists containing n elements.\",\n",
              "  'authors': ['A. Borodin 1', ' J. E. Hopcroft 2'],\n",
              "  'date': '1985',\n",
              "  'identifier': '2069489095',\n",
              "  'references': ['2060270693',\n",
              "   '1976284552',\n",
              "   '2076458424',\n",
              "   '2004618348',\n",
              "   '1977908721',\n",
              "   '1836810876',\n",
              "   '2089828587',\n",
              "   '2058355999',\n",
              "   '2089062581',\n",
              "   '1972897119'],\n",
              "  'title': 'Routing, merging, and sorting on parallel models of computation'},\n",
              " {'abstract': 'Commonly used evaluation measures including Recall, Precision, F-Measure and Rand Accuracy are biased and should not be used without clear understanding of the biases, and corresponding identification of chance or base case levels of the statistic. Using these measures a system that performs worse in the objective sense of Informedness, can appear to perform better under any of these commonly used measures. We discuss several concepts and measures that reflect the probability that prediction is informed versus chance. Informedness and introduce Markedness as a dual measure for the probability that prediction is marked versus chance. Finally we demonstrate elegant connections between the concepts of Informedness, Markedness, Correlation and Significance as well as their intuitive relationships with Recall and Precision, and outline the extension from the dichotomous case to the general multi-class case.',\n",
              "  'authors': ['David Martin Powers'],\n",
              "  'date': '2011',\n",
              "  'identifier': '46659105',\n",
              "  'references': ['2147880316',\n",
              "   '1574901103',\n",
              "   '1988520084',\n",
              "   '2974222084',\n",
              "   '2153804780',\n",
              "   '1546962148',\n",
              "   '2131046448',\n",
              "   '2053154970',\n",
              "   '2011101028',\n",
              "   '2086202918'],\n",
              "  'title': 'Evaluation: from Precision, Recall and F-measure to ROC, Informedness, Markedness and Correlation'},\n",
              " {'abstract': \"In this paper, we describe an improved version of our previous approach for low bit rate near- perceptually transparent image compression. The method exploits both frequency and spatial domain visual masking effects and uses a combination of Fourier and wavelet representations to encode different bands. The frequency domain masking model is based on the psychophysical masking experimental data of sinusoidal patterns while the spatial domain masking is computed with a modified version of Girod's model. A discrete cosine transform is used in conjunction with frequency domain masking to encode the low frequency subimages. The medium and high frequency subimages are encoded in the wavelet domain with spatial domain masking. The main improvement over our previous technique is that a better model is used to calculate the tolerable error level for the subimages in the wavelet domain, and a boundary control is used to prevent or reduce the ringing noise in the decoded image. This greatly improves the decoded image quality for the same coding bit rates. Experiments show the approach can achieve very high quality to nearly transparent compression at bit rates of 0.2 to 0.4 bits/pixel for the image Lena.© (1995) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.\",\n",
              "  'authors': ['Bin Zhu 1', ' Ahmed H. Tewfik 1', ' Oemer Nezih Gerek 2'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2016372521',\n",
              "  'references': ['2166982406',\n",
              "   '2136017820',\n",
              "   '2134774992',\n",
              "   '2003495805',\n",
              "   '1991221331',\n",
              "   '2114842177'],\n",
              "  'title': 'Low bit rate near-transparent image coding'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Gilbert Strang ', ' Truong Nguyen'],\n",
              "  'date': '1996',\n",
              "  'identifier': '1658679052',\n",
              "  'references': ['2018332268',\n",
              "   '2015370045',\n",
              "   '2155511848',\n",
              "   '1582484699',\n",
              "   '2993281142',\n",
              "   '2099619765',\n",
              "   '1975358183',\n",
              "   '2003410902',\n",
              "   '2131065845',\n",
              "   '2136952590'],\n",
              "  'title': 'Wavelets and filter banks'},\n",
              " {'abstract': 'Probabilistic inference is an attractive approach to uncertain reasoning and empirical learning in artificial intelligence. Computational difficulties arise, however, because probabilistic models with the necessary realism and flexibility lead to complex distributions over high-dimensional spaces. Related problems in other fields have been tackled using Monte Carlo methods based on sampling using Markov chains, providing a rich array of techniques that can be applied to problems in artificial intelligence. The “Metropolis algorithm” has been used to solve difficult problems in statistical physics for over forty years, and, in the last few years, the related method of “Gibbs sampling” has been applied to problems of statistical inference. Concurrently, an alternative method for solving problems in statistical physics by means of dynamical simulation has been developed as well, and has recently been unified with the Metropolis algorithm to produce the “hybrid Monte Carlo” method. In computer science, Markov chain sampling is the basis of the heuristic optimization technique of “simulated annealing”, and has recently been used in randomized algorithms for approximate counting of large sets. In this review, I outline the role of probabilistic inference in artificial intelligence, present the theory of Markov chains, and describe various Markov chain Monte Carlo algorithms, along with a number of supporting techniques. I try to present a comprehensive picture of the range of methods that have been developed, including techniques from the varied literature that have not yet seen wide application in artificial intelligence, but which appear relevant. As illustrative examples, I use the problems of probabilistic inference in expert systems, discovery of latent classes from data, and Bayesian learning for neural networks.',\n",
              "  'authors': ['Radford M. Neal'],\n",
              "  'date': '2011',\n",
              "  'identifier': '195465510',\n",
              "  'references': ['2581275558',\n",
              "   '1498436455',\n",
              "   '1997063559',\n",
              "   '2049633694',\n",
              "   '1988520084',\n",
              "   '2083875149',\n",
              "   '2148534890',\n",
              "   '1593793857',\n",
              "   '2111051539',\n",
              "   '2914275007'],\n",
              "  'title': 'Probabilistic Inference Using Markov Chain Monte Carlo Methods'},\n",
              " {'abstract': 'Statistics is the science of learning from experience, especially experience that arrives a little bit at a time. The earliest information science was statistics, originating in about 1650. This century has seen statistical techniques become the analytic methods of choice in biomedical science, psychology, education, economics, communications theory, sociology, genetic studies, epidemiology, and other areas. Recently, traditional sciences like geology, physics, and astronomy have begun to make increasing use of statistical methods as they focus on areas that demand informational efficiency, such as the study of rare and exotic particles or extremely distant galaxies. Most people are not natural-born statisticians. Left to our own devices we are not very good at picking out patterns from a sea of noisy data. To put it another way, we are all too good at picking out non-existent patterns that happen to suit our purposes. Statistical theory attacks the problem from both ends. It provides optimal methods for finding a real signal in a noisy background, and also provides strict checks against the overinterpretation of random patterns.',\n",
              "  'authors': ['Bradley Efron ', ' Robert J. Tibshirani'],\n",
              "  'date': '1993',\n",
              "  'identifier': '2102865756',\n",
              "  'references': ['2140190241',\n",
              "   '2155965977',\n",
              "   '1570448133',\n",
              "   '2135046866',\n",
              "   '2038702827',\n",
              "   '3102641634',\n",
              "   '2912934387',\n",
              "   '2115709314',\n",
              "   '1964357740'],\n",
              "  'title': 'An introduction to the bootstrap'},\n",
              " {'abstract': 'Let X be n × N containing i.i.d. complex entries with E |X11 − EX11|2 = 1, and T an n × n random Hermitian nonnegative definite, independent of X. Assume, almost surely, as n → ∞, the empirical distribution function (e.d.f.) of the eigenvalues of T converges in distribution, and the ratio n/N tends to a positive number. Then it is shown that, almost surely, the e.d.f. of the eigenvalues of (1/N) XX*T converges in distribution. The limit is nonrandom and is characterized in terms of its Stieltjes transform, which satisfies a certain equation.',\n",
              "  'authors': ['Jack W. Silverstein'],\n",
              "  'date': '1995',\n",
              "  'identifier': '1969097180',\n",
              "  'references': ['2039953809',\n",
              "   '2011892826',\n",
              "   '1980073352',\n",
              "   '2017703830',\n",
              "   '2060581589'],\n",
              "  'title': 'Strong convergence of the empirical distribution of eigenvalues of large dimensional random matrices'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Yvonne Cossart'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2004869546',\n",
              "  'references': ['2038264706',\n",
              "   '2089551619',\n",
              "   '2016137045',\n",
              "   '2328399749',\n",
              "   '2022277835',\n",
              "   '2028973331'],\n",
              "  'title': 'TTV a common virus, but pathogenic?'},\n",
              " {'abstract': '',\n",
              "  'authors': ['Stuart G. Siddell'],\n",
              "  'date': '1995',\n",
              "  'identifier': '3011200155',\n",
              "  'references': ['2097706568',\n",
              "   '2106258670',\n",
              "   '2153127922',\n",
              "   '2055757365',\n",
              "   '2110414335',\n",
              "   '2049526168',\n",
              "   '1527662113',\n",
              "   '1985916880',\n",
              "   '2027910008',\n",
              "   '2035920610'],\n",
              "  'title': 'The Coronaviridae: An Introduction'},\n",
              " {'abstract': 'In this paper, upper and lower bounds on the transmission capacity of spread-spectrum (SS) wireless ad hoc networks are derived. We define transmission capacity as the product of the maximum density of successful transmissions multiplied by their data rate, given an outage constraint. Assuming that the nodes are randomly distributed in space according to a Poisson point process, we derive upper and lower bounds for frequency hopping (FH-CDMA) and direct sequence (DS-CDMA) SS networks, which incorporate traditional modulation types (no spreading) as a special case. These bounds cleanly summarize how ad hoc network capacity is affected by the outage probability, spreading factor, transmission power, target signal-to-noise ratio (SNR), and other system parameters. Using these bounds, it can be shown that FH-CDMA obtains a higher transmission capacity than DS-CDMA on the order of M/sup 1-2//spl alpha//, where M is the spreading factor and /spl alpha/>2 is the path loss exponent. A tangential contribution is an (apparently) novel technique for obtaining tight bounds on tail probabilities of additive functionals of homogeneous Poisson point processes.',\n",
              "  'authors': ['S.P. Weber 1',\n",
              "   ' Xiangying Yang 2',\n",
              "   ' J.G. Andrews 2',\n",
              "   ' G. de Veciana 2'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2095796369',\n",
              "  'references': ['2137775453',\n",
              "   '2912369344',\n",
              "   '2149959815',\n",
              "   '2118166339',\n",
              "   '1969492090',\n",
              "   '2170469173',\n",
              "   '1525552993',\n",
              "   '2141431231',\n",
              "   '2162180430',\n",
              "   '2160389555'],\n",
              "  'title': 'Transmission capacity of wireless ad hoc networks with outage constraints'},\n",
              " {'abstract': \"From the Publisher: Classifier systems play a major role in machine learning and knowledge-based systems, and Ross Quinlan's work on ID3 and C4.5 is widely acknowledged to have made some of the most significant contributions to their development. This book is a complete guide to the C4.5 system as implemented in C for the UNIX environment. It contains a comprehensive guide to the system's use , the source code (about 8,800 lines), and implementation notes. The source code and sample datasets are also available on a 3.5-inch floppy diskette for a Sun workstation. C4.5 starts with large sets of cases belonging to known classes. The cases, described by any mixture of nominal and numeric properties, are scrutinized for patterns that allow the classes to be reliably discriminated. These patterns are then expressed as models, in the form of decision trees or sets of if-then rules, that can be used to classify new cases, with emphasis on making the models understandable as well as accurate. The system has been applied successfully to tasks involving tens of thousands of cases described by hundreds of properties. The book starts from simple core learning methods and shows how they can be elaborated and extended to deal with typical problems such as missing data and over hitting. Advantages and disadvantages of the C4.5 approach are discussed and illustrated with several case studies. This book and software should be of interest to developers of classification-based intelligent systems and to students in machine learning and expert systems courses.\",\n",
              "  'authors': ['J. Ross Quinlan'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2125055259',\n",
              "  'references': ['1484413656',\n",
              "   '2148143831',\n",
              "   '2149684865',\n",
              "   '2112076978',\n",
              "   '2132549764',\n",
              "   '3100785508',\n",
              "   '2142827986',\n",
              "   '2153010521',\n",
              "   '2017337590',\n",
              "   '607505555'],\n",
              "  'title': 'C4.5: Programs for Machine Learning'},\n",
              " {'abstract': 'Statistical Problems. Applications of Finite Mixture Models. Mathematical Aspects of Mixtures. Learning About the Parameters of a Mixture. Learning About the Components of a Mixture. Sequential Problems and Procedures.',\n",
              "  'authors': ['D. M. Titterington ', ' Adrian F. M. Smith ', ' U. E. Makov'],\n",
              "  'date': '1986',\n",
              "  'identifier': '2166698530',\n",
              "  'references': ['1992419399',\n",
              "   '2132549764',\n",
              "   '1479807131',\n",
              "   '2156267802',\n",
              "   '2144898279',\n",
              "   '1966385142',\n",
              "   '830076066',\n",
              "   '2110575115',\n",
              "   '2093390569'],\n",
              "  'title': 'Statistical analysis of finite mixture distributions'},\n",
              " {'abstract': 'A Monte Carlo study compared 14 methods to test the statistical significance of the intervening variable effect. An intervening variable (mediator) transmits the effect of an independent variable to a dependent variable. The commonly used R. M. Baron and D. A. Kenny (1986) approach has low statistical power. Two methods based on the distribution of the product and 2 difference-in-coefficients methods have the most accurate Type I error rates and greatest statistical power except in 1 important case in which Type I error rates are too high. The best balance of Type I error and statistical power across all cases is the test of the joint significance of the two effects comprising the intervening variable effect.',\n",
              "  'authors': ['David P. MacKinnon ',\n",
              "   ' Chondra M. Lockwood ',\n",
              "   ' Jeanne M. Hoffman ',\n",
              "   ' Stephen G. West ',\n",
              "   ' Virgil Sheets'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2068719957',\n",
              "  'references': ['1971440513',\n",
              "   '1730782591',\n",
              "   '1491644571',\n",
              "   '2905732640',\n",
              "   '2159401492',\n",
              "   '1715619412',\n",
              "   '1483679835',\n",
              "   '1667831672',\n",
              "   '1976876708',\n",
              "   '2948665298'],\n",
              "  'title': 'A comparison of methods to test mediation and other intervening variable effects.'},\n",
              " {'abstract': 'A new approach toward target representation and localization, the central component in visual tracking of nonrigid objects, is proposed. The feature histogram-based target representations are regularized by spatial masking with an isotropic kernel. The masking induces spatially-smooth similarity functions suitable for gradient-based optimization, hence, the target localization problem can be formulated using the basin of attraction of the local maxima. We employ a metric derived from the Bhattacharyya coefficient as similarity measure, and use the mean shift procedure to perform the optimization. In the presented tracking examples, the new method successfully coped with camera motion, partial occlusions, clutter, and target scale variations. Integration with motion filters and data association techniques is also discussed. We describe only a few of the potential applications: exploitation of background information, Kalman tracking using motion models, and face tracking.',\n",
              "  'authors': ['D. Comaniciu 1', ' V. Ramesh 2', ' P. Meer 2'],\n",
              "  'date': '2003',\n",
              "  'identifier': '2132103241',\n",
              "  'references': ['2170120409',\n",
              "   '2099111195',\n",
              "   '2341283081',\n",
              "   '2160337655',\n",
              "   '2067191022',\n",
              "   '2125838338',\n",
              "   '2313307644',\n",
              "   '2140235142',\n",
              "   '2159128898',\n",
              "   '2161406034'],\n",
              "  'title': 'Kernel-based object tracking'},\n",
              " {'abstract': \"Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually categorized newswire stories recently made available by Reuters, Ltd. for research purposes. Use of this data for research on text categorization requires a detailed understanding of the real world constraints under which the data was produced. Drawing on interviews with Reuters personnel and access to Reuters documentation, we describe the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data. We refer to the original data as RCV1-v1, and the corrected data as RCV1-v2. We benchmark several widely used supervised learning methods on RCV1-v2, illustrating the collection's properties, suggesting new directions for research, and providing baseline results for future studies. We make available detailed, per-category experimental results, as well as corrected versions of the category assignments and taxonomy structures, via online appendices.\",\n",
              "  'authors': ['David D. Lewis ', ' Yiming Yang ', ' Tony G. Rose ', ' Fan Li'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2150102617',\n",
              "  'references': ['2118020653',\n",
              "   '2149684865',\n",
              "   '2098162425',\n",
              "   '2118202495',\n",
              "   '2435251607',\n",
              "   '2114535528',\n",
              "   '2005422315',\n",
              "   '2107008379',\n",
              "   '2768149277',\n",
              "   '2000672666'],\n",
              "  'title': 'RCV1: A New Benchmark Collection for Text Categorization Research'},\n",
              " {'abstract': '',\n",
              "  'authors': ['John T. Betts'],\n",
              "  'date': '1998',\n",
              "  'identifier': '2162218551',\n",
              "  'references': ['2077658674',\n",
              "   '2954064014',\n",
              "   '2068484625',\n",
              "   '2162870748',\n",
              "   '2075151302',\n",
              "   '2341059552',\n",
              "   '34580700',\n",
              "   '2494779131',\n",
              "   '1510003436',\n",
              "   '2798500587'],\n",
              "  'title': 'Survey of Numerical Methods for Trajectory Optimization'},\n",
              " {'abstract': 'Abstract This paper describes a computationally inexpensive, yet high performance trajectory generation algorithm for omnidirectional vehicles. It is shown that the associated non-linear control problem can be made tractable by restricting the set of admissible control functions. The resulting problem is linear with coupled control efforts and a near-optimal control strategy is shown to be piecewise constant (bang–bang type). A very favorable trade-off between optimality and computational efficiency is achieved. The proposed algorithm is based on a small number of evaluations of simple closed-form expressions and is thus extremely efficient. The low computational cost makes this method ideal for path planning in dynamic environments.',\n",
              "  'authors': ['Tamás Kalmár-Nagy 1',\n",
              "   ' Raffaello D’Andrea 2',\n",
              "   ' Pritam Ganguly 2'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2111479185',\n",
              "  'references': ['2152427109',\n",
              "   '2095936905',\n",
              "   '2152495729',\n",
              "   '2049088815',\n",
              "   '1607505686',\n",
              "   '1587799944',\n",
              "   '1775521486',\n",
              "   '1500788106',\n",
              "   '2096447271',\n",
              "   '1503438515'],\n",
              "  'title': 'Near-optimal dynamic trajectory generation and control of an omnidirectional vehicle'},\n",
              " {'abstract': 'For pt. I see ibid., p.891-905. An investigation has been made into the use of stochastic arithmetic to implement an artificial neural network solution to a typical pattern recognition application. Optical character recognition is performed on very noisy characters in the E-13B MICR font. The artificial neural network is composed of two layers, the first layer being a set of soft competitive learning subnetworks and the second a set of fully connected linear output neurons. The observed number of clock cycles in the stochastic case represents an order of magnitude improvement over the floating-point implementation assuming clock frequency parity. Network generalization capabilities were also compared based on the network squared error as a function of the amount of noise added to the input patterns. The stochastic network maintains a squared error within 10 percent of that of the floating-point implementation for a wide range of noise levels.',\n",
              "  'authors': ['B.D. Brown 1', ' H.C. Card 2'],\n",
              "  'date': '2001',\n",
              "  'identifier': '2127574124',\n",
              "  'references': ['1554663460',\n",
              "   '2117812871',\n",
              "   '2133671888',\n",
              "   '2051385641',\n",
              "   '2151770284',\n",
              "   '2076567023',\n",
              "   '1580495158',\n",
              "   '2165550102',\n",
              "   '2100816322',\n",
              "   '2159540571'],\n",
              "  'title': 'Stochastic neural computation. II. Soft competitive learning'},\n",
              " {'abstract': 'In this paper, we consider regression problems with one-hidden-layer neural networks (1NNs). We distill some properties of activation functions that lead to local strong convexity in the neighborhood of the ground-truth parameters for the 1NN squared-loss objective and most popular nonlinear activation functions satisfy the distilled properties, including rectiﬁed linear units (ReLUs), leaky ReLUs, squared ReLUs and sigmoids. For activation functions that are also smooth, we show local linear convergence guarantees of gradient descent under a resampling rule. For homogeneous activations, we show tensor methods are able to initialize the parameters to fall into the local strong convexity region. As a result, tensor initialization followed by gradient descent is guaranteed to recover the ground truth with sample complexity d·log(1/\\x0f)·poly(k,λ) and computational complexity n·d·poly(k,λ) for smooth homogeneous activations with high probability, where d is the dimension of the input, k (k ≤ d) is the number of hidden nodes, λ is a conditioning property of the ground-truth parameter matrix between the input layer and the hidden layer, \\x0f is the targeted precision and n is the number of samples. To the best of our knowledge, this is the ﬁrst work that provides recovery guarantees for 1NNs with both sample complexity and computational complexity linear in the input dimension and logarithmic in the precision.',\n",
              "  'authors': ['Kai Zhong 1',\n",
              "   ' Zhao Song 1',\n",
              "   ' Prateek Jain 2',\n",
              "   ' Peter L. Bartlett 3',\n",
              "   ' Inderjit S. Dhillon 1'],\n",
              "  'date': '2017',\n",
              "  'identifier': '2962767131',\n",
              "  'references': ['2969215180',\n",
              "   '2964232029',\n",
              "   '2991290085',\n",
              "   '3100522009',\n",
              "   '2995625976',\n",
              "   '2905919172',\n",
              "   '2885208219',\n",
              "   '2891942459',\n",
              "   '2996822312'],\n",
              "  'title': 'Recovery Guarantees for One-hidden-layer Neural Networks'},\n",
              " {'abstract': \"CCP4mg is a project that aims to provide a general-purpose tool for structural biologists, providing tools for X-ray structure solution, structure comparison and analysis, and publication-quality graphics. The map-fitting tools are available as a stand-alone package, distributed as `Coot'.\",\n",
              "  'authors': ['Paul Emsley ', ' Kevin Cowtan'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2144081223',\n",
              "  'references': ['2130479394',\n",
              "   '2013083986',\n",
              "   '2135839939',\n",
              "   '1986830449',\n",
              "   '1969222787'],\n",
              "  'title': 'Coot: model-building tools for molecular graphics.'},\n",
              " {'abstract': 'The uncertainty principle can easily be generalized to cases where the “sets of concentration” are not intervals. Such generalizations are presented for continuous and discrete-time functions, and for several measures of “concentration” (e.g., $L_2 $ and $L_1 $ measures). The generalizations explain interesting phenomena in signal recovery problems where there is an interplay of missing data, sparsity, and bandlimiting.',\n",
              "  'authors': ['David L. Donoho ', ' Philip B. Stark'],\n",
              "  'date': '1989',\n",
              "  'identifier': '2125455772',\n",
              "  'references': ['2903005364',\n",
              "   '2051933044',\n",
              "   '2075894130',\n",
              "   '2108943734',\n",
              "   '2013378881',\n",
              "   '2067111814',\n",
              "   '1982061533',\n",
              "   '1983794113',\n",
              "   '1969469319',\n",
              "   '2030096006'],\n",
              "  'title': 'Uncertainty principles and signal recovery'},\n",
              " {'abstract': 'Artificial bee colony (ABC) algorithm is an optimization algorithm based on a particular intelligent behaviour of honeybee swarms. This work compares the performance of ABC algorithm with that of differential evolution (DE), particle swarm optimization (PSO) and evolutionary algorithm (EA) for multi-dimensional numeric problems. The simulation results show that the performance of ABC algorithm is comparable to those of the mentioned algorithms and can be efficiently employed to solve engineering problems with high dimensionality.',\n",
              "  'authors': ['D. Karaboga ', ' B. Basturk'],\n",
              "  'date': '2008',\n",
              "  'identifier': '2144317842',\n",
              "  'references': ['2152195021',\n",
              "   '1639032689',\n",
              "   '1497256448',\n",
              "   '1879678483',\n",
              "   '2143560894',\n",
              "   '2126554879',\n",
              "   '2287814884',\n",
              "   '2152150600',\n",
              "   '194800985',\n",
              "   '1607022282'],\n",
              "  'title': 'On the performance of artificial bee colony (ABC) algorithm'},\n",
              " {'abstract': \"Supervised learning networks based on a decision-based formulation are explored. More specifically, a decision-based neural network (DBNN) is proposed, which combines the perceptron-like learning rule and hierarchical nonlinear network structure. The decision-based mutual training can be applied to both static and temporal pattern recognition problems. For static pattern recognition, two hierarchical structures are proposed: hidden-node and subcluster structures. The relationships between DBNN's and other models (linear perceptron, piecewise-linear perceptron, LVQ, and PNN) are discussed. As to temporal DBNN's, model-based discriminant functions may be chosen to compensate possible temporal variations, such as waveform warping and alignments. Typical examples include DTW distance, prediction error, or likelihood functions. For classification applications, DBNN's are very effective in computation time and performance. This is confirmed by simulations conducted for several applications, including texture classification, OCR, and ECG analysis. >\",\n",
              "  'authors': ['S.Y. Kung ', ' J.S. Taur'],\n",
              "  'date': '1995',\n",
              "  'identifier': '2159540571',\n",
              "  'references': ['1965324089',\n",
              "   '2103496339',\n",
              "   '1991848143',\n",
              "   '1971735090',\n",
              "   '1964168965',\n",
              "   '2128160875',\n",
              "   '1548502347',\n",
              "   '2063541597',\n",
              "   '1576891459',\n",
              "   '2118020555'],\n",
              "  'title': 'Decision-based neural networks with signal/image classification applications'},\n",
              " {'abstract': 'From the Publisher: This book brings together - in an informal and tutorial fashion - the computer techniques, mathematical tools, and research results that will enable both students and practitioners to apply genetic algorithms to problems in many fields. Major concepts are illustrated with running examples, and major algorithms are illustrated by Pascal computer programs. No prior knowledge of GAs or genetics is assumed, and only a minimum of computer programming and mathematics background is required.',\n",
              "  'authors': ['David E. Goldberg'],\n",
              "  'date': '1989',\n",
              "  'identifier': '1639032689',\n",
              "  'references': ['2140190241',\n",
              "   '2076063813',\n",
              "   '1570448133',\n",
              "   '1595159159',\n",
              "   '1992419399',\n",
              "   '2107941094',\n",
              "   '2165299997',\n",
              "   '2121863487',\n",
              "   '2097571405',\n",
              "   '1976744965'],\n",
              "  'title': 'Genetic algorithms in search, optimization, and machine learning'},\n",
              " {'abstract': 'A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (“semantic structure”) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising.',\n",
              "  'authors': ['Scott Deerwester 1',\n",
              "   ' Susan T. Dumais 2',\n",
              "   ' George W. Furnas 2',\n",
              "   ' Thomas K. Landauer 2',\n",
              "   ' Richard Harshman 3'],\n",
              "  'date': '1990',\n",
              "  'identifier': '2147152072',\n",
              "  'references': ['1956559956',\n",
              "   '1984565341',\n",
              "   '1964262399',\n",
              "   '2000215628',\n",
              "   '2114804204',\n",
              "   '2151561903',\n",
              "   '3012395598',\n",
              "   '2024683548',\n",
              "   '1965061793',\n",
              "   '2096411881'],\n",
              "  'title': 'Indexing by Latent Semantic Analysis'},\n",
              " {'abstract': 'Many neural network realizations have been recently proposed for the statistical technique of Principal Component Analysis (PCA). Explicit connections between numerical constrained adaptive algorithms and neural networks with constrained Hebbian learning rules are reviewed. The Stochastic Gradient Ascent (SGA) neural network is proposed and shown to be closely related to the Generalized Hebbian Algorithm (GHA). The SGA behaves better for extracting the less dominant eigenvectors. The SGA algorithm is further extended to the case of learning minor components. The symmetrical Subspace Network is known to give a rotated basis of the dominant eigenvector subspace, but usually not the true eigenvectors themselves. Two extensions are proposed: in the first one, each neuron has a scalar parameter which breaks the symmetry. True eigenvectors are obtained in a local and fully parallel learning rule. In the second one, the case of an arbitrary number of parallel neurons is considered, not necessarily less than the input vector dimension.',\n",
              "  'authors': ['Erkki Oja'],\n",
              "  'date': '1992',\n",
              "  'identifier': '5731987',\n",
              "  'references': ['2115907784',\n",
              "   '2131329059',\n",
              "   '2122925692',\n",
              "   '2078626246',\n",
              "   '2432567885',\n",
              "   '2023963201',\n",
              "   '2017257315',\n",
              "   '1564660545',\n",
              "   '2133884101',\n",
              "   '1981479913'],\n",
              "  'title': 'Original Contribution: Principal components, minor components, and linear neural networks'},\n",
              " {'abstract': 'We consider the problem of estimating detailed 3D structure from a single still image of an unstructured environment. Our goal is to create 3D models that are both quantitatively accurate as well as visually pleasing. For each small homogeneous patch in the image, we use a Markov random field (MRF) to infer a set of \"plane parametersrdquo that capture both the 3D location and 3D orientation of the patch. The MRF, trained via supervised learning, models both image depth cues as well as the relationships between different parts of the image. Other than assuming that the environment is made up of a number of small planes, our model makes no explicit assumptions about the structure of the scene; this enables the algorithm to capture much more detailed 3D structure than does prior art and also give a much richer experience in the 3D flythroughs created using image-based rendering, even for scenes with significant nonvertical structure. Using this approach, we have created qualitatively correct 3D models for 64.9 percent of 588 images downloaded from the Internet. We have also extended our model to produce large-scale 3D models from a few images.',\n",
              "  'authors': ['A. Saxena 1', ' Min Sun 2', ' A.Y. Ng 1'],\n",
              "  'date': '2009',\n",
              "  'identifier': '2132947399',\n",
              "  'references': ['2296319761',\n",
              "   '2161969291',\n",
              "   '1663973292',\n",
              "   '1677409904',\n",
              "   '2104974755',\n",
              "   '1999478155',\n",
              "   '2156598602',\n",
              "   '1508960934',\n",
              "   '2119823327',\n",
              "   '2146352414'],\n",
              "  'title': 'Make3D: Learning 3D Scene Structure from a Single Still Image'},\n",
              " {'abstract': 'The genetic and antigenic variability of the G glycoproteins from 76 human respiratory syncytial (RS) viruses (subgroup A) isolated during six consecutive epidemics in either Montevideo, Uruguay, or Madrid, Spain, have been analyzed. Genetic diversity was evaluated for all viruses by the RNase A mismatch cleavage method and for selected strains by dideoxy sequencing. The sequences reported here were added to those published for six isolates from Birmingham, United Kingdom, and for two reference strains (A2 and Long), to derive a phylogenetic tree of subgroup A viruses that contained two main branches and several subbranches. During the same epidemic, viruses from different branches were isolated. In addition, closely related viruses were isolated in distant places and in different years. These results illustrate the capacity of the virus to spread worldwide, influencing its mode of evolution. The antigenic analysis of all isolates was carried out with a panel of anti-G monoclonal antibodies that recognized strain-specific (or variable) epitopes. A close correlation between genetic relatedness and antigenic relatedness in the G protein was observed. These results, together with an accumulation of amino acid changes in a major antigenic area of the G glycoprotein, suggest that immune selection may be a factor influencing the generation of RS virus diversity. The pattern of RS virus evolution is thus similar to that described for influenza type B viruses, expect that the level of genetic divergence among the G glycoproteins of RS virus isolates is the highest reported for an RNA virus gene product.',\n",
              "  'authors': ['O García ',\n",
              "   ' M Martín ',\n",
              "   ' J Dopazo ',\n",
              "   ' J Arbiza ',\n",
              "   ' S Frabasile ',\n",
              "   ' J Russi ',\n",
              "   ' M Hortal ',\n",
              "   ' P Perez-Breña ',\n",
              "   ' I Martínez ',\n",
              "   ' B García-Barreno'],\n",
              "  'date': '1994',\n",
              "  'identifier': '1525273492',\n",
              "  'references': ['2101108802',\n",
              "   '2030966943',\n",
              "   '2060333964',\n",
              "   '1579352620',\n",
              "   '2119627949',\n",
              "   '2081114699',\n",
              "   '2104748973',\n",
              "   '2131354424',\n",
              "   '2033319485',\n",
              "   '2023654189'],\n",
              "  'title': 'Evolutionary pattern of human respiratory syncytial virus (subgroup A): cocirculating lineages and correlation of genetic and antigenic changes in the G glycoprotein.'},\n",
              " {'abstract': 'PROBLEM TO BE SOLVED: To provide a position specifying device and method for specifying the ground position of an autonomous vehicle on the ground of a planet or in the neighborhood of the ground. SOLUTION: This system and method for position-specifying and navigating autonomous vehicles (102, 310) enable those vehicles (102, 310) to travel between those positions. The first position estimation (112) of the vehicles (102, 310) is derived from both or one of satellites (132-170, 200-206) and one or more pseudo satellites (105) of a global position specifying system (100A). One or more pseudo satellites (105) can be exclusively used when the satellites (132-170, 200-206) are not present in the field of view of the vehicles (102, 310). The second position estimation (114) is derived from both or one of an inertia reference unit (904) and a vehicle traveling distance meter (902). The first and second position estimation is combined and filtered so that the third position estimation (118) can be derived. The navigation of the vehicles (102, 310) is searched by using position information (414), obstacle detection and prevention data (416), and mounted vehicle data (908, 910). COPYRIGHT: (C)2003,JPO',\n",
              "  'authors': ['Dana A Christensen ',\n",
              "   ' Douglas W Friedrich ',\n",
              "   ' Adam J Gudat ',\n",
              "   ' Christos T Kyrtsos ',\n",
              "   ' James W Sennot ',\n",
              "   ' Darrell E Stafford ',\n",
              "   ' クリストス ティー キルツォス ',\n",
              "   ' アダム ジェイ グダット ',\n",
              "   ' ダナ エイ クリステンセン ',\n",
              "   ' ダーレル イー スタッフォード ',\n",
              "   ' ジェームズ ダブリュー センノット ',\n",
              "   ' ダグラス ダブリュー フリードリック'],\n",
              "  'date': '2002',\n",
              "  'identifier': '2756201449',\n",
              "  'references': ['3017622320', '2413794979'],\n",
              "  'title': 'Method and system for generating follow-up path of vehicle'},\n",
              " {'abstract': 'Abstract : Inspired by the information theoretic idea of minimum description length, we add a term to the usual back-propagation cost function that penalizes network complexity. From a Bayesian perspective, the complexity term can be usefully interpreted as an assumption about prior distribution of the weights. This method, called weight-elimination, is contrasted to ridge regression and to cross-validation. We apply weight-elimination to time series prediction. On the sunspot series, the network outperforms traditional statistical approaches and shows the same predictive power as multivariate adaptive regression splines.',\n",
              "  'authors': ['Andreas S. Weigend ', ' David E. Rumelhart'],\n",
              "  'date': '1992',\n",
              "  'identifier': '308480622',\n",
              "  'references': ['2133671888',\n",
              "   '2112514080',\n",
              "   '2156913264',\n",
              "   '188592340',\n",
              "   '1492725832',\n",
              "   '2000369938',\n",
              "   '1990522705',\n",
              "   '2155826788',\n",
              "   '2534975150',\n",
              "   '27706556'],\n",
              "  'title': 'Generalization through Minimal Networks with Application to Forecasting'},\n",
              " {'abstract': \"Most of the online news media outlets rely heavily on the revenues generated from the clicks made by their readers, and due to the presence of numerous such outlets, they need to compete with each other for reader attention. To attract the readers to click on an article and subsequently visit the media site, the outlets often come up with catchy headlines accompanying the article links, which lure the readers to click on the link. Such headlines are known as Clickbaits. While these baits may trick the readers into clicking, in the long-run, clickbaits usually don't live up to the expectation of the readers, and leave them disappointed. In this work, we attempt to automatically detect clickbaits and then build a browser extension which warns the readers of different media sites about the possibility of being baited by such headlines. The extension also offers each reader an option to block clickbaits she doesn't want to see. Then, using such reader choices, the extension automatically blocks similar clickbaits during her future visits. We run extensive offline and online experiments across multiple media sites and find that the proposed clickbait detection and the personalized blocking approaches perform very well achieving 93% accuracy in detecting and 89% accuracy in blocking clickbaits.\",\n",
              "  'authors': ['Abhijnan Chakraborty ',\n",
              "   ' Bhargavi Paranjape ',\n",
              "   ' Sourya Kakarla ',\n",
              "   ' Niloy Ganguly'],\n",
              "  'date': '2016',\n",
              "  'identifier': '2542192908',\n",
              "  'references': ['2251939518',\n",
              "   '2123442489',\n",
              "   '2096765155',\n",
              "   '1508977358',\n",
              "   '2120699290',\n",
              "   '1773803948',\n",
              "   '2248267741',\n",
              "   '2046881809',\n",
              "   '2160269795',\n",
              "   '900993354'],\n",
              "  'title': 'Stop clickbait: detecting and preventing clickbaits in online news media'},\n",
              " {'abstract': 'The issue of reducing the space overhead when indexing large text databases is becoming more and more important, as the text collections grow in size. Another subject, which is gaining importance as text databases grow and get more heterogeneous and error prone, is that of flexible string matching. One of the best tools to make the search more flexible is to allow a limited number of differences between the words found and those sought. This is called “approximate text searching,” which is becoming more and more popular. In recent years some indexing schemes with very low space overhead have appeared, some of them dealing with approximate searching. These low overhead indices (whose most notorious exponent is Glimpse) are modified inverted files, where space is saved by making the lists of occurrences point to text blocks instead of exact word positions. Despite their existence, little is known about the expected behavior of these “block addressing” indices, and even less is known when it comes to cope with approximate search. Our main contribution is an analytical study of the space-time trade-offs for indexed text searching. We study the space overhead and retrieval times as functions of the block size. We find that, under reasonable assumptions, it is possible to build an index which is simultaneously sublinear in space overhead and in query time. This surprising analytical conclusion is validated with extensive experiments, obtaining typical performance figures. These results are valid for classical exact queries as well as for approximate searching. We apply our analysis to the Web, using recent statistics on the distribution of the document sizes. We show that pointing to documents instead of to fixed size blocks reduces space requirements but increases search times.',\n",
              "  'authors': ['Ricardo Baeza-Yates 1', ' Gonzalo Nevarro 2'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2017392697',\n",
              "  'references': ['1660390307',\n",
              "   '2133985894',\n",
              "   '1997841190',\n",
              "   '1529205966',\n",
              "   '2887107689',\n",
              "   '2889395214',\n",
              "   '3027900649',\n",
              "   '2010392031',\n",
              "   '2016219933',\n",
              "   '2165156013'],\n",
              "  'title': 'Block addressing indices for approximate text retrieval'},\n",
              " {'abstract': 'We present the concept of the feature space sequence: 2D distributions of voxel features of two images generated at registration and a sequence of misregistrations. We provide an explanation of the structure seen in these images. Feature space sequences have been generated for a pair of MR image volumes identical apart from the addition of Gaussian noise to one, MR image volumes with and without Gadolinium enhancement, MR and PET-FDG image volumes and MR and CT image volumes, all of the head. The structure seen in the feature space sequences was used to devise two new measures of similarity which in turn were used to produce plots of cost versus misregistration for the 6 degrees of freedom of rigid body motion. One of these, the third order moment of the feature space histogram, was used to register the MR image volumes with and without Gadolinium enhancement. These techniques have the potential for registration accuracy to within a small fraction of a voxel or resolution element and therefore interpolation errors in image transformation can be the dominant source of error in subtracted images. We present a method for removing these errors using sinc interpolation and show how interpolation errors can be reduced by over two orders of magnitude.',\n",
              "  'authors': ['Derek L.G. Hill ', ' Colin Studholme ', ' David John Hawkes'],\n",
              "  'date': '1994',\n",
              "  'identifier': '2049928737',\n",
              "  'references': ['1639032689',\n",
              "   '1990005524',\n",
              "   '2051809205',\n",
              "   '2044719420',\n",
              "   '2108117677',\n",
              "   '1966011527',\n",
              "   '2090698554',\n",
              "   '2152312926',\n",
              "   '2087815379',\n",
              "   '2682739702'],\n",
              "  'title': 'Voxel similarity measures for automated image registration'},\n",
              " {'abstract': 'Correlated information sequences \\\\cdots ,X_{-1},X_0,X_1, \\\\cdots and \\\\cdots,Y_{-1},Y_0,Y_1, \\\\cdots are generated by repeated independent drawings of a pair of discrete random variables X, Y from a given bivariate distribution P_{XY} (x,y) . We determine the minimum number of bits per character R_X and R_Y needed to encode these sequences so that they can be faithfully reproduced under a variety of assumptions regarding the encoders and decoders. The results, some of which are not at all obvious, are presented as an admissible rate region \\\\mathcal{R} in the R_X - R_Y plane. They generalize a similar and well-known result for a single information sequence, namely R_X \\\\geq H (X) for faithful reproduction.',\n",
              "  'authors': ['D. Slepian 1', ' J. Wolf 2'],\n",
              "  'date': '1973',\n",
              "  'identifier': '2099213070',\n",
              "  'references': ['2142901448', '2947000318'],\n",
              "  'title': 'Noiseless coding of correlated information sources'},\n",
              " {'abstract': 'The term fuzzy logic is used in this paper to describe an imprecise logical system, FL, in which the truth-values are fuzzy subsets of the unit interval with linguistic labels such as true, false, not true, very true, quite true, not very true and not very false, etc. The truth-value set, ℐ, of FL is assumed to be generated by a context-free grammar, with a semantic rule providing a means of computing the meaning of each linguistic truth-value in ℐ as a fuzzy subset of [0, 1].',\n",
              "  'authors': ['L. A. Zadeh'],\n",
              "  'date': '1996',\n",
              "  'identifier': '179611734',\n",
              "  'references': ['2912565176',\n",
              "   '2598771954',\n",
              "   '2082550766',\n",
              "   '2092180595',\n",
              "   '1768003599',\n",
              "   '2413835057',\n",
              "   '2017462139',\n",
              "   '1964071625',\n",
              "   '2052544013',\n",
              "   '1965185410'],\n",
              "  'title': 'Fuzzy logic and approximate reasoning'},\n",
              " {'abstract': 'Learning general functional dependencies between arbitrary input and output spaces is one of the key challenges in computational intelligence. While recent progress in machine learning has mainly focused on designing flexible and powerful input representations, this paper addresses the complementary issue of designing classification algorithms that can deal with more complex outputs, such as trees, sequences, or sets. More generally, we consider problems involving multiple dependent output variables, structured output spaces, and classification problems with class attributes. In order to accomplish this, we propose to appropriately generalize the well-known notion of a separation margin and derive a corresponding maximum-margin formulation. While this leads to a quadratic program with a potentially prohibitive, i.e. exponential, number of constraints, we present a cutting plane algorithm that solves the optimization problem in polynomial time for a large class of problems. The proposed method has important applications in areas such as computational biology, natural language processing, information retrieval/extraction, and optical character recognition. Experiments from various domains involving different types of output spaces emphasize the breadth and generality of our approach.',\n",
              "  'authors': ['Ioannis Tsochantaridis ',\n",
              "   ' Thorsten Joachims ',\n",
              "   ' Thomas Hofmann ',\n",
              "   ' Yasemin Altun'],\n",
              "  'date': '2005',\n",
              "  'identifier': '2105842272',\n",
              "  'references': ['2148603752',\n",
              "   '2147880316',\n",
              "   '1574901103',\n",
              "   '2047221353',\n",
              "   '2008652694',\n",
              "   '2053463056',\n",
              "   '2890040444',\n",
              "   '2157791002',\n",
              "   '2611147814',\n",
              "   '2429914308'],\n",
              "  'title': 'Large Margin Methods for Structured and Interdependent Output Variables'},\n",
              " {'abstract': '',\n",
              "  'authors': ['T. Kohonen'],\n",
              "  'date': '1989',\n",
              "  'identifier': '23758216',\n",
              "  'references': ['2076063813',\n",
              "   '1992419399',\n",
              "   '2121601095',\n",
              "   '2161160262',\n",
              "   '2144499799',\n",
              "   '2186428165',\n",
              "   '2171277043',\n",
              "   '2137570937',\n",
              "   '2095757522',\n",
              "   '2063532964'],\n",
              "  'title': 'Self-organization and associative memory: 3rd edition'},\n",
              " {'abstract': 'SETL is a set-theoretically oriented language of very high level whose repertoire of semantic objects includes finite sets, ordered n-tuples, and sets of ordered n-tuples useable as mappings. This paper sets forth techniques for the logical analysis and optimization of SETL programs. The techniques described allow relations of inclusion and membership to be established, the domains and ranges of (tabulated) mappings to be estimated from above and below, and the singlevaluedness of (tabulated) mappings to be proved. Once facts of this kind have been established, automatic choice of data structures becomes possible. The methods employed are based upon, and extend, known techniques of data-flow analysis.',\n",
              "  'authors': ['J. T. Schwartz'],\n",
              "  'date': '1975',\n",
              "  'identifier': '2109647823',\n",
              "  'references': ['1606724894', '1559460776', '1554731703', '3022861402'],\n",
              "  'title': 'Automatic data structure choice in a language of very high level'},\n",
              " {'abstract': 'The risk for hospitalization with respiratory syncytial virus infection during the first year of life was about five per 1,000 live births per year for infants born to low-income families in Houston from 1975 to 1979. The risk varied depending upon the intensity of the epidemic for a given season, the month of birth of the infant, and the level of passively acquired maternal antibody at the time of birth. Over 80% of the children hospitalized were less than 6 months of age; thus, most were born during the six months preceding the peak of RS virus activity. The neutralizing antibody titers in cord sera of 68 infants with culture-proven infections before 6 months of age were significantly lower than those of 575 randomly selected cord samples of infants born during the same period. The level of antibody at the time of birth was directly correlated with age at the time of infection. In addition, infants with more severe illnesses had lower levels of antibody in serum collected near onset of illness than did infants with milder illnesses. These observations demonstrate protection against RS infection in early infancy that is correlated with the level of maternal antibody, but it is not known if this protection is mediated directly by the passively acquired antibody or by some other mechanism.',\n",
              "  'authors': ['W. Paul Glezen ',\n",
              "   ' Abel Paredes ',\n",
              "   ' James E. Allison ',\n",
              "   ' Larry H. Taber ',\n",
              "   ' Arthur L. Frank'],\n",
              "  'date': '1981',\n",
              "  'identifier': '2025391611',\n",
              "  'references': ['1898933481',\n",
              "   '2336830409',\n",
              "   '2123817481',\n",
              "   '2086064348',\n",
              "   '1929856540',\n",
              "   '1996218943',\n",
              "   '1969516167',\n",
              "   '1987020978',\n",
              "   '1639681742',\n",
              "   '1987410181'],\n",
              "  'title': 'Risk of respiratory syncytial virus infection for infants from low-income families in relationship to age, sex, ethnic group, and maternal antibody level.'},\n",
              " {'abstract': 'We report steps toward the systematic management, standardization, and analysis of functional genomics data. We developed the ExpressDB database for yeast RNA expression data and loaded it with approximately 17.5 million pieces of data reported by 11 studies with three different kinds of high-throughput RNA assays. A web-based tool supports queries across the data from these studies. We examined comparability of data by converting data from 9 studies (217 conditions) into mRNA relative abundance estimates (ERAs) and by clustering of conditions by ERAs. We report on generation of ERAs and condition clustering for non-microarray data (5 studies, 63 conditions) and describe initial attempts to generate microarray-based ERAs (4 studies, 154 conditions), which exhibit increased error, on our web site http://arep.med.harvard. edu/ExpressDB. We recommend standards for data reporting, suggest research into improving comparability of microarray data through quantifying and standardizing control condition RNA populations, and also suggest research into the calibration of different RNA assays. We introduce a model for a database that integrates different kinds of functional genomics data, Biomolecule Interaction, Growth and Expression Database (BIGED).',\n",
              "  'authors': ['John Aach ', ' Wayne Rindone ', ' George M. Church'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2054774141',\n",
              "  'references': [],\n",
              "  'title': 'Systematic management and analysis of yeast gene expression data.'},\n",
              " {'abstract': 'We describe a learning-based method for low-level vision problems—estimating scenes from images. We generate a synthetic world of scenes and their corresponding rendered images, modeling their relationships with a Markov network. Bayesian belief propagation allows us to efficiently find a local maximum of the posterior probability for the scene, given an image. We call this approach VISTA—Vision by Image/Scene TrAining. We apply VISTA to the “super-resolution” problem (estimating high frequency details from a low-resolution image), showing good results. To illustrate the potential breadth of the technique, we also apply it in two other problem domains, both simplified. We learn to distinguish shading from reflectance variations in a single image under particular lighting conditions. For the motion estimation problem in a “blobs world”, we show figure/ground discrimination, solution of the aperture problem, and filling-in arising from application of the same probabilistic machinery.',\n",
              "  'authors': ['William T. Freeman 1',\n",
              "   ' Egon C. Pasztor 2',\n",
              "   ' Owen T. Carmichael 3'],\n",
              "  'date': '2000',\n",
              "  'identifier': '2149760002',\n",
              "  'references': ['1554663460',\n",
              "   '2159080219',\n",
              "   '1997063559',\n",
              "   '2145889472',\n",
              "   '1988520084',\n",
              "   '2911709767',\n",
              "   '1746680969',\n",
              "   '2103504761',\n",
              "   '1481420047',\n",
              "   '2137234026'],\n",
              "  'title': 'Learning Low-Level Vision'},\n",
              " {'abstract': 'PROCEDURES BASED ON CLASSICAL APPROACHES FOR FIXED--EFFECTS LINEAR MODELS WITH NORMAL HOMOSCEDASTIC INDEPENDENT ERRORS. Some Theory of Multiple Comparisons Procedure Fixed--effects Linear Models. Single--step Procedures for Pairwise and More General Comparisons Among All Treatments. Stepwise Procedures for Pairwise and More General Comparisons Among All Treatments. Procedures for Some Other Nonhierarchical Finite Families of Comparisons. Designing Experiments for Multiple Comparisons. PROCEDURES FOR OTHER MODELS AND PROBLEMS, AND PROCEDURES BASED ON ALTERNATIVE APPROACHES. Procedures for One--way Layouts with Unequal Variances. Procedures for Some Mixed--effects Models. Distribution--free and Robust Procedures. Some Miscellaneous Multiple Comparison Problems. Optimal Procedures Using Decision--theoretic, Bayesian, and Other Approaches. Appendixes. Tables. References. Index.',\n",
              "  'authors': ['Y. Hochberg ', ' A. C. Tamhane'],\n",
              "  'date': '2009',\n",
              "  'identifier': '1997917263',\n",
              "  'references': ['2110065044',\n",
              "   '2159267296',\n",
              "   '1596515083',\n",
              "   '2571593881',\n",
              "   '2115012618',\n",
              "   '2046658845',\n",
              "   '2148766438',\n",
              "   '2158202057',\n",
              "   '2954811775',\n",
              "   '2135230352'],\n",
              "  'title': 'Multiple Comparison Procedures'},\n",
              " {'abstract': 'A two-stage neural vision system for locating facial features is described. The first stage generates search regions in an image at low spatial resolution, and the second pinpoints the features at high resolution. Both stages employ multilayered perceptrons trained to detect specific visual details, followed by sophisticated global postprocessing of their outputs. This work demonstrates the power of combining neural feature detection with knowledge-based context-sensitive methods.',\n",
              "  'authors': ['J.M. Vincent ', ' J.B. Waite ', ' D.J. Myers'],\n",
              "  'date': '1992',\n",
              "  'identifier': '2121863133',\n",
              "  'references': ['2141278204',\n",
              "   '1573503290',\n",
              "   '2118496821',\n",
              "   '1976678415',\n",
              "   '2496076758',\n",
              "   '2174571159',\n",
              "   '2257788605',\n",
              "   '2031016367',\n",
              "   '2466298077'],\n",
              "  'title': 'Automatic location of visual features by a system of multilayered perceptrons'},\n",
              " {'abstract': \"This paper addresses the issues of charging, rate control and routing for a communication network carrying elastic traffic, such as an ATM network offering an available bit rate service. A model is described from which max-min fairness of rates emerges as a limiting special case; more generally, the charges users are prepared to pay influence their allocated rates. In the preferred version of the model, a user chooses the charge per unit time that the user will pay; thereafter the user's rate is determined by the network according to a proportional fairness criterion applied to the rate per unit charge. A system optimum is achieved when users' choices of charges and the network's choice of allocated rates are in equilibrium.\",\n",
              "  'authors': ['Frank Kelly'],\n",
              "  'date': '1997',\n",
              "  'identifier': '1987497363',\n",
              "  'references': [],\n",
              "  'title': 'Charging and rate control for elastic traffic'},\n",
              " {'abstract': 'A program is described for simultaneously aligning two or more molecular sequences which is based on first finding common segments above a specified length and then piecing these together to maximize an alignment scoring function. Optimal as well as near-optimal alignments are found, and there is also provided a means for randomizing the given sequences for testing the statistical significance of an alignment. Alignments may be made in the original alphabets of the sequences or in user-specified alternate ones to take advantage of chemical similarities (such as hydrophobic-hydrophilic).',\n",
              "  'authors': ['Eric Sobel ', ' Hugo M. Martinez'],\n",
              "  'date': '1986',\n",
              "  'identifier': '1994414218',\n",
              "  'references': ['1998300401',\n",
              "   '2094031081',\n",
              "   '1525759724',\n",
              "   '2106258670',\n",
              "   '2105516199',\n",
              "   '2068083406',\n",
              "   '2028903194',\n",
              "   '1527979595',\n",
              "   '2118938838',\n",
              "   '2033775040'],\n",
              "  'title': 'A multiple sequence alignment program'},\n",
              " {'abstract': 'Is perception of the whole based on perception of its parts? There is psychological1 and physiological2,3 evidence for parts-based representations in the brain, and certain computational theories of object recognition rely on such representations4,5. But little is known about how brains or computers might learn the parts of objects. Here we demonstrate an algorithm for non-negative matrix factorization that is able to learn parts of faces and semantic features of text. This is in contrast to other methods, such as principal components analysis and vector quantization, that learn holistic, not parts-based, representations. Non-negative matrix factorization is distinguished from the other methods by its use of non-negativity constraints. These constraints lead to a parts-based representation because they allow only additive, not subtractive, combinations. When non-negative matrix factorization is implemented as a neural network, parts-based representations emerge by virtue of two properties: the firing rates of neurons are never negative and synaptic strengths do not change sign.',\n",
              "  'authors': ['Daniel D. Lee 1', ' H. Sebastian Seung 1', ' 2'],\n",
              "  'date': '1999',\n",
              "  'identifier': '1902027874',\n",
              "  'references': ['2138451337',\n",
              "   '2108384452',\n",
              "   '2049633694',\n",
              "   '1956559956',\n",
              "   '2145889472',\n",
              "   '1983578042',\n",
              "   '1996355918',\n",
              "   '1993845689',\n",
              "   '2156406284',\n",
              "   '2180838288'],\n",
              "  'title': 'Learning the parts of objects by non-negative matrix factorization'},\n",
              " {'abstract': 'Identifying sentiments (the affective parts of opinions) is a challenging problem. We present a system that, given a topic, automatically finds the people who hold opinions about that topic and the sentiment of each opinion. The system contains a module for determining word sentiment and another for combining sentiments within a sentence. We experiment with various models of classifying and combining sentiment at word and sentence levels, with promising results.',\n",
              "  'authors': ['Soo-Min Kim ', ' Eduard Hovy'],\n",
              "  'date': '2004',\n",
              "  'identifier': '2112422413',\n",
              "  'references': ['2166706824',\n",
              "   '2155328222',\n",
              "   '2199803028',\n",
              "   '2102381086',\n",
              "   '2080558111',\n",
              "   '2098136027',\n",
              "   '2002664886',\n",
              "   '1558751900',\n",
              "   '1997210479',\n",
              "   '2085519921'],\n",
              "  'title': 'Determining the sentiment of opinions'},\n",
              " {'abstract': 'Continuous Distributions (General). Normal Distributions. Lognormal Distributions. Inverse Gaussian (Wald) Distributions. Cauchy Distribution. Gamma Distributions. Chi-Square Distributions Including Chi and Rayleigh. Exponential Distributions. Pareto Distributions. Weibull Distributions. Abbreviations. Indexes.',\n",
              "  'authors': ['Norman Lloyd Johnson ', ' Samuel Kotz ', ' N. Balakrishnan'],\n",
              "  'date': '1994',\n",
              "  'identifier': '1991567646',\n",
              "  'references': [],\n",
              "  'title': 'Continuous univariate distributions'},\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbxllYOOip7y"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "این قسمت برای لود کردن اطلاعات ذخیره شده است.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYg3fQLbSOvW",
        "outputId": "72b4b117-3e12-4e02-c369-e5f204593323"
      },
      "source": [
        "set_of_all_paper = set()\n",
        "for paper in papers:\n",
        "  set_of_all_paper.add(paper[\"identifier\"])\n",
        "list_of_all_paper = list(set_of_all_paper)\n",
        "size_of_matrix = len(set_of_all_paper)\n",
        "size_of_matrix\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe0_GBRscTnY"
      },
      "source": [
        "import numpy as np\n",
        "s = (size_of_matrix,size_of_matrix)\n",
        "adjacency_matrix = np.zeros(s)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3nNs4J-dlmU",
        "outputId": "d649dfcb-a4c9-4f99-fb73-2bb51f913e2b"
      },
      "source": [
        "for paper in papers:\n",
        "  index_of_adj_matrix_i = list_of_all_paper.index(paper[\"identifier\"])\n",
        "  if len(paper[\"references\"]) != 0:\n",
        "    arr_of_ref_paper = []\n",
        "    for ref_paper in paper[\"references\"]:\n",
        "      if ref_paper in list_of_all_paper:\n",
        "        arr_of_ref_paper.append(ref_paper)\n",
        "    if len(arr_of_ref_paper) != 0:\n",
        "      p = 1/len(arr_of_ref_paper)\n",
        "      for ref_paper in arr_of_ref_paper:\n",
        "        index_of_adj_matrix_j = list_of_all_paper.index(ref_paper)\n",
        "        adjacency_matrix[index_of_adj_matrix_i][index_of_adj_matrix_j] = p\n",
        "    else:\n",
        "      p = 1/len(list_of_all_paper)\n",
        "      for j in range(len(list_of_all_paper)):\n",
        "        adjacency_matrix[index_of_adj_matrix_i][j] = p\n",
        "adjacency_matrix.sum(axis=1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., ..., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeGHLRuUi3DE"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "در قسمت های بالا ابتدا لیست رفرنس های مقالات را به رفرنس های ولید کوتاه می کنیم و سپس ماتریس همسایگی را برای هر مقاله می سازیم.\n",
        "\n",
        "رفرنس های ولید رفرنس هایی هستند که در مقالات بررسی شده آمده باشند.\n",
        "اگر یک مقاله ای هیچ رفرنس ولیدی نداشته باشد احتمال خیلی کمی برای رفتن از آن مقاله به همه مقالات ولید در نظر میگیریم.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HgV9QVKfT2N"
      },
      "source": [
        "def pagerank(M, num_iterations: int = 100, d: float = 0.9):\n",
        "\n",
        "    N = M.shape[1]\n",
        "    v = np.random.rand(N, 1)\n",
        "    v = v / np.linalg.norm(v, 1)\n",
        "    M_hat = (d * M + (1 - d) / N)\n",
        "    for i in range(num_iterations):\n",
        "        v = M_hat @ v\n",
        "        v = v / np.linalg.norm(v, 1)\n",
        "    return v"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0KpKkGEjdT3"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "الگوریتم پیج رنک\n",
        "\n",
        "reference: https://en.wikipedia.org/wiki/PageRank\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFqEmdJuflpb",
        "outputId": "aff0591a-a24d-43f5-8c87-28a9bb098489"
      },
      "source": [
        "pr = pagerank(adjacency_matrix.T, 100, 0.9)\n",
        "pr"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.20871213e-04],\n",
              "       [6.29673494e-04],\n",
              "       [6.10159046e-05],\n",
              "       ...,\n",
              "       [5.03424197e-05],\n",
              "       [3.69687812e-04],\n",
              "       [1.22223533e-04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W23tMaMjn1Q"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "الگوریتم را با ضریب dump_factor=0.9 و تعداد iteration 100 اجرا می کنیم.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhbFyzKBttTf",
        "outputId": "a0f5861d-2a13-487b-edf1-8acef424bd8b"
      },
      "source": [
        "top_ten_score = np.sort(pr,axis=None)[::-1]\n",
        "for i in range(10):\n",
        "  print(top_ten_score[i])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0077854651865100055\n",
            "0.007213955672903991\n",
            "0.006083251382714299\n",
            "0.004265184368760648\n",
            "0.0031347575926778844\n",
            "0.002929801165190786\n",
            "0.0029232079471596993\n",
            "0.002808904932552366\n",
            "0.0027166247610322155\n",
            "0.0026443049269620936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj3_jnJVj_f7"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "۱۰ امتیاز برتر در الگوریتم پیج رنک\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqhl5XqSh7t-",
        "outputId": "b0171ebf-fe50-45c5-d0c7-d05308b0ddbd"
      },
      "source": [
        "top = np.argsort(pr,axis=None)[::-1]\n",
        "top"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 466, 4197, 2828, ..., 3421, 3205,  902])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufPqR1A-pm7L",
        "outputId": "0735b8e9-04ab-40ca-f52f-901f2a9ad730"
      },
      "source": [
        "count_ref = np.zeros(5000)\n",
        "for paper in papers:\n",
        "  for ref_paper in paper[\"references\"]:\n",
        "    if ref_paper in list_of_all_paper:\n",
        "      count_ref[list_of_all_paper.index(ref_paper)] += 1\n",
        "for i in range(20):\n",
        "  top_id = list_of_all_paper[top[i]]\n",
        "  for paper in papers:\n",
        "    if paper[\"identifier\"] == top_id:\n",
        "      print(\"title: \" + str(paper[\"title\"]))\n",
        "      print(\"number of references to it: \" + str(int(count_ref[top[i]])))\n",
        "      print(\"page rank score: \" + str(top_ten_score[i]))\n",
        "  print()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: An improved method of testing for evolutionary homology.\n",
            "number of references to it: 5\n",
            "page rank score: 0.0077854651865100055\n",
            "\n",
            "title: RNA CODEWORDS AND PROTEIN SYNTHESIS, VI. ON THE NUCLEOTIDE SEQUENCES OF DEGENERATE CODEWORD SETS FOR ISOLEUCINE, TYROSINE, ASPARAGINE, AND LYSINE.\n",
            "number of references to it: 1\n",
            "page rank score: 0.007213955672903991\n",
            "\n",
            "title: Spherical model of a spin glass\n",
            "number of references to it: 2\n",
            "page rank score: 0.006083251382714299\n",
            "\n",
            "title: The Nature of Statistical Learning Theory\n",
            "number of references to it: 62\n",
            "page rank score: 0.004265184368760648\n",
            "\n",
            "title: Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis\n",
            "number of references to it: 4\n",
            "page rank score: 0.0031347575926778844\n",
            "\n",
            "title: Maximum likelihood from incomplete data via the EM algorithm\n",
            "number of references to it: 80\n",
            "page rank score: 0.002929801165190786\n",
            "\n",
            "title: Elements of the Theory of Functions and Functional Analysis\n",
            "number of references to it: 1\n",
            "page rank score: 0.0029232079471596993\n",
            "\n",
            "title: Isolation of a cDNA clone derived from a blood-borne non-A, non-B viral hepatitis genome\n",
            "number of references to it: 15\n",
            "page rank score: 0.002808904932552366\n",
            "\n",
            "title: A cluster of cases of severe acute respiratory syndrome in Hong Kong.\n",
            "number of references to it: 16\n",
            "page rank score: 0.0027166247610322155\n",
            "\n",
            "title: Gradient-based learning applied to document recognition\n",
            "number of references to it: 66\n",
            "page rank score: 0.0026443049269620936\n",
            "\n",
            "title: Communicable Disease Control Handbook\n",
            "number of references to it: 1\n",
            "page rank score: 0.0025376528870317667\n",
            "\n",
            "title: Force determination employing sheet sensor\n",
            "number of references to it: 4\n",
            "page rank score: 0.0024622361859023326\n",
            "\n",
            "title: Data Mining: Concepts and Techniques\n",
            "number of references to it: 23\n",
            "page rank score: 0.002456252116162946\n",
            "\n",
            "title: A mathematical theory of communication\n",
            "number of references to it: 29\n",
            "page rank score: 0.0024426750580096154\n",
            "\n",
            "title: Dynamics of Contention\n",
            "number of references to it: 2\n",
            "page rank score: 0.0024218818109999498\n",
            "\n",
            "title: Interpreting chromosomal DNA restriction patterns produced by pulsed-field gel electrophoresis: criteria for bacterial strain typing.\n",
            "number of references to it: 4\n",
            "page rank score: 0.0022832339419631646\n",
            "\n",
            "title: The New Transnational Activism\n",
            "number of references to it: 1\n",
            "page rank score: 0.0022656609222669486\n",
            "\n",
            "title: APACHE II: a severity of disease classification system.\n",
            "number of references to it: 8\n",
            "page rank score: 0.002256787000863621\n",
            "\n",
            "title: Transfusion-associated hepatitis not due to viral hepatitis type A or B\n",
            "number of references to it: 5\n",
            "page rank score: 0.00217483384077775\n",
            "\n",
            "title: Learning internal representations by error propagation\n",
            "number of references to it: 61\n",
            "page rank score: 0.002169591250160606\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osvCjMO6kHZi"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "در این قسمت هم ۲۰ مقاله برتر به همراه عنوان و تعداد رفرنس به آنها و امتیاز page_rank آورده شده اند.\n",
        "</div>"
      ]
    }
  ]
}